{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supriyag123/PHD_Pub/blob/main/PAPER_GDRNet_METROPM_Step4-VAR-LATEST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "HoP7OuWNxlsJ",
        "outputId": "38ceea3c-ad53-4198-9f03-c72814074973",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error\n",
            "RMSE: 1.3503097119121505 1.5002465652043568 2.837338449071969 1.5963914298880122 1.020955371098352\n",
            "MAPE: 0.6891745407226914 0.7660456714610211 1.7857976818782204 0.750466542640601 0.377035791594537\n",
            "MAE: 0.1685213302116819 0.18072839798571852 0.20651606722068036 0.1586292978244769 0.13245363757094158\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import math\n",
        "import plotly.graph_objects as go\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, RepeatVector, TimeDistributed, Input\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import keras.backend as K\n",
        "from keras.callbacks import Callback\n",
        "import plotly\n",
        "import plotly.express as px # for data visualization\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import IsolationForest\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "from numpy import array\n",
        "from numpy import hstack\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LassoCV, MultiTaskLassoCV\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from math import sqrt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from keras.models import Model\n",
        "from statsmodels.tsa.api import VAR\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.tools.eval_measures import rmse, aic\n",
        "from statsmodels.tsa.stattools import acf\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from numpy import arange\n",
        "#-----------------------------------------------------GET DATA - X, Predicted Wndow from MLP, and Derived Labels, for the entire dataset that was gennerated through VAE-----------------------------------\n",
        "\n",
        "\n",
        "#-----------for test dataset-----------------------------------------------------------------------\n",
        "y_pred = np.loadtxt(r'/content/drive/MyDrive/PHD/2024/MLPOutput/METROPM_predicted_window.csv')\n",
        "y_true = np.loadtxt(r'/content/drive/MyDrive/PHD/2024/MLPOutput/METROPM_derived_window_label.csv')\n",
        "x_orig = np.loadtxt(r'/content/drive/MyDrive/PHD/2024/MLPOutput/METROPM_test_data.csv')\n",
        "\n",
        "\n",
        "\n",
        "n_features = 12\n",
        "n_future = 1\n",
        "window_size = int(x_orig.shape[1]/n_features)\n",
        "x = x_orig.reshape((x_orig.shape[0],window_size,n_features))\n",
        "\n",
        "sample_size = 5000\n",
        "#-----------------------------------------------CASES - pot window values and pick a few fixed window sizes -------------------------------------------\n",
        "\n",
        "plt.figure(figsize=(15,6))\n",
        "plt.subplot(1,2,1)\n",
        "plt.title(\"Distribution before Transformation\", fontsize=15)\n",
        "sns.histplot(y_true, kde=True, color=\"red\")\n",
        "plt.subplot(1,2,2)\n",
        "\n",
        "# Import libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "fig = plt.figure(figsize =(10, 7))\n",
        "# Creating plot\n",
        "plt.boxplot(y_true)\n",
        "# show plot\n",
        "plt.show()\n",
        "\n",
        "fx_window1 = 10\n",
        "fx_window2 = 15\n",
        "fx_window3 = 20\n",
        "fx_window4 = 25\n",
        "pred_step = n_future=1\n",
        "\n",
        "se_1 = list()\n",
        "se_2 = list()\n",
        "se_3 = list()\n",
        "se_4 = list()\n",
        "se_x = list()\n",
        "\n",
        "ape_1 = list()\n",
        "ape_2 = list()\n",
        "ape_3 = list()\n",
        "ape_4 = list()\n",
        "ape_x = list()\n",
        "\n",
        "ae_1 = list()\n",
        "ae_2 = list()\n",
        "ae_3 = list()\n",
        "ae_4 = list()\n",
        "ae_x = list()\n",
        "\n",
        "\n",
        "for i in range(sample_size) :\n",
        "  k=fx_window1\n",
        "  x1 = x[i]\n",
        "  df = pd.DataFrame(x1, columns=['V1','V2','V3','V4','V5','V6','V7','V8','V9','V10','V11','V12'])\n",
        "  df_train, df_test = df[0:-pred_step], df[-pred_step:]\n",
        "  model= VAR(df_train)\n",
        "  try:\n",
        "    model_fitted1 = model.fit(k)\n",
        "    forecast_input1 = df_train.values[-k:]\n",
        "    fc1 = model_fitted1.forecast(y=forecast_input1, steps=n_future)\n",
        "    df_forecast1 = pd.DataFrame(fc1, index=df.index[-n_future:], columns=df.columns)\n",
        "    se =  ((df_test['V1'].values - df_forecast1['V1'].values)**2/abs(df_test['V1'])).values[0]\n",
        "    se_1.append(se)\n",
        "\n",
        "    ape = np.abs((df_test['V1'].values - df_forecast1['V1'].values) / df_test['V1']).values[0]\n",
        "\n",
        "    ape_1.append(ape)\n",
        "\n",
        "    ae = np.abs(df_test['V1'].values - df_forecast1['V1'].values)[0]\n",
        "    ae_1.append(ae)\n",
        "  except:\n",
        "    se_1.append(99999)\n",
        "    ape_1.append(99999)\n",
        "    ae_1.append(99999)\n",
        "    print('VAR could not solve row number')\n",
        "    print(i, k)\n",
        "\n",
        "  k=fx_window2\n",
        "  try:\n",
        "    model_fitted2 = model.fit(k)\n",
        "    forecast_input2 = df_train.values[-k:]\n",
        "    fc2 = model_fitted2.forecast(y=forecast_input2, steps=n_future)\n",
        "    df_forecast2 = pd.DataFrame(fc2, index=df.index[-n_future:], columns=df.columns)\n",
        "\n",
        "    se =  ((df_test['V1'].values - df_forecast2['V1'].values)**2/abs(df_test['V1'])).values[0]\n",
        "    se_2.append(se)\n",
        "    ape = np.abs((df_test['V1'].values - df_forecast2['V1'].values) / df_test['V1']).values[0]\n",
        "\n",
        "    ape_2.append(ape)\n",
        "    ae = np.abs(df_test['V1'].values - df_forecast2['V1'].values)[0]\n",
        "    ae_2.append(ae)\n",
        "\n",
        "  except:\n",
        "    se_2.append(99999)\n",
        "    ape_2.append(99999)\n",
        "    ae_2.append(99999)\n",
        "    print('VAR could not solve row number')\n",
        "    print(i, k)\n",
        "\n",
        "  k=fx_window3\n",
        "  try:\n",
        "    model_fitted3 = model.fit(k)\n",
        "    forecast_input3 = df_train.values[-k:]\n",
        "    fc3 = model_fitted3.forecast(y=forecast_input3, steps=n_future)\n",
        "    df_forecast3 = pd.DataFrame(fc3, index=df.index[-n_future:], columns=df.columns)\n",
        "    se =  ((df_test['V1'].values - df_forecast3['V1'].values)**2/abs(df_test['V1'])).values[0]\n",
        "    se_3.append(se)\n",
        "    ape = np.abs((df_test['V1'].values - df_forecast3['V1'].values) / df_test['V1']).values[0]\n",
        "\n",
        "    ape_3.append(ape)\n",
        "    ae = np.abs(df_test['V1'].values - df_forecast3['V1'].values)[0]\n",
        "    ae_3.append(ae)\n",
        "\n",
        "\n",
        "  except:\n",
        "    se_3.append(99999)\n",
        "    ape_3.append(99999)\n",
        "    ae_3.append(99999)\n",
        "    print('VAR could not solve row number')\n",
        "    print(i, k)\n",
        "\n",
        "  k=fx_window4\n",
        "  try:\n",
        "    model_fitted4 = model.fit(k)\n",
        "    forecast_input4 = df_train.values[-k:]\n",
        "    fc4 = model_fitted4.forecast(y=forecast_input4, steps=n_future)\n",
        "    df_forecast4 = pd.DataFrame(fc4, index=df.index[-n_future:], columns=df.columns)\n",
        "\n",
        "    se =  ((df_test['V1'].values - df_forecast4['V1'].values)**2/abs(df_test['V1'])).values[0]\n",
        "    se_4.append(se)\n",
        "    ape = np.abs((df_test['V1'].values - df_forecast4['V1'].values) / df_test['V1']).values[0]\n",
        "\n",
        "    ape_4.append(ape)\n",
        "    ae = np.abs(df_test['V1'].values - df_forecast4['V1'].values)[0]\n",
        "    ae_4.append(ae)\n",
        "\n",
        "\n",
        "  except:\n",
        "    se_4.append(99999)\n",
        "    ape_4.append(99999)\n",
        "    ae_4.append(99999)\n",
        "\n",
        "    print('VAR could not solve row number')\n",
        "    print(i, k)\n",
        "\n",
        "\n",
        "  k=int(y_pred[i])\n",
        "  try:\n",
        "    model_fittedx = model.fit(k)\n",
        "    forecast_inputx = df_train.values[-k:]\n",
        "    fcx = model_fittedx.forecast(y=forecast_inputx, steps=n_future)\n",
        "    df_forecastx = pd.DataFrame(fcx, index=df.index[-n_future:], columns=df.columns)\n",
        "    se =  (((df_test['V1'].values - df_forecastx['V1'].values)**2)/abs(df_test['V1'])).values[0]\n",
        "    se_x.append(se)\n",
        "\n",
        "    ape = np.abs((df_test['V1'].values - df_forecastx['V1'].values) / df_test['V1']).values[0]\n",
        "\n",
        "    ape_x.append(ape)\n",
        "    ae = np.abs(df_test['V1'].values - df_forecastx['V1'].values)[0]\n",
        "    ae_x.append(ae)\n",
        "\n",
        "\n",
        "  except:\n",
        "    se_x.append(99999)\n",
        "    ape_x.append(99999)\n",
        "    ae_x.append(99999)\n",
        "\n",
        "    print('VAR could not solve row number')\n",
        "    print(i, k)\n",
        "\n",
        "\n",
        "se_1 = [i for i in se_1 if i != 99999]\n",
        "se_2 = [i for i in se_2 if i != 99999]\n",
        "se_3 = [i for i in se_3 if i != 99999]\n",
        "se_4 = [i for i in se_4 if i != 99999]\n",
        "se_x = [i for i in se_x if i != 99999]\n",
        "\n",
        "ape_1 = [i for i in ape_1 if i != 99999]\n",
        "ape_2 = [i for i in ape_2 if i != 99999]\n",
        "ape_3 = [i for i in ape_3 if i != 99999]\n",
        "ape_4 = [i for i in ape_4 if i != 99999]\n",
        "ape_x = [i for i in ape_x if i != 99999]\n",
        "\n",
        "ae_1 = [i for i in ae_1 if i != 99999]\n",
        "ae_2 = [i for i in ae_2 if i != 99999]\n",
        "ae_3 = [i for i in ae_3 if i != 99999]\n",
        "ae_4 = [i for i in ae_4 if i != 99999]\n",
        "ae_x = [i for i in ae_x if i != 99999]\n",
        "\n",
        "rmse_1 = sqrt(np.mean(se_1))\n",
        "rmse_2 = sqrt(np.mean(se_2))\n",
        "rmse_3 = sqrt(np.mean(se_3))\n",
        "rmse_4 = sqrt(np.mean(se_4))\n",
        "rmse_x = sqrt(np.mean(se_x))\n",
        "\n",
        "\n",
        "mape_1 = mean(ape_1)\n",
        "mape_2 = mean(ape_2)\n",
        "mape_3 = mean(ape_3)\n",
        "mape_4 = mean(ape_4)\n",
        "mape_x = mean(ape_x)\n",
        "mae_1 = mean(ae_1)\n",
        "mae_2 = mean(ae_2)\n",
        "mae_3 = mean(ae_3)\n",
        "mae_4 = mean(ae_4)\n",
        "mae_x = mean(ae_x)\n",
        "\n",
        "\n",
        "print(\"RMSE:\", rmse_1, rmse_2, rmse_3, rmse_4, rmse_x)\n",
        "print(\"MAPE:\", mape_1, mape_2, mape_3, mape_4, mape_x)\n",
        "print(\"MAE:\", mae_1, mae_2, mae_3, mae_4, mae_x)\n",
        "\n",
        "\n",
        "\n",
        "# Import libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "fig = plt.figure(figsize =(10, 10))\n",
        "ax = fig.add_axes([0, 0, 1, 1])\n",
        "\n",
        "# Creating plot\n",
        "data = [mape_v1, mape_v2, mape_v3, mape_v4, mape_vx]\n",
        "bp = ax.boxplot(data)\n",
        "plt.ylim(-0.000025, 0.00015)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "##################RMSE NO VAR---------------------------------------------\n",
        "\n",
        "\n",
        "################---------------------------METHOD 2- -GO BY RMSE----------------------------------------------------####################\n",
        "\n",
        "def generate_small_seq(series, n_past, n_future):\n",
        "  #\n",
        "  # n_past ==> no of past observations -- OR -- sliding window\n",
        "  #\n",
        "  # n_future ==> no of future observations -- prediction variable y\n",
        "  #\n",
        "  X, y = list(), list()\n",
        "  for window_start in range(len(series)):\n",
        "    past_end = window_start + n_past\n",
        "    future_end = past_end + n_future\n",
        "    if future_end > len(series):\n",
        "      break\n",
        "    # slicing the past and future parts of the window\n",
        "    past, future = series[window_start:past_end, :], series[past_end:future_end, 1] #We just take the active power as the prediction variable\n",
        "    X.append(past)\n",
        "    y.append(future)\n",
        "  return np.array(X), np.array(y)\n",
        "\n",
        "se_1 = list()\n",
        "se_2 = list()\n",
        "se_3 = list()\n",
        "se_4 = list()\n",
        "se_x = list()\n",
        "\n",
        "ape_1 = list()\n",
        "ape_2 = list()\n",
        "ape_3 = list()\n",
        "ape_4 = list()\n",
        "ape_x = list()\n",
        "\n",
        "ae_1 = list()\n",
        "ae_2 = list()\n",
        "ae_3 = list()\n",
        "ae_4 = list()\n",
        "ae_x = list()\n",
        "\n",
        "\n",
        "min_window_list = list()\n",
        "best_window_for_long_seq = list()\n",
        "AIC = list()\n",
        "n_fold = 6 # 5 fold plus 1 for test)\n",
        "# evaluate a logistic regression model using k-fold cross-validation\n",
        "n_future=1\n",
        "predictions = list()\n",
        "\n",
        "\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "\n",
        "best_window_for_long_seq.clear()\n",
        "\n",
        "#window_list = [fx_window1, fx_window2, fx_window3, fx_window4]\n",
        "########------------Window 1-------------------------\n",
        "\n",
        "\n",
        "############## Window 1-----------------------------------\n",
        "se_1.clear()\n",
        "ape_1.clear()\n",
        "ae_1.clear()\n",
        "for i in range(sample_size) :\n",
        "#iterate over the entire  long sequences of multivariate time series\n",
        "  Total_small_seq_X, Total_small_seq_y = generate_small_seq(x[i,:,:], fx_window1 , n_future)\n",
        "  Total_small_seq_X_reshaped = Total_small_seq_X.reshape(Total_small_seq_X.shape[0],Total_small_seq_X.shape[1]*Total_small_seq_X.shape[2])\n",
        "  Total_small_seq_y_reshaped = Total_small_seq_y\n",
        "  maxval2 = Total_small_seq_X_reshaped.shape[0]\n",
        "  count_train2 = int(math.ceil(0.7*maxval2))\n",
        "  Small_train_X = Total_small_seq_X_reshaped[0:count_train2]\n",
        "  Small_train_y = Total_small_seq_y_reshaped[0:count_train2]\n",
        "  Small_test_X =  Total_small_seq_X_reshaped[count_train2:]\n",
        "  Small_test_y = Total_small_seq_y_reshaped[count_train2:]\n",
        "  tscv = TimeSeriesSplit(n_splits=n_fold-1)\n",
        "  #regressor = LassoCV(alphas=arange(0, 1, 0.01), cv=tscv, n_jobs=-1)\n",
        "  regressor = LinearRegression()\n",
        "  try:\n",
        "    regressor.fit(Small_train_X, Small_train_y.ravel()) #get jth time series only\n",
        "    if Small_test_X.shape[0] == 0:\n",
        "      break\n",
        "    y_predk = regressor.predict(Small_test_X)\n",
        "    #print('alpha: %f' % regressor.alpha_)\n",
        "    se =  ((Small_test_y-y_predk)**2).mean()/abs(Small_test_y.mean())\n",
        "    ape = abs(Small_test_y-y_predk).mean()/abs(Small_test_y.mean())\n",
        "    ae = abs(Small_test_y-y_predk).mean()\n",
        "    #mse = mean_squared_error(Small_test_y, y_predk)\n",
        "    #print(rmse)\n",
        "    se_1.append(se)\n",
        "    ape_1.append(ape)\n",
        "    ae_1.append(ae)\n",
        "  except:\n",
        "    se_1.append(9999)\n",
        "    ape_1.append(9999)\n",
        "    ae_1.append(9999)\n",
        "    print('error')\n",
        "\n",
        "\n",
        "\n",
        "############## Window 2-----------------------------------\n",
        "se_2.clear()\n",
        "ape_2.clear()\n",
        "ae_2.clear()\n",
        "for i in range(sample_size) :\n",
        "#iterate over the entire  long sequences of multivariate time series\n",
        "  Total_small_seq_X, Total_small_seq_y = generate_small_seq(x[i,:,:], fx_window2 , n_future)\n",
        "  Total_small_seq_X_reshaped = Total_small_seq_X.reshape(Total_small_seq_X.shape[0],Total_small_seq_X.shape[1]*Total_small_seq_X.shape[2])\n",
        "  Total_small_seq_y_reshaped = Total_small_seq_y\n",
        "  maxval2 = Total_small_seq_X_reshaped.shape[0]\n",
        "  count_train2 = int(math.ceil(0.7*maxval2))\n",
        "  Small_train_X = Total_small_seq_X_reshaped[0:count_train2]\n",
        "  Small_train_y = Total_small_seq_y_reshaped[0:count_train2]\n",
        "  Small_test_X =  Total_small_seq_X_reshaped[count_train2:]\n",
        "  Small_test_y = Total_small_seq_y_reshaped[count_train2:]\n",
        "  tscv = TimeSeriesSplit(n_splits=n_fold-1)\n",
        "  #regressor = LassoCV(alphas=arange(0, 1, 0.01), cv=tscv, n_jobs=-1)\n",
        "  regressor = LinearRegression()\n",
        "  try:\n",
        "    regressor.fit(Small_train_X, Small_train_y.ravel()) #get jth time series only\n",
        "    if Small_test_X.shape[0] == 0:\n",
        "      break\n",
        "    y_predk = regressor.predict(Small_test_X)\n",
        "    #print('alpha: %f' % regressor.alpha_)\n",
        "    se =  ((Small_test_y-y_predk)**2).mean()/abs(Small_test_y.mean())\n",
        "    ape = abs(Small_test_y-y_predk).mean()/abs(Small_test_y.mean())\n",
        "    ae = abs(Small_test_y-y_predk).mean()\n",
        "    #mse = mean_squared_error(Small_test_y, y_predk)\n",
        "    #print(rmse)\n",
        "    se_2.append(se)\n",
        "    ape_2.append(ape)\n",
        "    ae_2.append(ae)\n",
        "  except:\n",
        "    se_2.append(9999)\n",
        "    ape_2.append(9999)\n",
        "    ae_2.append(9999)\n",
        "    print('error')\n",
        "\n",
        "\n",
        "############## Window 3-----------------------------------\n",
        "se_3.clear()\n",
        "ape_3.clear()\n",
        "ae_3.clear()\n",
        "for i in range(sample_size) :\n",
        "#iterate over the entire  long sequences of multivariate time series\n",
        "  Total_small_seq_X, Total_small_seq_y = generate_small_seq(x[i,:,:], fx_window3 , n_future)\n",
        "  Total_small_seq_X_reshaped = Total_small_seq_X.reshape(Total_small_seq_X.shape[0],Total_small_seq_X.shape[1]*Total_small_seq_X.shape[2])\n",
        "  Total_small_seq_y_reshaped = Total_small_seq_y\n",
        "  maxval2 = Total_small_seq_X_reshaped.shape[0]\n",
        "  count_train2 = int(math.ceil(0.7*maxval2))\n",
        "  Small_train_X = Total_small_seq_X_reshaped[0:count_train2]\n",
        "  Small_train_y = Total_small_seq_y_reshaped[0:count_train2]\n",
        "  Small_test_X =  Total_small_seq_X_reshaped[count_train2:]\n",
        "  Small_test_y = Total_small_seq_y_reshaped[count_train2:]\n",
        "  tscv = TimeSeriesSplit(n_splits=n_fold-1)\n",
        "  #regressor = LassoCV(alphas=arange(0, 1, 0.01), cv=tscv, n_jobs=-1)\n",
        "  regressor = LinearRegression()\n",
        "  try:\n",
        "    regressor.fit(Small_train_X, Small_train_y.ravel()) #get jth time series only\n",
        "    if Small_test_X.shape[0] == 0:\n",
        "      break\n",
        "    y_predk = regressor.predict(Small_test_X)\n",
        "    #print('alpha: %f' % regressor.alpha_)\n",
        "    se =  ((Small_test_y-y_predk)**2).mean()/abs(Small_test_y.mean())\n",
        "    ape = abs(Small_test_y-y_predk).mean()/abs(Small_test_y.mean())\n",
        "    ae = abs(Small_test_y-y_predk).mean()\n",
        "    #mse = mean_squared_error(Small_test_y, y_predk)\n",
        "    #print(rmse)\n",
        "    se_3.append(se)\n",
        "    ape_3.append(ape)\n",
        "    ae_3.append(ae)\n",
        "  except:\n",
        "    se_3.append(9999)\n",
        "    ape_3.append(9999)\n",
        "    ae_3.append(9999)\n",
        "    print('error')\n",
        "\n",
        "\n",
        "############## Window 4-----------------------------------\n",
        "se_4.clear()\n",
        "ape_4.clear()\n",
        "ae_4.clear()\n",
        "for i in range(sample_size) :\n",
        "#iterate over the entire  long sequences of multivariate time series\n",
        "  Total_small_seq_X, Total_small_seq_y = generate_small_seq(x[i,:,:], fx_window4 , n_future)\n",
        "  Total_small_seq_X_reshaped = Total_small_seq_X.reshape(Total_small_seq_X.shape[0],Total_small_seq_X.shape[1]*Total_small_seq_X.shape[2])\n",
        "  Total_small_seq_y_reshaped = Total_small_seq_y\n",
        "  maxval2 = Total_small_seq_X_reshaped.shape[0]\n",
        "  count_train2 = int(math.ceil(0.7*maxval2))\n",
        "  Small_train_X = Total_small_seq_X_reshaped[0:count_train2]\n",
        "  Small_train_y = Total_small_seq_y_reshaped[0:count_train2]\n",
        "  Small_test_X =  Total_small_seq_X_reshaped[count_train2:]\n",
        "  Small_test_y = Total_small_seq_y_reshaped[count_train2:]\n",
        "  tscv = TimeSeriesSplit(n_splits=n_fold-1)\n",
        "  #regressor = LassoCV(alphas=arange(0, 1, 0.01), cv=tscv, n_jobs=-1)\n",
        "  regressor = LinearRegression()\n",
        "  try:\n",
        "    regressor.fit(Small_train_X, Small_train_y.ravel()) #get jth time series only\n",
        "    if Small_test_X.shape[0] == 0:\n",
        "      break\n",
        "    y_predk = regressor.predict(Small_test_X)\n",
        "    #print('alpha: %f' % regressor.alpha_)\n",
        "    se =  ((Small_test_y-y_predk)**2).mean()/abs(Small_test_y.mean())\n",
        "    ape = abs(Small_test_y-y_predk).mean()/abs(Small_test_y.mean())\n",
        "    ae = abs(Small_test_y-y_predk).mean()\n",
        "    #mse = mean_squared_error(Small_test_y, y_predk)\n",
        "    #print(rmse)\n",
        "    se_4.append(se)\n",
        "    ape_4.append(ape)\n",
        "    ae_4.append(ae)\n",
        "  except:\n",
        "    se_4.append(9999)\n",
        "    ape_4.append(9999)\n",
        "    ae_4.append(9999)\n",
        "    print('error')\n",
        "\n",
        "\n",
        "############## NOW FOR PREDICTED WINDOW -----------------------------------\n",
        "\n",
        "se_x.clear()\n",
        "ape_x.clear()\n",
        "ae_x.clear()\n",
        "for i in range(sample_size) :\n",
        "#iterate over the entire  long sequences of multivariate time series\n",
        "  Total_small_seq_X, Total_small_seq_y = generate_small_seq(x[i,:,:], int(y_pred[i]) , n_future)\n",
        "  Total_small_seq_X_reshaped = Total_small_seq_X.reshape(Total_small_seq_X.shape[0],Total_small_seq_X.shape[1]*Total_small_seq_X.shape[2])\n",
        "  Total_small_seq_y_reshaped = Total_small_seq_y\n",
        "  maxval2 = Total_small_seq_X_reshaped.shape[0]\n",
        "  count_train2 = int(math.ceil(0.7*maxval2))\n",
        "  Small_train_X = Total_small_seq_X_reshaped[0:count_train2]\n",
        "  Small_train_y = Total_small_seq_y_reshaped[0:count_train2]\n",
        "  Small_test_X =  Total_small_seq_X_reshaped[count_train2:]\n",
        "  Small_test_y = Total_small_seq_y_reshaped[count_train2:]\n",
        "  tscv = TimeSeriesSplit(n_splits=n_fold-1)\n",
        "  #regressor = LassoCV(alphas=arange(0, 1, 0.01), cv=tscv, n_jobs=-1)\n",
        "  regressor = LinearRegression()\n",
        "  try:\n",
        "    regressor.fit(Small_train_X, Small_train_y.ravel()) #get jth time series only\n",
        "    if Small_test_X.shape[0] == 0:\n",
        "      break\n",
        "    y_predk = regressor.predict(Small_test_X)\n",
        "    #print('alpha: %f' % regressor.alpha_)\n",
        "    se =  ((Small_test_y-y_predk)**2).mean()/abs(Small_test_y.mean())\n",
        "    ape = abs(Small_test_y-y_predk).mean()/abs(Small_test_y.mean())\n",
        "    ae = abs(Small_test_y-y_predk).mean()\n",
        "    #mse = mean_squared_error(Small_test_y, y_predk)\n",
        "    #print(rmse)\n",
        "    se_x.append(se)\n",
        "    ape_x.append(ape)\n",
        "    ae_x.append(ae)\n",
        "  except:\n",
        "    se_x.append(9999)\n",
        "    ape_x.append(9999)\n",
        "    ae_x.append(9999)\n",
        "    print('error')\n",
        "\n",
        "\n",
        "se_1 = [i for i in se_1 if i != 9999]\n",
        "se_2 = [i for i in se_2 if i != 9999]\n",
        "se_3 = [i for i in se_3 if i != 9999]\n",
        "se_4 = [i for i in se_4 if i != 9999]\n",
        "se_x = [i for i in se_x if i != 9999]\n",
        "\n",
        "ape_1 = [i for i in ape_1 if i != 9999]\n",
        "ape_2 = [i for i in ape_2 if i != 9999]\n",
        "ape_3 = [i for i in ape_3 if i != 9999]\n",
        "ape_4 = [i for i in ape_4 if i != 9999]\n",
        "ape_x = [i for i in ape_x if i != 9999]\n",
        "\n",
        "ae_1 = [i for i in ae_1 if i != 9999]\n",
        "ae_2 = [i for i in ae_2 if i != 9999]\n",
        "ae_3 = [i for i in ae_3 if i != 9999]\n",
        "ae_4 = [i for i in ae_4 if i != 9999]\n",
        "ae_x = [i for i in ae_x if i != 9999]\n",
        "\n",
        "rmse_1 = sqrt(np.mean(se_1))\n",
        "rmse_2 = sqrt(np.mean(se_2))\n",
        "rmse_3 = sqrt(np.mean(se_3))\n",
        "rmse_4 = sqrt(np.mean(se_4))\n",
        "rmse_x = sqrt(np.mean(se_x))\n",
        "\n",
        "\n",
        "mape_1 = mean(ape_1)\n",
        "mape_2 = mean(ape_2)\n",
        "mape_3 = mean(ape_3)\n",
        "mape_4 = mean(ape_4)\n",
        "mape_x = mean(ape_x)\n",
        "mae_1 = mean(ae_1)\n",
        "mae_2 = mean(ae_2)\n",
        "mae_3 = mean(ae_3)\n",
        "mae_4 = mean(ae_4)\n",
        "mae_x = mean(ae_x)\n",
        "\n",
        "\n",
        "print(\"RMSE:\", rmse_1, rmse_2, rmse_3, rmse_4, rmse_x)\n",
        "print(\"MAPE:\", mape_1, mape_2, mape_3, mape_4, mape_x)\n",
        "print(\"MAE:\", mae_1, mae_2, mae_3, mae_4, mae_x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df.to_csv('/content/drive/MyDrive/PHD/2024/PREDICTION_COMPARISON/Electricity_mse_comparison.csv', index = False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "v_5iji919H_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8OtWHK--uG6W"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "https://github.com/supriyag123/PHD_Pub/blob/main/PAPER_GDRNet_METROPM_Step4-VAR-LATEST.ipynb",
      "authorship_tag": "ABX9TyMtbmW9R0UOs7YhBgjJOVnT",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}