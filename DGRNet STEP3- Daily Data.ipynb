{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supriyag123/PHD_Pub/blob/main/DGRNet%20STEP3-%20Daily%20Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "bx-5b_puABG1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "fdd6d24e-8150-49c2-d394-e430fd630fa1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 6 and the array at index 1413 has size 181",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-c9f813c09a6a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'/content/drive/MyDrive/PHD/2024/labelled_subsquence_data_daily'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 6 and the array at index 1413 has size 181"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import math\n",
        "import plotly.graph_objects as go\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, RepeatVector, TimeDistributed, Input\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import keras.backend as K\n",
        "from keras.callbacks import Callback\n",
        "import plotly\n",
        "import plotly.express as px # for data visualization\n",
        "import seaborn as sns\n",
        "\n",
        "generator_multiply = 50 #each input record will generate 100 random vectors from the latent space, given the mu and sigma generated by the encoder\n",
        "\n",
        "#from keras.utils import plot_model\n",
        "#import matplotlib.pyplot as plt\n",
        "\n",
        "#window1 = np.load(r'/content/drive/MyDrive/PHD/2021/multivariate_long_sequences_WINDOW-500.npy')\n",
        "#window2 = np.load(r'/content/drive/MyDrive/PHD/2021/multivariate_long_sequences_WINDOW-1000.npy')\n",
        "#window = np.concatenate((window1, window2), axis=0)\n",
        "#train_data = np.load(r'/content/drive/MyDrive/PHD/2021/multivariate_long_sequences-TRAIN.npy')\n",
        "#test_data = np.load(r'/content/drive/MyDrive/PHD/2021/multivariate_long_sequences-TEST.npy')\n",
        "\n",
        "\n",
        "\n",
        "#get data\n",
        "train_data = np.load(r'/content/drive/MyDrive/PHD/2024/multivariate_long_sequences-TRAIN-Daily-May2024.npy')\n",
        "\n",
        "\n",
        "#test_data = np.load(r'/content/drive/MyDrive/PHD/2024/multivariate_long_sequences-TEST_hourly.npy')\n",
        "#all_data = np.concatenate((train_data,test_data),axis=0)\n",
        "window_label = np.load(r'/content/drive/MyDrive/PHD/2024/multivariate_long_sequences_WINDOW-Daily-May2024.npy')\n",
        "n_seq = train_data.shape[0]\n",
        "window_size = train_data.shape[1]\n",
        "n_features = train_data.shape[2]\n",
        "\n",
        "\n",
        "plt.suptitle('Sub sequence plotting', fontsize='30')\n",
        "plt.xlabel('Time', fontsize ='20')\n",
        "plt.ylabel('Feature 1', fontsize='20')\n",
        "plt.plot(train_data[:,:,1])\n",
        "plt.show()\n",
        "\n",
        "#---------------------------VAE ------------------------------------------\n",
        "#from sklearn.model_selection import train_test_split\n",
        "#x_train, x_test, y_train, y_test = train_test_split(train_data, window_label, test_size = 0.2, random_state = 42)\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "encoder = keras.models.load_model(r'/content/drive/MyDrive/PHD/2024/VAE_SIMULATION/vae-encoder-saved-round4-latent5-dim256.model')\n",
        "decoder = keras.models.load_model(r'/content/drive/MyDrive/PHD/2024/VAE_SIMULATION/vae-decoder-saved-round4-latent5-dim256.model')\n",
        "\n",
        "X_train_encoded = encoder.predict(train_data)\n",
        "mu, logvar, z = X_train_encoded\n",
        "sigma = tf.exp(0.5 * logvar)\n",
        "batch = tf.shape(mu)[0]  #number of recors / batchs\n",
        "dim = tf.shape(mu)[1] #Ndimension of latent variable\n",
        "store = list()\n",
        "storetemp = list()\n",
        "\n",
        "\n",
        "#For each batch, iterate, get the generator_multipy number of latent vectors with same window_size.\n",
        "#For each z, concatenate z_mean, so it will become 100 dimensional vector\n",
        "\n",
        "for i in range(0,batch):\n",
        "  all_Z_i = tf.random.normal(shape=(generator_multiply,dim), mean = mu[i,:], stddev=sigma[i,:]) #all randorm vectors for this record i\n",
        "  X_train_decoded = decoder.predict(all_Z_i)\n",
        "  X_train_decoded = X_train_decoded.reshape((X_train_decoded.shape[0],window_size*n_features))\n",
        "  a = np.arange(generator_multiply)\n",
        "  a.fill(window_label[i])\n",
        "  c=np.concatenate(((X_train_decoded,a[:,None])),axis=1)\n",
        "  store.append(c)\n",
        "\n",
        "results=np.concatenate(store,axis=0)\n",
        "np.save(r'/content/drive/MyDrive/PHD/2024/labelled_subsquence_data_daily',results)\n",
        "\n",
        "\n",
        "#Regression fitting\n",
        "x=results[:,:-1]\n",
        "y=results[:,dim]\n",
        "\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "#----- get a test set from this data, to avoid further wrangling----------------\n",
        "#x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.1, random_state = 42)\n",
        "\n",
        "\n",
        "maxval = x.shape[0]\n",
        "count_train = int(math.ceil(0.9*maxval))\n",
        "x_train = x[:count_train]\n",
        "x_test = x[count_train:]\n",
        "\n",
        "y_train = y[:count_train]\n",
        "y_test = y[count_train:]\n",
        "\n",
        "\n",
        "from sklearn.ensemble import IsolationForest\n",
        "iso = IsolationForest(contamination=0.1)\n",
        "yhat = iso.fit_predict(x_train)\n",
        "# select all rows that are not outliers\n",
        "mask = yhat != -1\n",
        "x_train, y_train = x_train[mask, :], y_train[mask]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation = 'relu', input_dim = dim))\n",
        "model.add(Dense(units = 256, activation = 'relu'))\n",
        "model.add(Dense(units = 256, activation = 'relu'))\n",
        "model.add(Dense(units = 128, activation = 'relu'))\n",
        "model.add(Dense(units = 128, activation = 'relu'))\n",
        "model.add(Dense(units = 1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
        "\n",
        "#model.fit(x_train, y_train,epochs=5, batch_size=50, verbose=True)\n",
        "\n",
        "#y_pred = model.predict(x_test)\n",
        "\n",
        "#transform\n",
        "\n",
        "model.fit(x_train, y_train,epochs=100, batch_size=100, verbose=True)\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "score= r2_score(y_test,y_pred)\n",
        "print(\"r2 score is ==\",score)\n",
        "print(\"mean_sqrd_error is==\",mean_squared_error(y_test,y_pred))\n",
        "print(\"root_mean_squared error of is==\",np.sqrt(mean_squared_error(y_test,y_pred)))\n",
        "\n",
        "#plt.scatter(y_test,y_pred);\n",
        "#plt.xlabel('Actual');\n",
        "#plt.ylabel('Predicted');\n",
        "plt.plot(y_test[0:100], color = 'red', label = 'Real data')\n",
        "plt.plot(y_pred[0:100], color = 'blue', label = 'Predicted data')\n",
        "plt.title('Prediction')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "np.savetxt(r'/content/drive/MyDrive/PHD/2024/MLPOutput/preduber_2.csv',y_pred)\n",
        "np.savetxt(r'/content/drive/MyDrive/PHD/2024/MLPOutput/realuber_2.csv',y_test)\n",
        "print(\"MAE is==\",mean_absolute_error(y_test,y_pred))\n",
        "\n",
        "#---------------------------------Without VAE------------------------------------\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "\n",
        "maxval = train_data.shape[0]\n",
        "count_train = int(math.ceil(0.9*maxval))\n",
        "x_train = train_data[:count_train]\n",
        "x_test = train_data[count_train:]\n",
        "\n",
        "y_train = window_label[:count_train]\n",
        "y_test = window_label[count_train:]\n",
        "\n",
        "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1]*n_features))\n",
        "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1]*n_features))\n",
        "\n",
        "from sklearn.ensemble import IsolationForest\n",
        "iso = IsolationForest(contamination=0.1)\n",
        "yhat = iso.fit_predict(x_train)\n",
        "# select all rows that are not outliers\n",
        "mask = yhat != -1\n",
        "x_train, y_train = x_train[mask, :], y_train[mask]\n",
        "\n",
        "\n",
        "x_train = x_train.reshape((x_train.shape[0], window_size, n_features))  #DONT RUN IF MLP\n",
        "x_test = x_test.reshape((x_test.shape[0], window_size, n_features))    #DONT RUN IF MLP\n",
        "\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.models import Sequential\n",
        "##!pip uninstall tensorflow\n",
        "#!pip install tensorflow==2.12.0\n",
        "#from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "\n",
        "#reduce_lr = tf.keras.callbacks.LearningRateScheduler(lambda x: 1e-3 * 0.90 ** x)\n",
        "es = keras.callbacks.EarlyStopping(patience=10, verbose=1, min_delta=0.01, monitor='loss', mode='auto', restore_best_weights=True)\n",
        "n_epochs = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(512, input_shape=(x_train.shape[1],x_train.shape[2])))\n",
        "model.add(Dense(512, activation = 'relu'))\n",
        "model.add(Dense(units = 128, activation = 'relu'))\n",
        "model.add(Dense(units = 64, activation = 'relu'))\n",
        "model.add(Dense(units = 32, activation = 'relu'))\n",
        "model.add(Dense(units = 16, activation = 'relu'))\n",
        "model.add(Dense(units = 1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
        "\n",
        "history=model.fit( x_train,y_train,\n",
        "                 epochs=n_epochs,\n",
        "                 batch_size=32,\n",
        "                   validation_split=0.1,\n",
        "                 callbacks=[es])\n",
        "\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "\n",
        "score= r2_score(y_test,y_pred)\n",
        "print(\"r2 score is ==\",score)\n",
        "print(\"mean_sqrd_error is==\",mean_squared_error(y_test,y_pred))\n",
        "print(\"root_mean_squared error of is==\",np.sqrt(mean_squared_error(y_test,y_pred)))\n",
        "\n",
        "#plt.scatter(y_test,y_pred);\n",
        "#plt.xlabel('Actual');\n",
        "#plt.ylabel('Predicted');\n",
        "plt.plot(y_test[0:100], color = 'red', label = 'Real data')\n",
        "plt.plot(y_pred[0:100], color = 'blue', label = 'Predicted data')\n",
        "plt.title('Prediction')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "v_5iji919H_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8OtWHK--uG6W"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/supriyag123/PHD_Pub/blob/main/DGRNet%20STEP3-%20Daily%20Data.ipynb",
      "authorship_tag": "ABX9TyMgE6eLJuOfcSTj2oSZ1gXz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}