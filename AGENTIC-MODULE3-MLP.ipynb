{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supriyag123/PHD_Pub/blob/main/AGENTIC-MODULE3-MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bx-5b_puABG1"
      },
      "outputs": [],
      "source": [
        "# agents/adaptive_window_agent.py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import json\n",
        "import os\n",
        "from collections import deque, defaultdict\n",
        "from typing import Dict, List, Tuple, Optional, Any\n",
        "import datetime as dt\n",
        "import logging\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "from statsmodels.tsa.vector_ar.var_model import VAR\n",
        "import keras\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense\n",
        "from keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "from scipy import stats\n",
        "import threading\n",
        "import queue\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class AdaptiveWindowAgent:\n",
        "    \"\"\"\n",
        "    Agent A: Adaptive Window Management with Enhanced MLP\n",
        "\n",
        "    Capabilities:\n",
        "    1. Invoke new data and score using trained MLP\n",
        "    2. Calculate actual performance using VAR forecast\n",
        "    3. Track accuracy and performance statistics\n",
        "    4. Monitor for drift in prediction performance\n",
        "    5. Communicate with sensor agents to verify drift\n",
        "    6. Retrain MLP when drift is confirmed\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, agent_id: str = \"adaptive_window_agent\",\n",
        "                 model_path: str = None,\n",
        "                 checkpoint_path: str = None):\n",
        "        self.agent_id = agent_id\n",
        "        self.model_path = model_path or \"/content/drive/MyDrive/PHD/2025/DGRNet-MLP-Versions/METROPM_MLP_model_Daily.keras\"\n",
        "        self.checkpoint_path = checkpoint_path or \"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/ckp2.weights.h5\"\n",
        "\n",
        "        # Core MLP components\n",
        "        self.model = None\n",
        "        self.transformer = StandardScaler()\n",
        "        self.transformer_fitted = False  # Flag to track if transformer is fitted\n",
        "        self.is_model_loaded = False\n",
        "        self._ground_truth_buffer = []\n",
        "\n",
        "        # Performance tracking\n",
        "        self.prediction_history = deque(maxlen=1000)\n",
        "        self.accuracy_history = deque(maxlen=200)\n",
        "        self.r2_history = deque(maxlen=200)\n",
        "        self.mse_history = deque(maxlen=200)\n",
        "\n",
        "        # Drift detection parameters\n",
        "        self.drift_detection_window = 50\n",
        "        self.drift_threshold_r2 = 0.1\n",
        "        self.drift_threshold_mse = 0.2\n",
        "        self.consecutive_poor_predictions = 0\n",
        "        self.drift_confirmed = False\n",
        "\n",
        "        # Message queue for agent communication\n",
        "        self.message_queue = queue.Queue()\n",
        "        self.sensor_agents = {}\n",
        "\n",
        "        # Statistics storage\n",
        "        self.performance_stats = {\n",
        "            'total_predictions': 0,\n",
        "            'avg_r2': 0.0,\n",
        "            'avg_mse': 0.0,\n",
        "            'avg_mae': 0.0,\n",
        "            'last_retrain_time': None,\n",
        "            'drift_events': 0,\n",
        "            'retraining_events': 0\n",
        "        }\n",
        "\n",
        "        # Retraining data storage\n",
        "        self.retraining_data = {\n",
        "            'x_buffer': deque(maxlen=10000),\n",
        "            'y_buffer': deque(maxlen=10000)\n",
        "        }\n",
        "\n",
        "        self.load_model()\n",
        "        print(f\"AdaptiveWindowAgent {self.agent_id} initialized\")\n",
        "        print(f\"Model loaded: {self.is_model_loaded}\")\n",
        "\n",
        "    def load_model(self):\n",
        "        \"\"\"Load trained MLP model and recreate transformer using original training data\"\"\"\n",
        "        try:\n",
        "            if os.path.exists(self.model_path):\n",
        "                self.model = keras.models.load_model(self.model_path)\n",
        "                print(f\"Loaded MLP model from {self.model_path}\")\n",
        "                self.is_model_loaded = True\n",
        "\n",
        "                # Try to load saved transformer first\n",
        "                transformer_path = self.model_path.replace('.keras', '_transformer.pkl')\n",
        "                if os.path.exists(transformer_path):\n",
        "                    with open(transformer_path, 'rb') as f:\n",
        "                        self.transformer = pickle.load(f)\n",
        "                    self.transformer_fitted = True\n",
        "                    print(\"Loaded saved transformer\")\n",
        "                else:\n",
        "                    # Option 2: Recreate transformer from original training data\n",
        "                    print(\"No saved transformer found, recreating from original training data...\")\n",
        "\n",
        "                    try:\n",
        "                        # Load your original y training data\n",
        "                        y_original = np.load('/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/generated-data-true-window2.npy')\n",
        "\n",
        "                        # Fit transformer on original training data (same as your training code)\n",
        "                        self.transformer = StandardScaler()\n",
        "                        self.transformer.fit(y_original.reshape(-1, 1))\n",
        "                        self.transformer_fitted = True\n",
        "\n",
        "                        # Save it for future use\n",
        "                        with open(transformer_path, 'wb') as f:\n",
        "                            pickle.dump(self.transformer, f)\n",
        "\n",
        "                        print(f\"Fitted transformer on {len(y_original)} original training samples and saved\")\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"Could not load original training data: {e}\")\n",
        "                        self.transformer = StandardScaler()\n",
        "                        self.transformer_fitted = False\n",
        "\n",
        "            else:\n",
        "                print(f\"Model file not found at {self.model_path}\")\n",
        "                self.is_model_loaded = False\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model: {e}\")\n",
        "            self.is_model_loaded = False\n",
        "\n",
        "    def _fit_transformer_if_needed(self, y_values: List[float]):\n",
        "        \"\"\"Fit transformer on representative data if not already fitted\"\"\"\n",
        "        if not self.transformer_fitted and len(y_values) >= 10:\n",
        "            try:\n",
        "                # Fit transformer on available y values\n",
        "                y_array = np.array(y_values).reshape(-1, 1)\n",
        "                self.transformer.fit(y_array)\n",
        "                self.transformer_fitted = True\n",
        "                print(f\"Fitted transformer on {len(y_values)} representative samples\")\n",
        "\n",
        "                # Optionally save the fitted transformer for future use\n",
        "                transformer_path = self.model_path.replace('.keras', '_transformer.pkl')\n",
        "                with open(transformer_path, 'wb') as f:\n",
        "                    pickle.dump(self.transformer, f)\n",
        "                print(f\"Saved fitted transformer to {transformer_path}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Failed to fit transformer: {e}\")\n",
        "\n",
        "    def calculate_var_ground_truth(self, sequence_3d: np.ndarray, n_future: int = 1) -> int:\n",
        "        \"\"\"\n",
        "        Calculate ground truth window size using your EXACT VAR analysis logic\n",
        "        \"\"\"\n",
        "        # Your exact VAR analysis logic\n",
        "        rmse_list = []\n",
        "        K = sequence_3d.shape[0]  # K is the number of timesteps (50 in your case)\n",
        "\n",
        "        for k in range(2, round(K)):\n",
        "            cur_seq = sequence_3d\n",
        "            df = pd.DataFrame(cur_seq, columns=['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12'])\n",
        "            df_train, df_test = df[0:-n_future], df[-n_future:]\n",
        "            model = VAR(df_train)\n",
        "            try:\n",
        "                model_fitted1 = model.fit(k)\n",
        "                forecast_input1 = df_train.values[-k:]\n",
        "                fc1 = model_fitted1.forecast(y=forecast_input1, steps=n_future)\n",
        "                df_forecast1 = pd.DataFrame(fc1, index=df.index[-n_future:], columns=df.columns)\n",
        "                mse = mean_squared_error(df_test['V1'], df_forecast1['V1'].values)\n",
        "                rmse_list.append(mse)\n",
        "            except:\n",
        "                rmse_list.append(99999)\n",
        "\n",
        "        if rmse_list:\n",
        "            min_index = rmse_list.index(min(rmse_list))\n",
        "            min_sw = min_index + 2\n",
        "            return min_sw\n",
        "        else:\n",
        "            return 20\n",
        "\n",
        "    def predict_window_size(self, feature_vector: np.ndarray, sequence_3d: Optional[np.ndarray] = None,\n",
        "                           actual_window: Optional[int] = None) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Enhanced prediction method that can:\n",
        "        1. Use your MLP for prediction\n",
        "        2. Calculate VAR-based ground truth if sequence data provided\n",
        "        3. Track performance against VAR ground truth\n",
        "        \"\"\"\n",
        "        if not self.is_model_loaded:\n",
        "            return {\n",
        "                'predicted_window': 20,\n",
        "                'confidence': 0.0,\n",
        "                'error': \"Model not loaded\"\n",
        "            }\n",
        "\n",
        "        try:\n",
        "            # Ensure feature vector is 2D\n",
        "            if feature_vector.ndim == 1:\n",
        "                feature_vector = feature_vector.reshape(1, -1)\n",
        "\n",
        "            # 1. INVOKE NEW DATA AND SCORE USING MLP\n",
        "            prediction_raw = self.model.predict(feature_vector, verbose=0)\n",
        "\n",
        "            # 2. CALCULATE VAR-BASED GROUND TRUTH if sequence provided\n",
        "            var_ground_truth = None\n",
        "            if sequence_3d is not None:\n",
        "                var_ground_truth = self.calculate_var_ground_truth(sequence_3d)\n",
        "            elif actual_window is not None:\n",
        "                var_ground_truth = actual_window\n",
        "\n",
        "            # 3. HANDLE TRANSFORMER SCALING\n",
        "            if var_ground_truth is not None:\n",
        "                # Collect ground truth values for transformer fitting\n",
        "                self._ground_truth_buffer.append(var_ground_truth)\n",
        "\n",
        "                # Fit transformer if not already fitted\n",
        "                if not self.transformer_fitted:\n",
        "                    self._fit_transformer_if_needed(self._ground_truth_buffer)\n",
        "\n",
        "            # Transform prediction back to original scale only if transformer is fitted\n",
        "            if self.transformer_fitted:\n",
        "                predicted_window = self.transformer.inverse_transform(prediction_raw)[0, 0]\n",
        "            else:\n",
        "                # Use raw prediction if transformer not fitted yet\n",
        "                predicted_window = prediction_raw[0, 0]\n",
        "                logger.warning(\"Transformer not fitted yet, using raw prediction\")\n",
        "\n",
        "            predicted_window = max(5, min(50, int(predicted_window)))\n",
        "\n",
        "            # Create prediction record\n",
        "            prediction_record = {\n",
        "                'timestamp': dt.datetime.now(),\n",
        "                'predicted_window': predicted_window,\n",
        "                'feature_vector': feature_vector.flatten(),\n",
        "                'raw_prediction': prediction_raw[0, 0],\n",
        "                'var_ground_truth': var_ground_truth,\n",
        "                'transformer_fitted': self.transformer_fitted\n",
        "            }\n",
        "\n",
        "            # 4. CALCULATE ACTUAL PERFORMANCE AGAINST VAR GROUND TRUTH\n",
        "            if var_ground_truth is not None:\n",
        "                absolute_error = abs(predicted_window - var_ground_truth)\n",
        "                relative_error = absolute_error / max(var_ground_truth, 1)\n",
        "                accuracy = max(0, 1 - relative_error)\n",
        "\n",
        "                self.accuracy_history.append(accuracy)\n",
        "\n",
        "                # Calculate metrics for recent predictions\n",
        "                if len(self.prediction_history) >= 10:\n",
        "                    recent_predictions = [p['predicted_window'] for p in list(self.prediction_history)[-10:]\n",
        "                                        if p['var_ground_truth'] is not None]\n",
        "                    recent_ground_truths = [p['var_ground_truth'] for p in list(self.prediction_history)[-10:]\n",
        "                                          if p['var_ground_truth'] is not None]\n",
        "\n",
        "                    if len(recent_predictions) >= 5:\n",
        "                        r2 = r2_score(recent_ground_truths, recent_predictions)\n",
        "                        mse = mean_squared_error(recent_ground_truths, recent_predictions)\n",
        "                        mae = mean_absolute_error(recent_ground_truths, recent_predictions)\n",
        "\n",
        "                        self.r2_history.append(r2)\n",
        "                        self.mse_history.append(mse)\n",
        "\n",
        "                        self.performance_stats.update({\n",
        "                            'total_predictions': self.performance_stats['total_predictions'] + 1,\n",
        "                            'avg_r2': np.mean(self.r2_history),\n",
        "                            'avg_mse': np.mean(self.mse_history),\n",
        "                            'avg_mae': mae\n",
        "                        })\n",
        "\n",
        "                        prediction_record.update({\n",
        "                            'absolute_error': absolute_error,\n",
        "                            'relative_error': relative_error,\n",
        "                            'accuracy': accuracy,\n",
        "                            'recent_r2': r2,\n",
        "                            'recent_mse': mse,\n",
        "                            'recent_mae': mae\n",
        "                        })\n",
        "\n",
        "                        # 5. CHECK FOR DRIFT\n",
        "                        drift_detected = self._check_for_drift()\n",
        "                        prediction_record['drift_detected'] = drift_detected\n",
        "\n",
        "                        if drift_detected:\n",
        "                            prediction_record['drift_action'] = self._handle_drift_detection(feature_vector, var_ground_truth)\n",
        "\n",
        "            # Store prediction\n",
        "            self.prediction_history.append(prediction_record)\n",
        "\n",
        "            # Add to retraining buffer\n",
        "            self.retraining_data['x_buffer'].append(feature_vector.flatten())\n",
        "            if var_ground_truth is not None:\n",
        "                # Store raw ground truth, transform only when needed during retraining\n",
        "                self.retraining_data['y_buffer'].append(var_ground_truth)\n",
        "\n",
        "            return {\n",
        "                'predicted_window': predicted_window,\n",
        "                'var_ground_truth': var_ground_truth,\n",
        "                'confidence': self._calculate_confidence(prediction_record),\n",
        "                'performance_stats': self.get_recent_performance(),\n",
        "                'drift_detected': prediction_record.get('drift_detected', False),\n",
        "                'prediction_id': len(self.prediction_history),\n",
        "                'transformer_status': 'fitted' if self.transformer_fitted else 'not_fitted'\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Prediction error: {e}\")\n",
        "            return {\n",
        "                'predicted_window': 20,\n",
        "                'confidence': 0.0,\n",
        "                'error': str(e)\n",
        "            }\n",
        "\n",
        "    def _check_for_drift(self) -> bool:\n",
        "        \"\"\"Monitor and identify drift in prediction performance\"\"\"\n",
        "        if len(self.r2_history) < self.drift_detection_window:\n",
        "            return False\n",
        "\n",
        "        try:\n",
        "            # Get recent and historical performance\n",
        "            recent_r2 = np.mean(list(self.r2_history)[-20:])\n",
        "            historical_r2 = np.mean(list(self.r2_history)[-self.drift_detection_window:-20])\n",
        "\n",
        "            recent_mse = np.mean(list(self.mse_history)[-20:])\n",
        "            historical_mse = np.mean(list(self.mse_history)[-self.drift_detection_window:-20])\n",
        "\n",
        "            # Check for significant performance degradation\n",
        "            r2_drop = historical_r2 - recent_r2\n",
        "            mse_increase = recent_mse / max(historical_mse, 0.001) - 1\n",
        "\n",
        "            # Drift conditions\n",
        "            r2_drift = r2_drop > self.drift_threshold_r2\n",
        "            mse_drift = mse_increase > self.drift_threshold_mse\n",
        "\n",
        "            # Track consecutive poor predictions\n",
        "            recent_accuracy = np.mean(list(self.accuracy_history)[-10:]) if len(self.accuracy_history) >= 10 else 1.0\n",
        "            if recent_accuracy < 0.7:\n",
        "                self.consecutive_poor_predictions += 1\n",
        "            else:\n",
        "                self.consecutive_poor_predictions = 0\n",
        "\n",
        "            consecutive_drift = self.consecutive_poor_predictions > 10\n",
        "\n",
        "            # Drift detected if multiple conditions met\n",
        "            drift_detected = (r2_drift and mse_drift) or consecutive_drift\n",
        "\n",
        "            if drift_detected:\n",
        "                logger.warning(f\"Drift detected: R2 drop={r2_drop:.3f}, MSE increase={mse_increase:.3f}, \"\n",
        "                             f\"Consecutive poor predictions={self.consecutive_poor_predictions}\")\n",
        "                self.performance_stats['drift_events'] += 1\n",
        "\n",
        "            return drift_detected\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Drift detection error: {e}\")\n",
        "            return False\n",
        "\n",
        "    def _handle_drift_detection(self, current_features: np.ndarray, actual_window: int) -> str:\n",
        "        \"\"\"Check with sensor agents if really drifting\"\"\"\n",
        "        if self.drift_confirmed:\n",
        "            return \"Already handling drift\"\n",
        "\n",
        "        # Query sensor agents for their drift status\n",
        "        sensor_drift_confirmations = self._query_sensor_agents_for_drift()\n",
        "\n",
        "        # If majority of sensors also detect drift, confirm and retrain\n",
        "        if sensor_drift_confirmations >= len(self.sensor_agents) * 0.6:\n",
        "            self.drift_confirmed = True\n",
        "            logger.info(\"Drift confirmed by sensor agents. Initiating retraining...\")\n",
        "\n",
        "            # Retrain MLP\n",
        "            retrain_success = self._retrain_model()\n",
        "\n",
        "            if retrain_success:\n",
        "                self.drift_confirmed = False\n",
        "                self.consecutive_poor_predictions = 0\n",
        "                self.performance_stats['retraining_events'] += 1\n",
        "                self.performance_stats['last_retrain_time'] = dt.datetime.now()\n",
        "                return \"Retraining completed successfully\"\n",
        "            else:\n",
        "                return \"Retraining failed\"\n",
        "        else:\n",
        "            return f\"Drift suspected but not confirmed by sensors ({sensor_drift_confirmations}/{len(self.sensor_agents)})\"\n",
        "\n",
        "    def _query_sensor_agents_for_drift(self) -> int:\n",
        "        \"\"\"Query sensor agents to confirm drift\"\"\"\n",
        "        confirmations = 0\n",
        "\n",
        "        for sensor_id, sensor_agent in self.sensor_agents.items():\n",
        "            try:\n",
        "                # This would be actual message passing in full implementation\n",
        "                sensor_drift = self._simulate_sensor_drift_check(sensor_id)\n",
        "                if sensor_drift:\n",
        "                    confirmations += 1\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error querying sensor {sensor_id}: {e}\")\n",
        "\n",
        "        return confirmations\n",
        "\n",
        "    def _simulate_sensor_drift_check(self, sensor_id: str) -> bool:\n",
        "        \"\"\"Simulate sensor drift check (replace with actual message passing)\"\"\"\n",
        "        return np.random.random() > 0.7\n",
        "\n",
        "    def _retrain_model(self) -> bool:\n",
        "        \"\"\"Retrain MLP and reinstate new model\"\"\"\n",
        "        try:\n",
        "            logger.info(\"Starting MLP retraining...\")\n",
        "\n",
        "            if len(self.retraining_data['x_buffer']) < 100:\n",
        "                logger.warning(\"Insufficient data for retraining\")\n",
        "                return False\n",
        "\n",
        "            # Prepare retraining data\n",
        "            X_retrain = np.array(list(self.retraining_data['x_buffer']))\n",
        "            y_raw = np.array(list(self.retraining_data['y_buffer']))\n",
        "\n",
        "            # Transform y data for training if transformer is fitted\n",
        "            if self.transformer_fitted:\n",
        "                y_retrain = self.transformer.transform(y_raw.reshape(-1, 1)).flatten()\n",
        "            else:\n",
        "                y_retrain = y_raw\n",
        "\n",
        "            # Create new model with same architecture\n",
        "            new_model = Sequential()\n",
        "            new_model.add(Dense(64, activation='relu', input_shape=(X_retrain.shape[1],)))\n",
        "            new_model.add(Dense(32, activation='relu'))\n",
        "            new_model.add(Dense(16, activation='relu'))\n",
        "            new_model.add(Dense(8, activation='relu'))\n",
        "            new_model.add(Dense(1))\n",
        "\n",
        "            optimizer = keras.optimizers.Adam(learning_rate=0.0003, clipnorm=1)\n",
        "            new_model.compile(loss='mean_squared_error', optimizer=optimizer,\n",
        "                            metrics=['mean_squared_error'])\n",
        "\n",
        "            es = keras.callbacks.EarlyStopping(\n",
        "                patience=10, verbose=0, min_delta=0.0001,\n",
        "                monitor='loss', mode='min', restore_best_weights=True\n",
        "            )\n",
        "\n",
        "            # Train the new model\n",
        "            history = new_model.fit(\n",
        "                X_retrain, y_retrain,\n",
        "                epochs=50,\n",
        "                batch_size=32,\n",
        "                validation_split=0.2,\n",
        "                callbacks=[es],\n",
        "                verbose=0\n",
        "            )\n",
        "\n",
        "            # Evaluate new model performance\n",
        "            val_loss = min(history.history['val_loss'])\n",
        "\n",
        "            # Only replace model if new one is better\n",
        "            current_recent_mse = np.mean(list(self.mse_history)[-10:]) if self.mse_history else float('inf')\n",
        "            if val_loss < current_recent_mse * 1.1:\n",
        "                # Replace the model\n",
        "                self.model = new_model\n",
        "\n",
        "                # Save the retrained model\n",
        "                retrain_path = self.model_path.replace('.keras', '_retrained.keras')\n",
        "                self.model.save(retrain_path)\n",
        "\n",
        "                # Clear history to start fresh\n",
        "                self.r2_history.clear()\n",
        "                self.mse_history.clear()\n",
        "                self.accuracy_history.clear()\n",
        "\n",
        "                logger.info(f\"Model successfully retrained. New validation loss: {val_loss:.4f}\")\n",
        "                return True\n",
        "            else:\n",
        "                logger.warning(f\"New model performance worse ({val_loss:.4f} vs {current_recent_mse:.4f})\")\n",
        "                return False\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Retraining failed: {e}\")\n",
        "            return False\n",
        "\n",
        "    def _calculate_confidence(self, prediction_record: Dict) -> float:\n",
        "        \"\"\"Calculate confidence based on recent performance\"\"\"\n",
        "        if len(self.accuracy_history) < 10:\n",
        "            return 0.5\n",
        "\n",
        "        recent_accuracy = np.mean(list(self.accuracy_history)[-10:])\n",
        "        recent_r2 = self.performance_stats.get('avg_r2', 0.0)\n",
        "\n",
        "        confidence = (recent_accuracy + max(0, recent_r2)) / 2\n",
        "        return min(1.0, max(0.1, confidence))\n",
        "\n",
        "    def get_recent_performance(self) -> Dict[str, Any]:\n",
        "        \"\"\"Get recent performance statistics\"\"\"\n",
        "        if not self.prediction_history:\n",
        "            return {}\n",
        "\n",
        "        return {\n",
        "            'recent_accuracy': np.mean(self.accuracy_history) if self.accuracy_history else 0.0,\n",
        "            'recent_r2': np.mean(self.r2_history) if self.r2_history else 0.0,\n",
        "            'recent_mse': np.mean(self.mse_history) if self.mse_history else 0.0,\n",
        "            'total_predictions': len(self.prediction_history),\n",
        "            'drift_events': self.performance_stats['drift_events'],\n",
        "            'last_retrain': self.performance_stats['last_retrain_time'],\n",
        "            'consecutive_poor': self.consecutive_poor_predictions,\n",
        "            'transformer_fitted': self.transformer_fitted\n",
        "        }\n",
        "\n",
        "    def connect_sensor_agents(self, sensor_agents: Dict):\n",
        "        \"\"\"Connect to sensor agents for drift confirmation\"\"\"\n",
        "        self.sensor_agents = sensor_agents\n",
        "        logger.info(f\"Connected to {len(sensor_agents)} sensor agents\")\n",
        "\n",
        "    def get_performance_plot_data(self) -> Dict[str, List]:\n",
        "        \"\"\"Get data for performance visualization\"\"\"\n",
        "        if not self.prediction_history:\n",
        "            return {}\n",
        "\n",
        "        recent_records = [p for p in self.prediction_history if p.get('var_ground_truth') is not None]\n",
        "\n",
        "        return {\n",
        "            'timestamps': [r['timestamp'] for r in recent_records],\n",
        "            'predicted': [r['predicted_window'] for r in recent_records],\n",
        "            'actual': [r['var_ground_truth'] for r in recent_records],\n",
        "            'accuracy': [r.get('accuracy', 0) for r in recent_records],\n",
        "            'r2_scores': list(self.r2_history),\n",
        "            'mse_scores': list(self.mse_history)\n",
        "        }\n",
        "\n",
        "    def save_performance_state(self, filepath: str):\n",
        "        \"\"\"Save current performance state\"\"\"\n",
        "        state = {\n",
        "            'performance_stats': self.performance_stats.copy(),\n",
        "            'prediction_history': list(self.prediction_history)[-100:],\n",
        "            'accuracy_history': list(self.accuracy_history),\n",
        "            'r2_history': list(self.r2_history),\n",
        "            'mse_history': list(self.mse_history),\n",
        "            'transformer_fitted': self.transformer_fitted\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            # Convert datetime objects to strings for JSON serialization\n",
        "            for record in state['prediction_history']:\n",
        "                if 'timestamp' in record:\n",
        "                    # Check if timestamp is already a string\n",
        "                    if hasattr(record['timestamp'], 'isoformat'):\n",
        "                        record['timestamp'] = record['timestamp'].isoformat()\n",
        "                # Convert numpy arrays to lists for JSON serialization\n",
        "                if 'feature_vector' in record and hasattr(record['feature_vector'], 'tolist'):\n",
        "                    record['feature_vector'] = record['feature_vector'].tolist()\n",
        "\n",
        "            # Handle last_retrain_time\n",
        "            if state['performance_stats']['last_retrain_time']:\n",
        "                if hasattr(state['performance_stats']['last_retrain_time'], 'isoformat'):\n",
        "                    state['performance_stats']['last_retrain_time'] = state['performance_stats']['last_retrain_time'].isoformat()\n",
        "\n",
        "            # Save to file\n",
        "            with open(filepath, 'w') as f:\n",
        "                json.dump(state, f, default=str, indent=2)\n",
        "\n",
        "            logger.info(f\"Performance state saved to {filepath}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to save performance state: {e}\")\n",
        "            # Try simpler save without complex objects\n",
        "            simple_state = {\n",
        "                'total_predictions': len(self.prediction_history),\n",
        "                'avg_accuracy': np.mean(self.accuracy_history) if self.accuracy_history else 0.0,\n",
        "                'avg_r2': np.mean(self.r2_history) if self.r2_history else 0.0,\n",
        "                'avg_mse': np.mean(self.mse_history) if self.mse_history else 0.0,\n",
        "                'drift_events': self.performance_stats['drift_events'],\n",
        "                'retraining_events': self.performance_stats['retraining_events']\n",
        "            }\n",
        "\n",
        "            with open(filepath.replace('.json', '_simple.json'), 'w') as f:\n",
        "                json.dump(simple_state, f, indent=2)\n",
        "            print(f\"Saved simplified performance state to {filepath.replace('.json', '_simple.json')}\")\n",
        "\n",
        "\n",
        "\n",
        "# Test with YOUR actual data - Real-time VAR calculation only\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize the agent with your actual model\n",
        "    agent = AdaptiveWindowAgent(\n",
        "        model_path=\"/content/drive/MyDrive/PHD/2025/DGRNet-MLP-Versions/METROPM_MLP_model_Daily.keras\"\n",
        "    )\n",
        "\n",
        "    print(\"Loading your actual dataset...\")\n",
        "\n",
        "    # Load your actual saved dataset\n",
        "    Long_train = np.load('/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/multivariate_long_sequences-TRAIN-Daily-DIRECT-VAR.npy')\n",
        "    print(f\"Loaded Long_train shape: {Long_train.shape}\")\n",
        "\n",
        "    # Take last 100 entries as test module\n",
        "    test_sequences = Long_train[-100:]\n",
        "    print(f\"Testing with last 100 sequences: {test_sequences.shape}\")\n",
        "\n",
        "    print(\"\\nStarting real-time VAR testing...\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Test with YOUR actual data - Real-time VAR calculation only\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize the agent with your actual model\n",
        "    agent = AdaptiveWindowAgent(\n",
        "        model_path=\"/content/drive/MyDrive/PHD/2025/DGRNet-MLP-Versions/METROPM_MLP_model_Daily.keras\"\n",
        "    )\n",
        "\n",
        "    print(\"Loading your actual dataset...\")\n",
        "\n",
        "    # Load your actual saved dataset\n",
        "    Long_train = np.load('/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/multivariate_long_sequences-TRAIN-Daily-DIRECT-VAR.npy')\n",
        "    print(f\"Loaded Long_train shape: {Long_train.shape}\")\n",
        "\n",
        "    # Take last 100 entries as test module\n",
        "    test_sequences = Long_train[-100:]\n",
        "    print(f\"Testing with last 100 sequences: {test_sequences.shape}\")\n",
        "\n",
        "    # Check model input requirements\n",
        "    if agent.model:\n",
        "        model_input_shape = agent.model.input_shape\n",
        "        print(f\"Model expects input shape: {model_input_shape}\")\n",
        "        required_features = model_input_shape[1]  # Should be 600 based on error\n",
        "    else:\n",
        "        required_features = 600  # Default from error message\n",
        "\n",
        "    print(f\"Model requires {required_features} features\")\n",
        "    print(\"\\nStarting real-time VAR testing...\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    for i in range(len(test_sequences)):\n",
        "        sequence_3d = test_sequences[i]  # Shape: (50, 12)\n",
        "\n",
        "        # Simply flatten the sequence to get 600 features (50 * 12 = 600)\n",
        "        features = sequence_3d.flatten()  # This gives you exactly 600 features\n",
        "\n",
        "        print(f\"Sample {i+1}: Using flattened sequence of size {len(features)}\")\n",
        "\n",
        "        # Test the agent with real-time VAR calculation\n",
        "        result = agent.predict_window_size(features, sequence_3d=sequence_3d)\n",
        "\n",
        "        # Handle potential missing keys safely\n",
        "        mlp_pred = result.get('predicted_window', 0)\n",
        "        var_gt = result.get('var_ground_truth', None)\n",
        "        error_msg = result.get('error', None)\n",
        "\n",
        "        if error_msg:\n",
        "            print(f\"Sample {i+1}: ERROR - {error_msg}\")\n",
        "            continue\n",
        "\n",
        "        # Print results every 10 iterations\n",
        "        if i % 10 == 0:\n",
        "            performance = agent.get_recent_performance()\n",
        "            error = abs(mlp_pred - var_gt) if var_gt else 0\n",
        "            accuracy_pct = ((1 - error/max(var_gt, 1)) * 100) if var_gt else 0\n",
        "\n",
        "            print(f\"Sample {i+1:3d}: MLP={mlp_pred:2d}, VAR_GT={var_gt if var_gt else 'N/A'}, \"\n",
        "                  f\"Error={error:2d}, Accuracy={accuracy_pct:5.1f}%, \"\n",
        "                  f\"R2={performance.get('recent_r2', 0):6.3f}\")\n",
        "\n",
        "        # Check for drift detection\n",
        "        if result.get('drift_detected', False):\n",
        "            print(f\"*** DRIFT DETECTED at sample {i+1} ***\")\n",
        "            drift_action = result.get('drift_action')\n",
        "            if drift_action:\n",
        "                print(f\"Drift action: {drift_action}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"FINAL PERFORMANCE SUMMARY\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    final_performance = agent.get_recent_performance()\n",
        "\n",
        "    print(f\"Total predictions: {final_performance.get('total_predictions', 0)}\")\n",
        "    print(f\"Average accuracy: {final_performance.get('recent_accuracy', 0):.4f}\")\n",
        "    print(f\"Average R2 score: {final_performance.get('recent_r2', 0):.4f}\")\n",
        "    print(f\"Average MSE: {final_performance.get('recent_mse', 0):.4f}\")\n",
        "    print(f\"Drift events: {final_performance.get('drift_events', 0)}\")\n",
        "    print(f\"Retraining events: {agent.performance_stats['retraining_events']}\")\n",
        "    print(f\"Transformer fitted: {final_performance.get('transformer_fitted', False)}\")\n",
        "\n",
        "    # Save test results\n",
        "    agent.save_performance_state(\"real_data_test_results.json\")\n",
        "    print(f\"\\nTest results saved to: real_data_test_results.json\")\n",
        "\n",
        "    # Plot final results if we have valid predictions\n",
        "    plot_data = agent.get_performance_plot_data()\n",
        "    if plot_data and len(plot_data.get('predicted', [])) > 5:\n",
        "        import matplotlib.pyplot as plt\n",
        "\n",
        "        plt.figure(figsize=(15, 5))\n",
        "\n",
        "        # Subplot 1: MLP vs VAR scatter\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.scatter(plot_data['actual'], plot_data['predicted'], alpha=0.7, color='blue')\n",
        "        min_val = min(min(plot_data['actual']), min(plot_data['predicted']))\n",
        "        max_val = max(max(plot_data['actual']), max(plot_data['predicted']))\n",
        "        plt.plot([min_val, max_val], [min_val, max_val], 'r--', label='Perfect prediction')\n",
        "        plt.xlabel('VAR Ground Truth Window Size')\n",
        "        plt.ylabel('MLP Predicted Window Size')\n",
        "        plt.title('MLP vs VAR Window Predictions')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        # Subplot 2: Accuracy trend\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.plot(plot_data['accuracy'], color='green')\n",
        "        plt.xlabel('Sample Number')\n",
        "        plt.ylabel('Prediction Accuracy')\n",
        "        plt.title('Accuracy Trend Over Time')\n",
        "        plt.grid(True)\n",
        "\n",
        "        # Subplot 3: R2 trend\n",
        "        plt.subplot(1, 3, 3)\n",
        "        if plot_data['r2_scores']:\n",
        "            plt.plot(plot_data['r2_scores'], color='orange')\n",
        "            plt.xlabel('Window Number')\n",
        "            plt.ylabel('R2 Score')\n",
        "            plt.title('R2 Score Evolution')\n",
        "            plt.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Calculate final statistics\n",
        "        from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "        final_r2 = r2_score(plot_data['actual'], plot_data['predicted'])\n",
        "        final_mse = mean_squared_error(plot_data['actual'], plot_data['predicted'])\n",
        "        final_mae = mean_absolute_error(plot_data['actual'], plot_data['predicted'])\n",
        "\n",
        "        print(f\"\\nFinal Test Statistics:\")\n",
        "        print(f\"Overall R2 Score: {final_r2:.4f}\")\n",
        "        print(f\"Overall MSE: {final_mse:.4f}\")\n",
        "        print(f\"Overall MAE: {final_mae:.4f}\")\n",
        "        print(f\"Mean prediction accuracy: {np.mean(plot_data['accuracy']):.4f}\")\n",
        "    else:\n",
        "        print(\"No valid predictions made for plotting\")\n",
        "\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"FINAL PERFORMANCE SUMMARY\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    final_performance = agent.get_recent_performance()\n",
        "\n",
        "    print(f\"Total predictions: {final_performance.get('total_predictions', 0)}\")\n",
        "    print(f\"Average accuracy: {final_performance.get('recent_accuracy', 0):.4f}\")\n",
        "    print(f\"Average R2 score: {final_performance.get('recent_r2', 0):.4f}\")\n",
        "    print(f\"Average MSE: {final_performance.get('recent_mse', 0):.4f}\")\n",
        "    print(f\"Drift events: {final_performance.get('drift_events', 0)}\")\n",
        "    print(f\"Retraining events: {agent.performance_stats['retraining_events']}\")\n",
        "    print(f\"Transformer fitted: {final_performance.get('transformer_fitted', False)}\")\n",
        "\n",
        "    # Save test results\n",
        "    agent.save_performance_state(\"real_data_test_results.json\")\n",
        "    print(f\"\\nTest results saved to: real_data_test_results.json\")\n",
        "\n",
        "    # Plot final results\n",
        "    plot_data = agent.get_performance_plot_data()\n",
        "    if plot_data and len(plot_data.get('predicted', [])) > 5:\n",
        "        import matplotlib.pyplot as plt\n",
        "\n",
        "        plt.figure(figsize=(15, 5))\n",
        "\n",
        "        # Subplot 1: MLP vs VAR scatter\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.scatter(plot_data['actual'], plot_data['predicted'], alpha=0.7, color='blue')\n",
        "        min_val = min(min(plot_data['actual']), min(plot_data['predicted']))\n",
        "        max_val = max(max(plot_data['actual']), max(plot_data['predicted']))\n",
        "        plt.plot([min_val, max_val], [min_val, max_val], 'r--', label='Perfect prediction')\n",
        "        plt.xlabel('VAR Ground Truth Window Size')\n",
        "        plt.ylabel('MLP Predicted Window Size')\n",
        "        plt.title('MLP vs VAR Window Predictions')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        # Subplot 2: Accuracy trend\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.plot(plot_data['accuracy'], color='green')\n",
        "        plt.xlabel('Sample Number')\n",
        "        plt.ylabel('Prediction Accuracy')\n",
        "        plt.title('Accuracy Trend Over Time')\n",
        "        plt.grid(True)\n",
        "\n",
        "        # Subplot 3: R2 trend\n",
        "        plt.subplot(1, 3, 3)\n",
        "        if plot_data['r2_scores']:\n",
        "            plt.plot(plot_data['r2_scores'], color='orange')\n",
        "            plt.xlabel('Window Number')\n",
        "            plt.ylabel('R2 Score')\n",
        "            plt.title('R2 Score Evolution')\n",
        "            plt.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Calculate and print final statistics\n",
        "        final_r2 = r2_score(plot_data['actual'], plot_data['predicted'])\n",
        "        final_mse = mean_squared_error(plot_data['actual'], plot_data['predicted'])\n",
        "        final_mae = mean_absolute_error(plot_data['actual'], plot_data['predicted'])\n",
        "\n",
        "        print(f\"\\nFinal Test Statistics:\")\n",
        "        print(f\"Overall R2 Score: {final_r2:.4f}\")\n",
        "        print(f\"Overall MSE: {final_mse:.4f}\")\n",
        "        print(f\"Overall MAE: {final_mae:.4f}\")\n",
        "        print(f\"Mean prediction accuracy: {np.mean(plot_data['accuracy']):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "nxij89jyeebm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "https://github.com/supriyag123/PHD_Pub/blob/main/AGENTIC-MODULE3-MLP.ipynb",
      "authorship_tag": "ABX9TyPZkJym1qQ3zvyU4rD0So6x",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}