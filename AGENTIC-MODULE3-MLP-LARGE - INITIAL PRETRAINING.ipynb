{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supriyag123/PHD_Pub/blob/main/AGENTIC-MODULE3-MLP-LARGE%20-%20INITIAL%20PRETRAINING.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bx-5b_puABG1",
        "outputId": "7d1cd5f5-be9a-426f-9a11-5e0b619d4f84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'os' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1220002920.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Found existing checkpoint. Loading best weights...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Build model with dummy forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import math\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, RepeatVector, TimeDistributed, Input\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import keras.backend as K\n",
        "from keras.callbacks import Callback\n",
        "import plotly.express as px\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import IsolationForest\n",
        "import scipy.stats as stats\n",
        "import pylab as pl\n",
        "\n",
        "# Load generated data from VAE module\n",
        "y = np.load(r'/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/generated-data-true-window2.npy')\n",
        "x = np.load(r'/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/generated-data2.npy')\n",
        "x = x.reshape(x.shape[0], -1)\n",
        "print(f\"Loaded data shapes - X: {x.shape}, Y: {y.shape}\")\n",
        "\n",
        "# Distribution visualization\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Distribution before Transformation\", fontsize=15)\n",
        "sns.histplot(y, kde=True, color=\"red\")\n",
        "plt.show()\n",
        "\n",
        "# Optional: Remove outliers (commented out as per original code)\n",
        "# from sklearn.ensemble import IsolationForest\n",
        "# iso = IsolationForest(contamination=0.4)\n",
        "# yhat = iso.fit_predict(x)\n",
        "# mask = yhat != -1\n",
        "# x, y = x[mask, :], y[mask]\n",
        "\n",
        "# Scale the target and split data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "transformer = StandardScaler()\n",
        "y_transformed = transformer.fit_transform(y.reshape(-1, 1)).flatten()\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y_transformed, test_size=0.1, random_state=42)\n",
        "\n",
        "print(f\"Train/Test split - X_train: {x_train.shape}, X_test: {x_test.shape}\")\n",
        "print(f\"Train/Test split - y_train: {y_train.shape}, y_test: {y_test.shape}\")\n",
        "\n",
        "# Set up model checkpointing\n",
        "checkpoint_path = \"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/large/ckp2.weights.h5\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    checkpoint_path,\n",
        "    monitor='loss',\n",
        "    save_best_only=True,\n",
        "    save_weights_only=True\n",
        ")\n",
        "\n",
        "# Build MLP model\n",
        "from keras.layers import LeakyReLU,Dropout\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(64, input_shape=(x_train.shape[1],)),\n",
        "    LeakyReLU(0.1),\n",
        "    Dropout(0.1),\n",
        "\n",
        "    Dense(32),\n",
        "    LeakyReLU(0.1),\n",
        "    Dropout(0.1),\n",
        "\n",
        "    Dense(16),\n",
        "    LeakyReLU(0.1),\n",
        "\n",
        "    Dense(8),\n",
        "    LeakyReLU(0.1),\n",
        "\n",
        "    Dense(1)  # linear output\n",
        "])\n",
        "\n",
        "optimizr = keras.optimizers.Adam(learning_rate=0.0003, clipnorm=1)\n",
        "model.compile( loss=tf.keras.losses.Huber(), optimizer=optimizr, metrics=['mae'])\n",
        "\n",
        "# Check if checkpoint exists and load it\n",
        "# Check if checkpoint exists and load it\n",
        "if os.path.exists(checkpoint_path):\n",
        "    print(\"Found existing checkpoint. Loading best weights...\")\n",
        "\n",
        "    # Build model with dummy forward pass\n",
        "    model(x_train[:1])\n",
        "\n",
        "    # Load the best weights\n",
        "    model.load_weights(checkpoint_path)\n",
        "    print(\"Loaded existing checkpoint weights.\")\n",
        "\n",
        "else:\n",
        "    print(\"No existing checkpoint found. Training from scratch...\")\n",
        "\n",
        "    # Build model first\n",
        "    model(x_train[:1])\n",
        "\n",
        "    # Now train fully (checkpoint will save best)\n",
        "    model.fit(\n",
        "        x_train, y_train,\n",
        "        epochs=1,\n",
        "        batch_size=64,\n",
        "        validation_split=0.1\n",
        "    )\n",
        "\n",
        "# Set up callbacks\n",
        "es = keras.callbacks.EarlyStopping(\n",
        "    patience=20,\n",
        "    verbose=1,\n",
        "    min_delta=0.0001,\n",
        "    monitor='loss',\n",
        "    mode='min',\n",
        "    restore_best_weights=True\n",
        ")\n",
        "n_epochs = 200\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train,\n",
        "                   epochs=n_epochs,\n",
        "                   batch_size=32,\n",
        "                   validation_split=0.1,\n",
        "                   callbacks=[cp_callback,es])\n",
        "\n",
        "# Plot training history\n",
        "plt.plot(history.history['loss'], label='Training loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation loss')\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Training evaluation\n",
        "y_train_pred_raw = model.predict(x_train)\n",
        "y_train_pred = transformer.inverse_transform(y_train_pred_raw)\n",
        "y_train_true = transformer.inverse_transform(y_train.reshape(-1, 1)).flatten()\n",
        "\n",
        "score_train = r2_score(y_train_true, y_train_pred)\n",
        "print(\"Training r2 score is ==\", score_train)\n",
        "\n",
        "plt.plot(y_train_true[0:100], color='red', label='Real data')\n",
        "plt.plot(y_train_pred[0:100], color='blue', label='Predicted data')\n",
        "plt.title('Training Prediction')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Test evaluation\n",
        "y_pred_raw = model.predict(x_test)\n",
        "y_test_pred = transformer.inverse_transform(y_pred_raw)\n",
        "y_test_true = transformer.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
        "\n",
        "score = r2_score(y_test_true, y_test_pred)\n",
        "print(\"Test r2 score is ==\", score)\n",
        "\n",
        "plt.plot(y_test_true[100:200], color='red', label='Real data')\n",
        "plt.plot(y_test_pred[100:200], color='blue', label='Predicted data')\n",
        "plt.title('Test Prediction')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Save model and results\n",
        "model.save(r'/content/drive/MyDrive/PHD/2025/DGRNet-MLP-Versions/METROPM_MLP_model_Daily.keras')\n",
        "\n",
        "# Final training history plot\n",
        "plt.plot(history.history['loss'], label='Training loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation loss')\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Load and test saved model\n",
        "base_model = keras.models.load_model(r'/content/drive/MyDrive/PHD/2025/DGRNet-MLP-Versions/METROPM_MLP_model_Daily.keras')\n",
        "\n",
        "# Final test evaluation with loaded model\n",
        "y_pred_raw = base_model.predict(x_test)\n",
        "y_test_pred = transformer.inverse_transform(y_pred_raw)\n",
        "y_test_true = transformer.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
        "\n",
        "score = r2_score(y_test_true, y_test_pred)\n",
        "print(\"Final test r2 score with loaded model ==\", score)\n",
        "\n",
        "plt.plot(y_test_true[100:200], color='red', label='Real data')\n",
        "plt.plot(y_test_pred[100:200], color='blue', label='Predicted data')\n",
        "plt.title('Final Prediction with Loaded Model')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Save results\n",
        "np.savetxt(r'/content/drive/MyDrive/PHD/2025/MLPOutput/METROPM_predicted_window.csv', y_test_pred)\n",
        "np.savetxt(r'/content/drive/MyDrive/PHD/2025/MLPOutput/METROPM_derived_window_label.csv', y_test_true)\n",
        "np.savetxt(r'/content/drive/MyDrive/PHD/2025/MLPOutput/METROPM_test_data.csv', x_test)\n",
        "\n",
        "print(\"MLP training complete. Model and results saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "nxij89jyeebm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "https://github.com/supriyag123/PHD_Pub/blob/main/AGENTIC-MODULE3-MLP-LARGE%20-%20INITIAL%20PRETRAINING.ipynb",
      "authorship_tag": "ABX9TyMjoYd0Yj4+EzGnEZ3wL03y",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}