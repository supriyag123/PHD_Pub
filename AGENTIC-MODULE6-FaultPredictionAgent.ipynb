{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supriyag123/PHD_Pub/blob/main/AGENTIC-MODULE6-FaultPredictionAgent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoP7OuWNxlsJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# ============================================================\n",
        "# Fault Classification Pipeline\n",
        "# ============================================================\n",
        "\n",
        "############PASTE ADAPTIVE WINDOW HERE - so everything is in one file - later, we can import as a package#####################\n",
        "\n",
        "\n",
        "# ====== AdaptiveWindowAgent ======\n",
        "# =====================================================\n",
        "# AdaptiveWindowAgent (improved version)\n",
        "# =====================================================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle, os, logging, datetime as dt\n",
        "from collections import deque\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from statsmodels.tsa.vector_ar.var_model import VAR\n",
        "import keras\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class AdaptiveWindowAgent:\n",
        "    \"\"\"\n",
        "    Adaptive Window Agent:\n",
        "    - Predicts window size using MLP\n",
        "    - Evaluates forecast with VAR\n",
        "    - Monitors anomalies & drift with adaptive thresholds\n",
        "    - Outputs severity scores + suppresses redundant events\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, agent_id=\"adaptive_window_agent\",\n",
        "                 model_path=None, checkpoint_path=None):\n",
        "        self.agent_id = agent_id\n",
        "        self.model_path = model_path or \"/content/drive/MyDrive/PHD/2025/DGRNet-MLP-Versions/METROPM_MLP_model_Daily.keras\"\n",
        "        self.checkpoint_path = checkpoint_path\n",
        "\n",
        "        # Core model\n",
        "        self.model = None\n",
        "        self.transformer = StandardScaler()\n",
        "        self.transformer_fitted = False\n",
        "        self.is_model_loaded = False\n",
        "\n",
        "        # Histories\n",
        "        self.prediction_history = deque(maxlen=1000)\n",
        "        self.mse_history = deque(maxlen=200)\n",
        "        self.mae_history = deque(maxlen=200)\n",
        "\n",
        "        # Event detection params\n",
        "        self.drift_detection_window = 20\n",
        "        self.drift_threshold_mse = 1.5   # stricter\n",
        "        self.drift_threshold_mae = 1.5\n",
        "        self.consecutive_poor_predictions = 0\n",
        "        self.cooldown_counter = 0\n",
        "\n",
        "        # Stats\n",
        "        self.performance_stats = {\n",
        "            'total_predictions': 0,\n",
        "            'avg_mse': 0.0,\n",
        "            'avg_mae': 0.0,\n",
        "            'last_retrain_time': None,\n",
        "            'drift_events': 0,\n",
        "            'anomaly_events': 0,\n",
        "            'retraining_events': 0\n",
        "        }\n",
        "\n",
        "        # Retraining buffers\n",
        "        self.retraining_data = {\n",
        "            'x_buffer': deque(maxlen=10000),\n",
        "            'y_buffer': deque(maxlen=10000)\n",
        "        }\n",
        "\n",
        "        self.load_model()\n",
        "        print(f\"AdaptiveWindowAgent {self.agent_id} initialized\")\n",
        "\n",
        "    # ------------------- Model -------------------\n",
        "\n",
        "    def load_model(self):\n",
        "        try:\n",
        "            if os.path.exists(self.model_path):\n",
        "                self.model = keras.models.load_model(self.model_path)\n",
        "                self.is_model_loaded = True\n",
        "                print(f\"✅ Loaded MLP model from {self.model_path}\")\n",
        "\n",
        "                # Try to load transformer\n",
        "                transformer_path = self.model_path.replace('.keras', '_transformer.pkl')\n",
        "                if os.path.exists(transformer_path):\n",
        "                    with open(transformer_path, 'rb') as f:\n",
        "                        self.transformer = pickle.load(f)\n",
        "                    self.transformer_fitted = True\n",
        "                else:\n",
        "                    # Fit transformer from true window labels\n",
        "                    y_original = np.load(\n",
        "                        \"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/generated-data-true-window2.npy\"\n",
        "                    )\n",
        "                    self.transformer.fit(y_original.reshape(-1, 1))\n",
        "                    self.transformer_fitted = True\n",
        "                    with open(transformer_path, 'wb') as f:\n",
        "                        pickle.dump(self.transformer, f)\n",
        "                    print(\"⚠️ No transformer found, fitted a new one.\")\n",
        "            else:\n",
        "                print(f\"❌ Model not found at {self.model_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error loading model: {e}\")\n",
        "\n",
        "    # ------------------- Forecast Eval -------------------\n",
        "    def evaluate_forecast_performance(self, sequence_3d, predicted_window, n_future=1):\n",
        "        try:\n",
        "            df = pd.DataFrame(sequence_3d, columns=[f'V{i+1}' for i in range(sequence_3d.shape[1])])\n",
        "            df_train, df_test = df[:-n_future], df[-n_future:]\n",
        "\n",
        "            # Drop constant cols\n",
        "            constant_cols = [c for c in df_train.columns if df_train[c].nunique() <= 1]\n",
        "            df_train = df_train.drop(columns=constant_cols, errors=\"ignore\")\n",
        "            df_test = df_test.drop(columns=constant_cols, errors=\"ignore\")\n",
        "\n",
        "            # If too few variables, fall back immediately\n",
        "            if len(df_train.columns) < 1:\n",
        "                return self._persistence_forecast(df, df_test)\n",
        "\n",
        "            k = min(predicted_window, len(df_train) - 2)\n",
        "            if k < 1: k = 1\n",
        "\n",
        "            # Try VAR\n",
        "            try:\n",
        "                model = VAR(df_train)\n",
        "                model_fitted = model.fit(maxlags=k, trend=\"c\")\n",
        "                forecast_input = df_train.values[-model_fitted.k_ar:]\n",
        "                fc = model_fitted.forecast(y=forecast_input, steps=n_future)\n",
        "                df_forecast = pd.DataFrame(fc, index=df.index[-n_future:], columns=df_train.columns)\n",
        "\n",
        "                actual = df_test[df_forecast.columns].values.flatten()\n",
        "                predicted = df_forecast.values.flatten()\n",
        "\n",
        "            except Exception:\n",
        "                # Try AutoReg\n",
        "                try:\n",
        "                    from statsmodels.tsa.ar_model import AutoReg\n",
        "                    col = df_train.columns[0]\n",
        "                    model = AutoReg(df_train[col], lags=min(k, len(df_train)//2)).fit()\n",
        "                    predicted = model.predict(start=len(df_train), end=len(df_train)+n_future-1).values\n",
        "                    actual = df_test[col].values\n",
        "                except Exception:\n",
        "                    # Fallback to persistence\n",
        "                    return self._persistence_forecast(df, df_test)\n",
        "\n",
        "            mse = np.mean((actual - predicted) ** 2)\n",
        "            mae = np.mean(np.abs(actual - predicted))\n",
        "\n",
        "            # If forecast is unstable, fallback\n",
        "            if np.isnan(mse) or np.isnan(mae) or mse > 10 or mae > 10:\n",
        "                return self._persistence_forecast(df, df_test)\n",
        "\n",
        "            return {\n",
        "                'mse': float(mse),\n",
        "                'mae': float(mae),\n",
        "                'forecast_success': True,\n",
        "                'actual_values': actual.tolist(),\n",
        "                'predicted_values': predicted.tolist(),\n",
        "                'used_columns': list(df_test.columns)\n",
        "            }\n",
        "\n",
        "        except Exception:\n",
        "            return self._persistence_forecast(df, df_test)\n",
        "\n",
        "# ------------------- Persistence fallback -------------------\n",
        "\n",
        "    def _persistence_forecast(self, df, df_test):\n",
        "        \"\"\"Simple last-value-carried-forward forecast.\"\"\"\n",
        "        try:\n",
        "            last_values = df.iloc[-1].values\n",
        "            predicted = np.tile(last_values, (len(df_test), 1))\n",
        "            actual = df_test.values.flatten()\n",
        "\n",
        "            mse = np.mean((actual - predicted.flatten()) ** 2)\n",
        "            mae = np.mean(np.abs(actual - predicted.flatten()))\n",
        "\n",
        "            return {\n",
        "                'mse': float(mse),\n",
        "                'mae': float(mae),\n",
        "                'forecast_success': True,\n",
        "                'actual_values': actual.tolist(),\n",
        "                'predicted_values': predicted.flatten().tolist(),\n",
        "                'used_columns': list(df_test.columns),\n",
        "                'note': 'persistence_fallback'\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {'mse': 9999, 'mae': 9999, 'forecast_success': True, 'error': str(e), 'note': 'persistence_fallback_failed'}\n",
        "\n",
        "\n",
        "\n",
        "    # ------------------- Prediction -------------------\n",
        "\n",
        "    def predict_window_size(self, feature_vector, sequence_3d):\n",
        "        if not self.is_model_loaded:\n",
        "            return {'predicted_window': 20, 'error': \"Model not loaded\"}\n",
        "\n",
        "        try:\n",
        "            if feature_vector.ndim == 1:\n",
        "                feature_vector = feature_vector.reshape(1, -1)\n",
        "\n",
        "            pred_raw = self.model.predict(feature_vector, verbose=0)\n",
        "            if self.transformer_fitted:\n",
        "                predicted_window = int(round(self.transformer.inverse_transform(pred_raw)[0, 0]))\n",
        "            else:\n",
        "                predicted_window = int(round(pred_raw[0, 0]))\n",
        "\n",
        "            # Evaluate\n",
        "            forecast_metrics = self.evaluate_forecast_performance(sequence_3d, predicted_window, n_future=1)\n",
        "\n",
        "            if forecast_metrics.get(\"forecast_success\", False):\n",
        "                self.mse_history.append(forecast_metrics[\"mse\"])\n",
        "                self.mae_history.append(forecast_metrics[\"mae\"])\n",
        "                self.performance_stats['total_predictions'] += 1\n",
        "                self.performance_stats['avg_mse'] = np.mean(self.mse_history)\n",
        "                self.performance_stats['avg_mae'] = np.mean(self.mae_history)\n",
        "\n",
        "            # Event check\n",
        "            event, sev = self._check_for_event()\n",
        "\n",
        "            # Save history\n",
        "            record = {\n",
        "                'timestamp': dt.datetime.now(),\n",
        "                'predicted_window': predicted_window,\n",
        "                'forecast_metrics': forecast_metrics,\n",
        "                'event_type': event,\n",
        "                'severity': sev\n",
        "            }\n",
        "            self.prediction_history.append(record)\n",
        "\n",
        "            return {\n",
        "                'predicted_window': predicted_window,\n",
        "                'forecast_metrics': forecast_metrics,\n",
        "                'event_type': event,\n",
        "                'severity': sev,\n",
        "                'performance_stats': self.get_recent_performance()\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {'predicted_window': 20, 'error': str(e)}\n",
        "\n",
        "    # ------------------- Event Logic -------------------\n",
        "\n",
        "    def _check_for_event(self):\n",
        "        if len(self.mse_history) < self.drift_detection_window:\n",
        "            return None, 0.0\n",
        "\n",
        "        mse_vals = np.array(self.mse_history)[-self.drift_detection_window:]\n",
        "        mae_vals = np.array(self.mae_history)[-self.drift_detection_window:]\n",
        "\n",
        "        # Rolling stats\n",
        "        mean_mse, std_mse = np.mean(mse_vals), np.std(mse_vals) + 1e-8\n",
        "        last_mse = mse_vals[-1]\n",
        "\n",
        "        # Normalized error\n",
        "        norm_error = (last_mse - mean_mse) / std_mse\n",
        "\n",
        "        # Severity\n",
        "        anomaly_severity = max(0, norm_error)\n",
        "        drift_severity = max(0, (np.mean(mse_vals) / (np.median(mse_vals)+1e-5)) - 1)\n",
        "\n",
        "        # Check anomaly\n",
        "        if last_mse > mean_mse + 2.0 * std_mse:\n",
        "            self.performance_stats['anomaly_events'] += 1\n",
        "            return \"ANOMALY\", anomaly_severity\n",
        "\n",
        "        # Check drift (with persistence + cooldown)\n",
        "        ema_mse = 0.3*np.mean(mse_vals) + 0.7*np.median(mse_vals)\n",
        "        ema_mae = 0.3*np.mean(mae_vals) + 0.7*np.median(mae_vals)\n",
        "        mse_ratio = ema_mse / max(np.median(mse_vals), 1e-5)\n",
        "        mae_ratio = ema_mae / max(np.median(mae_vals), 1e-5)\n",
        "\n",
        "        if mse_ratio > self.drift_threshold_mse and mae_ratio > self.drift_threshold_mae:\n",
        "            self.consecutive_poor_predictions += 1\n",
        "            if self.consecutive_poor_predictions >= 5 and self.cooldown_counter == 0:\n",
        "                self.performance_stats['drift_events'] += 1\n",
        "                self.cooldown_counter = 10\n",
        "                return \"DRIFT\", drift_severity\n",
        "        else:\n",
        "            self.consecutive_poor_predictions = 0\n",
        "\n",
        "        if self.cooldown_counter > 0:\n",
        "            self.cooldown_counter -= 1\n",
        "\n",
        "        return None, 0.0\n",
        "\n",
        "    # ------------------- Helpers -------------------\n",
        "\n",
        "    def get_recent_performance(self):\n",
        "        successful_predictions = [\n",
        "            p for p in list(self.prediction_history)[-50:]\n",
        "            if p.get('forecast_metrics', {}).get('forecast_success', False)\n",
        "        ]\n",
        "        return {\n",
        "            'total_predictions': len(self.prediction_history),\n",
        "            'successful_predictions': len(successful_predictions),\n",
        "            'success_rate': len(successful_predictions) / max(len(self.prediction_history), 1),\n",
        "            'drift_events': self.performance_stats['drift_events'],\n",
        "            'anomaly_events': self.performance_stats['anomaly_events'],\n",
        "            'retraining_events': self.performance_stats['retraining_events'],\n",
        "            'recent_mse': float(np.mean(list(self.mse_history)[-10:])) if self.mse_history else 0,\n",
        "            'avg_mse': float(np.mean(self.mse_history)) if self.mse_history else 0,\n",
        "            'recent_mae': float(np.mean(list(self.mae_history)[-10:])) if self.mae_history else 0,\n",
        "            'avg_mae': float(np.mean(self.mae_history)) if self.mae_history else 0,\n",
        "            'transformer_fitted': self.transformer_fitted\n",
        "        }\n",
        "\n",
        "\n",
        "    def save_performance_state(self, filepath: str):\n",
        "        \"\"\"Save performance statistics + prediction history to JSON\"\"\"\n",
        "        try:\n",
        "            state = {\n",
        "                'performance_stats': self.performance_stats.copy(),\n",
        "                'prediction_history': list(self.prediction_history)[-100:],  # last 100\n",
        "                'mse_history': list(self.mse_history),\n",
        "                'mae_history': list(self.mae_history),\n",
        "                'transformer_fitted': self.transformer_fitted\n",
        "            }\n",
        "            import json\n",
        "            with open(filepath, 'w') as f:\n",
        "                json.dump(state, f, indent=2, default=str)\n",
        "            print(f\"✅ Performance state saved to {filepath}\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to save performance state: {e}\")\n",
        "\n",
        "\n",
        "#############################################\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import joblib\n",
        "\n",
        "# ============================================================\n",
        "# 1. Load Data\n",
        "# ============================================================\n",
        "# Long subsequences (length=50) and labels\n",
        "long_sequences = np.load(\"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/multivariate_long_sequences-TRAIN-Daily-DIRECT-VAR.npy\")\n",
        "labels_detection = np.load(\"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/anomaly_labels_detection.npy\")  # fault labels\n",
        "labels_h1 = np.load(\"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/anomaly_labels_H1.npy\")  # optional predictive labels\n",
        "\n",
        "print(\"Data loaded:\", long_sequences.shape, labels_detection.shape)\n",
        "\n",
        "# ============================================================\n",
        "# 2. Baseline Fixed Window Features (window=50, flattened)\n",
        "# ============================================================\n",
        "X_fixed = long_sequences.reshape(long_sequences.shape[0], -1)\n",
        "y = labels_detection  # detection labels (can switch to h1/h3/h12)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_fixed, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(\"Train/Test shapes:\", X_train.shape, X_test.shape)\n",
        "\n",
        "# Baseline-1: Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42, n_jobs=-1)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "print(\"\\n=== Baseline-1: Fixed Window Random Forest ===\")\n",
        "print(classification_report(y_test, y_pred_rf, digits=4))\n",
        "print(confusion_matrix(y_test, y_pred_rf))\n",
        "joblib.dump(rf, \"rf_fixed_window.pkl\")\n",
        "\n",
        "# ============================================================\n",
        "# 3. Dynamic Window Features (using your AdaptiveWindowAgent)\n",
        "# ============================================================\n",
        "#from agents.adaptive_window_agent import AdaptiveWindowAgent\n",
        "\n",
        "window_agent = AdaptiveWindowAgent(\n",
        "    model_path=\"/content/drive/MyDrive/PHD/2025/DGRNet-MLP-Versions/METROPM_MLP_model_Daily.keras\"\n",
        ")\n",
        "\n",
        "# Generate features for each subsequence using predicted window\n",
        "dynamic_features = []\n",
        "for seq in long_sequences:\n",
        "    features = seq.flatten()\n",
        "    result = window_agent.predict_window_size(features, seq)\n",
        "    w = result.get(\"predicted_window\", 50)\n",
        "    # Extract the last w timesteps from the long sequence\n",
        "    seq_dynamic = seq[-w:].flatten()\n",
        "    dynamic_features.append(seq_dynamic)\n",
        "\n",
        "# Pad to same length (use max window=50)\n",
        "X_dynamic = np.array([np.pad(f, (0, 50*seq.shape[1] - len(f))) for f in dynamic_features])\n",
        "\n",
        "X_train_dyn, X_test_dyn, y_train_dyn, y_test_dyn = train_test_split(X_dynamic, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Baseline-2: XGBoost\n",
        "xgb = XGBClassifier(\n",
        "    n_estimators=300, max_depth=8, learning_rate=0.05,\n",
        "    subsample=0.8, colsample_bytree=0.8,\n",
        "    random_state=42, n_jobs=-1\n",
        ")\n",
        "xgb.fit(X_train_dyn, y_train_dyn)\n",
        "y_pred_xgb = xgb.predict(X_test_dyn)\n",
        "\n",
        "print(\"\\n=== Baseline-2: Dynamic Window XGBoost ===\")\n",
        "print(classification_report(y_test_dyn, y_pred_xgb, digits=4))\n",
        "print(confusion_matrix(y_test_dyn, y_pred_xgb))\n",
        "joblib.dump(xgb, \"xgb_dynamic_window.pkl\")\n",
        "\n",
        "# ============================================================\n",
        "# Ready for Next Steps\n",
        "# ============================================================\n",
        "print(\"\\n✅ Baseline models trained and evaluated.\")\n",
        "print(\"Next: add Transformer-based sequence classifier, then coordinator features.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "v_5iji919H_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8OtWHK--uG6W"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "https://github.com/supriyag123/PHD_Pub/blob/main/AGENTIC-MODULE6-FaultPredictionAgent.ipynb",
      "authorship_tag": "ABX9TyOlHJG1JjzLidEfV5iSXxjJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}