{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supriyag123/PHD_Pub/blob/main/DGRNet%20STEP1%20-%20Labelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bx-5b_puABG1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "927e5b3d-8da7-4481-cc5b-923fc0bad86e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "252/252 [==============================] - 28s 101ms/step - loss: 1409.1432 - mean_squared_error: 1409.1432\n",
            "Epoch 2/100\n",
            "252/252 [==============================] - 25s 101ms/step - loss: 1354.7278 - mean_squared_error: 1354.7278\n",
            "Epoch 3/100\n",
            "252/252 [==============================] - 25s 99ms/step - loss: 1356.2617 - mean_squared_error: 1356.2617\n",
            "Epoch 4/100\n",
            "252/252 [==============================] - 25s 100ms/step - loss: 1346.9451 - mean_squared_error: 1346.9451\n",
            "Epoch 5/100\n",
            "252/252 [==============================] - 25s 101ms/step - loss: 1349.2594 - mean_squared_error: 1349.2594\n",
            "Epoch 6/100\n",
            "252/252 [==============================] - 25s 100ms/step - loss: 1348.9341 - mean_squared_error: 1348.9341\n",
            "Epoch 7/100\n",
            "252/252 [==============================] - 25s 100ms/step - loss: 1350.1298 - mean_squared_error: 1350.1296\n",
            "Epoch 8/100\n",
            "252/252 [==============================] - 25s 101ms/step - loss: 1349.0437 - mean_squared_error: 1349.0437\n",
            "Epoch 9/100\n",
            "252/252 [==============================] - 25s 101ms/step - loss: 1342.5187 - mean_squared_error: 1342.5187\n",
            "Epoch 10/100\n",
            "252/252 [==============================] - 25s 101ms/step - loss: 1347.8635 - mean_squared_error: 1347.8635\n",
            "Epoch 11/100\n",
            "252/252 [==============================] - 25s 101ms/step - loss: 1350.2739 - mean_squared_error: 1350.2739\n",
            "Epoch 12/100\n",
            "252/252 [==============================] - 25s 101ms/step - loss: 1345.8256 - mean_squared_error: 1345.8258\n",
            "Epoch 13/100\n",
            "252/252 [==============================] - 25s 100ms/step - loss: 1350.2404 - mean_squared_error: 1350.2404\n",
            "Epoch 14/100\n",
            "252/252 [==============================] - 25s 101ms/step - loss: 1343.8241 - mean_squared_error: 1343.8242\n",
            "Epoch 15/100\n",
            "252/252 [==============================] - 25s 101ms/step - loss: 1347.2535 - mean_squared_error: 1347.2535\n",
            "Epoch 16/100\n",
            "252/252 [==============================] - 25s 101ms/step - loss: 1343.8481 - mean_squared_error: 1343.8481\n",
            "Epoch 17/100\n",
            "252/252 [==============================] - 25s 101ms/step - loss: 1344.5435 - mean_squared_error: 1344.5435\n",
            "Epoch 18/100\n",
            "252/252 [==============================] - 25s 101ms/step - loss: 1343.9247 - mean_squared_error: 1343.9247\n",
            "Epoch 19/100\n",
            "252/252 [==============================] - 25s 101ms/step - loss: 1348.8910 - mean_squared_error: 1348.8910\n",
            "Epoch 20/100\n",
            "252/252 [==============================] - 25s 101ms/step - loss: 1346.4808 - mean_squared_error: 1346.4808\n",
            "Epoch 21/100\n",
            "252/252 [==============================] - 25s 100ms/step - loss: 1341.0167 - mean_squared_error: 1341.0167\n",
            "Epoch 22/100\n",
            "252/252 [==============================] - 25s 100ms/step - loss: 1341.8365 - mean_squared_error: 1341.8365\n",
            "Epoch 23/100\n",
            "252/252 [==============================] - 25s 100ms/step - loss: 1343.5812 - mean_squared_error: 1343.5812\n",
            "Epoch 24/100\n",
            "252/252 [==============================] - 25s 100ms/step - loss: 1344.2072 - mean_squared_error: 1344.2072\n",
            "Epoch 25/100\n",
            "252/252 [==============================] - 25s 100ms/step - loss: 1343.2534 - mean_squared_error: 1343.2534\n",
            "Epoch 26/100\n",
            "252/252 [==============================] - 25s 100ms/step - loss: 1345.1217 - mean_squared_error: 1345.1215\n",
            "Epoch 27/100\n",
            "252/252 [==============================] - 25s 100ms/step - loss: 1341.8884 - mean_squared_error: 1341.8884\n",
            "Epoch 28/100\n",
            "252/252 [==============================] - 25s 100ms/step - loss: 1341.4529 - mean_squared_error: 1341.4529\n",
            "Epoch 29/100\n",
            "252/252 [==============================] - 25s 100ms/step - loss: 1342.6348 - mean_squared_error: 1342.6348\n",
            "Epoch 30/100\n",
            "252/252 [==============================] - 25s 100ms/step - loss: 1343.9618 - mean_squared_error: 1343.9618\n",
            "Epoch 31/100\n",
            "252/252 [==============================] - 25s 100ms/step - loss: 1341.9839 - mean_squared_error: 1341.9839\n",
            "Epoch 32/100\n",
            "252/252 [==============================] - 25s 100ms/step - loss: 1340.9795 - mean_squared_error: 1340.9795\n",
            "Epoch 33/100\n",
            "252/252 [==============================] - 25s 100ms/step - loss: 1342.8331 - mean_squared_error: 1342.8331\n",
            "Epoch 34/100\n",
            "252/252 [==============================] - 25s 101ms/step - loss: 1344.7742 - mean_squared_error: 1344.7742\n",
            "Epoch 35/100\n",
            "252/252 [==============================] - 25s 101ms/step - loss: 1343.4916 - mean_squared_error: 1343.4916\n",
            "Epoch 36/100\n",
            "252/252 [==============================] - 25s 101ms/step - loss: 1345.9912 - mean_squared_error: 1345.9912\n",
            "Epoch 37/100\n",
            "252/252 [==============================] - 25s 101ms/step - loss: 1346.0442 - mean_squared_error: 1346.0442\n",
            "Epoch 38/100\n",
            "252/252 [==============================] - 25s 101ms/step - loss: 1340.8918 - mean_squared_error: 1340.8918\n",
            "Epoch 39/100\n",
            "252/252 [==============================] - 25s 101ms/step - loss: 1343.4080 - mean_squared_error: 1343.4080\n",
            "Epoch 40/100\n",
            "252/252 [==============================] - 25s 101ms/step - loss: 1341.8054 - mean_squared_error: 1341.8054\n",
            "Epoch 41/100\n",
            "252/252 [==============================] - 25s 101ms/step - loss: 1339.1384 - mean_squared_error: 1339.1384\n",
            "Epoch 42/100\n",
            "252/252 [==============================] - 25s 101ms/step - loss: 1340.3522 - mean_squared_error: 1340.3522\n",
            "Epoch 43/100\n",
            "252/252 [==============================] - 25s 101ms/step - loss: 1343.2822 - mean_squared_error: 1343.2822\n",
            "Epoch 44/100\n",
            "252/252 [==============================] - 25s 101ms/step - loss: 1341.5464 - mean_squared_error: 1341.5464\n",
            "Epoch 45/100\n",
            "252/252 [==============================] - 25s 101ms/step - loss: 1342.7950 - mean_squared_error: 1342.7950\n",
            "Epoch 46/100\n",
            "252/252 [==============================] - 25s 100ms/step - loss: 1342.8624 - mean_squared_error: 1342.8624\n",
            "Epoch 47/100\n",
            "252/252 [==============================] - 25s 100ms/step - loss: 1344.7687 - mean_squared_error: 1344.7687\n",
            "Epoch 48/100\n",
            "252/252 [==============================] - 25s 100ms/step - loss: 1339.5242 - mean_squared_error: 1339.5242\n",
            "Epoch 49/100\n",
            "252/252 [==============================] - 25s 100ms/step - loss: 1339.6188 - mean_squared_error: 1339.6188\n",
            "Epoch 50/100\n",
            "252/252 [==============================] - 25s 100ms/step - loss: 1344.1161 - mean_squared_error: 1344.1161\n",
            "Epoch 51/100\n",
            "252/252 [==============================] - 25s 100ms/step - loss: 1341.3779 - mean_squared_error: 1341.3779\n",
            "Epoch 52/100\n",
            "252/252 [==============================] - 25s 100ms/step - loss: 1337.8621 - mean_squared_error: 1337.8621\n",
            "Epoch 53/100\n",
            "252/252 [==============================] - 25s 100ms/step - loss: 1342.0081 - mean_squared_error: 1342.0081\n",
            "Epoch 54/100\n",
            "252/252 [==============================] - 25s 101ms/step - loss: 1340.0963 - mean_squared_error: 1340.0963\n",
            "Epoch 55/100\n",
            "252/252 [==============================] - 25s 101ms/step - loss: 1341.5350 - mean_squared_error: 1341.5350\n",
            "Epoch 56/100\n",
            " 99/252 [==========>...................] - ETA: 15s - loss: 1343.4703 - mean_squared_error: 1343.4703"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import math\n",
        "import plotly.graph_objects as go\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, RepeatVector, TimeDistributed, Input\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import keras.backend as K\n",
        "from keras.callbacks import Callback\n",
        "import plotly\n",
        "import plotly.express as px # for data visualization\n",
        "import seaborn as sns\n",
        "\n",
        "generator_multiply = 1 #each input record will generate 100 random vectors from the latent space, given the mu and sigma generated by the encoder\n",
        "\n",
        "#from keras.utils import plot_model\n",
        "#import matplotlib.pyplot as plt\n",
        "\n",
        "#window1 = np.load(r'/content/drive/MyDrive/PHD/2021/multivariate_long_sequences_WINDOW-500.npy')\n",
        "#window2 = np.load(r'/content/drive/MyDrive/PHD/2021/multivariate_long_sequences_WINDOW-1000.npy')\n",
        "#window = np.concatenate((window1, window2), axis=0)\n",
        "#train_data = np.load(r'/content/drive/MyDrive/PHD/2021/multivariate_long_sequences-TRAIN.npy')\n",
        "#test_data = np.load(r'/content/drive/MyDrive/PHD/2021/multivariate_long_sequences-TEST.npy')\n",
        "\n",
        "\n",
        "\n",
        "#get data\n",
        "train_data = np.load(r'/content/drive/MyDrive/PHD/2024/multivariate_long_sequences-TRAIN_hourly.npy')\n",
        "index = 500\n",
        "#We missed i=500 from processing the iosw. So here we are dropping row with index =500\n",
        "train_data= np.delete(train_data, index, axis=0)\n",
        "\n",
        "#test_data = np.load(r'/content/drive/MyDrive/PHD/2024/multivariate_long_sequences-TEST_hourly.npy')\n",
        "#all_data = np.concatenate((train_data,test_data),axis=0)\n",
        "window_label = np.load(r'/content/drive/MyDrive/PHD/2024/multivariate_long_sequences_WINDOW-TRAIN_hourly.npy')\n",
        "n_seq = train_data.shape[0]\n",
        "window_size = train_data.shape[1]\n",
        "n_features = train_data.shape[2]\n",
        "\n",
        "\n",
        "plt.suptitle('Sub sequence plotting', fontsize='30')\n",
        "plt.xlabel('Time', fontsize ='20')\n",
        "plt.ylabel('Feature 1', fontsize='20')\n",
        "plt.plot(train_data[:,:,1])\n",
        "plt.show()\n",
        "\n",
        "#---------------------------Folowing Uber paper ------------------------------------------\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(train_data, window_label, test_size = 0.2, random_state = 42)\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "encoder = keras.models.load_model(r'/content/drive/MyDrive/PHD/2024/VAE_SIMULATION/vae-encoder-saved-round4-latent50-dim1000.model')\n",
        "decoder = keras.models.load_model(r'/content/drive/MyDrive/PHD/2024/VAE_SIMULATION/vae-decoder-saved-round4-latent50-dim1000.model')\n",
        "\n",
        "X_train_encoded = encoder.predict(train_data)\n",
        "mu, logvar, z = X_train_encoded\n",
        "sigma = tf.exp(0.5 * logvar)\n",
        "batch = tf.shape(mu)[0]  #number of recors / batchs\n",
        "dim = tf.shape(mu)[1] #Ndimension of latent variable\n",
        "store = list()\n",
        "storetemp = list()\n",
        "\n",
        "#Find average Z - a 50-dimensional vector\n",
        "\n",
        "z_mean = np.mean(z, axis=0)\n",
        "\n",
        "#For each batch, iterate, get the generator_multipy number of latent vectors with same window_size.\n",
        "#For each z, concatenate z_mean, so it will become 100 dimensional vector\n",
        "\n",
        "for i in range(0,batch):\n",
        "  all_Z_i = tf.random.normal(shape=(generator_multiply,dim), mean = mu[i,:], stddev=sigma[i,:]) #all randorm vectors for this record i\n",
        "  z_mod = np.concatenate((z_mean[None,:],all_Z_i),axis=1)\n",
        "  #X_train_decoded = decoder.predict(z_mod)\n",
        "  a = np.arange(generator_multiply)\n",
        "  a.fill(window_label[i])\n",
        "  c=np.concatenate(((z_mod,a[:,None])),axis=1)\n",
        "  store.append(c)\n",
        "\n",
        "results=np.concatenate(store,axis=0)\n",
        "np.save(r'/content/drive/MyDrive/PHD/2024/labelled_concat_subsquence_data',results)\n",
        "\n",
        "dim_new = 100\n",
        "#Regression fitting\n",
        "x=results[:,:-1]\n",
        "y=results[:,dim_new]\n",
        "\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "#----- get a test set from this data, to avoid further wrangling----------------\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.1, random_state = 42)\n",
        "\n",
        "\n",
        "from sklearn.ensemble import IsolationForest\n",
        "iso = IsolationForest(contamination=0.1)\n",
        "yhat = iso.fit_predict(x_train)\n",
        "# select all rows that are not outliers\n",
        "mask = yhat != -1\n",
        "x_train, y_train = x_train[mask, :], y_train[mask]\n",
        "\n",
        "#Reshape now to fi LSTM\n",
        "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
        "x_test = x_test.reshape((x_test.shape[0], x_train.shape[1], 1))\n",
        "\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.models import Sequential\n",
        "##!pip uninstall tensorflow\n",
        "#!pip install tensorflow==2.12.0\n",
        "#from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(1000, input_shape=(x_train.shape[1],x_train.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "#model.add(LSTM(1000))\n",
        "#model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(1000, activation = 'relu'))\n",
        "model.add(Dense(units = 512, activation = 'relu'))\n",
        "model.add(Dense(units = 512, activation = 'relu'))\n",
        "#model.add(Dense(units = 128, activation = 'relu'))\n",
        "#model.add(Dense(units = 128, activation = 'relu'))\n",
        "model.add(Dense(units = 1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
        "\n",
        "#model.fit(x_train, y_train,epochs=5, batch_size=50, verbose=True)\n",
        "\n",
        "#y_pred = model.predict(x_test)\n",
        "\n",
        "#transform\n",
        "\n",
        "model.fit(x_train, y_train,epochs=100, batch_size=100, verbose=True)\n",
        "y_pred = model.predict(x_test)\n",
        "score= r2_score(y_test,y_pred)\n",
        "print(\"r2 score is ==\",score)\n",
        "print(\"mean_sqrd_error is==\",mean_squared_error(y_test,y_pred))\n",
        "print(\"root_mean_squared error of is==\",np.sqrt(mean_squared_error(y_test,y_pred)))\n",
        "\n",
        "#plt.scatter(y_test,y_pred);\n",
        "#plt.xlabel('Actual');\n",
        "#plt.ylabel('Predicted');\n",
        "plt.plot(y_test[0:100], color = 'red', label = 'Real data')\n",
        "plt.plot(y_pred[0:100], color = 'blue', label = 'Predicted data')\n",
        "plt.title('Prediction')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "np.savetxt(r'/content/drive/MyDrive/PHD/2024/MLPOutput/preduber_2.csv',y_pred)\n",
        "np.savetxt(r'/content/drive/MyDrive/PHD/2024/MLPOutput/realuber_2.csv',y_test)\n",
        "print(\"MAE is==\",mean_absolute_error(y_test,y_pred))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8OtWHK--uG6W"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/supriyag123/PHD_Pub/blob/main/DGRNet%20Prediction.ipynb",
      "authorship_tag": "ABX9TyNKt7u8DjCoIjMMkmNQVrRn",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}