{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supriyag123/PHD_Pub/blob/main/DGRNet%20STEP3-%20Hourly%20Data%20-%20MLP-%20Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HoP7OuWNxlsJ",
        "outputId": "b21ae9e2-468a-4d99-91fa-5ff0e1bb72f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1885/1885 [==============================] - 29s 14ms/step - loss: 0.9076 - mean_squared_error: 0.9076 - val_loss: 0.8804 - val_mean_squared_error: 0.8804\n",
            "Epoch 2/1000\n",
            "1885/1885 [==============================] - 23s 12ms/step - loss: 0.8805 - mean_squared_error: 0.8805 - val_loss: 0.8750 - val_mean_squared_error: 0.8750\n",
            "Epoch 3/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8724 - mean_squared_error: 0.8724 - val_loss: 0.8800 - val_mean_squared_error: 0.8800\n",
            "Epoch 4/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8730 - mean_squared_error: 0.8730 - val_loss: 0.8715 - val_mean_squared_error: 0.8715\n",
            "Epoch 5/1000\n",
            "1885/1885 [==============================] - 23s 12ms/step - loss: 0.8715 - mean_squared_error: 0.8715 - val_loss: 0.8783 - val_mean_squared_error: 0.8783\n",
            "Epoch 6/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8707 - mean_squared_error: 0.8707 - val_loss: 0.8733 - val_mean_squared_error: 0.8733\n",
            "Epoch 7/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8687 - mean_squared_error: 0.8687 - val_loss: 0.8667 - val_mean_squared_error: 0.8667\n",
            "Epoch 8/1000\n",
            "1885/1885 [==============================] - 24s 12ms/step - loss: 0.8675 - mean_squared_error: 0.8675 - val_loss: 0.8699 - val_mean_squared_error: 0.8699\n",
            "Epoch 9/1000\n",
            "1885/1885 [==============================] - 23s 12ms/step - loss: 0.8675 - mean_squared_error: 0.8675 - val_loss: 0.8686 - val_mean_squared_error: 0.8686\n",
            "Epoch 10/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8674 - mean_squared_error: 0.8674 - val_loss: 0.8736 - val_mean_squared_error: 0.8736\n",
            "Epoch 11/1000\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8668 - mean_squared_error: 0.8668 - val_loss: 0.8655 - val_mean_squared_error: 0.8655\n",
            "Epoch 12/1000\n",
            "1885/1885 [==============================] - 23s 12ms/step - loss: 0.8662 - mean_squared_error: 0.8662 - val_loss: 0.8705 - val_mean_squared_error: 0.8705\n",
            "Epoch 13/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8658 - mean_squared_error: 0.8658 - val_loss: 0.8677 - val_mean_squared_error: 0.8677\n",
            "Epoch 14/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8656 - mean_squared_error: 0.8656 - val_loss: 0.8754 - val_mean_squared_error: 0.8754\n",
            "Epoch 15/1000\n",
            "1885/1885 [==============================] - 23s 12ms/step - loss: 0.8643 - mean_squared_error: 0.8643 - val_loss: 0.8659 - val_mean_squared_error: 0.8659\n",
            "Epoch 16/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8646 - mean_squared_error: 0.8646 - val_loss: 0.8696 - val_mean_squared_error: 0.8696\n",
            "Epoch 17/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8646 - mean_squared_error: 0.8646 - val_loss: 0.8647 - val_mean_squared_error: 0.8647\n",
            "Epoch 18/1000\n",
            "1885/1885 [==============================] - 23s 12ms/step - loss: 0.8643 - mean_squared_error: 0.8643 - val_loss: 0.8703 - val_mean_squared_error: 0.8703\n",
            "Epoch 19/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8640 - mean_squared_error: 0.8640 - val_loss: 0.8700 - val_mean_squared_error: 0.8700\n",
            "Epoch 20/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8631 - mean_squared_error: 0.8631 - val_loss: 0.8662 - val_mean_squared_error: 0.8662\n",
            "Epoch 21/1000\n",
            "1885/1885 [==============================] - 23s 12ms/step - loss: 0.8632 - mean_squared_error: 0.8632 - val_loss: 0.8663 - val_mean_squared_error: 0.8663\n",
            "Epoch 22/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8624 - mean_squared_error: 0.8624 - val_loss: 0.8652 - val_mean_squared_error: 0.8652\n",
            "Epoch 23/1000\n",
            "1885/1885 [==============================] - 26s 14ms/step - loss: 0.8627 - mean_squared_error: 0.8627 - val_loss: 0.8672 - val_mean_squared_error: 0.8672\n",
            "Epoch 24/1000\n",
            "1885/1885 [==============================] - 23s 12ms/step - loss: 0.8630 - mean_squared_error: 0.8630 - val_loss: 0.8645 - val_mean_squared_error: 0.8645\n",
            "Epoch 25/1000\n",
            "1885/1885 [==============================] - 24s 12ms/step - loss: 0.8631 - mean_squared_error: 0.8631 - val_loss: 0.8682 - val_mean_squared_error: 0.8682\n",
            "Epoch 26/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8626 - mean_squared_error: 0.8626 - val_loss: 0.8653 - val_mean_squared_error: 0.8653\n",
            "Epoch 27/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8616 - mean_squared_error: 0.8616 - val_loss: 0.8722 - val_mean_squared_error: 0.8722\n",
            "Epoch 28/1000\n",
            "1885/1885 [==============================] - 23s 12ms/step - loss: 0.8615 - mean_squared_error: 0.8615 - val_loss: 0.8646 - val_mean_squared_error: 0.8646\n",
            "Epoch 29/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8619 - mean_squared_error: 0.8619 - val_loss: 0.8649 - val_mean_squared_error: 0.8649\n",
            "Epoch 30/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8613 - mean_squared_error: 0.8613 - val_loss: 0.8645 - val_mean_squared_error: 0.8645\n",
            "Epoch 31/1000\n",
            "1885/1885 [==============================] - 23s 12ms/step - loss: 0.8615 - mean_squared_error: 0.8615 - val_loss: 0.8659 - val_mean_squared_error: 0.8659\n",
            "Epoch 32/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8622 - mean_squared_error: 0.8622 - val_loss: 0.8673 - val_mean_squared_error: 0.8673\n",
            "Epoch 33/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8610 - mean_squared_error: 0.8610 - val_loss: 0.8663 - val_mean_squared_error: 0.8663\n",
            "Epoch 34/1000\n",
            "1885/1885 [==============================] - 23s 12ms/step - loss: 0.8609 - mean_squared_error: 0.8609 - val_loss: 0.8663 - val_mean_squared_error: 0.8663\n",
            "Epoch 35/1000\n",
            "1885/1885 [==============================] - 26s 14ms/step - loss: 0.8610 - mean_squared_error: 0.8610 - val_loss: 0.8658 - val_mean_squared_error: 0.8658\n",
            "Epoch 36/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8607 - mean_squared_error: 0.8607 - val_loss: 0.8653 - val_mean_squared_error: 0.8653\n",
            "Epoch 37/1000\n",
            "1885/1885 [==============================] - 23s 12ms/step - loss: 0.8611 - mean_squared_error: 0.8611 - val_loss: 0.8656 - val_mean_squared_error: 0.8656\n",
            "Epoch 38/1000\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8603 - mean_squared_error: 0.8603 - val_loss: 0.8678 - val_mean_squared_error: 0.8678\n",
            "Epoch 39/1000\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8604 - mean_squared_error: 0.8604 - val_loss: 0.8648 - val_mean_squared_error: 0.8648\n",
            "Epoch 40/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8605 - mean_squared_error: 0.8605 - val_loss: 0.8661 - val_mean_squared_error: 0.8661\n",
            "Epoch 41/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8604 - mean_squared_error: 0.8604 - val_loss: 0.8652 - val_mean_squared_error: 0.8652\n",
            "Epoch 42/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8598 - mean_squared_error: 0.8598 - val_loss: 0.8650 - val_mean_squared_error: 0.8650\n",
            "Epoch 43/1000\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8599 - mean_squared_error: 0.8599 - val_loss: 0.8704 - val_mean_squared_error: 0.8704\n",
            "Epoch 44/1000\n",
            "1885/1885 [==============================] - 23s 12ms/step - loss: 0.8599 - mean_squared_error: 0.8599 - val_loss: 0.8672 - val_mean_squared_error: 0.8672\n",
            "Epoch 45/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8598 - mean_squared_error: 0.8598 - val_loss: 0.8669 - val_mean_squared_error: 0.8669\n",
            "Epoch 46/1000\n",
            "1885/1885 [==============================] - 27s 14ms/step - loss: 0.8597 - mean_squared_error: 0.8597 - val_loss: 0.8645 - val_mean_squared_error: 0.8645\n",
            "Epoch 47/1000\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8590 - mean_squared_error: 0.8590 - val_loss: 0.8688 - val_mean_squared_error: 0.8688\n",
            "Epoch 48/1000\n",
            "1885/1885 [==============================] - 23s 12ms/step - loss: 0.8588 - mean_squared_error: 0.8588 - val_loss: 0.8694 - val_mean_squared_error: 0.8694\n",
            "Epoch 49/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8597 - mean_squared_error: 0.8597 - val_loss: 0.8656 - val_mean_squared_error: 0.8656\n",
            "Epoch 50/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8594 - mean_squared_error: 0.8594 - val_loss: 0.8657 - val_mean_squared_error: 0.8657\n",
            "Epoch 51/1000\n",
            "1885/1885 [==============================] - 23s 12ms/step - loss: 0.8583 - mean_squared_error: 0.8583 - val_loss: 0.8645 - val_mean_squared_error: 0.8645\n",
            "Epoch 52/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8582 - mean_squared_error: 0.8582 - val_loss: 0.8664 - val_mean_squared_error: 0.8664\n",
            "Epoch 53/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8583 - mean_squared_error: 0.8583 - val_loss: 0.8654 - val_mean_squared_error: 0.8654\n",
            "Epoch 54/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8589 - mean_squared_error: 0.8589 - val_loss: 0.8648 - val_mean_squared_error: 0.8648\n",
            "Epoch 55/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8589 - mean_squared_error: 0.8589 - val_loss: 0.8658 - val_mean_squared_error: 0.8658\n",
            "Epoch 56/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8587 - mean_squared_error: 0.8587 - val_loss: 0.8648 - val_mean_squared_error: 0.8648\n",
            "Epoch 57/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8588 - mean_squared_error: 0.8588 - val_loss: 0.8678 - val_mean_squared_error: 0.8678\n",
            "Epoch 58/1000\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8588 - mean_squared_error: 0.8588 - val_loss: 0.8661 - val_mean_squared_error: 0.8661\n",
            "Epoch 59/1000\n",
            "1885/1885 [==============================] - 24s 12ms/step - loss: 0.8582 - mean_squared_error: 0.8582 - val_loss: 0.8644 - val_mean_squared_error: 0.8644\n",
            "Epoch 60/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8591 - mean_squared_error: 0.8591 - val_loss: 0.8659 - val_mean_squared_error: 0.8659\n",
            "Epoch 61/1000\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8590 - mean_squared_error: 0.8590 - val_loss: 0.8654 - val_mean_squared_error: 0.8654\n",
            "Epoch 62/1000\n",
            "1885/1885 [==============================] - 23s 12ms/step - loss: 0.8585 - mean_squared_error: 0.8585 - val_loss: 0.8658 - val_mean_squared_error: 0.8658\n",
            "Epoch 63/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8588 - mean_squared_error: 0.8588 - val_loss: 0.8648 - val_mean_squared_error: 0.8648\n",
            "Epoch 64/1000\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8589 - mean_squared_error: 0.8589 - val_loss: 0.8656 - val_mean_squared_error: 0.8656\n",
            "Epoch 65/1000\n",
            "1885/1885 [==============================] - 23s 12ms/step - loss: 0.8581 - mean_squared_error: 0.8581 - val_loss: 0.8634 - val_mean_squared_error: 0.8634\n",
            "Epoch 66/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8579 - mean_squared_error: 0.8579 - val_loss: 0.8642 - val_mean_squared_error: 0.8642\n",
            "Epoch 67/1000\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8581 - mean_squared_error: 0.8581 - val_loss: 0.8658 - val_mean_squared_error: 0.8658\n",
            "Epoch 68/1000\n",
            "1885/1885 [==============================] - 23s 12ms/step - loss: 0.8583 - mean_squared_error: 0.8583 - val_loss: 0.8661 - val_mean_squared_error: 0.8661\n",
            "Epoch 69/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8584 - mean_squared_error: 0.8584 - val_loss: 0.8647 - val_mean_squared_error: 0.8647\n",
            "Epoch 70/1000\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8580 - mean_squared_error: 0.8580 - val_loss: 0.8657 - val_mean_squared_error: 0.8657\n",
            "Epoch 71/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8582 - mean_squared_error: 0.8582 - val_loss: 0.8644 - val_mean_squared_error: 0.8644\n",
            "Epoch 72/1000\n",
            "1885/1885 [==============================] - 23s 12ms/step - loss: 0.8580 - mean_squared_error: 0.8580 - val_loss: 0.8658 - val_mean_squared_error: 0.8658\n",
            "Epoch 73/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8580 - mean_squared_error: 0.8580 - val_loss: 0.8650 - val_mean_squared_error: 0.8650\n",
            "Epoch 74/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8580 - mean_squared_error: 0.8580 - val_loss: 0.8652 - val_mean_squared_error: 0.8652\n",
            "Epoch 75/1000\n",
            "1885/1885 [==============================] - 23s 12ms/step - loss: 0.8587 - mean_squared_error: 0.8587 - val_loss: 0.8667 - val_mean_squared_error: 0.8667\n",
            "Epoch 76/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8574 - mean_squared_error: 0.8574 - val_loss: 0.8657 - val_mean_squared_error: 0.8657\n",
            "Epoch 77/1000\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8573 - mean_squared_error: 0.8573 - val_loss: 0.8674 - val_mean_squared_error: 0.8674\n",
            "Epoch 78/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8575 - mean_squared_error: 0.8575 - val_loss: 0.8651 - val_mean_squared_error: 0.8651\n",
            "Epoch 79/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8583 - mean_squared_error: 0.8583 - val_loss: 0.8650 - val_mean_squared_error: 0.8650\n",
            "Epoch 80/1000\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8582 - mean_squared_error: 0.8582 - val_loss: 0.8641 - val_mean_squared_error: 0.8641\n",
            "Epoch 81/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8581 - mean_squared_error: 0.8581 - val_loss: 0.8644 - val_mean_squared_error: 0.8644\n",
            "Epoch 82/1000\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8576 - mean_squared_error: 0.8576 - val_loss: 0.8653 - val_mean_squared_error: 0.8653\n",
            "Epoch 83/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8575 - mean_squared_error: 0.8575 - val_loss: 0.8645 - val_mean_squared_error: 0.8645\n",
            "Epoch 84/1000\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8577 - mean_squared_error: 0.8577 - val_loss: 0.8641 - val_mean_squared_error: 0.8641\n",
            "Epoch 85/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8577 - mean_squared_error: 0.8577 - val_loss: 0.8643 - val_mean_squared_error: 0.8643\n",
            "Epoch 86/1000\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8574 - mean_squared_error: 0.8574 - val_loss: 0.8642 - val_mean_squared_error: 0.8642\n",
            "Epoch 87/1000\n",
            "1885/1885 [==============================] - 26s 14ms/step - loss: 0.8582 - mean_squared_error: 0.8582 - val_loss: 0.8642 - val_mean_squared_error: 0.8642\n",
            "Epoch 88/1000\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8569 - mean_squared_error: 0.8569 - val_loss: 0.8660 - val_mean_squared_error: 0.8660\n",
            "Epoch 89/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8568 - mean_squared_error: 0.8568 - val_loss: 0.8642 - val_mean_squared_error: 0.8642\n",
            "Epoch 90/1000\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8581 - mean_squared_error: 0.8581 - val_loss: 0.8636 - val_mean_squared_error: 0.8636\n",
            "Epoch 91/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8569 - mean_squared_error: 0.8569 - val_loss: 0.8646 - val_mean_squared_error: 0.8646\n",
            "Epoch 92/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8575 - mean_squared_error: 0.8575 - val_loss: 0.8652 - val_mean_squared_error: 0.8652\n",
            "Epoch 93/1000\n",
            "1885/1885 [==============================] - 26s 14ms/step - loss: 0.8571 - mean_squared_error: 0.8571 - val_loss: 0.8671 - val_mean_squared_error: 0.8671\n",
            "Epoch 94/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8566 - mean_squared_error: 0.8566 - val_loss: 0.8642 - val_mean_squared_error: 0.8642\n",
            "Epoch 95/1000\n",
            "1885/1885 [==============================] - 23s 12ms/step - loss: 0.8572 - mean_squared_error: 0.8572 - val_loss: 0.8662 - val_mean_squared_error: 0.8662\n",
            "Epoch 96/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8570 - mean_squared_error: 0.8570 - val_loss: 0.8647 - val_mean_squared_error: 0.8647\n",
            "Epoch 97/1000\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8567 - mean_squared_error: 0.8567 - val_loss: 0.8637 - val_mean_squared_error: 0.8637\n",
            "Epoch 98/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8569 - mean_squared_error: 0.8569 - val_loss: 0.8662 - val_mean_squared_error: 0.8662\n",
            "Epoch 99/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8572 - mean_squared_error: 0.8572 - val_loss: 0.8649 - val_mean_squared_error: 0.8649\n",
            "Epoch 100/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8579 - mean_squared_error: 0.8579 - val_loss: 0.8635 - val_mean_squared_error: 0.8635\n",
            "Epoch 101/1000\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8568 - mean_squared_error: 0.8568 - val_loss: 0.8653 - val_mean_squared_error: 0.8653\n",
            "Epoch 102/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8569 - mean_squared_error: 0.8569 - val_loss: 0.8657 - val_mean_squared_error: 0.8657\n",
            "Epoch 103/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8575 - mean_squared_error: 0.8575 - val_loss: 0.8656 - val_mean_squared_error: 0.8656\n",
            "Epoch 104/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8563 - mean_squared_error: 0.8563 - val_loss: 0.8635 - val_mean_squared_error: 0.8635\n",
            "Epoch 105/1000\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8563 - mean_squared_error: 0.8563 - val_loss: 0.8652 - val_mean_squared_error: 0.8652\n",
            "Epoch 106/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8566 - mean_squared_error: 0.8566 - val_loss: 0.8636 - val_mean_squared_error: 0.8636\n",
            "Epoch 107/1000\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8567 - mean_squared_error: 0.8567 - val_loss: 0.8646 - val_mean_squared_error: 0.8646\n",
            "Epoch 108/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8570 - mean_squared_error: 0.8570 - val_loss: 0.8669 - val_mean_squared_error: 0.8669\n",
            "Epoch 109/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8570 - mean_squared_error: 0.8570 - val_loss: 0.8644 - val_mean_squared_error: 0.8644\n",
            "Epoch 110/1000\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8565 - mean_squared_error: 0.8565 - val_loss: 0.8652 - val_mean_squared_error: 0.8652\n",
            "Epoch 111/1000\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8571 - mean_squared_error: 0.8571 - val_loss: 0.8643 - val_mean_squared_error: 0.8643\n",
            "Epoch 112/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8565 - mean_squared_error: 0.8565 - val_loss: 0.8640 - val_mean_squared_error: 0.8640\n",
            "Epoch 113/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8562 - mean_squared_error: 0.8562 - val_loss: 0.8649 - val_mean_squared_error: 0.8649\n",
            "Epoch 114/1000\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8571 - mean_squared_error: 0.8571 - val_loss: 0.8636 - val_mean_squared_error: 0.8636\n",
            "Epoch 115/1000\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8560 - mean_squared_error: 0.8560 - val_loss: 0.8658 - val_mean_squared_error: 0.8658\n",
            "Epoch 116/1000\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8565 - mean_squared_error: 0.8565 - val_loss: 0.8655 - val_mean_squared_error: 0.8655\n",
            "Epoch 117/1000\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8565 - mean_squared_error: 0.8565 - val_loss: 0.8646 - val_mean_squared_error: 0.8646\n",
            "Epoch 118/1000\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8560 - mean_squared_error: 0.8560 - val_loss: 0.8654 - val_mean_squared_error: 0.8654\n",
            "Epoch 119/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8564 - mean_squared_error: 0.8564 - val_loss: 0.8661 - val_mean_squared_error: 0.8661\n",
            "Epoch 120/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8561 - mean_squared_error: 0.8561 - val_loss: 0.8645 - val_mean_squared_error: 0.8645\n",
            "Epoch 121/1000\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8562 - mean_squared_error: 0.8562 - val_loss: 0.8650 - val_mean_squared_error: 0.8650\n",
            "Epoch 122/1000\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8564 - mean_squared_error: 0.8564 - val_loss: 0.8643 - val_mean_squared_error: 0.8643\n",
            "Epoch 123/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8567 - mean_squared_error: 0.8567 - val_loss: 0.8672 - val_mean_squared_error: 0.8672\n",
            "Epoch 124/1000\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8559 - mean_squared_error: 0.8559 - val_loss: 0.8649 - val_mean_squared_error: 0.8649\n",
            "Epoch 125/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8565 - mean_squared_error: 0.8565 - val_loss: 0.8650 - val_mean_squared_error: 0.8650\n",
            "Epoch 126/1000\n",
            "1885/1885 [==============================] - 23s 12ms/step - loss: 0.8565 - mean_squared_error: 0.8565 - val_loss: 0.8670 - val_mean_squared_error: 0.8670\n",
            "Epoch 127/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8568 - mean_squared_error: 0.8568 - val_loss: 0.8648 - val_mean_squared_error: 0.8648\n",
            "Epoch 128/1000\n",
            "1885/1885 [==============================] - 26s 14ms/step - loss: 0.8554 - mean_squared_error: 0.8554 - val_loss: 0.8644 - val_mean_squared_error: 0.8644\n",
            "Epoch 129/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8563 - mean_squared_error: 0.8563 - val_loss: 0.8643 - val_mean_squared_error: 0.8643\n",
            "Epoch 130/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8561 - mean_squared_error: 0.8561 - val_loss: 0.8658 - val_mean_squared_error: 0.8658\n",
            "Epoch 131/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8565 - mean_squared_error: 0.8565 - val_loss: 0.8643 - val_mean_squared_error: 0.8643\n",
            "Epoch 132/1000\n",
            "1885/1885 [==============================] - 26s 14ms/step - loss: 0.8560 - mean_squared_error: 0.8560 - val_loss: 0.8641 - val_mean_squared_error: 0.8641\n",
            "Epoch 133/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8555 - mean_squared_error: 0.8555 - val_loss: 0.8650 - val_mean_squared_error: 0.8650\n",
            "Epoch 134/1000\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8560 - mean_squared_error: 0.8560 - val_loss: 0.8648 - val_mean_squared_error: 0.8648\n",
            "Epoch 135/1000\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8558 - mean_squared_error: 0.8558 - val_loss: 0.8636 - val_mean_squared_error: 0.8636\n",
            "Epoch 136/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8565 - mean_squared_error: 0.8565 - val_loss: 0.8646 - val_mean_squared_error: 0.8646\n",
            "Epoch 137/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8560 - mean_squared_error: 0.8560 - val_loss: 0.8669 - val_mean_squared_error: 0.8669\n",
            "Epoch 138/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8564 - mean_squared_error: 0.8564 - val_loss: 0.8652 - val_mean_squared_error: 0.8652\n",
            "Epoch 139/1000\n",
            "1885/1885 [==============================] - 26s 14ms/step - loss: 0.8558 - mean_squared_error: 0.8558 - val_loss: 0.8660 - val_mean_squared_error: 0.8660\n",
            "Epoch 140/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8560 - mean_squared_error: 0.8560 - val_loss: 0.8655 - val_mean_squared_error: 0.8655\n",
            "Epoch 141/1000\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8563 - mean_squared_error: 0.8563 - val_loss: 0.8636 - val_mean_squared_error: 0.8636\n",
            "Epoch 142/1000\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8560 - mean_squared_error: 0.8560 - val_loss: 0.8724 - val_mean_squared_error: 0.8724\n",
            "Epoch 143/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8559 - mean_squared_error: 0.8559 - val_loss: 0.8640 - val_mean_squared_error: 0.8640\n",
            "Epoch 144/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8565 - mean_squared_error: 0.8565 - val_loss: 0.8663 - val_mean_squared_error: 0.8663\n",
            "Epoch 145/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8559 - mean_squared_error: 0.8559 - val_loss: 0.8656 - val_mean_squared_error: 0.8656\n",
            "Epoch 146/1000\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8559 - mean_squared_error: 0.8559 - val_loss: 0.8645 - val_mean_squared_error: 0.8645\n",
            "Epoch 147/1000\n",
            "1885/1885 [==============================] - 23s 12ms/step - loss: 0.8556 - mean_squared_error: 0.8556 - val_loss: 0.8676 - val_mean_squared_error: 0.8676\n",
            "Epoch 148/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8562 - mean_squared_error: 0.8562 - val_loss: 0.8645 - val_mean_squared_error: 0.8645\n",
            "Epoch 149/1000\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8555 - mean_squared_error: 0.8555 - val_loss: 0.8646 - val_mean_squared_error: 0.8646\n",
            "Epoch 150/1000\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8558 - mean_squared_error: 0.8558 - val_loss: 0.8633 - val_mean_squared_error: 0.8633\n",
            "Epoch 151/1000\n",
            "1885/1885 [==============================] - 26s 14ms/step - loss: 0.8554 - mean_squared_error: 0.8554 - val_loss: 0.8651 - val_mean_squared_error: 0.8651\n",
            "Epoch 152/1000\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8554 - mean_squared_error: 0.8554 - val_loss: 0.8642 - val_mean_squared_error: 0.8642\n",
            "Epoch 153/1000\n",
            "1885/1885 [==============================] - 26s 14ms/step - loss: 0.8561 - mean_squared_error: 0.8561 - val_loss: 0.8670 - val_mean_squared_error: 0.8670\n",
            "Epoch 154/1000\n",
            "1885/1885 [==============================] - 26s 14ms/step - loss: 0.8557 - mean_squared_error: 0.8557 - val_loss: 0.8657 - val_mean_squared_error: 0.8657\n",
            "Epoch 155/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8559 - mean_squared_error: 0.8559 - val_loss: 0.8666 - val_mean_squared_error: 0.8666\n",
            "Epoch 156/1000\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8562 - mean_squared_error: 0.8562 - val_loss: 0.8644 - val_mean_squared_error: 0.8644\n",
            "Epoch 157/1000\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8558 - mean_squared_error: 0.8558 - val_loss: 0.8653 - val_mean_squared_error: 0.8653\n",
            "Epoch 158/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8554 - mean_squared_error: 0.8554 - val_loss: 0.8632 - val_mean_squared_error: 0.8632\n",
            "Epoch 159/1000\n",
            "1885/1885 [==============================] - 24s 12ms/step - loss: 0.8554 - mean_squared_error: 0.8554 - val_loss: 0.8662 - val_mean_squared_error: 0.8662\n",
            "Epoch 160/1000\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8560 - mean_squared_error: 0.8560 - val_loss: 0.8638 - val_mean_squared_error: 0.8638\n",
            "Epoch 161/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8557 - mean_squared_error: 0.8557 - val_loss: 0.8638 - val_mean_squared_error: 0.8638\n",
            "Epoch 162/1000\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8551 - mean_squared_error: 0.8551 - val_loss: 0.8642 - val_mean_squared_error: 0.8642\n",
            "Epoch 163/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8551 - mean_squared_error: 0.8551 - val_loss: 0.8635 - val_mean_squared_error: 0.8635\n",
            "Epoch 164/1000\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8551 - mean_squared_error: 0.8551 - val_loss: 0.8632 - val_mean_squared_error: 0.8632\n",
            "Epoch 165/1000\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8551 - mean_squared_error: 0.8551 - val_loss: 0.8617 - val_mean_squared_error: 0.8617\n",
            "Epoch 166/1000\n",
            "1687/1885 [=========================>....] - ETA: 2s - loss: 0.8543 - mean_squared_error: 0.8543"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-1728ae5123cc>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m history=model.fit( x_train,y_train,\n\u001b[0m\u001b[1;32m      9\u001b[0m                  \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import math\n",
        "import plotly.graph_objects as go\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, RepeatVector, TimeDistributed, Input\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import keras.backend as K\n",
        "from keras.callbacks import Callback\n",
        "import plotly\n",
        "import plotly.express as px # for data visualization\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import IsolationForest\n",
        "#from keras import ops\n",
        "\n",
        "generator_multiply = 4 #each input record will generate 100 random vectors from the latent space, given the mu and sigma generated by the encoder\n",
        "\n",
        "\n",
        "train_data = np.load(r'/content/drive/MyDrive/PHD/2024/multivariate_long_sequences-TRAIN_hourly.npy') #------for Hourly data\n",
        "index = 500\n",
        "#We missed i=500 from processing the iosw. So here we are dropping row with index =500\n",
        "train_data= np.delete(train_data, index, axis=0)\n",
        "\n",
        "window_label = np.load(r'/content/drive/MyDrive/PHD/2024/multivariate_long_sequences_WINDOW-TRAIN_hourly.npy')\n",
        "n_seq = train_data.shape[0]\n",
        "window_size = train_data.shape[1]\n",
        "n_features = train_data.shape[2]\n",
        "\n",
        "\n",
        "##---------------------------IGNORE THIS IF NOT GENERATING FRESH VAE DATASET--------------------------------------------------------------------------------------------\n",
        "encoder = keras.models.load_model(r'/content/drive/MyDrive/PHD/2024/VAE_SIMULATION/vae-encoder-saved-hourly-latent10-dim128-latest.model')\n",
        "decoder = keras.models.load_model(r'/content/drive/MyDrive/PHD/2024/VAE_SIMULATION/vae-decoder-saved-hourly-latent10-dim128-latest.model')\n",
        "\n",
        "X_train_encoded = encoder.predict(train_data)\n",
        "mu, logvar, z = X_train_encoded\n",
        "sigma = tf.exp(0.5 * logvar)\n",
        "batch = tf.shape(mu)[0]  #number of recors / batchs\n",
        "dim = tf.shape(mu)[1] #Ndimension of latent variable\n",
        "store = list()\n",
        "storetemp = list()\n",
        "\n",
        "#For each batch, iterate, get the generator_multipy number of latent vectors with same window_size.\n",
        "#For each z, concatenate z_mean, so it will become 100 dimensional vector\n",
        "\n",
        "for i in range(0,batch):\n",
        "  all_Z_i = tf.random.normal(shape=(generator_multiply,dim), mean = mu[i,:], stddev=sigma[i,:]) #all randorm vectors for this record i\n",
        "  X_train_decoded = decoder.predict(all_Z_i)\n",
        "  X_train_decoded = X_train_decoded.reshape((X_train_decoded.shape[0],window_size*n_features))\n",
        "  a = np.arange(generator_multiply)\n",
        "  a.fill(window_label[i])\n",
        "  c=np.concatenate(((X_train_decoded,a[:,None])),axis=1)\n",
        "  store.append(c)\n",
        "\n",
        "results1=np.concatenate(store,axis=0)\n",
        "np.save(r'/content/drive/MyDrive/PHD/2024/labelled_subsquence_data_hourly_X4',results1)\n",
        "\n",
        "#----------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "results1=np.load(r'/content/drive/MyDrive/PHD/2024/labelled_subsquence_data_hourly_X4.npy')\n",
        "\n",
        "x=results1[:,:-1]\n",
        "y=results1[:,window_size*n_features]\n",
        "\n",
        "#maxval = x.shape[0]\n",
        "#count_train = int(math.ceil(0.9*maxval))\n",
        "#x_train = x[:count_train]\n",
        "#x_test = x[count_train:]\n",
        "\n",
        "#y_train = y[:count_train]\n",
        "#y_test = y[count_train:]\n",
        "\n",
        "\n",
        "from sklearn.ensemble import IsolationForest\n",
        "iso = IsolationForest(contamination=0.4)\n",
        "yhat = iso.fit_predict(x)\n",
        "# select all rows that are not outliers\n",
        "mask = yhat != -1\n",
        "x, y = x[mask, :], y[mask]\n",
        "\n",
        "\n",
        "###############Scale the target and then split the data into train test----------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "transformer = StandardScaler()\n",
        "y_transformed = transformer.fit_transform(y.reshape(-1,1)).flatten()\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y_transformed, test_size = 0.1, random_state = 42)\n",
        "\n",
        "#--------------------------------------------------------------------------------------CONSTRUCT, COMPILE, AND TRAIN THE MODEL------------------------------------------------------------------------------------------------------------------\n",
        "#------------MLP------------------------------------------------------\n",
        "#x_train = x_train.reshape(x_train.shape[0],x_train.shape[1],1)\n",
        "#x_test = x_test.reshape(x_test.shape[0],x_test.shape[1],1)\n",
        "from keras.layers import LeakyReLU\n",
        "\n",
        "model = Sequential()\n",
        "#model.add(Dense(units = 128))\n",
        "#model.add(LeakyReLU(alpha=0.1))\n",
        "#model.add(Dense(units = 64))\n",
        "#model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(Dense(units = 32))\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(Dense(units = 16))\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(Dense(units = 8))\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "\n",
        "model.add(Dense(units = 1, activation = 'linear'))\n",
        "\n",
        "model.summary()\n",
        "#--------------------------------------------------------------LSTM--------------------------\n",
        "\n",
        "a =  x_train.reshape((x_train.shape[0], window_size, n_features))  #DONT RUN IF MLP\n",
        "b =  x_test.reshape((x_test.shape[0], window_size, n_features))    #DONT RUN IF MLP\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(16, input_shape=(a.shape[1],a.shape[2]),return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(16))\n",
        "model.add(Dropout(0.2))\n",
        "#model.add(Dense(units = 1024))\n",
        "#model.add(LeakyReLU(alpha=0.1))\n",
        "#model.add(Dense(units = 512))\n",
        "#model.add(LeakyReLU(alpha=0.1))\n",
        "#model.add(Dense(units = 512))\n",
        "#model.add(LeakyReLU(alpha=0.1))\n",
        "#model.add(Dense(units = 256))\n",
        "#model.add(LeakyReLU(alpha=0.1))\n",
        "\n",
        "model.add(Dense(units = 8))\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "#model.add(Dense(units = 16))\n",
        "#model.add(LeakyReLU(alpha=0.01))\n",
        "#model.add(Dense(units = 8))\n",
        "#model.add(LeakyReLU(alpha=0.01))\n",
        "#model.add(Dense(units = 4))\n",
        "#model.add(LeakyReLU(alpha=0.01))\n",
        "model.add(Dense(units = 1, activation = 'linear'))\n",
        "model.summary()\n",
        "x_train = a\n",
        "x_test = b\n",
        "#-------------------------------------------------------------------------------------\n",
        "\n",
        "optimizr = keras.optimizers.Adam(learning_rate=0.001,clipnorm=1)\n",
        "model.compile(loss='mean_squared_error', optimizer= optimizr, metrics=['mean_squared_error'])\n",
        "\n",
        "#reduce_lr = tf.keras.callbacks.LearningRateScheduler(lambda x: 1e-3 * 0.90 ** x)\n",
        "es = keras.callbacks.EarlyStopping(patience=20, verbose=1, min_delta=0.0001, monitor='loss', mode='auto', restore_best_weights=True)\n",
        "n_epochs = 1000\n",
        "\n",
        "history=model.fit( x_train,y_train,\n",
        "                 epochs=n_epochs,\n",
        "                 batch_size=32,\n",
        "                   #validation_data=(x_val,y_val),\n",
        "                   validation_split=0.1,\n",
        "                   verbose=1)\n",
        "               # callbacks=[es])\n",
        "\n",
        "#-----------------------------------------------------TRAIN EVALUATION----------------------------------------------------------------\n",
        "y_train_pred_raw = model.predict(x_train)\n",
        "y_train_pred = transformer.inverse_transform(y_train_pred_raw)\n",
        "y_train_true = transformer.inverse_transform(y_train.reshape(-1,1)).flatten()\n",
        "\n",
        "score_train= r2_score(y_train_true,y_train_pred)\n",
        "print(\"r2 score is ==\",score_train)\n",
        "\n",
        "plt.plot(y_train_true[0:100], color = 'red', label = 'Real data')\n",
        "plt.plot(y_train_pred[0:100], color = 'blue', label = 'Predicted data')\n",
        "plt.title('Prediction')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#-----------------------------------------------------TEST EVALUATION----------------------------------------------------------------\n",
        "\n",
        "y_pred_raw = model.predict(x_test)\n",
        "y_test_pred = transformer.inverse_transform(y_pred_raw)\n",
        "y_test_true = transformer.inverse_transform(y_test.reshape(-1,1)).flatten()\n",
        "\n",
        "\n",
        "\n",
        "score= r2_score(y_test_true,y_test_pred)\n",
        "print(\"r2 score is ==\",score)\n",
        "\n",
        "\n",
        "plt.plot(y_test_true[100:150], color = 'red', label = 'Real data')\n",
        "plt.plot(y_test_pred[100:150], color = 'blue', label = 'Predicted data')\n",
        "plt.title('Prediction')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#------------------------------------------------------SAVE MODEL AND RESULTS-----------------------------------------------------------------\n",
        "\n",
        "model.save(r'/content/drive/MyDrive/PHD/2024/DGRNet-MLP-Versions/MLP_model_hourly.keras')\n",
        "# It can be used to reconstruct the model identically.\n",
        "reconstructed_model = keras.models.load_model(r'/content/drive/MyDrive/PHD/2024/DGRNet-MLP-Versions/MLP_model_hourly.keras')\n",
        "\n",
        "# Let's check:\n",
        "np.testing.assert_allclose(\n",
        "    model.predict(test_input), reconstructed_model.predict(test_input)\n",
        ")\n",
        "\n",
        "\n",
        "np.savetxt(r'/content/drive/MyDrive/PHD/2024/MLPOutput/preduber_2.csv',y_pred)\n",
        "np.savetxt(r'/content/drive/MyDrive/PHD/2024/MLPOutput/realuber_2.csv',y_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "v_5iji919H_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8OtWHK--uG6W"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/supriyag123/PHD_Pub/blob/main/DGRNet%20STEP3-%20Hourly%20Data%20-%20MLP-%20Final.ipynb",
      "authorship_tag": "ABX9TyP5rTBMXF02O7mWXIflcMX9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}