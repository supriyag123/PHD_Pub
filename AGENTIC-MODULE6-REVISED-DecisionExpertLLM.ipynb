{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supriyag123/PHD_Pub/blob/main/AGENTIC-MODULE6-REVISED-DecisionExpertLLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoP7OuWNxlsJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "183ff777-1252-4395-9432-8366eb943b4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total main: (2127, 50, 12) (2127,)\n",
            "Holdout: (1500, 50, 12) (1500,)\n",
            "Data loaded: (2127, 50, 12) (2127,)\n",
            "Train: (1563, 50, 12) (1563,)\n",
            "Test: (564, 50, 12) (564,)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# ============================================================\n",
        "# Fault Classification Pipeline\n",
        "# ============================================================\n",
        "\n",
        "############PASTE ADAPTIVE WINDOW HERE - so everything is in one file - later, we can import as a package#####################\n",
        "\n",
        "\n",
        "# ====== AdaptiveWindowAgent ======\n",
        "# =====================================================\n",
        "# AdaptiveWindowAgent (improved version)\n",
        "# =====================================================\n",
        "# agents/adaptive_window_agent.py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import json\n",
        "import os\n",
        "from collections import deque\n",
        "from typing import Dict, Any\n",
        "import datetime as dt\n",
        "import logging\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor  # ✅ MOVED TO TOP\n",
        "from statsmodels.tsa.vector_ar.var_model import VAR\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from datetime import datetime\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "import sqlite3\n",
        "import json\n",
        "from datetime import datetime\n",
        "import json\n",
        "\n",
        "\n",
        "class EventStore:\n",
        "    def __init__(self, db_path=\"event_store.db\"):\n",
        "        self.conn = sqlite3.connect(db_path)\n",
        "        self._init_tables()\n",
        "\n",
        "    def _init_tables(self):\n",
        "        c = self.conn.cursor()\n",
        "        c.execute(\"\"\"\n",
        "            CREATE TABLE IF NOT EXISTS events (\n",
        "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "                timestamp TEXT,\n",
        "                event_type TEXT,\n",
        "                packet_json TEXT,\n",
        "                expert_json TEXT,\n",
        "                human_json TEXT\n",
        "            )\n",
        "        \"\"\")\n",
        "        self.conn.commit()\n",
        "\n",
        "    def save_event(self, event_type, packet, expert=None, human=None):\n",
        "        c = self.conn.cursor()\n",
        "        c.execute(\n",
        "            \"INSERT INTO events(timestamp,event_type,packet_json,expert_json,human_json) VALUES (?,?,?,?,?)\",\n",
        "            (\n",
        "                datetime.now().isoformat(),\n",
        "                event_type,\n",
        "                json.dumps(packet, default=str),\n",
        "                json.dumps(expert, default=str) if expert else None,\n",
        "                json.dumps(human, default=str) if human else None,\n",
        "            )\n",
        "        )\n",
        "        self.conn.commit()\n",
        "\n",
        "    def fetch_recent(self, limit=100):\n",
        "        c = self.conn.cursor()\n",
        "        c.execute(\"SELECT packet_json, expert_json, human_json FROM events ORDER BY id DESC LIMIT ?\", (limit,))\n",
        "        return [json.loads(row[0]) for row in c.fetchall()]\n",
        "\n",
        "#########################################################################\n",
        "# Window Agent - Global Context or Global Predictive Context\n",
        "#########################################################################\n",
        "\n",
        "class AdaptiveWindowAgent:\n",
        "    \"\"\"\n",
        "    Adaptive Window Agent:\n",
        "    - Predicts window size using MLP\n",
        "    - Evaluates forecast with RF/persistence\n",
        "    - Computes:\n",
        "        * FDS: Forecast Deviation Score (normalized error)\n",
        "        * FDI: Forecast Drift Index (JSD over FDS distribution)\n",
        "        * WSS: Window Shift Score (normalized window size)\n",
        "        * WDI: Window Drift Index (JSD over window size distribution)\n",
        "    - Detects anomaly (local) + drift (regime) events.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, agent_id=\"adaptive_window_agent\",\n",
        "                 model_path=None, checkpoint_path=None):\n",
        "        self.agent_id = agent_id\n",
        "        self.model_path = model_path or \"/content/drive/MyDrive/PHD/2025/DGRNet-MLP-Versions/METROPM_MLP_model_10Sec.keras\"\n",
        "\n",
        "        self.baseline_path = \"/content/drive/MyDrive/PHD/2025/DGRNet-MLP-Versions/METROPM_MLP_baseline.pkl\"\n",
        "        self.checkpoint_path = checkpoint_path\n",
        "\n",
        "        # --------------------------------------------------\n",
        "        # Core model\n",
        "        # --------------------------------------------------\n",
        "        self.model = None\n",
        "        self.transformer = StandardScaler()\n",
        "        self.transformer_fitted = False\n",
        "        self.is_model_loaded = False\n",
        "\n",
        "        # Baseline error stats (median / MAD) – filled from baseline file\n",
        "        self.rolling_stats = {\n",
        "            'median': 0.0,\n",
        "            'mad': 1.0,\n",
        "        }\n",
        "\n",
        "        # --------------------------------------------------\n",
        "        # Metrics memory\n",
        "        # --------------------------------------------------\n",
        "        # Raw error\n",
        "        self.error_memory = deque(maxlen=300)     # long-term errors\n",
        "        self.recent_errors = deque(maxlen=50)     # kept for backward compat (not central now)\n",
        "\n",
        "        # FDS (Forecast Deviation Score) history\n",
        "        self.fds_memory = deque(maxlen=300)\n",
        "        self.recent_fds = deque(maxlen=50)\n",
        "\n",
        "        # Window history\n",
        "        self.window_memory = deque(maxlen=300)\n",
        "        self.recent_windows = deque(maxlen=50)\n",
        "\n",
        "        # Last-step metrics (for returning)\n",
        "        self.last_fds = 0.0\n",
        "        self.last_fdi = 0.0\n",
        "        self.last_wss = 0.0\n",
        "        self.last_wdi = 0.0\n",
        "\n",
        "        # Baseline distributions\n",
        "        self.baseline_errors = None\n",
        "        self.baseline_fds = None\n",
        "        self.baseline_windows = None\n",
        "        self.window_mean = 50.0    # a reasonable mid value\n",
        "        self.window_std = 10.0     # non-zero, avoids div-by-zero\n",
        "\n",
        "        # Optional histogram bins stored in baseline\n",
        "        self.window_hist_bins = None\n",
        "        self.window_hist_counts = None\n",
        "\n",
        "        # Debug flag (OFF by default)\n",
        "        self.debug = False\n",
        "\n",
        "        # --------------------------------------------------\n",
        "        # Anomaly / drift settings\n",
        "        # --------------------------------------------------\n",
        "        self.threshold_k = 3.0\n",
        "        self.anomaly_cooldown = 0\n",
        "        self.anomaly_cooldown_steps = 5\n",
        "\n",
        "        # Drift detection\n",
        "        self.drift_threshold = 0.25          # for FDI (JSD over FDS)\n",
        "        self.window_drift_threshold = 0.20   # for WDI (JSD over window sizes)\n",
        "        self.consecutive_drift_votes = 0\n",
        "        self.drift_cooldown = 0\n",
        "        self.drift_votes_required = 10\n",
        "        self.drift_cooldown_steps = 100\n",
        "\n",
        "        # --------------------------------------------------\n",
        "        # Retraining buffer (unchanged)\n",
        "        # --------------------------------------------------\n",
        "        self.performance_stats = {\n",
        "            'total_predictions': 0,\n",
        "            'avg_mse': 0.0,\n",
        "            'avg_mae': 0.0,\n",
        "            'last_retrain_time': None,\n",
        "            'drift_events': 0,\n",
        "            'anomaly_events': 0,\n",
        "            'retraining_events': 0\n",
        "        }\n",
        "\n",
        "        self.retraining_data = {\n",
        "            'x_buffer': deque(maxlen=10000),\n",
        "            'y_buffer': deque(maxlen=10000)\n",
        "        }\n",
        "\n",
        "        # --------------------------------------------------\n",
        "        # Prediction history (for reporting)\n",
        "        # --------------------------------------------------\n",
        "        self.prediction_history = deque(maxlen=1000)\n",
        "        self.mse_history = deque(maxlen=200)\n",
        "        self.mae_history = deque(maxlen=200)\n",
        "\n",
        "        # --------------------------------------------------\n",
        "        # Load baseline (errors + windows)\n",
        "        # --------------------------------------------------\n",
        "        self._load_baseline()\n",
        "\n",
        "        # --------------------------------------------------\n",
        "        # Load model last\n",
        "        # --------------------------------------------------\n",
        "        self.load_model()\n",
        "        print(f\"AdaptiveWindowAgent {self.agent_id} initialized\")\n",
        "\n",
        "        # --------------------------------------------------\n",
        "        # Load NSP (Next-Step Predictor)\n",
        "        # --------------------------------------------------\n",
        "        self.nsp_model_path = \"/content/drive/MyDrive/PHD/2025/NSP_LSTM_next_step.keras\"\n",
        "        self.nsp_model = keras.models.load_model(self.nsp_model_path)\n",
        "        print(\"✅ Loaded NSP LSTM next-step predictor\")\n",
        "\n",
        "    # =================== BASELINE LOADING ===================\n",
        "\n",
        "    def _load_baseline(self):\n",
        "        \"\"\"\n",
        "        Load baseline stats:\n",
        "          - baseline_errors, median, mad\n",
        "          - baseline_windows, window_mean, window_std\n",
        "          - optional histogram bins/counts for windows\n",
        "        \"\"\"\n",
        "        if os.path.exists(self.baseline_path):\n",
        "            with open(self.baseline_path, \"rb\") as f:\n",
        "                base = pickle.load(f)\n",
        "\n",
        "            # Error baseline\n",
        "            self.baseline_errors = np.array(base[\"baseline_errors\"])\n",
        "            self.rolling_stats[\"median\"] = base[\"median\"]\n",
        "            self.rolling_stats[\"mad\"] = base[\"mad\"]\n",
        "\n",
        "            # Precompute baseline FDS distribution\n",
        "            med = self.rolling_stats[\"median\"]\n",
        "            mad = self.rolling_stats[\"mad\"] if self.rolling_stats[\"mad\"] > 0 else 1e-6\n",
        "            self.baseline_fds = (self.baseline_errors - med) / (mad + 1e-8)\n",
        "\n",
        "            # Window baseline (may or may not exist)\n",
        "            if \"baseline_windows\" in base:\n",
        "                self.baseline_windows = np.array(base[\"baseline_windows\"])\n",
        "                self.window_mean = float(base.get(\"window_mean\", np.mean(self.baseline_windows)))\n",
        "                self.window_std = float(base.get(\"window_std\", np.std(self.baseline_windows) + 1e-8))\n",
        "                self.window_hist_bins = np.array(base.get(\"window_hist_bins\", [])) if \"window_hist_bins\" in base else None\n",
        "                self.window_hist_counts = np.array(base.get(\"window_hist_counts\", [])) if \"window_hist_counts\" in base else None\n",
        "            else:\n",
        "                self.baseline_windows = None\n",
        "                self.window_mean = 0.0\n",
        "                self.window_std = 1.0\n",
        "                self.window_hist_bins = None\n",
        "                self.window_hist_counts = None\n",
        "\n",
        "            print(\"✅ Loaded baseline error + window distribution.\")\n",
        "            print(f\"   Error median={self.rolling_stats['median']:.6f}, MAD={self.rolling_stats['mad']:.6f}\")\n",
        "            if self.baseline_windows is not None:\n",
        "                print(f\"   Window mean={self.window_mean:.3f}, std={self.window_std:.3f}\")\n",
        "        else:\n",
        "            print(\"⚠️ No baseline found. Using live history only.\")\n",
        "            self.baseline_errors = None\n",
        "            self.baseline_fds = None\n",
        "            self.baseline_windows = None\n",
        "\n",
        "    # =================== MODEL LOADING ===================\n",
        "\n",
        "    def load_model(self):\n",
        "        try:\n",
        "            if os.path.exists(self.model_path):\n",
        "                self.model = keras.models.load_model(self.model_path)\n",
        "                self.is_model_loaded = True\n",
        "                print(f\"✅ Loaded MLP model from {self.model_path}\")\n",
        "\n",
        "                # Try to load transformer\n",
        "                transformer_path = self.model_path.replace('.keras', '_transformer.pkl')\n",
        "                if os.path.exists(transformer_path):\n",
        "                    with open(transformer_path, 'rb') as f:\n",
        "                        self.transformer = pickle.load(f)\n",
        "                    self.transformer_fitted = True\n",
        "                else:\n",
        "                    # Fit transformer from true window labels\n",
        "                    y_original = np.load(\n",
        "                        \"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/generated-data-true-window2.npy\"\n",
        "                    )\n",
        "                    self.transformer.fit(y_original.reshape(-1, 1))\n",
        "                    self.transformer_fitted = True\n",
        "                    with open(transformer_path, 'wb') as f:\n",
        "                        pickle.dump(self.transformer, f)\n",
        "                    print(\"⚠️ No transformer found, fitted a new one.\")\n",
        "            else:\n",
        "                print(f\"❌ Model not found at {self.model_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error loading model: {e}\")\n",
        "\n",
        "    # =================== FORECAST EVALUATION ===================\n",
        "\n",
        "    def evaluate_forecast_performance(self, sequence_3d, predicted_window, n_future=1):\n",
        "        try:\n",
        "            seq = np.asarray(sequence_3d)\n",
        "            T, F = seq.shape\n",
        "\n",
        "            W = int(predicted_window)\n",
        "            if W < 2:\n",
        "                W = 2\n",
        "            if W > T - n_future - 1:\n",
        "                W = max(2, T - n_future - 1)\n",
        "\n",
        "            # --- Prepare NSP input ---\n",
        "            window = seq[-W:-n_future, :]   # shape (W-1, F)\n",
        "            x = window[np.newaxis, ...]      # shape (1, W-1, F)\n",
        "\n",
        "            # --- NSP prediction ---\n",
        "            y_pred = self.nsp_model.predict(x, verbose=0)[0]  # (F,)\n",
        "            y_true = seq[-n_future, :]                        # (F,)\n",
        "\n",
        "            mse = float(np.mean((y_true - y_pred) ** 2))\n",
        "            mae = float(np.mean(np.abs(y_true - y_pred)))\n",
        "\n",
        "            return {\n",
        "                \"mse\": mse,\n",
        "                \"mae\": mae,\n",
        "                \"forecast_success\": True,\n",
        "                \"actual_values\": y_true.tolist(),\n",
        "                \"predicted_values\": y_pred.tolist(),\n",
        "                \"window_size_used\": W,\n",
        "                \"method\": \"NSP_LSTM\"\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                \"mse\": 9999.0,\n",
        "                \"mae\": 9999.0,\n",
        "                \"forecast_success\": False,\n",
        "                \"error\": str(e),\n",
        "                \"method\": \"NSP_LSTM\"\n",
        "            }\n",
        "\n",
        "    # =================== PERSISTENCE FALLBACK ===================\n",
        "\n",
        "    def _persistence_forecast(self, seq, target_sensor_index, n_future):\n",
        "        \"\"\"\n",
        "        Persistence fallback for RF evaluation.\n",
        "        Last-value-carried-forward for target sensor.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            seq = np.asarray(seq)\n",
        "            if len(seq) < 2:\n",
        "                return {\n",
        "                    'mse': 9999,\n",
        "                    'mae': 9999,\n",
        "                    'forecast_success': False,\n",
        "                    'error': 'Sequence too short',\n",
        "                    'method': 'Persistence'\n",
        "                }\n",
        "\n",
        "            last_value = seq[-1, target_sensor_index]\n",
        "            predicted_vals = [last_value]\n",
        "            actual = [seq[-1, target_sensor_index]]\n",
        "\n",
        "            mse = 0.0\n",
        "            mae = 0.0\n",
        "\n",
        "            return {\n",
        "                'mse': mse,\n",
        "                'mae': mae,\n",
        "                'forecast_success': True,\n",
        "                'actual_values': actual,\n",
        "                'predicted_values': predicted_vals,\n",
        "                'target_sensor_index': target_sensor_index,\n",
        "                'method': 'Persistence',\n",
        "                'note': 'persistence_fallback'\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'mse': 9999,\n",
        "                'mae': 9999,\n",
        "                'forecast_success': False,\n",
        "                'error': str(e),\n",
        "                'method': 'Persistence',\n",
        "                'note': 'persistence_fallback_failed'\n",
        "            }\n",
        "\n",
        "    # =================== PREDICTION PIPELINE ===================\n",
        "\n",
        "    def predict_window_size(self, feature_vector, sequence_3d):\n",
        "        \"\"\"\n",
        "        Main entrypoint:\n",
        "          - Predict window W_t\n",
        "          - Evaluate forecast error e_t\n",
        "          - Compute FDS (S_t) and WSS (Z_t)\n",
        "          - Update drift/anomaly logic (FDI, WDI, events)\n",
        "          - Return full metrics packet\n",
        "        \"\"\"\n",
        "        if not self.is_model_loaded:\n",
        "            return {'predicted_window': 20, 'error': \"Model not loaded\"}\n",
        "\n",
        "        try:\n",
        "            if feature_vector.ndim == 1:\n",
        "                feature_vector = feature_vector.reshape(1, -1)\n",
        "\n",
        "            pred_raw = self.model.predict(feature_vector, verbose=0)\n",
        "\n",
        "            if self.transformer_fitted:\n",
        "                predicted_window = int(round(self.transformer.inverse_transform(pred_raw)[0, 0]))\n",
        "            else:\n",
        "                predicted_window = int(round(pred_raw[0, 0]))\n",
        "\n",
        "            # ----------------------------------------\n",
        "            # WINDOW CLAMP — HARD SAFETY FIX\n",
        "            # ----------------------------------------\n",
        "            # Prevent negative, zero, or extreme window sizes\n",
        "            predicted_window = max(2, predicted_window)        # lower bound\n",
        "\n",
        "            # Forecast evaluation\n",
        "            forecast_metrics = self.evaluate_forecast_performance(sequence_3d, predicted_window, n_future=1)\n",
        "\n",
        "            fds = None\n",
        "            wss = None\n",
        "\n",
        "            if forecast_metrics.get(\"forecast_success\", False):\n",
        "                mse = forecast_metrics[\"mse\"]\n",
        "                mae = forecast_metrics[\"mae\"]\n",
        "\n",
        "                # Basic stats\n",
        "                self.mse_history.append(mse)\n",
        "                self.mae_history.append(mae)\n",
        "                self.error_memory.append(mse)\n",
        "\n",
        "                self.performance_stats['total_predictions'] += 1\n",
        "                self.performance_stats['avg_mse'] = float(np.mean(self.mse_history))\n",
        "                self.performance_stats['avg_mae'] = float(np.mean(self.mae_history))\n",
        "\n",
        "                # ---------- Forecast Deviation Score (FDS) ----------\n",
        "                baseline_median = self.rolling_stats[\"median\"]\n",
        "                baseline_mad = self.rolling_stats[\"mad\"] if self.rolling_stats[\"mad\"] > 0 else 1e-6\n",
        "                fds = (mse - baseline_median) / (baseline_mad + 1e-8)\n",
        "                fds = float(fds) if fds is not None and not np.isnan(fds) else 0.0\n",
        "\n",
        "\n",
        "                self.last_fds = fds\n",
        "                self.fds_memory.append(fds)\n",
        "                self.recent_fds.append(fds)\n",
        "\n",
        "                # ---------- Window Shift Score (WSS) ----------\n",
        "                if self.baseline_windows is not None and self.window_std > 0:\n",
        "                    wss = (predicted_window - self.window_mean) / (self.window_std + 1e-8)\n",
        "                else:\n",
        "                    wss = 0.0\n",
        "\n",
        "                wss = float(wss)\n",
        "                self.last_wss = wss\n",
        "                self.window_memory.append(predicted_window)\n",
        "                self.recent_windows.append(predicted_window)\n",
        "\n",
        "            # Event (ANOMALY / DRIFT) + Drift indices\n",
        "            event, sev, fdi, wdi = self._check_for_event()\n",
        "            self.last_fdi = fdi\n",
        "            self.last_wdi = wdi\n",
        "\n",
        "            # Save history for reporting\n",
        "            record = {\n",
        "                'timestamp': dt.datetime.now(),\n",
        "                'predicted_window': predicted_window,\n",
        "                'forecast_metrics': forecast_metrics,\n",
        "                'fds': self.last_fds,\n",
        "                'wss': self.last_wss,\n",
        "                'fdi': self.last_fdi,\n",
        "                'wdi': self.last_wdi,\n",
        "                'event_type': event,\n",
        "                'severity': sev\n",
        "            }\n",
        "            self.prediction_history.append(record)\n",
        "\n",
        "            return {\n",
        "                'predicted_window': predicted_window,\n",
        "                'forecast_metrics': forecast_metrics,\n",
        "                'fds': self.last_fds,\n",
        "                'fdi': self.last_fdi,\n",
        "                'wss': self.last_wss,\n",
        "                'wdi': self.last_wdi,\n",
        "                'event_type': event,\n",
        "                'severity': sev,\n",
        "                'performance_stats': self.get_recent_performance()\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {'predicted_window': 20, 'error': str(e)}\n",
        "\n",
        "    # =================== EVENT LOGIC (ANOMALY + DRIFT) ===================\n",
        "\n",
        "    def _check_for_event(self):\n",
        "        \"\"\"\n",
        "        Event detection for the Adaptive Window Agent.\n",
        "\n",
        "        - ANOMALY: deviation of last MSE from baseline (median + k * MAD)\n",
        "        - DRIFT:\n",
        "            * FDI: JSD between recent FDS distribution and baseline FDS\n",
        "            * WDI: JSD between recent window distribution and baseline window distribution\n",
        "        \"\"\"\n",
        "        # Require enough history\n",
        "        if len(self.error_memory) < 30:\n",
        "            return None, 0.0, None, None\n",
        "\n",
        "        last_mse = float(self.error_memory[-1])\n",
        "        live_errors = np.array(self.error_memory)\n",
        "\n",
        "        # ---------- BASELINE STATS ----------\n",
        "        if self.baseline_errors is not None and len(self.baseline_errors) > 10:\n",
        "            base_errors = np.array(self.baseline_errors)\n",
        "            baseline_median = np.median(base_errors)\n",
        "            baseline_mad = np.median(np.abs(base_errors - baseline_median)) + 1e-8\n",
        "        else:\n",
        "            baseline_median = np.median(live_errors)\n",
        "            baseline_mad = np.median(np.abs(live_errors - baseline_median)) + 1e-8\n",
        "\n",
        "        # Update rolling_stats so other components can see latest baseline-ish values\n",
        "        self.rolling_stats[\"median\"] = baseline_median\n",
        "        self.rolling_stats[\"mad\"] = baseline_mad\n",
        "\n",
        "        # ---------- LIVE STATS ----------\n",
        "        live_median = np.median(live_errors)\n",
        "        live_mad = np.median(np.abs(live_errors - live_median)) + 1e-8\n",
        "\n",
        "        # ---------- ANOMALY THRESHOLD ----------\n",
        "        baseline_threshold = baseline_median + self.threshold_k * baseline_mad\n",
        "        live_threshold = live_median + self.threshold_k * live_mad\n",
        "\n",
        "        anomaly_threshold = 0.8 * baseline_threshold + 0.2 * live_threshold\n",
        "\n",
        "        is_anomaly = last_mse > anomaly_threshold\n",
        "\n",
        "        if self.anomaly_cooldown > 0:\n",
        "            self.anomaly_cooldown -= 1\n",
        "            is_anomaly = False\n",
        "        elif is_anomaly:\n",
        "            self.anomaly_cooldown = self.anomaly_cooldown_steps\n",
        "\n",
        "        if is_anomaly:\n",
        "            severity = (last_mse - anomaly_threshold) / (baseline_mad + 1e-6)\n",
        "            severity = float(severity)\n",
        "            self.performance_stats[\"anomaly_events\"] += 1\n",
        "            if self.debug:\n",
        "                print(f\"[ANOMALY] mse={last_mse:.6f}, thr={anomaly_threshold:.6f}, sev={severity:.3f}\")\n",
        "            return \"ANOMALY\", severity, 0.0, 0.0\n",
        "\n",
        "        # ---------- DRIFT (FDI + WDI) ----------\n",
        "        fdi = None\n",
        "        wdi = None\n",
        "\n",
        "        # FDI: JSD over FDS distribution\n",
        "        if self.baseline_fds is not None and len(self.recent_fds) >= 30:\n",
        "            base_fds = np.asarray(self.baseline_fds)\n",
        "            recent_fds = np.asarray(self.recent_fds)\n",
        "\n",
        "            hist_base, bins = np.histogram(base_fds, bins=25, density=True)\n",
        "            hist_recent, _ = np.histogram(recent_fds, bins=bins, density=True)\n",
        "\n",
        "            hist_base = hist_base / (hist_base.sum() + 1e-12)\n",
        "            hist_recent = hist_recent / (hist_recent.sum() + 1e-12)\n",
        "\n",
        "            fdi = float(jensenshannon(hist_base + 1e-12, hist_recent + 1e-12))\n",
        "\n",
        "        # WDI: JSD over window-size distribution\n",
        "        if self.baseline_windows is not None and len(self.recent_windows) >= 30:\n",
        "            base_win = np.asarray(self.baseline_windows)\n",
        "            recent_win = np.asarray(self.recent_windows)\n",
        "\n",
        "            hist_w_base, bins_w = np.histogram(base_win, bins=20, density=True)\n",
        "            hist_w_recent, _ = np.histogram(recent_win, bins=bins_w, density=True)\n",
        "\n",
        "            hist_w_base = hist_w_base / (hist_w_base.sum() + 1e-12)\n",
        "            hist_w_recent = hist_w_recent / (hist_w_recent.sum() + 1e-12)\n",
        "\n",
        "            wdi = float(jensenshannon(hist_w_base + 1e-12, hist_w_recent + 1e-12))\n",
        "\n",
        "        # Decide drift if either index is high\n",
        "        is_drift_fdi = fdi is not None and fdi > self.drift_threshold\n",
        "        is_drift_wdi = wdi is not None and wdi > self.window_drift_threshold\n",
        "\n",
        "        is_drift = is_drift_fdi or is_drift_wdi\n",
        "\n",
        "        if self.drift_cooldown > 0:\n",
        "            self.drift_cooldown -= 1\n",
        "            is_drift = False\n",
        "        else:\n",
        "            if is_drift:\n",
        "                self.consecutive_drift_votes += 1\n",
        "            else:\n",
        "                self.consecutive_drift_votes = 0\n",
        "\n",
        "        if self.consecutive_drift_votes >= self.drift_votes_required:\n",
        "            self.consecutive_drift_votes = 0\n",
        "            self.drift_cooldown = self.drift_cooldown_steps\n",
        "            self.performance_stats[\"drift_events\"] += 1\n",
        "            if self.debug:\n",
        "                print(f\"[DRIFT] FDI={fdi:.4f} WDI={wdi:.4f}\")\n",
        "            fdi = float(fdi) if fdi is not None else 0.0\n",
        "            wdi = float(wdi) if wdi is not None else 0.0\n",
        "            return \"DRIFT\", fdi, fdi, wdi\n",
        "\n",
        "        # Make safe for printing\n",
        "        fdi = float(fdi) if fdi is not None else 0.0\n",
        "        wdi = float(wdi) if wdi is not None else 0.0\n",
        "\n",
        "        return None, 0.0, fdi, wdi\n",
        "\n",
        "\n",
        "    # =================== HELPERS ===================\n",
        "\n",
        "    def get_recent_performance(self):\n",
        "        all_preds = list(self.prediction_history)\n",
        "\n",
        "        successful_predictions = [\n",
        "            p for p in all_preds\n",
        "            if p.get('forecast_metrics', {}).get('forecast_success', False)\n",
        "        ]\n",
        "\n",
        "        return {\n",
        "            'total_predictions': len(all_preds),\n",
        "            'successful_predictions': len(successful_predictions),\n",
        "            'success_rate': len(successful_predictions) / max(len(all_preds), 1),\n",
        "            'drift_events': self.performance_stats['drift_events'],\n",
        "            'anomaly_events': self.performance_stats['anomaly_events'],\n",
        "            'retraining_events': self.performance_stats['retraining_events'],\n",
        "            'recent_mse': float(np.mean(list(self.mse_history)[-10:])) if self.mse_history else 0,\n",
        "            'avg_mse': float(np.mean(self.mse_history)) if self.mse_history else 0,\n",
        "            'recent_mae': float(np.mean(list(self.mae_history)[-10:])) if self.mae_history else 0,\n",
        "            'avg_mae': float(np.mean(self.mae_history)) if self.mae_history else 0,\n",
        "            'transformer_fitted': self.transformer_fitted,\n",
        "            'last_fdi': self.last_fdi,\n",
        "            'last_wdi': self.last_wdi,\n",
        "        }\n",
        "\n",
        "    def save_performance_state(self, filepath: str):\n",
        "        \"\"\"Save performance statistics + prediction history to JSON\"\"\"\n",
        "        try:\n",
        "            state = {\n",
        "                'performance_stats': self.performance_stats.copy(),\n",
        "                'prediction_history': list(self.prediction_history)[-100:],\n",
        "                'mse_history': list(self.mse_history),\n",
        "                'mae_history': list(self.mae_history),\n",
        "                'transformer_fitted': self.transformer_fitted\n",
        "            }\n",
        "            with open(filepath, 'w') as f:\n",
        "                json.dump(state, f, indent=2, default=str)\n",
        "            print(f\"✅ Performance state saved to {filepath}\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to save performance state: {e}\")\n",
        "\n",
        "\n",
        "#===============================================================================================================================================\n",
        "###  SENSOR AGENTS - INDIVIDUAL AND MASTER\n",
        "#--------------------------------------==========================================================================================================\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "from collections import deque\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Tuple\n",
        "import warnings\n",
        "import pandas as pd\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ML libraries\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from scipy import stats\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "\n",
        "# Deep learning\n",
        "try:\n",
        "    from tensorflow.keras.models import load_model\n",
        "    KERAS_AVAILABLE = True\n",
        "except ImportError:\n",
        "    KERAS_AVAILABLE = False\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        "    roc_auc_score,\n",
        "    average_precision_score,\n",
        "    precision_recall_curve,\n",
        "    roc_curve\n",
        ")\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# ROBUST SENSOR AGENT - Observes ONE sensor with AE model\n",
        "# =====================================================\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# ROBUST SENSOR AGENT - Observes ONE sensor with AE model\n",
        "# =====================================================\n",
        "\n",
        "class RobustSensorAgent:\n",
        "    \"\"\"\n",
        "    Robust Sensor Agent for ONE sensor with advanced anomaly & drift detection.\n",
        "\n",
        "    Loads pretrained AE model + metadata (scaler, baseline errors, rolling stats).\n",
        "    Computes anomaly score via reconstruction error, applies adaptive thresholding,\n",
        "    drift detection, and outputs robust anomaly/drift/retrain flags.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 sensor_id: int,\n",
        "                 model_path: str = None,\n",
        "                 window_length: int = 10, #K\n",
        "                 memory_size: int = 1000,\n",
        "                 threshold_k: float = 2.0,\n",
        "                 drift_threshold: float = 0.1,\n",
        "                warmup_steps: int = 100):    # <── NEW PARAM\n",
        "\n",
        "        self.sensor_id = sensor_id\n",
        "        self.window_length = window_length\n",
        "        self.threshold_k = threshold_k\n",
        "        self.drift_threshold = drift_threshold\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "        # Model & metadata\n",
        "        self.model = None\n",
        "        self.scaler = None\n",
        "        self.is_model_loaded = False\n",
        "\n",
        "        # Buffers\n",
        "        self.error_memory = deque(maxlen=memory_size)\n",
        "        self.data_memory = deque(maxlen=memory_size)\n",
        "        self.recent_errors = deque(maxlen=100)\n",
        "\n",
        "        # Rolling stats\n",
        "        self.rolling_stats = {\n",
        "            'median': 0.0,\n",
        "            'mad': 1.0,\n",
        "            'mean': 0.0,   # backward compatibility\n",
        "            'std': 1.0,    # backward compatibility\n",
        "            'q95': 0.0,\n",
        "            'q99': 0.0\n",
        "        }\n",
        "        self.baseline_errors = None\n",
        "\n",
        "        # Counters\n",
        "        self.total_processed = 0\n",
        "        self.anomalies_detected = 0\n",
        "        self.drift_detected_count = 0\n",
        "        self.last_stats_update = datetime.now()\n",
        "\n",
        "        self.anomaly_cooldown = 0\n",
        "        self.drift_cooldown = 0\n",
        "\n",
        "        self.anomaly_cooldown_steps = 5    # you can tune\n",
        "        self.drift_cooldown_steps = 10     # you can tune\n",
        "\n",
        "        self.consecutive_drift_votes = 0\n",
        "        self.consecutive_anomaly_votes = 0\n",
        "\n",
        "        if model_path:\n",
        "            self.load_model(model_path)\n",
        "\n",
        "    def load_model(self, model_path: str) -> bool:\n",
        "        \"\"\"Load pretrained AE model + metadata.\"\"\"\n",
        "        try:\n",
        "            if KERAS_AVAILABLE and model_path.endswith('.h5'):\n",
        "                self.model = load_model(model_path, compile=False)\n",
        "\n",
        "                # Correct metadata file\n",
        "                metadata_path = model_path.replace('_model.h5', '_metadata.pkl')\n",
        "\n",
        "                if os.path.exists(metadata_path):\n",
        "                    with open(metadata_path, 'rb') as f:\n",
        "                        metadata = pickle.load(f)\n",
        "\n",
        "                    baseline = metadata.get('baseline_stats', None)\n",
        "\n",
        "                    if baseline is not None:\n",
        "                        # Initialize rolling stats from training\n",
        "                        # Load robust baseline stats\n",
        "                        self.rolling_stats['median'] = baseline.get('median')\n",
        "                        self.rolling_stats['mad']    = baseline.get('mad')\n",
        "\n",
        "                        # Backward compatibility for other parts of system\n",
        "                        self.rolling_stats['mean'] = self.rolling_stats['median']\n",
        "                        self.rolling_stats['std']  = self.rolling_stats['mad']\n",
        "\n",
        "                        self.rolling_stats['q95']  = baseline['q95']\n",
        "                        self.rolling_stats['q99']  = baseline['q99']\n",
        "\n",
        "                        # Save baseline distribution for drift detection\n",
        "                        self.baseline_errors = np.array(baseline['baseline_errors'])\n",
        "\n",
        "                # AE was trained on raw, NOT scaled\n",
        "                self.scaler = None\n",
        "\n",
        "            else:\n",
        "                raise ValueError(\"Unsupported model format – expecting .h5 AE model\")\n",
        "\n",
        "            self.is_model_loaded = True\n",
        "            print(f\"✅ AE model loaded for sensor {self.sensor_id}\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to load AE model for sensor {self.sensor_id}: {e}\")\n",
        "            return False\n",
        "\n",
        "\n",
        "    def observe(self, sensor_subsequence: np.ndarray) -> Dict:\n",
        "        \"\"\"Observe subsequence [window_length] and return anomaly/drift flags.\"\"\"\n",
        "        if not self.is_model_loaded:\n",
        "            return {\"sensor_id\": self.sensor_id, \"error\": \"no_model_loaded\", \"timestamp\": datetime.now()}\n",
        "\n",
        "        if len(sensor_subsequence) != self.window_length:\n",
        "            return {\"sensor_id\": self.sensor_id,\n",
        "                    \"error\": f\"invalid_length_expected_{self.window_length}_got_{len(sensor_subsequence)}\",\n",
        "                    \"timestamp\": datetime.now()}\n",
        "\n",
        "        # 1. Anomaly score\n",
        "        anomaly_score = self._compute_robust_anomaly_score(sensor_subsequence)\n",
        "\n",
        "        # 2. Update memory\n",
        "        self.data_memory.append(sensor_subsequence.copy())\n",
        "        self.error_memory.append(anomaly_score)\n",
        "        self.recent_errors.append(anomaly_score)\n",
        "\n",
        "        # 3\n",
        "\n",
        "        # --------------- WARM-UP PHASE -----------------\n",
        "        # During warm-up, rolling stats ignore live data and stay fixed\n",
        "        if self.total_processed < self.warmup_steps:\n",
        "            med = np.median(self.baseline_errors)\n",
        "            mad = np.median(np.abs(self.baseline_errors - med)) + 1e-8\n",
        "\n",
        "            self.rolling_stats['median'] = med\n",
        "            self.rolling_stats['mad'] = mad\n",
        "            self.rolling_stats['mean'] = med     # backward compatibility\n",
        "            self.rolling_stats['std'] = mad\n",
        "        else:\n",
        "            # After warm-up, rolling stats evolve normally\n",
        "            if len(self.error_memory) >= 50 and len(self.error_memory) % 10 == 0:\n",
        "                self._update_rolling_stats(list(self.error_memory)[-50:])\n",
        "\n",
        "        # 4. Flags\n",
        "        is_anomaly = self._check_adaptive_anomaly(anomaly_score)\n",
        "        drift_flag = self._check_advanced_drift()\n",
        "        needs_retrain = self._check_retrain_need()\n",
        "        confidence = self._compute_robust_confidence(anomaly_score)\n",
        "\n",
        "        # 5. Update counters\n",
        "        self.total_processed += 1\n",
        "        if is_anomaly: self.anomalies_detected += 1\n",
        "        if drift_flag: self.drift_detected_count += 1\n",
        "\n",
        "        return {\n",
        "            \"sensor_id\": self.sensor_id,\n",
        "            \"timestamp\": datetime.now(),\n",
        "            \"is_anomaly\": bool(is_anomaly),\n",
        "            \"drift_flag\": bool(drift_flag),\n",
        "            \"needs_retrain_flag\": bool(needs_retrain),\n",
        "            \"anomaly_score\": float(anomaly_score),\n",
        "            \"confidence\": float(confidence),\n",
        "            \"threshold_used\": float(self.rolling_stats['median'] + self.threshold_k * self.rolling_stats['mad']),\n",
        "            \"anomaly_rate\": self.anomalies_detected / max(1, self.total_processed),\n",
        "            \"drift_rate\": self.drift_detected_count / max(1, self.total_processed)\n",
        "        }\n",
        "\n",
        "    def _compute_robust_anomaly_score(self, subsequence: np.ndarray) -> float:\n",
        "        \"\"\"Compute reconstruction error using AE model on RAW values.\"\"\"\n",
        "        try:\n",
        "            # Ensure shape: [1, window_length, 1]\n",
        "            X = subsequence.reshape(1, self.window_length, 1)\n",
        "            reconstruction = self.model.predict(X, verbose=0)\n",
        "\n",
        "            error = mean_squared_error(\n",
        "                subsequence.flatten(),\n",
        "                reconstruction.flatten()\n",
        "            )\n",
        "            return max(0.0, error)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ AE inference failed for sensor {self.sensor_id}: {e}\")\n",
        "            # Fallback: variance of raw subsequence\n",
        "            return float(np.var(subsequence))\n",
        "\n",
        "    def _update_rolling_stats(self, errors: List[float]):\n",
        "        errors_array = np.array(errors)\n",
        "\n",
        "        median = np.median(errors_array)\n",
        "        mad = np.median(np.abs(errors_array - median)) + 1e-8  # avoid zero\n",
        "\n",
        "        # Store\n",
        "        self.rolling_stats['median'] = median\n",
        "        self.rolling_stats['mad'] = mad\n",
        "\n",
        "        # Backward compatibility fields (for plotting)\n",
        "        self.rolling_stats['mean'] = median\n",
        "        self.rolling_stats['std'] = mad\n",
        "\n",
        "        # Percentile bands (unchanged; good for drift & visualization)\n",
        "        self.rolling_stats['q95'] = np.percentile(errors_array, 95)\n",
        "        self.rolling_stats['q99'] = np.percentile(errors_array, 99)\n",
        "\n",
        "        self.last_stats_update = datetime.now()\n",
        "\n",
        "    def _check_adaptive_anomaly(self, score: float) -> bool:\n",
        "        median = self.rolling_stats.get('median', self.rolling_stats['mean'])\n",
        "        mad = self.rolling_stats.get('mad', self.rolling_stats['std'])\n",
        "        threshold = median + self.threshold_k * mad\n",
        "        is_anomaly_now = score > threshold\n",
        "\n",
        "        # Cooldown active → suppress anomaly\n",
        "        if self.anomaly_cooldown > 0:\n",
        "            self.anomaly_cooldown -= 1\n",
        "            return False\n",
        "\n",
        "        # No cooldown and anomaly happened → activate cooldown\n",
        "        if is_anomaly_now:\n",
        "            self.anomaly_cooldown = self.anomaly_cooldown_steps\n",
        "            return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def _check_advanced_drift(self) -> bool:\n",
        "        if self.baseline_errors is None or len(self.recent_errors) < 30:\n",
        "            return False\n",
        "        try:\n",
        "            hist_baseline, bins = np.histogram(self.baseline_errors, bins=20, density=True)\n",
        "            hist_recent, _ = np.histogram(list(self.recent_errors), bins=bins, density=True)\n",
        "            hist_baseline += 1e-10; hist_recent += 1e-10\n",
        "            hist_baseline /= hist_baseline.sum(); hist_recent /= hist_recent.sum()\n",
        "            js_divergence = jensenshannon(hist_baseline, hist_recent)\n",
        "            is_drift_now = js_divergence > self.drift_threshold\n",
        "\n",
        "            # Cooldown active → suppress\n",
        "            if self.drift_cooldown > 0:\n",
        "                self.drift_cooldown -= 1\n",
        "                return False\n",
        "\n",
        "            # Multi-step confirmation: require 3 drift votes in last few steps\n",
        "            if is_drift_now:\n",
        "                self.consecutive_drift_votes += 1\n",
        "            else:\n",
        "                self.consecutive_drift_votes = 0\n",
        "\n",
        "            if self.consecutive_drift_votes >= 3:\n",
        "                self.drift_cooldown = self.drift_cooldown_steps\n",
        "                self.consecutive_drift_votes = 0\n",
        "                return True\n",
        "\n",
        "            return False\n",
        "\n",
        "        except Exception:\n",
        "            try:\n",
        "                _, p_value = stats.ks_2samp(self.baseline_errors, list(self.recent_errors))\n",
        "                return p_value < 0.05\n",
        "            except:\n",
        "                return False\n",
        "\n",
        "    def _check_retrain_need(self) -> bool:\n",
        "        if len(self.error_memory) < 100: return False\n",
        "        recent_errors = list(self.error_memory)[-50:]\n",
        "        threshold = self.rolling_stats['mean'] + self.threshold_k * self.rolling_stats['std']\n",
        "        anomaly_rate = sum(1 for e in recent_errors if e > threshold) / len(recent_errors)\n",
        "        criteria = [\n",
        "            anomaly_rate > 0.3,\n",
        "            self.drift_detected_count > 0.1 * self.total_processed,\n",
        "            np.mean(recent_errors) > 2.0 * self.rolling_stats['mean'] if len(recent_errors) > 0 else False,\n",
        "            (datetime.now() - self.last_stats_update).days > 7\n",
        "        ]\n",
        "        return sum(criteria) >= 2\n",
        "\n",
        "    def _compute_robust_confidence(self, score: float) -> float:\n",
        "        median = self.rolling_stats.get('median')\n",
        "        mad = self.rolling_stats.get('mad')\n",
        "\n",
        "        if mad == 0:\n",
        "            return 0.5\n",
        "\n",
        "        threshold = median + self.threshold_k * mad\n",
        "\n",
        "        z = (score - threshold) / mad  # how far beyond threshold?\n",
        "\n",
        "        # Smooth probability-like mapping\n",
        "        confidence = 1 / (1 + np.exp(-z))\n",
        "\n",
        "        return float(np.clip(confidence, 0.0, 1.0))\n",
        "\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# ROBUST MASTER AGENT\n",
        "# =====================================================\n",
        "\n",
        "class RobustMasterAgent:\n",
        "    \"\"\"Aggregates sensor results, makes system-level anomaly/drift/retrain decisions.\"\"\"\n",
        "    def __init__(self, sensor_agents: List[RobustSensorAgent],\n",
        "                 system_anomaly_threshold: float = 0.3,\n",
        "                 drift_threshold: float = 0.2,\n",
        "                 retrain_threshold: float = 0.15):\n",
        "        self.sensor_agents = sensor_agents\n",
        "        self.num_sensors = len(sensor_agents)\n",
        "        self.system_anomaly_threshold = system_anomaly_threshold\n",
        "        self.drift_threshold = drift_threshold\n",
        "        self.retrain_threshold = retrain_threshold\n",
        "\n",
        "    def process_system_input(self, system_subsequence: np.ndarray) -> Dict:\n",
        "        \"\"\"Process [window_length, num_sensors] multivariate subsequence.\"\"\"\n",
        "        timestamp = datetime.now()\n",
        "        if system_subsequence.shape[1] != self.num_sensors:\n",
        "            return {\"error\": f\"Expected {self.num_sensors} sensors, got {system_subsequence.shape[1]}\",\n",
        "                    \"timestamp\": timestamp}\n",
        "\n",
        "        # 1. Collect sensor observations\n",
        "        sensor_results = []\n",
        "        for i, agent in enumerate(self.sensor_agents):\n",
        "            sensor_data = system_subsequence[:, i]\n",
        "            result = agent.observe(sensor_data)\n",
        "            sensor_results.append(result)\n",
        "\n",
        "        # 2. Simple aggregation\n",
        "        anomalies = sum(1 for r in sensor_results if r.get(\"is_anomaly\"))\n",
        "        drifts = sum(1 for r in sensor_results if r.get(\"drift_flag\"))\n",
        "        retrains = sum(1 for r in sensor_results if r.get(\"needs_retrain_flag\"))\n",
        "\n",
        "        anomaly_rate = anomalies / max(1, self.num_sensors)\n",
        "        drift_rate = drifts / max(1, self.num_sensors)\n",
        "        retrain_rate = retrains / max(1, self.num_sensors)\n",
        "\n",
        "        system_decisions = {\n",
        "            \"system_anomaly\": anomaly_rate >= self.system_anomaly_threshold,\n",
        "            \"system_drift\": drift_rate >= self.drift_threshold,\n",
        "            \"system_needs_retrain\": retrain_rate >= self.retrain_threshold,\n",
        "            \"anomaly_rate\": anomaly_rate,\n",
        "            \"drift_rate\": drift_rate,\n",
        "            \"retrain_rate\": retrain_rate\n",
        "        }\n",
        "\n",
        "        return {\n",
        "            \"timestamp\": timestamp,\n",
        "            \"sensor_results\": sensor_results,\n",
        "            \"system_decisions\": system_decisions\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# SYSTEM CREATION\n",
        "# =====================================================\n",
        "\n",
        "def create_robust_system(num_sensors: int, models_dir: str, win_length: int, warmup_steps: int = 100) -> Tuple[List[RobustSensorAgent], RobustMasterAgent]:\n",
        "    \"\"\"Create robust sensor system loading AE models + metadata.\"\"\"\n",
        "    print(f\"🚀 Creating robust system with {num_sensors} sensors\")\n",
        "    sensor_agents = []\n",
        "    for sensor_id in range(num_sensors):\n",
        "        model_path = os.path.join(models_dir, f\"sensor_{sensor_id}_model.h5\")\n",
        "        agent = RobustSensorAgent(sensor_id=sensor_id,\n",
        "                                  model_path=model_path if os.path.exists(model_path) else None,\n",
        "                                  window_length=win_length,\n",
        "                                  memory_size=1000,\n",
        "                                  threshold_k=2.0,\n",
        "                                  drift_threshold=0.1,\n",
        "                                  warmup_steps=warmup_steps)       # <── NEW\n",
        "        sensor_agents.append(agent)\n",
        "\n",
        "    master = RobustMasterAgent(sensor_agents=sensor_agents,\n",
        "                               system_anomaly_threshold=0.3,\n",
        "                               drift_threshold=0.2,\n",
        "                               retrain_threshold=0.15)\n",
        "    print(f\"✅ Created system: {len([a for a in sensor_agents if a.is_model_loaded])}/{num_sensors} models loaded\")\n",
        "\n",
        "    return sensor_agents, master\n",
        "\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# DECISION AGENT (replaces / extends CoordinatorAgent)\n",
        "# =====================================================\n",
        "from typing import Optional\n",
        "\n",
        "# =====================================================\n",
        "# DecisionAgent V2-PURE (Prediction-focused fusion)\n",
        "# =====================================================\n",
        "from typing import Optional, Dict, Any\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class DecisionAgent:\n",
        "    \"\"\"\n",
        "    DecisionAgent V2-PURE:\n",
        "\n",
        "    - INPUTS (same call signature as before):\n",
        "        * master_output: RobustMasterAgent.process_system_input(...)\n",
        "        * window_output: AdaptiveWindowAgent.predict_window_size(...)\n",
        "        * model_outputs: optional dict, expected keys:\n",
        "              - \"failure_prob\": float in [0,1]  (ML failure prediction)\n",
        "              - \"prototype_score\": float (optional, diagnostic only)\n",
        "              - \"transformer_prob\": float (optional, diagnostic only)\n",
        "        * metadata: optional dict (e.g. index, timestamps)\n",
        "\n",
        "    - LOGIC:\n",
        "        * Detection layer (ANOMALY / DRIFT / RETRAIN)\n",
        "              -> derived ONLY from sensor + window signals\n",
        "        * Prediction layer (FAILURE PREDICTION)\n",
        "              -> derived ONLY from ML failure_prob\n",
        "        * Fusion:\n",
        "              -> prediction dominates alert_level / severity\n",
        "              -> detection still influences severity but has lower weight\n",
        "\n",
        "    - OUTPUT (unified decision packet):\n",
        "        {\n",
        "          \"timestamp\": ...\n",
        "          \"final_failure\": bool               # prediction-driven\n",
        "          \"final_anomaly\": bool               # sensor-driven\n",
        "          \"final_drift\": bool                 # sensor/window-driven\n",
        "          \"final_retrain\": bool               # retrain suggestion\n",
        "          \"alert_level\": \"NORMAL\"/\"LOW\"/\"MEDIUM\"/\"HIGH\"/\"CRITICAL\",\n",
        "          \"scores\": {\n",
        "              \"prediction_failure_prob\": float,\n",
        "              \"prediction_fused_score\": float,      # main score for alerting\n",
        "              \"sensor_anomaly_rate\": float,\n",
        "              \"sensor_drift_rate\": float,\n",
        "              \"sensor_retrain_rate\": float,\n",
        "              \"window_event_is_anomaly\": 0/1,\n",
        "              \"window_event_is_drift\": 0/1,\n",
        "              \"window_mse\": float or None,\n",
        "              \"prototype_score\": float or None,\n",
        "              \"transformer_prob\": float or None,\n",
        "          },\n",
        "          \"window_agent\": {\n",
        "              \"predicted_window\": int or None,\n",
        "              \"window_anomaly\": bool,\n",
        "              \"window_drift\": bool,\n",
        "          },\n",
        "          \"raw\": {\n",
        "              \"master_output\": ...,\n",
        "              \"window_output\": ...,\n",
        "              \"model_outputs\": ...,\n",
        "              \"metadata\": ...,\n",
        "          },\n",
        "        }\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        # weights for FUSION (prediction vs detection)\n",
        "        prediction_weight: float = 0.7,     # ML failure prediction dominates\n",
        "        sensor_weight: float = 0.2,         # sensor anomaly contribution\n",
        "        drift_weight: float = 0.1,          # drift contribution\n",
        "\n",
        "        # thresholds\n",
        "        failure_threshold: float = 0.5,     # base failure decision\n",
        "        failure_critical_threshold: float = 0.8,  # high-risk cutoff\n",
        "\n",
        "        anomaly_rate_threshold: float = 0.3,    # for final_anomaly\n",
        "        drift_rate_threshold: float = 0.2,      # for final_drift\n",
        "        retrain_rate_threshold: float = 0.15,   # for final_retrain\n",
        "    ):\n",
        "        # Fusion weights (normalised later)\n",
        "        self.prediction_weight = prediction_weight\n",
        "        self.sensor_weight = sensor_weight\n",
        "        self.drift_weight = drift_weight\n",
        "\n",
        "        self.failure_threshold = failure_threshold\n",
        "        self.failure_critical_threshold = failure_critical_threshold\n",
        "\n",
        "        self.anomaly_rate_threshold = anomaly_rate_threshold\n",
        "        self.drift_rate_threshold = drift_rate_threshold\n",
        "        self.retrain_rate_threshold = retrain_rate_threshold\n",
        "\n",
        "        # history buffer (optional)\n",
        "        self.history = []\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # Main decision function\n",
        "    # -------------------------------------------------\n",
        "    def decide(\n",
        "        self,\n",
        "        master_output: Dict[str, Any],\n",
        "        window_output: Dict[str, Any],\n",
        "        model_outputs: Optional[Dict[str, Any]] = None,\n",
        "        metadata: Optional[Dict[str, Any]] = None,\n",
        "    ) -> Dict[str, Any]:\n",
        "        timestamp = datetime.now()\n",
        "\n",
        "        # -----------------------------\n",
        "        # 1) Extract master/system info\n",
        "        # -----------------------------\n",
        "        sys_dec = master_output.get(\"system_decisions\", {}) if master_output else {}\n",
        "        sys_anomaly = bool(sys_dec.get(\"system_anomaly\", False))\n",
        "        sys_drift = bool(sys_dec.get(\"system_drift\", False))\n",
        "        sys_retrain = bool(sys_dec.get(\"system_needs_retrain\", False))\n",
        "\n",
        "        anomaly_rate = float(sys_dec.get(\"anomaly_rate\", 0.0))\n",
        "        drift_rate = float(sys_dec.get(\"drift_rate\", 0.0))\n",
        "        retrain_rate = float(sys_dec.get(\"retrain_rate\", 0.0))\n",
        "\n",
        "        # -----------------------------\n",
        "        # 2) Extract window agent info\n",
        "        # -----------------------------\n",
        "        window_event_type = window_output.get(\"event_type\", None) if window_output else None\n",
        "        win_anomaly = (window_event_type == \"ANOMALY\")\n",
        "        win_drift = (window_event_type == \"DRIFT\")\n",
        "\n",
        "        predicted_window = window_output.get(\"predicted_window\", None) if window_output else None\n",
        "        window_mse = None\n",
        "        if window_output and \"forecast_metrics\" in window_output:\n",
        "            window_mse = window_output[\"forecast_metrics\"].get(\"mse\", None)\n",
        "\n",
        "        # -----------------------------\n",
        "        # 3) Extract ML prediction info\n",
        "        # -----------------------------\n",
        "        failure_prob = None\n",
        "        prototype_score = None\n",
        "        transformer_prob = None\n",
        "\n",
        "        if model_outputs is not None:\n",
        "            # failure prediction only – this is the ML “truth” in this layer\n",
        "            failure_prob = model_outputs.get(\"failure_prob\", None)\n",
        "            # keep these as diagnostic/extra info, NOT for anomaly\n",
        "            prototype_score = model_outputs.get(\"prototype_score\", None)\n",
        "            transformer_prob = model_outputs.get(\"transformer_prob\", None)\n",
        "\n",
        "        # Guard: normalise missing failure_prob -> 0.0\n",
        "        if failure_prob is None:\n",
        "            failure_prob = 0.0\n",
        "        failure_prob = float(failure_prob)\n",
        "\n",
        "        # -----------------------------\n",
        "        # 4) Detection layer (ANOMALY / DRIFT / RETRAIN)\n",
        "        #    -> purely sensor + window based\n",
        "        # -----------------------------\n",
        "        # final_anomaly: system anomaly rate OR strong window anomaly\n",
        "        final_anomaly = (\n",
        "            anomaly_rate >= self.anomaly_rate_threshold\n",
        "            or sys_anomaly\n",
        "            or win_anomaly\n",
        "        )\n",
        "\n",
        "        # final_drift: drift rate OR window drift\n",
        "        final_drift = (\n",
        "            drift_rate >= self.drift_rate_threshold\n",
        "            or sys_drift\n",
        "            or win_drift\n",
        "        )\n",
        "\n",
        "        # final_retrain: explicit retrain + high retrain rate\n",
        "        final_retrain = (\n",
        "            sys_retrain\n",
        "            or retrain_rate >= self.retrain_rate_threshold\n",
        "            or (final_drift and anomaly_rate > 0.1)\n",
        "        )\n",
        "\n",
        "        # -----------------------------\n",
        "        # 5) Prediction layer (FAILURE)\n",
        "        #    -> failure_prob from ML ONLY\n",
        "        # -----------------------------\n",
        "        # Base failure flag purely from probability\n",
        "        base_failure = failure_prob >= self.failure_threshold\n",
        "\n",
        "        # Context-aware adjustment:\n",
        "        # if failure_prob is moderate but sensor anomalies are strong,\n",
        "        # we can gently promote final_failure = True\n",
        "        strong_sensor_context = (\n",
        "            anomaly_rate > (self.anomaly_rate_threshold * 1.2)\n",
        "            or (win_anomaly and anomaly_rate > 0.1)\n",
        "        )\n",
        "\n",
        "        if not base_failure and failure_prob >= (self.failure_threshold * 0.7) and strong_sensor_context:\n",
        "            final_failure = True\n",
        "        else:\n",
        "            final_failure = base_failure\n",
        "\n",
        "        # -----------------------------\n",
        "        # 6) Fused severity / alert scoring\n",
        "        # -----------------------------\n",
        "        # normalise weights\n",
        "        w_sum = self.prediction_weight + self.sensor_weight + self.drift_weight\n",
        "        if w_sum <= 0:\n",
        "            w_pred = 1.0\n",
        "            w_sens = 0.0\n",
        "            w_drift = 0.0\n",
        "        else:\n",
        "            w_pred = self.prediction_weight / w_sum\n",
        "            w_sens = self.sensor_weight / w_sum\n",
        "            w_drift = self.drift_weight / w_sum\n",
        "\n",
        "        # detection “intensity” – bounded in [0,1]\n",
        "        detection_intensity = np.clip(anomaly_rate, 0.0, 1.0)\n",
        "        drift_intensity = np.clip(drift_rate, 0.0, 1.0)\n",
        "\n",
        "        # fused prediction-driven risk score\n",
        "        prediction_fused_score = (\n",
        "            w_pred * failure_prob +\n",
        "            w_sens * detection_intensity +\n",
        "            w_drift * drift_intensity +\n",
        "            (0.05 if win_anomaly else 0.0) +\n",
        "            (0.03 if win_drift else 0.0)\n",
        "        )\n",
        "        prediction_fused_score = float(np.clip(prediction_fused_score, 0.0, 1.0))\n",
        "\n",
        "        # -----------------------------\n",
        "        # 7) Map fused score + flags → alert_level\n",
        "        # -----------------------------\n",
        "        alert_level = self._compute_alert_level(\n",
        "            failure_prob=failure_prob,\n",
        "            fused_score=prediction_fused_score,\n",
        "            final_failure=final_failure,\n",
        "            final_anomaly=final_anomaly,\n",
        "            final_drift=final_drift,\n",
        "        )\n",
        "\n",
        "        # -----------------------------\n",
        "        # 8) Build decision packet\n",
        "        # -----------------------------\n",
        "        decision = {\n",
        "            \"timestamp\": timestamp.isoformat(),\n",
        "            # prediction-focused\n",
        "            \"final_failure\": bool(final_failure),\n",
        "            # detection-focused\n",
        "            \"final_anomaly\": bool(final_anomaly),\n",
        "            \"final_drift\": bool(final_drift),\n",
        "            \"final_retrain\": bool(final_retrain),\n",
        "            # human-facing\n",
        "            \"alert_level\": alert_level,\n",
        "            # structured scores\n",
        "            \"scores\": {\n",
        "                # Prediction side\n",
        "                \"prediction_failure_prob\": float(failure_prob),\n",
        "                \"prediction_fused_score\": float(prediction_fused_score),\n",
        "\n",
        "                # Detection side\n",
        "                \"sensor_anomaly_rate\": float(anomaly_rate),\n",
        "                \"sensor_drift_rate\": float(drift_rate),\n",
        "                \"sensor_retrain_rate\": float(retrain_rate),\n",
        "\n",
        "                # Window side\n",
        "                \"window_event_type\": window_event_type,\n",
        "                \"window_event_is_anomaly\": 1.0 if win_anomaly else 0.0,\n",
        "                \"window_event_is_drift\": 1.0 if win_drift else 0.0,\n",
        "                \"window_mse\": float(window_mse) if window_mse is not None else None,\n",
        "\n",
        "                # Extra ML diagnostics (not used for detection)\n",
        "                \"prototype_score\": float(prototype_score) if prototype_score is not None else None,\n",
        "                \"transformer_prob\": float(transformer_prob) if transformer_prob is not None else None,\n",
        "            },\n",
        "            \"window_agent\": {\n",
        "                \"predicted_window\": predicted_window,\n",
        "                \"window_anomaly\": bool(win_anomaly),\n",
        "                \"window_drift\": bool(win_drift),\n",
        "            },\n",
        "            \"raw\": {\n",
        "                \"master_output\": master_output,\n",
        "                \"window_output\": window_output,\n",
        "                \"model_outputs\": model_outputs,\n",
        "                \"metadata\": metadata,\n",
        "            },\n",
        "        }\n",
        "\n",
        "        self.history.append(decision)\n",
        "        return decision\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # Helper: alert level mapping\n",
        "    # -------------------------------------------------\n",
        "    def _compute_alert_level(\n",
        "        self,\n",
        "        failure_prob: float,\n",
        "        fused_score: float,\n",
        "        final_failure: bool,\n",
        "        final_anomaly: bool,\n",
        "        final_drift: bool,\n",
        "    ) -> str:\n",
        "        \"\"\"\n",
        "        Map scores + flags into a discrete alert level.\n",
        "        ML failure prediction dominates; sensor anomalies modulate.\n",
        "        \"\"\"\n",
        "        # Hard overrides for critical cases\n",
        "        if failure_prob >= self.failure_critical_threshold and (final_anomaly or final_drift):\n",
        "            return \"CRITICAL\"\n",
        "\n",
        "        if final_failure and fused_score >= 0.9:\n",
        "            return \"CRITICAL\"\n",
        "\n",
        "        # General mapping based on fused_score and flags\n",
        "        if not final_failure and not final_anomaly and not final_drift:\n",
        "            if fused_score < 0.3:\n",
        "                return \"NORMAL\"\n",
        "            if fused_score < 0.4:\n",
        "                return \"LOW\"\n",
        "\n",
        "        # moderate region\n",
        "        if fused_score < 0.5:\n",
        "            return \"LOW\"\n",
        "        if fused_score < 0.7:\n",
        "            return \"MEDIUM\"\n",
        "        if fused_score < 0.9:\n",
        "            return \"HIGH\"\n",
        "\n",
        "        return \"CRITICAL\"\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# UPGRADED EXPERT AGENT (SOTA-STYLE FOR METROPT)\n",
        "# =====================================================\n",
        "import json\n",
        "from datetime import datetime\n",
        "from typing import Optional, Dict, Any, List\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class ExpertAgent:\n",
        "    \"\"\"\n",
        "    ExpertAgent (Upgraded):\n",
        "      - Invoked when DecisionAgent flags an anomaly (or when you choose).\n",
        "      - Uses rich context:\n",
        "          * decision_packet (DecisionAgent output)\n",
        "          * raw master_output (sensor-level results)\n",
        "          * raw window_output (AdaptiveWindowAgent)\n",
        "          * prototype scores, etc. via model_outputs in decision_packet\n",
        "          * recent multivariate sensor window (numeric snapshot)\n",
        "          * recent history from EventStore\n",
        "          * static domain knowledge (sensor metadata, fault patterns)\n",
        "      - Calls an LLM to produce:\n",
        "          * summary\n",
        "          * explanation\n",
        "          * likely_fault\n",
        "          * recommended_action\n",
        "          * severity\n",
        "      - Validates JSON and falls back gracefully on errors.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        event_store,\n",
        "        system_description: str = \"MetroPT Air Production Unit (APU)\",\n",
        "        llm_client: Optional[object] = None,\n",
        "        history_limit: int = 100,\n",
        "        max_history_for_prompt: int = 10,\n",
        "        window_preview_len: int = 10,\n",
        "        sensor_metadata: Optional[Dict[str, str]] = None,\n",
        "        fault_knowledge: Optional[List[str]] = None,\n",
        "        max_retries: int = 2,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        event_store         : EventStore instance (for past decisions)\n",
        "        system_description  : short description of the system\n",
        "        llm_client          : OpenAI client (OpenAI())\n",
        "        history_limit       : how many past events to fetch from DB\n",
        "        max_history_for_prompt : how many to actually show to LLM\n",
        "        window_preview_len  : last N timesteps per sensor to show\n",
        "        sensor_metadata     : mapping sensor_index -> human-readable name\n",
        "        fault_knowledge     : list of domain fault patterns (strings)\n",
        "        max_retries         : number of LLM retry attempts on failure\n",
        "        \"\"\"\n",
        "        self.store = event_store\n",
        "        self.system_description = system_description\n",
        "        self.llm_client = llm_client\n",
        "        self.history_limit = history_limit\n",
        "        self.max_history_for_prompt = max_history_for_prompt\n",
        "        self.window_preview_len = window_preview_len\n",
        "        self.max_retries = max_retries\n",
        "\n",
        "        # Default MetroPT-style sensor metadata (can be overridden)\n",
        "        if sensor_metadata is None:\n",
        "            self.sensor_metadata = {\n",
        "                0: \"TP2 (bar): the measure of the pressure on the compressor\",\n",
        "                1: \"TP3 (bar): the measure of the pressure generated at the pneumatic panel\",\n",
        "                2: \"H1 (bar) – the measure of the pressure generated due to pressure drop when the discharge of the cyclonic separator filter occurs\",\n",
        "                3: \"DV pressure (bar): the measure of the pressure drop generated when the towers discharge air dryers; a zero reading indicates that the compressor is operating under load\",\n",
        "                4: \"Reservoirs (bar): the measure of the downstream pressure of the reservoirs, which should be close to the pneumatic panel pressure (TP3)\",\n",
        "                5: \"Oil Temperature (ºC) :  the measure of the oil temperature on the compressor\",\n",
        "                6: \"Motor Current (A) –  the measure of the current of one phase of the three-phase motor; it presents values close to 0A - when it turns off, 4A - when working offloaded, 7A - when working under load, and 9A - when it starts working\",\n",
        "                7: \"COMP - the electrical signal of the air intake valve on the compressor; it is active when there is no air intake, indicating that the compressor is either turned off or operating in an offloaded state.\",\n",
        "                8: \"DV electric – the electrical signal that controls the compressor outlet valve; it is active when the compressor is functioning under load and inactive when the compressor is either off or operating in an offloaded state.\",\n",
        "                9: \"TOWERS – the electrical signal that defines the tower responsible for drying the air and the tower responsible for draining the humidity removed from the air; when not active, it indicates that tower one is functioning; when active, it indicates that tower two is in operation.\",\n",
        "                10: \"MPG – the electrical signal responsible for starting the compressor under load by activating the intake valve when the pressure in the air production unit (APU) falls below 8.2 bar; it activates the COMP sensor, which assumes the same behaviour as the MPG sensor\",\n",
        "                11: \"LPS – the electrical signal that detects and activates when the pressure drops below 7 bars\",\n",
        "\n",
        "            }\n",
        "        else:\n",
        "            self.sensor_metadata = sensor_metadata\n",
        "\n",
        "        # Default MetroPT-style fault patterns (can be overridden)\n",
        "        if fault_knowledge is None:\n",
        "            self.fault_knowledge = [\n",
        "                \"Air Leak: gradual pressure decay + increased compressor runtime.\",\n",
        "                \"Blockage: oscillatory or unstable pressure + abnormal valve cycling.\",\n",
        "                \"Overheating: rising oil temperature + increased motor current.\",\n",
        "                \"Valve Stuck: valve digital state frozen while pressure behaviour is abnormal.\",\n",
        "                \"Short Cycling: frequent compressor start/stop in short intervals.\",\n",
        "                \"Sensor Failure: flat-line, impossible values, or inconsistent readings.\",\n",
        "            ]\n",
        "        else:\n",
        "            self.fault_knowledge = fault_knowledge\n",
        "\n",
        "    # =====================================================\n",
        "    # PUBLIC ENTRYPOINT\n",
        "    # =====================================================\n",
        "    def analyse_anomaly(\n",
        "        self,\n",
        "        decision_packet: dict,\n",
        "        system_subsequence: np.ndarray,\n",
        "        extra_context: Optional[dict] = None,\n",
        "    ) -> dict:\n",
        "        \"\"\"\n",
        "        Main entry point:\n",
        "          - decision_packet: from DecisionAgent.decide(...)\n",
        "          - system_subsequence: [window_length, num_sensors] np.ndarray\n",
        "          - extra_context: anything else (index, timestamps, etc.)\n",
        "\n",
        "        Returns:\n",
        "          expert_packet dict with:\n",
        "            - timestamp\n",
        "            - decision_packet\n",
        "            - prompt_used\n",
        "            - llm_result (JSON from model or fallback)\n",
        "        \"\"\"\n",
        "        # 1) Fetch recent past decisions from EventStore\n",
        "        recent_raw_decisions = self.store.fetch_recent(limit=self.history_limit)\n",
        "\n",
        "        # 2) Build rich prompt\n",
        "        prompt = self._build_prompt(\n",
        "            decision_packet=decision_packet,\n",
        "            system_subsequence=system_subsequence,\n",
        "            extra_context=extra_context,\n",
        "            recent_events=recent_raw_decisions,\n",
        "        )\n",
        "\n",
        "        # 3) Call LLM with JSON-only contract\n",
        "        llm_result = self._call_llm_with_json(prompt)\n",
        "\n",
        "        expert_packet = {\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"decision_packet\": decision_packet,\n",
        "            \"prompt_used\": prompt,\n",
        "            \"llm_result\": llm_result,\n",
        "        }\n",
        "\n",
        "        return expert_packet\n",
        "\n",
        "    # =====================================================\n",
        "    # PROMPT CONSTRUCTION\n",
        "    # =====================================================\n",
        "    def _build_prompt(\n",
        "        self,\n",
        "        decision_packet: dict,\n",
        "        system_subsequence: np.ndarray,\n",
        "        extra_context: Optional[dict],\n",
        "        recent_events: List[dict],\n",
        "    ) -> str:\n",
        "        \"\"\"\n",
        "        Build a rich natural-language + structured prompt for the LLM.\n",
        "        Includes:\n",
        "          - system description\n",
        "          - sensor metadata\n",
        "          - known fault patterns\n",
        "          - current decision scores + flags\n",
        "          - per-sensor anomaly info (if available)\n",
        "          - small numeric snapshot of current window\n",
        "          - compressed recent history\n",
        "          - explicit JSON response schema\n",
        "        \"\"\"\n",
        "\n",
        "        # -------------------------------\n",
        "        # 1) Extract top-level scores\n",
        "        # -------------------------------\n",
        "        scores = decision_packet.get(\"scores\", {})\n",
        "        window_info = decision_packet.get(\"window_agent\", {})\n",
        "        alert_level = decision_packet.get(\"alert_level\", \"UNKNOWN\")\n",
        "        final_anomaly = decision_packet.get(\"final_anomaly\", False)\n",
        "        final_drift = decision_packet.get(\"final_drift\", False)\n",
        "        final_retrain = decision_packet.get(\"final_retrain\", False)\n",
        "\n",
        "        # -------------------------------\n",
        "        # 2) Extract raw master/window/model data (if available)\n",
        "        # -------------------------------\n",
        "        raw_block = decision_packet.get(\"raw\", {})\n",
        "        master_output = raw_block.get(\"master_output\", None)\n",
        "        window_output = raw_block.get(\"window_output\", None)\n",
        "        model_outputs = raw_block.get(\"model_outputs\", {})\n",
        "        metadata = raw_block.get(\"metadata\", {})\n",
        "\n",
        "        prototype_score = model_outputs.get(\"prototype_score\", None)\n",
        "        transformer_prob = model_outputs.get(\"transformer_prob\", None)\n",
        "\n",
        "        # -------------------------------\n",
        "        # 3) Per-sensor anomaly stats from master_output\n",
        "        # -------------------------------\n",
        "        per_sensor_summary = []\n",
        "        if master_output is not None:\n",
        "            sensor_results = master_output.get(\"sensor_results\", [])\n",
        "            for i, res in enumerate(sensor_results):\n",
        "                name = self.sensor_metadata.get(i, f\"Sensor_{i}\")\n",
        "                per_sensor_summary.append({\n",
        "                    \"sensor_index\": i,\n",
        "                    \"name\": name,\n",
        "                    \"is_anomaly\": bool(res.get(\"is_anomaly\", False)),\n",
        "                    \"drift_flag\": bool(res.get(\"drift_flag\", False)),\n",
        "                    \"needs_retrain\": bool(res.get(\"needs_retrain_flag\", False)),\n",
        "                    \"anomaly_score\": float(res.get(\"anomaly_score\", 0.0)),\n",
        "                    \"confidence\": float(res.get(\"confidence\", 0.0)),\n",
        "                })\n",
        "\n",
        "        # -------------------------------\n",
        "        # 4) Numeric snapshot of current window\n",
        "        # -------------------------------\n",
        "        # system_subsequence: [T, F]\n",
        "        try:\n",
        "            seq = np.asarray(system_subsequence)\n",
        "            T, F = seq.shape\n",
        "        except Exception:\n",
        "            seq = np.array(system_subsequence)\n",
        "            if seq.ndim == 1:\n",
        "                seq = seq.reshape(-1, 1)\n",
        "            T, F = seq.shape\n",
        "\n",
        "        preview_len = min(self.window_preview_len, T)\n",
        "        window_preview = seq[-preview_len:]  # shape [preview_len, F]\n",
        "\n",
        "        # Represent as {sensor_name: [values...]}\n",
        "        sensor_window_dict = {}\n",
        "        for j in range(F):\n",
        "            name = self.sensor_metadata.get(j, f\"Sensor_{j}\")\n",
        "            sensor_window_dict[name] = window_preview[:, j].round(4).tolist()\n",
        "\n",
        "        # -------------------------------\n",
        "        # 5) Compressed recent history\n",
        "        # -------------------------------\n",
        "        history_summaries = []\n",
        "        for ev in recent_events[: self.max_history_for_prompt]:\n",
        "            try:\n",
        "                # ev is a past decision_packet (because we stored 'packet=decision_packet')\n",
        "                scores_ev = ev.get(\"scores\", {})\n",
        "                history_summaries.append({\n",
        "                    \"timestamp\": ev.get(\"timestamp\", \"\"),\n",
        "                    \"alert_level\": ev.get(\"alert_level\", \"UNKNOWN\"),\n",
        "                    \"anomaly_score\": scores_ev.get(\"anomaly_score\", None),\n",
        "                    \"drift_score\": scores_ev.get(\"drift_score\", None),\n",
        "                })\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "        # -------------------------------\n",
        "        # 6) Sensor metadata & fault patterns as text\n",
        "        # -------------------------------\n",
        "        sensor_meta_list = [f\"{idx}: {desc}\" for idx, desc in self.sensor_metadata.items()]\n",
        "\n",
        "        fault_knowledge_text = \"\\n\".join(\n",
        "            [f\"- {fk}\" for fk in self.fault_knowledge]\n",
        "        )\n",
        "\n",
        "        # -------------------------------\n",
        "        # 7) Build final instruction with JSON schema\n",
        "        # -------------------------------\n",
        "        schema_instruction = \"\"\"\n",
        "You MUST respond with ONLY a single valid JSON object, no extra text.\n",
        "The JSON MUST have exactly the following keys at the top level:\n",
        "\n",
        "- \"summary\": short 1-2 sentence description of what is happening.\n",
        "- \"explanation\": 2-6 sentences, clear reasoning in industrial / physical terms.\n",
        "- \"likely_fault\": short label of the most likely fault type, or \"Unknown\".\n",
        "- \"recommended_action\": one of:\n",
        "    - \"IGNORE\"\n",
        "    - \"MONITOR\"\n",
        "    - \"ACK_AND_INVESTIGATE\"\n",
        "    - \"SCHEDULE_MAINTENANCE\"\n",
        "    - \"IMMEDIATE_SHUTDOWN\"\n",
        "- \"severity\": one of: \"LOW\", \"MEDIUM\", \"HIGH\", \"CRITICAL\".\n",
        "\n",
        "Do NOT include any extra keys outside these five.\n",
        "Do NOT include any surrounding text, markdown, or commentary.\n",
        "Return ONLY the JSON object.\n",
        "\"\"\"\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "You are an expert industrial fault diagnosis assistant for: {self.system_description}.\n",
        "\n",
        "System context:\n",
        "- This is a compressed-air production unit (APU) of a metro train.\n",
        "- Sensors include analog (pressure, current, temperature) and digital (valves, states).\n",
        "\n",
        "Sensor metadata (index -> description):\n",
        "{json.dumps(sensor_meta_list, indent=2)}\n",
        "\n",
        "Known fault patterns (domain knowledge):\n",
        "{fault_knowledge_text}\n",
        "\n",
        "CURRENT DECISION PACKET:\n",
        "\n",
        "- Alert level: {alert_level}\n",
        "\n",
        "PREDICTION SIGNALS (from ML failure model):\n",
        "- final_failure (prediction-based): {decision_packet.get(\"final_failure\")}\n",
        "- prediction_failure_prob: {scores.get(\"prediction_failure_prob\")}\n",
        "- prediction_fused_score: {scores.get(\"prediction_fused_score\")}\n",
        "\n",
        "DETECTION SIGNALS (from sensor & window agents):\n",
        "- final_anomaly (sensor-based): {final_anomaly}\n",
        "- final_drift (sensor/window-based): {final_drift}\n",
        "- final_retrain: {final_retrain}\n",
        "\n",
        "All prediction and detection signals are separate:\n",
        "- Prediction = future failure likelihood (ML)\n",
        "- Detection = current abnormalities (sensor + drift + window)\n",
        "\n",
        "Window agent info:\n",
        "{json.dumps(window_info)}\n",
        "\n",
        "Prototype / transformer outputs (if any):\n",
        "- prototype_score: {prototype_score}\n",
        "- transformer_prob: {transformer_prob}\n",
        "\n",
        "Per-sensor anomaly summary:\n",
        "{json.dumps(per_sensor_summary, indent=2)}\n",
        "\n",
        "Current sensor window snapshot (last {preview_len} timesteps for each sensor):\n",
        "{json.dumps(sensor_window_dict, indent=2)}\n",
        "\n",
        "Recent history of decisions (compressed):\n",
        "{json.dumps(history_summaries, indent=2)}\n",
        "\n",
        "Extra context:\n",
        "{json.dumps(extra_context, default=str)}\n",
        "\n",
        "Your tasks:\n",
        "1. Decide whether this anomaly is likely REAL or a FALSE POSITIVE.\n",
        "2. Infer which fault pattern (if any) best matches the evidence.\n",
        "3. Explain the reasoning in terms of sensor behaviour (pressure, current, valves, temperature).\n",
        "4. Recommend the next action for the human operator, considering safety and cost.\n",
        "5. Assign a severity level: LOW, MEDIUM, HIGH, or CRITICAL.\n",
        "\n",
        "{schema_instruction}\n",
        "\"\"\"\n",
        "        return prompt\n",
        "\n",
        "    # =====================================================\n",
        "    # LLM CALL + JSON HANDLING\n",
        "    # =====================================================\n",
        "    def _call_llm_with_json(self, prompt: str) -> dict:\n",
        "        \"\"\"\n",
        "        Calls the LLM via self.llm_client and returns a validated JSON dict.\n",
        "        Uses:\n",
        "          - prompt-based JSON contract\n",
        "          - retry with minimal fallback\n",
        "          - schema validation\n",
        "        \"\"\"\n",
        "\n",
        "        # If no client configured, return fallback\n",
        "        if self.llm_client is None:\n",
        "            return {\n",
        "                \"summary\": \"Anomaly detected (fallback, no LLM client configured).\",\n",
        "                \"explanation\": \"ExpertAgent has no LLM client; returning default recommendation.\",\n",
        "                \"likely_fault\": \"Unknown\",\n",
        "                \"recommended_action\": \"ACK_AND_INVESTIGATE\",\n",
        "                \"severity\": \"MEDIUM\",\n",
        "            }\n",
        "\n",
        "        last_error = None\n",
        "\n",
        "        for attempt in range(self.max_retries):\n",
        "            try:\n",
        "                response = self.llm_client.responses.create(\n",
        "                    model=\"gpt-4o-mini\",\n",
        "                    input=prompt,\n",
        "                    max_output_tokens=400,\n",
        "                )\n",
        "\n",
        "                # Using unified Responses API: easiest is output_text\n",
        "                raw_text = getattr(response, \"output_text\", None)\n",
        "                if raw_text is None:\n",
        "                    # fallback to explicit extraction\n",
        "                    raw_text = response.output[0].content[0].text\n",
        "\n",
        "                parsed = self._robust_json_parse(raw_text)\n",
        "                validated = self._validate_llm_json(parsed)\n",
        "                return validated\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ ExpertAgent LLM error (attempt {attempt+1}): {e}\")\n",
        "                last_error = e\n",
        "\n",
        "        # Final fallback if everything fails\n",
        "        return {\n",
        "            \"summary\": \"Anomaly detected (LLM fallback).\",\n",
        "            \"explanation\": f\"LLM failed or returned invalid JSON. Last error: {last_error}\",\n",
        "            \"likely_fault\": \"Unknown\",\n",
        "            \"recommended_action\": \"ACK_AND_INVESTIGATE\",\n",
        "            \"severity\": \"MEDIUM\",\n",
        "        }\n",
        "\n",
        "    def _robust_json_parse(self, text: str) -> dict:\n",
        "        \"\"\"\n",
        "        Best-effort JSON parsing:\n",
        "          - First try direct json.loads\n",
        "          - If fails, try to extract the first {...} block\n",
        "        \"\"\"\n",
        "        text = text.strip()\n",
        "        try:\n",
        "            return json.loads(text)\n",
        "        except Exception:\n",
        "            # Try to find a JSON object substring\n",
        "            start = text.find(\"{\")\n",
        "            end = text.rfind(\"}\")\n",
        "            if start != -1 and end != -1 and end > start:\n",
        "                snippet = text[start : end + 1]\n",
        "                return json.loads(snippet)\n",
        "            # If still failing, raise\n",
        "            raise\n",
        "\n",
        "    def _validate_llm_json(self, obj: Any) -> dict:\n",
        "        \"\"\"\n",
        "        Enforce a minimal schema:\n",
        "          - must be a dict\n",
        "          - must contain keys: summary, explanation, likely_fault, recommended_action, severity\n",
        "        If keys are missing, fill with defaults.\n",
        "        \"\"\"\n",
        "\n",
        "        if not isinstance(obj, dict):\n",
        "            raise ValueError(\"LLM output is not a JSON object\")\n",
        "\n",
        "        required_keys = [\"summary\", \"explanation\", \"likely_fault\", \"recommended_action\", \"severity\"]\n",
        "        defaults = {\n",
        "            \"summary\": \"No summary provided by LLM.\",\n",
        "            \"explanation\": \"No explanation provided by LLM.\",\n",
        "            \"likely_fault\": \"Unknown\",\n",
        "            \"recommended_action\": \"ACK_AND_INVESTIGATE\",\n",
        "            \"severity\": \"MEDIUM\",\n",
        "        }\n",
        "\n",
        "        cleaned = {}\n",
        "        for k in required_keys:\n",
        "            v = obj.get(k, defaults[k])\n",
        "            # ensure string\n",
        "            cleaned[k] = str(v)\n",
        "\n",
        "        # Optionally normalise recommended_action/severity to known values\n",
        "        cleaned[\"recommended_action\"] = cleaned[\"recommended_action\"].upper().strip()\n",
        "        cleaned[\"severity\"] = cleaned[\"severity\"].upper().strip()\n",
        "\n",
        "        # Clamp to allowed sets if desired\n",
        "        allowed_actions = {\n",
        "            \"IGNORE\",\n",
        "            \"MONITOR\",\n",
        "            \"ACK_AND_INVESTIGATE\",\n",
        "            \"SCHEDULE_MAINTENANCE\",\n",
        "            \"IMMEDIATE_SHUTDOWN\",\n",
        "        }\n",
        "        if cleaned[\"recommended_action\"] not in allowed_actions:\n",
        "            cleaned[\"recommended_action\"] = \"ACK_AND_INVESTIGATE\"\n",
        "\n",
        "        allowed_severity = {\"LOW\", \"MEDIUM\", \"HIGH\", \"CRITICAL\"}\n",
        "        if cleaned[\"severity\"] not in allowed_severity:\n",
        "            cleaned[\"severity\"] = \"MEDIUM\"\n",
        "\n",
        "        return cleaned\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# SIMPLE HUMAN LOOP + ALERT STUB\n",
        "# =====================================================\n",
        "\n",
        "import smtplib\n",
        "from email.mime.text import MIMEText\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "\n",
        "\n",
        "def send_alert_to_human(expert_packet: dict):\n",
        "    \"\"\"\n",
        "    Sends an email alert to a human operator using SMTP.\n",
        "    Includes summary, recommended action, severity, and JSON dump.\n",
        "    \"\"\"\n",
        "\n",
        "    # ----------------------\n",
        "    # Extract ExpertAgent output\n",
        "    # ----------------------\n",
        "    result = expert_packet.get(\"llm_result\", {})\n",
        "    summary = result.get(\"summary\", \"No summary\")\n",
        "    action = result.get(\"recommended_action\", \"N/A\")\n",
        "    severity = result.get(\"severity\", \"N/A\")\n",
        "\n",
        "    decision_packet_json = json.dumps(\n",
        "        expert_packet.get(\"decision_packet\", {}),\n",
        "        indent=2\n",
        "    )\n",
        "    llm_json = json.dumps(result, indent=2)\n",
        "\n",
        "    # ----------------------\n",
        "    # Email content\n",
        "    # ----------------------\n",
        "    subject = f\"⚠️ APU Alert – Severity: {severity}\"\n",
        "\n",
        "    body = f\"\"\"\n",
        "Human Operator,\n",
        "\n",
        "An alert has been generated by the APU Monitoring System.\n",
        "\n",
        "-------------------\n",
        "SUMMARY\n",
        "-------------------\n",
        "{summary}\n",
        "\n",
        "-------------------\n",
        "RECOMMENDED ACTION\n",
        "-------------------\n",
        "{action}\n",
        "\n",
        "-------------------\n",
        "SEVERITY\n",
        "-------------------\n",
        "{severity}\n",
        "\n",
        "-------------------\n",
        "FULL LLM RESULT\n",
        "-------------------\n",
        "{llm_json}\n",
        "\n",
        "-------------------\n",
        "RAW DECISION PACKET\n",
        "-------------------\n",
        "{decision_packet_json}\n",
        "\n",
        "Timestamp: {expert_packet.get('timestamp')}\n",
        "\"\"\"\n",
        "\n",
        "    # ----------------------\n",
        "    # Create email object\n",
        "    # ----------------------\n",
        "    msg = MIMEMultipart()\n",
        "    msg[\"From\"] = EMAIL_SENDER\n",
        "    msg[\"To\"] = EMAIL_RECIPIENT\n",
        "    msg[\"Subject\"] = subject\n",
        "\n",
        "    msg.attach(MIMEText(body, \"plain\"))\n",
        "\n",
        "    # ----------------------\n",
        "    # Send email via SMTP\n",
        "    # ----------------------\n",
        "    try:\n",
        "        server = smtplib.SMTP(SMTP_SERVER, SMTP_PORT)\n",
        "        server.starttls()\n",
        "        server.login(EMAIL_SENDER, EMAIL_PASSWORD)\n",
        "        server.sendmail(EMAIL_SENDER, EMAIL_RECIPIENT, msg.as_string())\n",
        "        server.quit()\n",
        "\n",
        "        print(\"\\n=== EMAIL ALERT SENT SUCCESSFULLY ===\")\n",
        "        print(f\"To: {EMAIL_RECIPIENT}\")\n",
        "        print(f\"Summary: {summary}\")\n",
        "        print(\"======================================\\n\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"❌ Failed to send alert email:\", e)\n",
        "\n",
        "\n",
        "\n",
        "def get_human_feedback_stub(expert_packet: dict) -> dict:\n",
        "    \"\"\"\n",
        "    Stub: in a real deployment, this would come from UI / operator.\n",
        "    Here we just echo back a synthetic 'ACK'.\n",
        "    \"\"\"\n",
        "    return {\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"final_decision\": \"ACK_AND_LOG\",\n",
        "        \"notes\": \"Stub human feedback – replace with real operator input.\",\n",
        "    }\n",
        "##################################################\n",
        "#GROUND TRUTH ANOMALY VS WHICH AGENT AGENT IS RIGHT\n",
        "############################################################\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_agent_vs_groundtruth(\n",
        "    results,\n",
        "    detection_labels=None,\n",
        "    h1_labels=None,\n",
        "    h3_labels=None,\n",
        "    h12_labels=None,\n",
        "    max_samples=200\n",
        "):\n",
        "    \"\"\"\n",
        "    Plot comparison between agent decisions, ground-truth labels,\n",
        "    coordinator outputs, and AdaptiveWindowAgent predictions.\n",
        "    \"\"\"\n",
        "\n",
        "    n = min(max_samples, len(results))\n",
        "    t = np.arange(n)\n",
        "\n",
        "    # Extract coordinator anomaly/drift\n",
        "    agent_anomaly = [1 if r[\"coordinator\"][\"final_anomaly\"] else 0 for r in results[:n]]\n",
        "    agent_drift   = [1 if r[\"coordinator\"][\"final_drift\"] else 0 for r in results[:n]]\n",
        "\n",
        "    # New: extract ML prediction\n",
        "    failure_prob = [\n",
        "        results[i][\"coordinator\"][\"scores\"].get(\"prediction_failure_prob\", 0.0)\n",
        "        for i in range(n)\n",
        "    ]\n",
        "    final_failure = [\n",
        "        1 if results[i][\"coordinator\"].get(\"final_failure\") else 0\n",
        "        for i in range(n)\n",
        "    ]\n",
        "\n",
        "    # Ground-truth labels\n",
        "    det = detection_labels[:n] if detection_labels is not None else None\n",
        "    h1  = h1_labels[:n] if h1_labels is not None else None\n",
        "    h3  = h3_labels[:n] if h3_labels is not None else None\n",
        "    h12 = h12_labels[:n] if h12_labels is not None else None\n",
        "\n",
        "    # Window agent outputs\n",
        "    window_sizes  = [r[\"window\"][\"predicted_window\"] for r in results[:n]]\n",
        "    window_events = [r[\"window\"].get(\"event_type\") for r in results[:n]]\n",
        "\n",
        "    # ---- Create subplots ----\n",
        "    fig, axes = plt.subplots(6, 1, figsize=(15, 17), sharex=True)\n",
        "\n",
        "    # Agent outputs\n",
        "    axes[0].plot(t, agent_anomaly, label=\"Agent Anomaly\", color=\"red\")\n",
        "    axes[0].plot(t, agent_drift,   label=\"Agent Drift\", color=\"orange\")\n",
        "    axes[0].set_ylabel(\"Agent\")\n",
        "    axes[0].legend()\n",
        "\n",
        "    # Detection labels\n",
        "    if det is not None:\n",
        "        axes[1].plot(t, det, label=\"Detection Labels\", color=\"blue\")\n",
        "        axes[1].set_ylabel(\"Detect\")\n",
        "        axes[1].legend()\n",
        "\n",
        "    # Prediction labels (1h, 3h, 12h)\n",
        "    if h1 is not None:\n",
        "        axes[2].plot(t, h1, label=\"H1\", color=\"green\")\n",
        "    if h3 is not None:\n",
        "        axes[2].plot(t, h3, label=\"H3\", color=\"purple\")\n",
        "    if h12 is not None:\n",
        "        axes[2].plot(t, h12, label=\"H12\", color=\"brown\")\n",
        "    axes[2].set_ylabel(\"Prediction\")\n",
        "    axes[2].legend()\n",
        "\n",
        "    # Coordinator alert level\n",
        "    alert_map = {\"NORMAL\": 0, \"MEDIUM\": 1, \"HIGH\": 2, \"CRITICAL\": 3}\n",
        "    alerts = [alert_map.get(r[\"coordinator\"][\"alert_level\"], 0) for r in results[:n]]\n",
        "    axes[3].plot(t, alerts, label=\"Alert Level\", color=\"black\")\n",
        "    axes[3].set_yticks([0,1,2,3])\n",
        "    axes[3].set_yticklabels([\"NORMAL\",\"MED\",\"HIGH\",\"CRIT\"])\n",
        "    axes[3].set_ylabel(\"Coordinator\")\n",
        "    axes[3].legend()\n",
        "\n",
        "    # AdaptiveWindowAgent subplot\n",
        "    axes[4].plot(t, window_sizes, label=\"Predicted Window\", color=\"blue\")\n",
        "\n",
        "    # Mark drift/anomaly events\n",
        "    for i, evt in enumerate(window_events):\n",
        "        if evt == \"DRIFT\":\n",
        "            axes[4].scatter(i, window_sizes[i], color=\"orange\", marker=\"x\", label=\"Window Drift\" if i==0 else \"\")\n",
        "        elif evt == \"ANOMALY\":\n",
        "            axes[4].scatter(i, window_sizes[i], color=\"red\", marker=\"o\", label=\"Window Anomaly\" if i==0 else \"\")\n",
        "\n",
        "        # ----------------------------------------------------\n",
        "    # ⭐ Row 6: ML Failure Prediction Probability\n",
        "    # ----------------------------------------------------\n",
        "    axes[5].plot(t, failure_prob, label=\"Failure Prob (ML)\", color=\"green\")\n",
        "    axes[5].plot(t, final_failure, label=\"Final Failure Decision\", color=\"red\", linestyle=\"--\")\n",
        "\n",
        "    axes[5].set_ylabel(\"Fail Prob\")\n",
        "    axes[5].set_ylim([-0.1, 1.1])\n",
        "    axes[5].legend()\n",
        "\n",
        "    # Overlay ground-truth fault events (vertical lines)\n",
        "    if det is not None:\n",
        "        for i, val in enumerate(det):\n",
        "            if val == 1:\n",
        "                axes[4].axvline(i, color=\"red\", linestyle=\"--\", alpha=0.3, label=\"Fault (Detection)\" if i==0 else \"\")\n",
        "    if h1 is not None:\n",
        "        for i, val in enumerate(h1):\n",
        "            if val == 1:\n",
        "                axes[4].axvline(i, color=\"green\", linestyle=\"--\", alpha=0.2, label=\"Fault (H1)\" if i==0 else \"\")\n",
        "    if h3 is not None:\n",
        "        for i, val in enumerate(h3):\n",
        "            if val == 1:\n",
        "                axes[4].axvline(i, color=\"purple\", linestyle=\"--\", alpha=0.2, label=\"Fault (H3)\" if i==0 else \"\")\n",
        "    if h12 is not None:\n",
        "        for i, val in enumerate(h12):\n",
        "            if val == 1:\n",
        "                axes[4].axvline(i, color=\"brown\", linestyle=\"--\", alpha=0.2, label=\"Fault (H12)\" if i==0 else \"\")\n",
        "\n",
        "    axes[4].set_ylabel(\"Window Size\")\n",
        "    axes[4].legend()\n",
        "\n",
        "    axes[-1].set_xlabel(\"Sample index\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "#=========================================================================================================================================\n",
        "#=========================================================================================================================================\n",
        "#=========================================================================================================================================\n",
        "#=========================================================================================================================================\n",
        "#############################################\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import joblib\n",
        "\n",
        "# =============================================================================================================================\n",
        "# 1. Load Data - BASELINE MODELS----------------------------\n",
        "# ============================================================-======================================================================\n",
        "# Long subsequences (length=50) and labels\n",
        "long_sequences = np.load(\"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/multivariate_long_sequences-TRAIN-Daily-DIRECT-VAR.npy\")\n",
        "labels_detection = np.load(\"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/anomaly_labels_detection.npy\")  # fault labels\n",
        "labels_h1 = np.load(\"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/anomaly_labels_H1.npy\")  # optional predictive labels\n",
        "labels_h3 = np.load(\"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/anomaly_labels_H3.npy\")  # optional predictive labels\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Holdout block (future data)\n",
        "H = 1500\n",
        "X_holdout = long_sequences[-H:]\n",
        "y_holdout = labels_h3[-H:]\n",
        "\n",
        "# Remaining data for train + test\n",
        "X_main = long_sequences[:-H]\n",
        "y_main = labels_h3[:-H]\n",
        "\n",
        "print(\"Total main:\", X_main.shape, y_main.shape)\n",
        "print(\"Holdout:\", X_holdout.shape, y_holdout.shape)\n",
        "\n",
        "long_sequences_fit = long_sequences[:-H]\n",
        "labels_detection_fit = labels_detection[:-H]\n",
        "\n",
        "print(\"Data loaded:\", long_sequences_fit.shape, labels_detection_fit.shape)\n",
        "\n",
        "\n",
        "# ======================================================================\n",
        "# 3. Chronological Splitting (NO random shuffle)\n",
        "# ======================================================================\n",
        "# Simple chronological split\n",
        "split_ratio = 0.735  # adjust if needed based on manual validation\n",
        "split_point = int(len(X_main) * split_ratio)\n",
        "\n",
        "X_train = X_main[:split_point]\n",
        "y_train = y_main[:split_point]\n",
        "\n",
        "X_test = X_main[split_point:]\n",
        "y_test = y_main[split_point:]\n",
        "\n",
        "print(\"Train:\", X_train.shape, y_train.shape)\n",
        "print(\"Test:\", X_test.shape, y_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "# ======================================================================\n",
        "# MANUAL TESTING - failure presence in data\n",
        "# ======================================================================\n",
        "print(\"Anomalies in TRAIN:\", y_train.sum())\n",
        "print(\"Anomalies in TEST :\", y_test.sum())\n",
        "print(\"Anomalies in HOLDOUT:\", y_holdout.sum())\n",
        "\n",
        "# ======================================================================\n",
        "# Flatten windows\n",
        "# ======================================================================\n",
        "\n",
        "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
        "X_test_flat  = X_test.reshape(X_test.shape[0], -1)\n",
        "X_holdout_flat = X_holdout.reshape(X_holdout.shape[0], -1)\n",
        "\n",
        "# ============================================================\n",
        "# 2. Baseline 1 Fixed Window Features (window=50, flattened)\n",
        "# ============================================================\n",
        "\n",
        "\n",
        "# Baseline-1: Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42, n_jobs=-1)\n",
        "rf.fit(X_train_flat, y_train)\n",
        "y_pred_test = rf.predict(X_test_flat)\n",
        "\n",
        "print(\"\\n=== Baseline-1: Fixed Window Random Forest test data ===\")\n",
        "print(classification_report(y_test, y_pred_test, digits=4))\n",
        "print(confusion_matrix(y_test, y_pred_test))\n",
        "joblib.dump(rf, \"rf_fixed_window.pkl\")\n",
        "\n",
        "########## HOLDOUT\n",
        "\n",
        "y_pred_h = rf.predict(X_holdout_flat)\n",
        "\n",
        "print(\"\\n=== Baseline-1: Fixed Window Random Forest holdout data ===\")\n",
        "print(classification_report(y_holdout, y_pred_h, digits=4))\n",
        "print(confusion_matrix(y_holdout, y_pred_h))\n",
        "joblib.dump(rf, \"rf_fixed_window_holdout.pkl\")\n",
        "\n",
        "\n",
        "# ==========================================================================================================================\n",
        "# 3. Dynamic Window Features (using your AdaptiveWindowAgent)\n",
        "# =============================================================================================================================\n",
        "#from agents.adaptive_window_agent import AdaptiveWindowAgent\n",
        "\n",
        "window_agent = AdaptiveWindowAgent(\n",
        "    model_path=\"/content/drive/MyDrive/PHD/2025/DGRNet-MLP-Versions/METROPM_MLP_model_Daily.keras\"\n",
        ")\n",
        "\n",
        "\n",
        "# Generate features for each subsequence using predicted window - including holdout.\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Paths\n",
        "dyn_feat_path = \"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/dynamic_features.npy\"\n",
        "\n",
        "if os.path.exists(dyn_feat_path):\n",
        "    print(f\"✅ Loading existing dynamic features from {dyn_feat_path}\")\n",
        "    dynamic_features = np.load(dyn_feat_path, allow_pickle=True)\n",
        "else:\n",
        "    print(\"⚠️ Dynamic features not found. Generating now...\")\n",
        "\n",
        "    dynamic_features = []\n",
        "    for i, seq in enumerate(long_sequences):\n",
        "        try:\n",
        "            features = seq.flatten()\n",
        "            result = window_agent.predict_window_size(features, seq)\n",
        "            w = result.get(\"predicted_window\", 50)\n",
        "\n",
        "            # Extract last w timesteps from the long sequence\n",
        "            seq_dynamic = seq[-w:].flatten()\n",
        "            dynamic_features.append(seq_dynamic)\n",
        "\n",
        "            if (i + 1) % 100 == 0:\n",
        "                print(f\"Processed {i+1}/{len(long_sequences)} sequences...\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error on sequence {i}: {e}\")\n",
        "            # fallback: use fixed window\n",
        "            seq_dynamic = seq[-50:].flatten()\n",
        "            dynamic_features.append(seq_dynamic)\n",
        "\n",
        "    dynamic_features = np.array(dynamic_features, dtype=object)\n",
        "    np.save(dyn_feat_path, dynamic_features)\n",
        "    print(f\"✅ Saved dynamic features to {dyn_feat_path}\")\n",
        "\n",
        "print(\"Dynamic feature shape:\", np.shape(dynamic_features))\n",
        "\n",
        "# Pad to same length (use max window=50)\n",
        "# Pad to same length (max window = 50)\n",
        "F = long_sequences.shape[2]   # <-- FIX: get number of sensors\n",
        "max_len = 50 * F\n",
        "\n",
        "X_dynamic = np.array([\n",
        "    np.pad(f, (0, max_len - len(f)))\n",
        "    for f in dynamic_features\n",
        "])\n",
        "\n",
        "X_holdout = X_dynamic[-H:]\n",
        "X_main = X_dynamic[:-H]\n",
        "X_train = X_main[:split_point]\n",
        "X_test = X_main[split_point:]\n",
        "\n",
        "# y vaues remain same as previous\n",
        "\n",
        "print(\"Anomalies in TRAIN:\", y_train.sum())\n",
        "print(\"Anomalies in TEST :\", y_test.sum())\n",
        "print(\"Anomalies in HOLDOUT:\", y_holdout.sum())\n",
        "\n",
        "# ======================================================================\n",
        "# Flatten windows\n",
        "# ======================================================================\n",
        "\n",
        "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
        "X_test_flat  = X_test.reshape(X_test.shape[0], -1)\n",
        "X_holdout_flat = X_holdout.reshape(X_holdout.shape[0], -1)\n",
        "\n",
        "# Baseline-2: Random Forest + dynamic window - test data\n",
        "rf = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42, n_jobs=-1)\n",
        "rf.fit(X_train_flat, y_train)\n",
        "y_pred_test = rf.predict(X_test_flat)\n",
        "\n",
        "print(\"\\n=== Baseline-2: dynamic Window Random Forest ===\")\n",
        "print(classification_report(y_test, y_pred_test, digits=4))\n",
        "print(confusion_matrix(y_test, y_pred_test))\n",
        "joblib.dump(rf, \"rf_dynamic_window.pkl\")\n",
        "\n",
        "\n",
        "########## Baseline-2: Random Forest + dynamic window -HOLDOUT\n",
        "\n",
        "y_pred_h = rf.predict(X_holdout)\n",
        "\n",
        "print(\"\\n=== Baseline-2: dynamic Window Random Forest holdout data ===\")\n",
        "print(classification_report(y_holdout, y_pred_h, digits=4))\n",
        "print(confusion_matrix(y_holdout, y_pred_h))\n",
        "joblib.dump(rf, \"rf_dynamic_window_holdout.pkl\")\n",
        "\n",
        "\n",
        "# Baseline-3: XGBoost dynamic\n",
        "xgb = XGBClassifier(\n",
        "    n_estimators=300, max_depth=8, learning_rate=0.05,\n",
        "    subsample=0.8, colsample_bytree=0.8,\n",
        "    random_state=42, n_jobs=-1\n",
        ")\n",
        "xgb.fit(X_train_flat, y_train)\n",
        "y_pred_h = xgb.predict(X_test_flat)\n",
        "\n",
        "print(\"\\n=== Baseline-3: Dynamic Window XGBoost ===\")\n",
        "print(classification_report(y_test, y_pred_h, digits=4))\n",
        "print(confusion_matrix(y_test, y_pred_h))\n",
        "joblib.dump(xgb, \"xgb_dynamic_window.pkl\")\n",
        "\n",
        "########## Baseline-3: XGBoost dynamic HOLDOUT\n",
        "\n",
        "y_pred_h = xgb.predict(X_holdout)\n",
        "\n",
        "print(\"\\n=== Baseline-3:Dynamic Window XGBoost holdout data ===\")\n",
        "print(classification_report(y_holdout, y_pred_h, digits=4))\n",
        "print(confusion_matrix(y_holdout, y_pred_h))\n",
        "joblib.dump(xgb, \"xgb_dynamic_window_holdout.pkl\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Ready for Next Steps\n",
        "# ============================================================\n",
        "print(\"\\n✅ Baseline models trained and evaluated.\")\n",
        "print(\"Next: add Transformer-based sequence classifier, then coordinator features.\")\n",
        "\n",
        "\n",
        "\n",
        "# ========================================================================================\n",
        "# SOTA: Transformer (PatchTST-style) Classifier\n",
        "# =======================================================================================\n",
        "# ========================================================================================\n",
        "# Contrastive Pretraining + Transformer Encoder + kNN Classifier\n",
        "# ========================================================================================\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "import tensorflow.keras.backend as K\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ====================\n",
        "# 1. Mixed Precision\n",
        "# ====================\n",
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy(\"mixed_float16\")\n",
        "\n",
        "# ====================\n",
        "# 2. Transformer Block\n",
        "# ====================\n",
        "def transformer_block(inputs, head_size=32, num_heads=2, ff_dim=64, dropout=0.2):\n",
        "    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads)(inputs, inputs)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x + inputs)\n",
        "\n",
        "    ff = layers.Dense(ff_dim, activation=\"relu\")(x)\n",
        "    ff = layers.Dropout(dropout)(ff)\n",
        "    ff = layers.Dense(inputs.shape[-1])(ff)\n",
        "    out = layers.LayerNormalization(epsilon=1e-6)(x + ff)\n",
        "    return out\n",
        "\n",
        "# ====================\n",
        "# 3. Transformer Encoder (for contrastive pretrain)\n",
        "# ====================\n",
        "def build_transformer_encoder(input_shape, projection_dim=64):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = transformer_block(inputs, 32, 2, 64, 0.2)\n",
        "    x = transformer_block(x, 32, 2, 64, 0.2)\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    outputs = layers.Dense(projection_dim, activation=None)(x)  # projection head\n",
        "    return keras.Model(inputs, outputs, name=\"transformer_encoder\")\n",
        "\n",
        "# ====================\n",
        "# 4. Contrastive Loss (NT-Xent style)\n",
        "# ====================\n",
        "def contrastive_loss(temperature=0.1):\n",
        "    def loss(y_true, y_pred):\n",
        "        y_pred = K.l2_normalize(y_pred, axis=-1)\n",
        "        batch_size = tf.shape(y_pred)[0] // 2\n",
        "        z1, z2 = tf.split(y_pred, 2, axis=0)\n",
        "        sim = tf.matmul(z1, z2, transpose_b=True) / temperature\n",
        "        labels = tf.range(batch_size)\n",
        "        loss1 = keras.losses.sparse_categorical_crossentropy(labels, sim, from_logits=True)\n",
        "        loss2 = keras.losses.sparse_categorical_crossentropy(labels, tf.transpose(sim), from_logits=True)\n",
        "        return tf.reduce_mean(loss1 + loss2)\n",
        "    return loss\n",
        "\n",
        "# ====================\n",
        "# 5. Augmentations for contrastive\n",
        "# ====================\n",
        "def augment_sequence(seq):\n",
        "    noise = np.random.normal(0, 0.01, seq.shape)\n",
        "    scale = np.random.uniform(0.9, 1.1)\n",
        "    mask = np.random.binomial(1, 0.95, seq.shape)\n",
        "    return seq * scale + noise * mask\n",
        "\n",
        "def create_contrastive_pairs(X, batch_size=128):\n",
        "    idx = np.random.choice(len(X), batch_size, replace=False)\n",
        "    x1 = np.array([augment_sequence(X[i]) for i in idx])\n",
        "    x2 = np.array([augment_sequence(X[i]) for i in idx])\n",
        "    return np.concatenate([x1, x2], axis=0)\n",
        "\n",
        "# ====================\n",
        "# 6. Load Data + Holdout\n",
        "# ====================\n",
        "long_sequences = np.load(\"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/multivariate_long_sequences-TRAIN-Daily-DIRECT-VAR.npy\")\n",
        "labels_detection = np.load(\"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/anomaly_labels_detection.npy\")\n",
        "\n",
        "\n",
        "# Holdout block (future data)\n",
        "H = 1500\n",
        "X_holdout = long_sequences[-H:]\n",
        "y_holdout = labels_detection[-H:]\n",
        "\n",
        "# Remaining data for train + test\n",
        "X_main = long_sequences[:-H]\n",
        "y_main = labels_detection[:-H]\n",
        "\n",
        "X_train = X_main[:split_point]\n",
        "y_train = y_main[:split_point]\n",
        "\n",
        "X_test = X_main[split_point:]\n",
        "y_test = y_main[split_point:]\n",
        "\n",
        "\n",
        "# class weights\n",
        "classes = np.unique(y_train)\n",
        "cw = compute_class_weight(\"balanced\", classes=classes, y=y_train)\n",
        "class_weight_dict = {i: w for i, w in zip(classes, cw)}\n",
        "print(\"Class weights:\", class_weight_dict)\n",
        "\n",
        "# ====================\n",
        "# 7. Contrastive Pretraining\n",
        "# ====================\n",
        "encoder = build_transformer_encoder(X_train.shape[1:], projection_dim=64)\n",
        "contrastive_model = keras.Model(encoder.input, encoder.output)\n",
        "contrastive_model.compile(optimizer=keras.optimizers.Adam(1e-3),\n",
        "                          loss=contrastive_loss(temperature=0.1))\n",
        "\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 128\n",
        "for epoch in range(EPOCHS):\n",
        "    X_batch = create_contrastive_pairs(X_train, batch_size=BATCH_SIZE//2)\n",
        "    y_dummy = np.zeros(len(X_batch))\n",
        "    loss = contrastive_model.train_on_batch(X_batch, y_dummy)\n",
        "    if epoch % 2 == 0:\n",
        "        print(f\"Epoch {epoch}: contrastive loss = {loss:.4f}\")\n",
        "\n",
        "# ====================\n",
        "# 8. Build Classifier (fine-tune encoder)\n",
        "# ====================\n",
        "encoder_backbone = build_transformer_encoder(X_train.shape[1:], projection_dim=64)\n",
        "encoder_backbone.set_weights(encoder.get_weights())  # transfer pretrained weights\n",
        "\n",
        "inputs = keras.Input(shape=X_train.shape[1:])\n",
        "x = encoder_backbone(inputs)\n",
        "x = layers.Dense(64, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\", dtype=\"float32\")(x)\n",
        "\n",
        "classifier = keras.Model(inputs, outputs)\n",
        "\n",
        "# focal loss\n",
        "def focal_loss(gamma=2., alpha=0.25):\n",
        "    def loss(y_true, y_pred):\n",
        "        y_true = tf.cast(y_true, tf.float32)\n",
        "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
        "        bce = K.binary_crossentropy(y_true, y_pred)\n",
        "        p_t = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
        "        alpha_factor = y_true * alpha + (1 - y_true) * (1 - alpha)\n",
        "        modulating = (1 - p_t) ** gamma\n",
        "        return K.mean(alpha_factor * modulating * bce, axis=-1)\n",
        "    return loss\n",
        "\n",
        "classifier.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-3),\n",
        "    loss=focal_loss(),\n",
        "    metrics=[\"accuracy\", Precision(name=\"precision\"), Recall(name=\"recall\")]\n",
        ")\n",
        "\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
        "lr_sched = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-6)\n",
        "\n",
        "history = classifier.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=30,\n",
        "    batch_size=128,\n",
        "    class_weight=class_weight_dict,\n",
        "    callbacks=[early_stop, lr_sched],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# ====================\n",
        "# 9. Evaluate on val\n",
        "# ====================\n",
        "y_probs = classifier.predict(X_test).flatten()\n",
        "y_pred = (y_probs >= 0.5).astype(int)\n",
        "print(\"\\n=== Contrastive Transformer (Validation) ===\")\n",
        "print(classification_report(y_test, y_pred, digits=4))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# ====================\n",
        "# 10. Evaluate on holdout\n",
        "# ====================\n",
        "y_probs = classifier.predict(X_holdout).flatten()\n",
        "y_pred = (y_probs >= 0.5).astype(int)\n",
        "print(\"\\n=== Contrastive Transformer (Holdout) ===\")\n",
        "print(classification_report(y_holdout, y_pred, digits=4))\n",
        "print(confusion_matrix(y_holdout, y_pred))\n",
        "\n",
        "# ==========================================================\n",
        "# Prototype Scoring Evaluation (Contrastive Embeddings)\n",
        "# ==========================================================\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics.pairwise import cosine_distances\n",
        "import numpy as np\n",
        "\n",
        "# Get embeddings from pretrained encoder (without classifier head)\n",
        "def get_embeddings(encoder, X):\n",
        "    return encoder.predict(X, batch_size=128, verbose=0)\n",
        "\n",
        "# ⚠️ IMPORTANT: use the backbone encoder, not classifier\n",
        "emb_train = get_embeddings(encoder_backbone, X_train)\n",
        "emb_val = get_embeddings(encoder_backbone, X_test)\n",
        "emb_holdout = get_embeddings(encoder_backbone, X_holdout)\n",
        "\n",
        "print(\"Embedding shapes:\", emb_train.shape, emb_val.shape, emb_holdout.shape)\n",
        "\n",
        "# Build prototype from normal training embeddings\n",
        "normal_emb = emb_train[y_train == 0]\n",
        "prototype = np.mean(normal_emb, axis=0, keepdims=True)\n",
        "\n",
        "# Function to compute prototype distance scores\n",
        "def prototype_scores(embeddings, prototype):\n",
        "    return cosine_distances(embeddings, prototype).flatten()\n",
        "\n",
        "scores_val = prototype_scores(emb_val, prototype)\n",
        "scores_holdout = prototype_scores(emb_holdout, prototype)\n",
        "\n",
        "# Evaluate at different thresholds\n",
        "def evaluate_prototype(scores, y_true, threshold):\n",
        "    y_pred = (scores > threshold).astype(int)\n",
        "    report = classification_report(y_true, y_pred, digits=4, zero_division=0)\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    return report, cm\n",
        "\n",
        "# Sweep thresholds\n",
        "thresholds = np.linspace(0.1, 0.9, 9)\n",
        "print(\"\\n=== Prototype Scoring Threshold Sweep (Validation) ===\")\n",
        "for th in thresholds:\n",
        "    report, cm = evaluate_prototype(scores_val, y_test, threshold=th)\n",
        "    print(f\"\\nThreshold={th:.2f}\")\n",
        "    print(report)\n",
        "    print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "# Aggressive threshold (say th=0.3)\n",
        "TH = 0.3\n",
        "print(\"\\n=== Prototype Scoring (Validation, th=0.3) ===\")\n",
        "report_val, cm_val = evaluate_prototype(scores_val, y_test, TH)\n",
        "print(report_val)\n",
        "print(cm_val)\n",
        "\n",
        "print(\"\\n=== Prototype Scoring (Holdout, th=0.3) ===\")\n",
        "report_holdout, cm_holdout = evaluate_prototype(scores_holdout, y_holdout, TH)\n",
        "print(report_holdout)\n",
        "print(cm_holdout)\n",
        "#######################################################################################################\n",
        "#Validate with coordination agent###############################\n",
        "#######################################################################################################\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# --------------------------\n",
        "# 1. Validation Function\n",
        "# --------------------------\n",
        "def validate_with_coordinator(\n",
        "    y_probs,\n",
        "    y_true,\n",
        "    coordinator_results,\n",
        "    threshold=0.5,\n",
        "    coord_weight=0.5,           # balance between prototype vs coordinator\n",
        "    conf_mode=\"sensor_rate\"     # options: \"sensor_rate\", \"anomaly_score\", \"hybrid\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Validate Prototype/Transformer predictions against coordinator agent decisions\n",
        "    using confidence-aware fusion.\n",
        "\n",
        "    Args:\n",
        "        y_probs: np.ndarray, predicted probabilities from prototype/transformer\n",
        "        y_true: np.ndarray, ground truth labels\n",
        "        coordinator_results: list of dicts with coordinator outputs\n",
        "        threshold: float, probability cutoff for prototype predictions\n",
        "        coord_weight: float [0,1], weight given to coordinator confidence\n",
        "        conf_mode: str, which confidence source to use\n",
        "                   (\"sensor_rate\", \"anomaly_score\", \"hybrid\")\n",
        "\n",
        "    Returns:\n",
        "        dict with reports, confusion matrices, raw & validated preds\n",
        "    \"\"\"\n",
        "    # Raw prototype predictions\n",
        "    y_pred_raw = (y_probs >= threshold).astype(int)\n",
        "\n",
        "    y_pred_validated = []\n",
        "    for pred, coord in zip(y_pred_raw, coordinator_results):\n",
        "        coord_data = coord.get(\"coordinator\", {})\n",
        "        coord_flag = coord_data.get(\"final_anomaly\", False)\n",
        "        scores = coord_data.get(\"scores\", {})\n",
        "\n",
        "        # -----------------------\n",
        "        # Compute confidence\n",
        "        # -----------------------\n",
        "        if conf_mode == \"sensor_rate\":\n",
        "            coord_conf = scores.get(\"sensor_anomaly_rate\", 0.0)\n",
        "        elif conf_mode == \"anomaly_score\":\n",
        "            coord_conf = scores.get(\"anomaly_score\", 0.0)\n",
        "        elif conf_mode == \"hybrid\":\n",
        "            coord_conf = 0.5 * scores.get(\"sensor_anomaly_rate\", 0.0) + \\\n",
        "                         0.5 * scores.get(\"anomaly_score\", 0.0)\n",
        "        else:\n",
        "            coord_conf = 0.0\n",
        "\n",
        "        # -----------------------\n",
        "        # Fusion Logic\n",
        "        # -----------------------\n",
        "        if pred == 1:\n",
        "            # keep anomaly unless coordinator strongly disagrees\n",
        "            if coord_flag or coord_conf < (1 - coord_weight):\n",
        "                y_pred_validated.append(1)\n",
        "            else:\n",
        "                y_pred_validated.append(0)\n",
        "        else:\n",
        "            # allow coordinator to promote anomaly if confident\n",
        "            if coord_flag and coord_conf > coord_weight:\n",
        "                y_pred_validated.append(1)\n",
        "            else:\n",
        "                y_pred_validated.append(0)\n",
        "\n",
        "    y_pred_validated = np.array(y_pred_validated)\n",
        "\n",
        "    # Reports\n",
        "    report_raw = classification_report(y_true, y_pred_raw, output_dict=True, zero_division=0)\n",
        "    report_validated = classification_report(y_true, y_pred_validated, output_dict=True, zero_division=0)\n",
        "\n",
        "    cm_raw = confusion_matrix(y_true, y_pred_raw)\n",
        "    cm_validated = confusion_matrix(y_true, y_pred_validated)\n",
        "\n",
        "    return {\n",
        "        \"report_raw\": report_raw,\n",
        "        \"report_validated\": report_validated,\n",
        "        \"confusion_matrix_raw\": cm_raw,\n",
        "        \"confusion_matrix_validated\": cm_validated,\n",
        "        \"raw_preds\": y_pred_raw,\n",
        "        \"validated_preds\": y_pred_validated\n",
        "    }\n",
        "\n",
        "# --------------------------\n",
        "# New: Weighted Fusion Validation\n",
        "# --------------------------\n",
        "def validate_with_fusion(y_probs, y_true, coordinator_results,\n",
        "                         proto_weight=0.7, coord_weight=0.3,\n",
        "                         threshold=0.5, persistence=2):\n",
        "    \"\"\"\n",
        "    Validate Prototype/Transformer predictions with weighted fusion + persistence filter.\n",
        "\n",
        "    Args:\n",
        "        y_probs: np.ndarray of anomaly probabilities (from prototype/transformer)\n",
        "        y_true: ground truth labels\n",
        "        coordinator_results: list of dicts with coordinator outputs (len=N)\n",
        "        proto_weight: float, weight for prototype score\n",
        "        coord_weight: float, weight for coordinator confidence (default assumes 0/1)\n",
        "        threshold: float, final decision threshold\n",
        "        persistence: int, number of consecutive anomalies required to flag\n",
        "\n",
        "    Returns:\n",
        "        dict with metrics and predictions\n",
        "    \"\"\"\n",
        "    # Make sure coordinator has confidence (fallback = 1.0 for anomalies, else 0.0)\n",
        "    coord_conf = []\n",
        "    for coord in coordinator_results:\n",
        "        if \"coordinator\" in coord and \"confidence\" in coord[\"coordinator\"]:\n",
        "            coord_conf.append(coord[\"coordinator\"][\"confidence\"])\n",
        "        else:\n",
        "            coord_conf.append(1.0 if coord[\"coordinator\"].get(\"final_anomaly\", False) else 0.0)\n",
        "    coord_conf = np.array(coord_conf)\n",
        "\n",
        "    # Weighted fusion score\n",
        "    fused_score = proto_weight * y_probs + coord_weight * coord_conf\n",
        "\n",
        "    # Apply threshold\n",
        "    fused_pred = (fused_score >= threshold).astype(int)\n",
        "\n",
        "    # Apply persistence smoothing\n",
        "    if persistence > 1:\n",
        "        smoothed = np.zeros_like(fused_pred)\n",
        "        run = 0\n",
        "        for i, val in enumerate(fused_pred):\n",
        "            if val == 1:\n",
        "                run += 1\n",
        "                if run >= persistence:\n",
        "                    smoothed[i] = 1\n",
        "            else:\n",
        "                run = 0\n",
        "        fused_pred = smoothed\n",
        "\n",
        "    # Reports\n",
        "    report_fused = classification_report(y_true, fused_pred, output_dict=True, zero_division=0)\n",
        "    cm_fused = confusion_matrix(y_true, fused_pred)\n",
        "\n",
        "    return {\n",
        "        \"report_fused\": report_fused,\n",
        "        \"confusion_matrix_fused\": cm_fused,\n",
        "        \"fused_preds\": fused_pred,\n",
        "        \"fused_scores\": fused_score\n",
        "    }\n",
        "\n",
        "# --------------------------\n",
        "# 2. Confusion Matrix Plot\n",
        "# --------------------------\n",
        "def plot_confusion_matrices(cm_raw, cm_validated, labels=[0,1]):\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "    sns.heatmap(cm_raw, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "                xticklabels=labels, yticklabels=labels, ax=axes[0])\n",
        "    axes[0].set_title(\"Transformer (Raw)\")\n",
        "    axes[0].set_xlabel(\"Predicted\")\n",
        "    axes[0].set_ylabel(\"True\")\n",
        "\n",
        "    sns.heatmap(cm_validated, annot=True, fmt=\"d\", cmap=\"Greens\",\n",
        "                xticklabels=labels, yticklabels=labels, ax=axes[1])\n",
        "    axes[1].set_title(\"Transformer + Coordinator\")\n",
        "    axes[1].set_xlabel(\"Predicted\")\n",
        "    axes[1].set_ylabel(\"True\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# --------------------------\n",
        "# 3. Run Coordinator on Test Set\n",
        "# --------------------------\n",
        "results = []\n",
        "coordinator_flags = []\n",
        "\n",
        "window_agent = AdaptiveWindowAgent(\n",
        "    model_path=\"/content/drive/MyDrive/PHD/2025/DGRNet-MLP-Versions/METROPM_MLP_model_Daily.keras\"\n",
        ")\n",
        "sensor_agents, master = create_robust_system(num_sensors=12, models_dir=\"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/sensor/model\")\n",
        "\n",
        "\n",
        "coordinator = DecisionAgent(\n",
        "    prediction_weight=0.7,    # ML dominates\n",
        "    sensor_weight=0.2,\n",
        "    drift_weight=0.1,\n",
        "    failure_threshold=0.5,\n",
        "    failure_critical_threshold=0.8,\n",
        ")\n",
        "\n",
        "print(\"Running Coordinator over test set...\")\n",
        "\n",
        "import os, pickle\n",
        "import numpy as np\n",
        "\n",
        "# --------------------------\n",
        "# 1. Load or Generate Coordinator Results\n",
        "# --------------------------\n",
        "if os.path.exists(\"coordinator_results.pkl\") and os.path.exists(\"coordinator_flags.npy\"):\n",
        "    print(\"📂 Loading saved coordinator results...\")\n",
        "    with open(\"coordinator_results.pkl\", \"rb\") as f:\n",
        "        results = pickle.load(f)\n",
        "    coordinator_flags = np.load(\"coordinator_flags.npy\")\n",
        "else:\n",
        "    print(\"⚡ Running coordinator fresh on holdout set...\")\n",
        "    results = []\n",
        "    coordinator_flags = []\n",
        "\n",
        "    for i, seq in enumerate(X_holdout):   # use holdout as test set\n",
        "        try:\n",
        "            features = seq.flatten()\n",
        "            master_out = master.process_system_input(seq)\n",
        "            window_out = window_agent.predict_window_size(features, seq)\n",
        "            final = coordinator.decide(master_out, window_out)\n",
        "\n",
        "            results.append({\n",
        "                \"master\": master_out,\n",
        "                \"window\": window_out,\n",
        "                \"coordinator\": final\n",
        "            })\n",
        "            coordinator_flags.append(1 if final[\"final_anomaly\"] else 0)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Sample {i} failed: {e}\")\n",
        "            results.append({\"coordinator\": {\"final_anomaly\": False}})\n",
        "            coordinator_flags.append(0)\n",
        "\n",
        "    coordinator_flags = np.array(coordinator_flags)\n",
        "\n",
        "    # Save for future use\n",
        "    with open(\"coordinator_results.pkl\", \"wb\") as f:\n",
        "        pickle.dump(results, f)\n",
        "    np.save(\"coordinator_flags.npy\", coordinator_flags)\n",
        "\n",
        "print(f\"✅ Coordinator outputs ready: {len(results)} entries\")\n",
        "print(f\"Unique flags: {np.unique(coordinator_flags, return_counts=True)}\")\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 4. Validate Predictions\n",
        "# --------------------------\n",
        "#y_probs = classifier.predict(X_holdout).flatten()   # Transformer predictions\n",
        "scores = prototype_scores(emb_holdout, prototype)\n",
        "y_probs = scores\n",
        "y_true  = y_holdout                               # Ground truth fault labels\n",
        "\n",
        "\n",
        "validation_out = validate_with_coordinator(\n",
        "    y_probs=scores,\n",
        "    y_true=y_holdout,\n",
        "    coordinator_results=results,\n",
        "    threshold=0.1,\n",
        "    coord_weight=1, #make it very high to stop coord to create more false positives\n",
        "    conf_mode=\"hybrid\"   # or \"hybrid\"\n",
        ")\n",
        "\n",
        "\n",
        "#=======================This was added later as a new fusion rule---need to check later which one is better===========================================\n",
        "fusion_out = validate_with_fusion(\n",
        "    y_probs=scores,\n",
        "    y_true=y_holdout,\n",
        "    coordinator_results=results,\n",
        "    proto_weight=0.7,\n",
        "    coord_weight=0.3,\n",
        "    threshold=0.1,      # you can tune this\n",
        "    persistence=2       # require 2 consecutive anomalies\n",
        ")\n",
        "\n",
        "print(\"\\n=== Prototype (Raw) ===\")\n",
        "print(classification_report(y_true, validation_out[\"raw_preds\"], digits=4))\n",
        "print(validation_out[\"confusion_matrix_raw\"])\n",
        "\n",
        "print(\"\\n=== prototype + Coordinator (Validated) ===\")\n",
        "print(classification_report(y_true, validation_out[\"validated_preds\"], digits=4))\n",
        "print(validation_out[\"confusion_matrix_validated\"])\n",
        "\n",
        "#=======================This was added later as a new fusion rule---need to check later which one is better===========================================\n",
        "print(\"\\n=== Prototype + Coordinator (Fusion) ===\")\n",
        "print(classification_report(y_holdout, fusion_out[\"fused_preds\"], digits=4))\n",
        "print(fusion_out[\"confusion_matrix_fused\"])\n",
        "\n",
        "# --------------------------\n",
        "# 5. Coordinator Impact Summary\n",
        "# --------------------------\n",
        "raw = validation_out[\"report_raw\"][\"1\"]\n",
        "val = validation_out[\"report_validated\"][\"1\"]\n",
        "\n",
        "print(\"\\n=== Coordinator Impact on Fault Class (1) ===\")\n",
        "print(f\"Precision: {raw['precision']:.3f} → {val['precision']:.3f}\")\n",
        "print(f\"Recall:    {raw['recall']:.3f} → {val['recall']:.3f}\")\n",
        "print(f\"F1-score:  {raw['f1-score']:.3f} → {val['f1-score']:.3f}\")\n",
        "\n",
        "# --------------------------\n",
        "# 6. Plot Confusion Matrices\n",
        "# --------------------------\n",
        "plot_confusion_matrices(\n",
        "    validation_out[\"confusion_matrix_raw\"],\n",
        "    validation_out[\"confusion_matrix_validated\"]\n",
        ")\n",
        "# ==========================================\n",
        "# 7. Overlay Plot: Prototype vs Coordinator vs Ground Truth\n",
        "# ==========================================\n",
        "def plot_timeline(y_true, raw_preds, validated_preds, coordinator_flags, max_samples=200):\n",
        "    \"\"\"\n",
        "    Visual timeline of ground truth faults, prototype predictions, and coordinator validated results.\n",
        "    \"\"\"\n",
        "    n = min(max_samples, len(y_true))\n",
        "    t = np.arange(n)\n",
        "\n",
        "    plt.figure(figsize=(14, 5))\n",
        "\n",
        "    # Ground truth faults\n",
        "    plt.plot(t, y_true[:n], label=\"Ground Truth\", color=\"black\", linewidth=2, alpha=0.7)\n",
        "\n",
        "    # Prototype raw predictions\n",
        "    plt.plot(t, raw_preds[:n], label=\"Prototype Raw\", color=\"red\", linestyle=\"--\", alpha=0.6)\n",
        "\n",
        "    # Coordinator validated predictions\n",
        "    plt.plot(t, validated_preds[:n], label=\"Validated (Prototype+Coordinator)\",\n",
        "             color=\"green\", linewidth=2, alpha=0.7)\n",
        "\n",
        "    # Coordinator anomaly flags only\n",
        "    plt.scatter(t, coordinator_flags[:n], label=\"Coordinator Final Anomaly\",\n",
        "                marker=\"x\", color=\"blue\", alpha=0.8)\n",
        "\n",
        "    plt.xlabel(\"Sample Index\")\n",
        "    plt.ylabel(\"Fault / Anomaly Flag\")\n",
        "    plt.title(\"Timeline: Prototype vs Coordinator vs Ground Truth\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n",
        "\n",
        "# ==========================================\n",
        "# Call Timeline Plot (with prototype outputs)\n",
        "# ==========================================\n",
        "plot_timeline(\n",
        "    y_true=y_true,\n",
        "    raw_preds=validation_out[\"raw_preds\"],        # Prototype raw predictions\n",
        "    validated_preds=validation_out[\"validated_preds\"],  # Prototype + Coordinator\n",
        "    coordinator_flags=coordinator_flags,\n",
        "    max_samples=200\n",
        ")\n",
        "\n",
        "# ==========================================\n",
        "# 8. Quantify False Positive Suppression (Prototype-based)\n",
        "# ==========================================\n",
        "def analyze_false_positive_suppression(y_true, raw_preds, validated_preds):\n",
        "    \"\"\"\n",
        "    Compare raw vs validated prototype predictions to quantify false positive suppression.\n",
        "    \"\"\"\n",
        "    # False positives = predicted 1, but true = 0\n",
        "    fp_raw = np.sum((raw_preds == 1) & (y_true == 0))\n",
        "    fp_validated = np.sum((validated_preds == 1) & (y_true == 0))\n",
        "\n",
        "    # False negatives = predicted 0, but true = 1\n",
        "    fn_raw = np.sum((raw_preds == 0) & (y_true == 1))\n",
        "    fn_validated = np.sum((validated_preds == 0) & (y_true == 1))\n",
        "\n",
        "    suppression_rate = (fp_raw - fp_validated) / max(fp_raw, 1)\n",
        "\n",
        "    return {\n",
        "        \"false_positives_raw\": int(fp_raw),\n",
        "        \"false_positives_validated\": int(fp_validated),\n",
        "        \"false_negatives_raw\": int(fn_raw),\n",
        "        \"false_negatives_validated\": int(fn_validated),\n",
        "        \"suppression_rate\": suppression_rate\n",
        "    }\n",
        "\n",
        "# Run analysis\n",
        "fp_analysis = analyze_false_positive_suppression(\n",
        "    y_true=y_true,\n",
        "    raw_preds=validation_out[\"raw_preds\"],         # Prototype raw\n",
        "    validated_preds=validation_out[\"validated_preds\"]  # Prototype + Coordinator\n",
        ")\n",
        "\n",
        "print(\"\\n=== False Positive Suppression Analysis (Prototype) ===\")\n",
        "print(f\"False Positives (Raw Prototype): {fp_analysis['false_positives_raw']}\")\n",
        "print(f\"False Positives (Validated): {fp_analysis['false_positives_validated']}\")\n",
        "print(f\"False Negatives (Raw Prototype): {fp_analysis['false_negatives_raw']}\")\n",
        "print(f\"False Negatives (Validated): {fp_analysis['false_negatives_validated']}\")\n",
        "print(f\"Suppression Rate: {fp_analysis['suppression_rate']*100:.2f}%\")\n",
        "\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "#  MAIN ORCHESTRATION: DECISION + EXPERT + EVENT STORE\n",
        "# =====================================================\n",
        "\n",
        "# Reuse your existing:\n",
        "# - window_agent  (AdaptiveWindowAgent)\n",
        "# - sensor_agents, master (RobustMasterAgent)\n",
        "# - scores        (prototype_scores on emb_holdout)\n",
        "# - X_holdout, y_holdout\n",
        "\n",
        "print(\"\\n🚀 Running DecisionAgent + ExpertAgent pipeline on HOLDOUT...\\n\")\n",
        "\n",
        "# 1) Initialise storage + agents\n",
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "from openai import OpenAI\n",
        "openai_client = OpenAI()\n",
        "\n",
        "event_store = EventStore(db_path=\"event_store.db\")\n",
        "\n",
        "decision_agent = DecisionAgent(\n",
        "    anomaly_weight=0.6,\n",
        "    window_weight=0.4,\n",
        "    proto_weight=0.3,\n",
        "    transformer_weight=0.0,   # set >0 if you start using transformer probabilities\n",
        "    anomaly_threshold=0.3,\n",
        "    drift_threshold=0.2\n",
        ")\n",
        "\n",
        "expert_agent = ExpertAgent(\n",
        "    event_store=event_store,\n",
        "    system_description=\"MetroPT multivariate APU system\",\n",
        "    llm_client=openai_client,          # ⬅️ important\n",
        "    history_limit=100,\n",
        "    max_history_for_prompt=10,\n",
        "    window_preview_len=30,\n",
        ")\n",
        "\n",
        "# 2) Run through holdout set and collect results\n",
        "decision_results = []\n",
        "decision_flags = []\n",
        "\n",
        "for i, seq in enumerate(X_holdout):\n",
        "    try:\n",
        "        features = seq.flatten()\n",
        "\n",
        "        # a) Local sensor agents + master\n",
        "        master_out = master.process_system_input(seq)\n",
        "\n",
        "        # b) Global window agent\n",
        "        window_out = window_agent.predict_window_size(features, seq)\n",
        "\n",
        "        # c) Prototype score for this sample\n",
        "        proto_score_i = float(scores[i]) if i < len(scores) else None\n",
        "\n",
        "        # d) Decision agent fusion\n",
        "       model_outputs = {\n",
        "        \"failure_prob\": float(failure_prob_i),       # NEW: your ML prediction\n",
        "        \"prototype_score\": float(scores[i]),        # optional, diagnostic\n",
        "        \"transformer_prob\": float(transf_prob_i),   # optional, if you have it\n",
        "        }\n",
        "        metadata = {\"index\": int(i)}\n",
        "\n",
        "        decision_packet = coordinator.decide(\n",
        "            master_output=master_out,\n",
        "            window_output=window_out,\n",
        "            model_outputs=model_outputs,\n",
        "            metadata={\"index\": int(i)},\n",
        "        )\n",
        "\n",
        "        expert_packet = None\n",
        "        human_feedback = None\n",
        "\n",
        "        # e) If anomaly → call ExpertAgent + human loop\n",
        "        if decision_packet[\"final_anomaly\"]:\n",
        "            expert_packet = expert_agent.analyse_anomaly(\n",
        "                decision_packet=decision_packet,\n",
        "                system_subsequence=seq,\n",
        "                extra_context={\"index\": int(i)}\n",
        "            )\n",
        "            send_alert_to_human(expert_packet)\n",
        "            human_feedback = get_human_feedback_stub(expert_packet)\n",
        "\n",
        "            event_store.save_event(\n",
        "                event_type=\"ANOMALY\",\n",
        "                packet=decision_packet,\n",
        "                expert=expert_packet,\n",
        "                human=human_feedback,\n",
        "            )\n",
        "        else:\n",
        "            event_store.save_event(\n",
        "                event_type=\"NORMAL_OR_DRIFT\",\n",
        "                packet=decision_packet,\n",
        "                expert=None,\n",
        "                human=None,\n",
        "            )\n",
        "\n",
        "        # Aggregate result object\n",
        "        decision_results.append({\n",
        "            \"master\": master_out,\n",
        "            \"window\": window_out,\n",
        "            \"decision\": decision_packet,\n",
        "            \"expert\": expert_packet,\n",
        "            \"human_feedback\": human_feedback\n",
        "        })\n",
        "        decision_flags.append(1 if decision_packet[\"final_anomaly\"] else 0)\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f\"Processed {i+1}/{len(X_holdout)} holdout samples...\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Sample {i} failed in decision/expert pipeline: {e}\")\n",
        "        decision_results.append({\n",
        "            \"master\": None,\n",
        "            \"window\": None,\n",
        "            \"decision\": {\"final_anomaly\": False, \"final_drift\": False},\n",
        "            \"expert\": None,\n",
        "            \"human_feedback\": None\n",
        "        })\n",
        "        decision_flags.append(0)\n",
        "\n",
        "decision_flags = np.array(decision_flags)\n",
        "print(\"\\n✅ Decision + Expert pipeline completed.\")\n",
        "print(\"Anomaly flags distribution:\", np.unique(decision_flags, return_counts=True))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "v_5iji919H_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8OtWHK--uG6W"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "https://github.com/supriyag123/PHD_Pub/blob/main/AGENTIC-MODULE6-REVISED-DecisionExpertLLM.ipynb",
      "authorship_tag": "ABX9TyP+iFd+hXX2Rl9ECzL0DVUM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}