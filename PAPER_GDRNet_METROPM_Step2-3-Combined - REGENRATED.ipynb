{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supriyag123/PHD_Pub/blob/main/PAPER_GDRNet_METROPM_Step2-3-Combined%20-%20REGENRATED.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bx-5b_puABG1",
        "outputId": "1f1995c9-9039-4e8d-fc63-7ea55403c3e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAR could not solve row number\n",
            "0 48\n",
            "VAR could not solve row number\n",
            "0 49\n",
            "i= 0 SW = 20 [0.0007235196404006365, 0.0011458782293855164, 4.139515295015108e-06, 6.116497689427199e-05, 0.0002490128283018995, 6.315765341650465e-05, 0.00013591757334205628, 0.0014475219048020707, 0.001756787151845844, 0.0053642473143515005, 0.004814051915871667, 0.02617840361934506, 0.013059940589545694, 0.0020357095834275495, 0.0006001404320818167, 0.00013801580183216223, 8.193656558718881e-05, 0.00028760103585397025, 7.858217217987537e-07, 3.361747432407173e-05, 2.798840222970638e-05, 2.036106671928605e-05, 5.673766163108273e-06, 8.135093968434186e-07, 0.0002331072195146555, 1.2005529347284544e-06, 8.016050291830207e-06, 1.360908633162695e-05, 2.244502287833759e-05, 3.7311992730846895e-06, 6.786588950107988e-06, 1.8893118504581934e-05, 0.0003930595931608554, 8.206439482329997e-05, 2.942578000079584e-05, 3.074519101038303e-05, 4.531707437081514e-05, 4.233983987771618e-05, 4.205841436633918e-05, 4.05505068333528e-05, 5.904223103212168e-05, 5.4813472628086406e-05, 4.195266116051082e-05, 4.009005922440907e-05, 1.5452264815803875e-05, 7.754189395837805e-05, 99999, 99999]\n",
            "VAR could not solve row number\n",
            "1 48\n",
            "VAR could not solve row number\n",
            "1 49\n",
            "i= 1 SW = 7 [0.00043877820943633434, 4.7984408902690835e-05, 8.349838800443155e-08, 5.8933927428602804e-08, 6.907781940246277e-06, 2.8752833596552617e-10, 0.00011980041782175676, 0.0002668374650666675, 0.0017033362354045682, 0.0026165936365327345, 8.420910036135981e-05, 0.07347000074099669, 0.03985803003447207, 0.002253695111781647, 0.0036920274687835017, 0.005718041154011503, 0.003502634878782819, 0.0002432837730811211, 9.796072085465703e-05, 5.6110674625897615e-05, 1.5659848254838384e-06, 4.074886915037746e-06, 5.764318055125339e-06, 1.6118115961347425e-05, 7.636971270813756e-06, 0.00010281283712731634, 3.014196454526944e-06, 2.2189516208868433e-05, 2.523437378300098e-05, 2.282810553095281e-05, 8.566178346454928e-06, 7.919942945899189e-05, 0.000848447821348813, 1.3753280466233966e-05, 2.3085982487470534e-05, 0.00011101666076912931, 9.325989255022012e-05, 8.041981295336869e-05, 7.812613825416077e-05, 7.496043429978707e-05, 7.14170105437208e-05, 6.59330154905324e-05, 5.781021900042624e-05, 5.55455060958701e-05, 3.185190935768869e-05, 9.691378303283088e-05, 99999, 99999]\n",
            "VAR could not solve row number\n",
            "2 48\n",
            "VAR could not solve row number\n",
            "2 49\n",
            "i= 2 SW = 32 [3.650039233049698e-06, 0.0002063353445563622, 2.36759882445154e-06, 5.2321138813943456e-05, 0.00045619904336566, 9.225114509481066e-05, 4.4404921175516855e-06, 0.0009732885448033347, 3.4685563633666714e-05, 0.00010415649698295175, 0.014352428668135339, 0.013957044279067592, 0.0166370036306906, 0.054161154718417814, 0.040211536467159956, 0.020976288282401733, 0.0033771292665161776, 0.0002088139856994751, 0.0015303616585212937, 0.00034477745071000864, 2.8183397228608128e-05, 2.0560974932116713e-05, 2.1401122027480382e-05, 3.38772400949694e-05, 0.00035569301436769136, 0.0002695621833690892, 0.000325150245659855, 0.00035622758731960845, 0.00020041606862549548, 2.0379828603040212e-05, 9.162738851540399e-07, 3.153192149720005e-05, 2.0182923184285823e-05, 0.00017124612943465218, 9.546562743579415e-05, 0.00011661500329887781, 8.761268525311212e-05, 6.963077695305575e-05, 6.816542647181828e-05, 6.20397285175132e-05, 9.408747941874304e-05, 8.884575818900274e-05, 7.336516303818159e-05, 8.306829033172176e-05, 4.4884238716115566e-05, 0.00019018262097042065, 99999, 99999]\n",
            "VAR could not solve row number\n",
            "3 48\n",
            "VAR could not solve row number\n",
            "3 49\n",
            "i= 3 SW = 7 [0.0003644133782363784, 2.8630254407243766e-06, 1.0078066163173944e-05, 6.222087127753208e-06, 4.8412035228969586e-05, 4.421439950789974e-07, 1.861314346069949e-05, 9.598759918845083e-06, 0.0002716645705545354, 9.697258185931405e-05, 0.00013063753436504623, 8.6223648874798e-05, 0.000539813708663462, 0.0001228666213805124, 5.405464965709064e-05, 3.3079228396367784e-05, 2.9175343546524712e-05, 3.94940458960449e-05, 1.4777788559939481e-05, 1.7021552215125635e-05, 1.3526857867560093e-05, 3.046376676947573e-05, 2.383438350300497e-05, 3.699593765116217e-05, 2.6295397863746213e-05, 1.7892383110273002e-05, 8.75232719282369e-06, 3.3997284089788693e-06, 3.0757398284063616e-06, 4.859018741845262e-06, 1.3440189035794119e-05, 6.814736999578767e-06, 3.818974523170595e-06, 3.0940263279281546e-05, 5.182599862282496e-05, 5.486568307329314e-05, 6.641824846255027e-05, 3.318157411301888e-05, 3.0137885010490202e-05, 2.8421853000609648e-05, 2.708385776359105e-05, 2.297806526467127e-05, 2.3082236715525715e-05, 2.1979972786680603e-05, 1.9948674724687556e-05, 8.883053842718068e-05, 99999, 99999]\n",
            "VAR could not solve row number\n",
            "4 48\n",
            "VAR could not solve row number\n",
            "4 49\n",
            "i= 4 SW = 4 [0.000401863930828812, 0.000174634524835754, 3.759689592862299e-09, 3.513211008039406e-05, 0.0002206002152003629, 4.762390629228804e-05, 4.1900463957410585e-05, 1.23099911863144e-05, 0.0007677625774585328, 0.001077182371318075, 0.08231601815160013, 0.013804690213910401, 9.871953838526924e-05, 0.00499220833465987, 0.006945442596524346, 0.0044370308779344125, 0.0024441706140144715, 0.0012682818799552784, 0.006498873574514275, 0.0006351230137049916, 0.0005828302180441025, 0.00028440582646047086, 0.0003334892709802688, 0.00022560894801107646, 0.0017450842021262162, 0.002027063304683732, 0.000966078643462485, 0.0008096450444945902, 0.0002850481351720031, 1.6167450038454673e-05, 4.663784832639365e-06, 1.9157068441763095e-07, 3.50339033614785e-06, 0.00014508596473490363, 5.280624510188385e-05, 0.000120579153252119, 9.728204558671226e-05, 9.268632460871034e-05, 9.894705595031589e-05, 5.077855575997059e-05, 9.869788078023491e-05, 9.14407394496532e-05, 7.179303242615041e-05, 8.220817529710799e-05, 4.107451855315269e-05, 0.0001810172234014551, 99999, 99999]\n",
            "VAR could not solve row number\n",
            "5 48\n",
            "VAR could not solve row number\n",
            "5 49\n",
            "i= 5 SW = 2 [7.55682326029385e-08, 0.00037529542704832497, 1.1042210832962224e-05, 9.387580187051205e-05, 0.00012334483053804828, 0.00013936128599871842, 7.895545138288046e-06, 0.0001733226063198411, 0.0008951788041141926, 1.0443423739400046e-05, 0.09187872625128658, 0.03400310708850632, 0.009188111529401898, 0.07498434784277852, 0.06605584588318084, 0.022674781979401176, 0.010428039205431094, 0.0032232959474604163, 0.006506732220424458, 0.0006052451728683503, 0.00011132641346168442, 5.0479530393429415e-05, 0.00011165546107733126, 9.878801535428943e-05, 0.0013963901602373587, 0.0017384406054768663, 0.0006012846907606325, 0.0009190629777005862, 0.00041465825740393057, 8.012967974851885e-06, 3.661117630857073e-06, 8.756160448876876e-07, 3.776303213955608e-06, 1.061791668039191e-05, 3.8377914585944754e-05, 9.603584826194099e-05, 7.829499897181814e-05, 6.527431476804516e-05, 7.861549990255031e-05, 6.118518085597464e-05, 8.452751839254415e-05, 8.121556977920201e-05, 6.522717794791757e-05, 7.193508498306022e-05, 3.537233667029788e-05, 0.00016292827397669299, 99999, 99999]\n",
            "VAR could not solve row number\n",
            "6 48\n",
            "VAR could not solve row number\n",
            "6 49\n",
            "i= 6 SW = 22 [0.0017568261556489093, 0.003805668703538796, 0.0001109114484483233, 6.208921184570062e-05, 0.00024323298375669966, 1.2039425101809646e-05, 0.0011914443918341253, 9.913881179175919e-05, 0.0009671338400894471, 0.007783051398985587, 0.012924951059884834, 0.004063201439352843, 0.004304348555006543, 0.03167438517704444, 0.012449376339111506, 0.0032201918710353904, 0.00020562797761897932, 7.008589662749544e-05, 4.578583070221239e-05, 6.466779125740494e-05, 5.016099273316153e-07, 2.001622399562486e-06, 3.0246819021211518e-06, 7.558289611811255e-07, 0.00026714180644006163, 1.573236336265963e-05, 4.1236113246445603e-05, 3.105871157817527e-05, 1.4799821621914222e-05, 2.011289048832151e-05, 1.3918312708987019e-05, 5.170262065717742e-05, 9.070694747051109e-06, 3.849974301411919e-05, 5.4690407936959033e-05, 0.0001160303820422777, 0.00011086822184167548, 9.100987148013385e-05, 9.104870211221038e-05, 0.00011119065467732057, 0.0001288728921159262, 0.0001248564728470371, 0.00010600205631049868, 0.0001078437673846676, 6.453240887668148e-05, 0.00024671042678365494, 99999, 99999]\n",
            "VAR could not solve row number\n",
            "7 48\n",
            "VAR could not solve row number\n",
            "7 49\n",
            "i= 7 SW = 21 [0.0004487967158448555, 8.757414110991429e-05, 1.0694616860215295e-06, 2.081691067724623e-05, 2.7530975767891162e-05, 0.0013487977159591291, 0.001240278473160437, 0.0010110399056713864, 0.004182397454072696, 0.008991920266252326, 0.012158407663154895, 0.030808810967044582, 0.00656839866455207, 0.004803274916418727, 0.0005003219555622747, 0.0008418144009113813, 0.0011949210175147865, 9.711058441954247e-05, 0.0003519544377634454, 4.943262559699101e-07, 3.792379955266621e-05, 3.42409109965178e-05, 3.3342793541471154e-05, 1.3232867893911233e-05, 4.343506533209052e-06, 2.9467120505848773e-05, 1.2757405609985464e-05, 2.2110608487059608e-05, 0.00013508032673901406, 3.960000962945076e-06, 2.2902735749035364e-06, 1.4902419824393302e-05, 0.00012151809353581275, 0.00015398018019785296, 6.624471080459655e-05, 5.121747525397874e-05, 3.0902232980154635e-05, 2.1821780415264218e-05, 1.979637704535364e-05, 2.0099216537185374e-05, 4.310817949888632e-05, 3.650970425140961e-05, 3.339733235342587e-05, 3.589906362280031e-05, 1.832426312774423e-05, 9.233464635872513e-05, 99999, 99999]\n",
            "VAR could not solve row number\n",
            "8 48\n",
            "VAR could not solve row number\n",
            "8 49\n",
            "i= 8 SW = 33 [9.607325026587297e-05, 0.00022977446380418898, 5.309443933576278e-06, 8.286846315962786e-05, 0.0001640831219888739, 0.000666992468093139, 6.731314672589807e-05, 0.0018359333942061806, 0.002870869346045247, 0.004231713191957271, 1.4493751266437182e-08, 0.004891961480049661, 0.0017847725279907265, 0.025320856054406423, 0.003159561651072892, 0.0003471949972327455, 0.0002992181856122844, 7.720308550884657e-05, 0.0002929623816685333, 5.885163801170415e-05, 2.0720338929023927e-07, 1.9810480209886254e-06, 2.157647234318997e-06, 8.202783774190621e-07, 3.0710719910633476e-05, 2.968877529547828e-05, 2.4553495785730156e-07, 2.948964442656088e-06, 1.4848985146753429e-05, 3.230695150264025e-07, 4.940790075641702e-06, 3.615023669263114e-09, 0.00013041864138440418, 0.00021815688412759777, 5.235243557497866e-05, 5.31433189182533e-05, 3.9203447320473445e-05, 2.7838697242440328e-05, 2.525434321191415e-05, 3.4711804255658294e-05, 5.512712931760902e-05, 5.145532230205085e-05, 4.3888635724254005e-05, 4.466896867841312e-05, 2.1302579601931422e-05, 0.00010866895495615579, 99999, 99999]\n",
            "VAR could not solve row number\n",
            "9 48\n",
            "VAR could not solve row number\n",
            "9 49\n",
            "i= 9 SW = 32 [3.2060698045382695e-05, 0.00016486330260815534, 1.9354963092606674e-05, 7.132724218735668e-05, 0.0003377926335655769, 2.266998047562059e-07, 1.2763582650114011e-05, 0.0003608256804684752, 8.666163661861941e-05, 0.00045345233917742396, 0.02632130217524699, 0.04039921704272728, 0.025823689160176688, 0.06271252832550003, 0.037867952300457045, 0.016672267229156473, 0.001511427771934292, 0.00024238197442653939, 0.0002558308511458208, 0.00022015476289096158, 6.932405820708034e-06, 7.547627310411984e-07, 2.103989298631635e-06, 2.776837279339121e-06, 0.0003127651450379964, 9.786298596152154e-05, 0.0001991879731933633, 0.00017961954706953142, 0.000155716551353154, 1.6620981144953098e-05, 1.776706739323529e-07, 2.319172857576401e-05, 1.2507972923226994e-05, 5.9696391875662595e-05, 7.050786517270176e-05, 0.00011868931903686857, 9.563720194064339e-05, 7.697297104459262e-05, 8.549226332796488e-05, 7.683411201862997e-05, 9.772673321168797e-05, 9.46394435794481e-05, 7.682977869397468e-05, 8.32026976821293e-05, 4.35389580585213e-05, 0.00018359268905102983, 99999, 99999]\n",
            "VAR could not solve row number\n",
            "10 48\n",
            "VAR could not solve row number\n",
            "10 49\n",
            "i= 10 SW = 31 [0.001861336610231606, 0.0010230879269429757, 2.7422433924743415e-06, 7.747023458017159e-05, 6.028307928469354e-07, 0.0017385836739399307, 0.0005032560628560626, 0.0027867933943166437, 0.0016994179832617556, 0.00017942578488561512, 0.040375163337216725, 0.03429444779076313, 0.010212805511879714, 0.02146201022294603, 0.020766950020547754, 1.1753300928155361e-06, 8.332639114363678e-05, 0.0003025244032483019, 0.00017348207412882458, 3.1164190764782624e-06, 4.688685422415451e-05, 4.2054091235741544e-05, 4.002944904027013e-05, 1.0496768598184237e-05, 5.664057948665207e-07, 7.174094561840828e-05, 1.9551653774055884e-05, 1.3382923911332707e-05, 2.5497065635063936e-05, 2.1751963815991703e-07, 4.45417196300268e-06, 1.2553094863380509e-05, 0.0001985770353677845, 0.000160623284702075, 5.892197431882126e-05, 5.606351086822132e-05, 4.1044865264794075e-05, 2.8759432002772822e-05, 3.264097462843569e-05, 3.7874152597371205e-05, 5.236412311572633e-05, 4.948763031603557e-05, 4.343500280262067e-05, 4.501167616572098e-05, 2.3865137530758218e-05, 0.00010678943173251906, 99999, 99999]\n",
            "VAR could not solve row number\n",
            "11 48\n",
            "VAR could not solve row number\n",
            "11 49\n",
            "i= 11 SW = 31 [0.00047923789679644513, 0.0009775439756281243, 1.2742860829145302e-05, 4.49618294282606e-05, 3.572812635092673e-06, 2.625241295843161e-05, 3.858291561017575e-05, 0.0015971808089518327, 0.002943718113199411, 0.004836535054092943, 0.005671710113087791, 0.0016480748844393235, 0.00010587156850353605, 0.03746070650254641, 0.009451730510471523, 0.0007453859893641042, 2.0362638084895796e-05, 0.00015242296308412215, 0.00028832522404287537, 6.319248283068161e-06, 1.5009373481444883e-05, 2.0938111632705218e-05, 1.701243235872618e-05, 1.8096362270502191e-06, 1.7059846908839943e-06, 5.831735375329485e-05, 1.1192884538042315e-06, 3.860570744153565e-06, 2.420889406844597e-05, 3.306178363282595e-07, 6.172776682334454e-07, 3.7856656680874787e-07, 7.759582310376333e-05, 0.00013212311270362345, 3.06891776267963e-05, 3.424226354024383e-05, 2.6994734622500865e-05, 1.8790475450176867e-05, 1.7599850386455774e-05, 2.7114285899020514e-05, 4.470826636340888e-05, 4.1384392095114795e-05, 3.5864099995536165e-05, 3.7159137237167236e-05, 1.6569770530406068e-05, 9.6163823923138e-05, 99999, 99999]\n",
            "VAR could not solve row number\n",
            "12 48\n",
            "VAR could not solve row number\n",
            "12 49\n",
            "i= 12 SW = 35 [0.0003685100573318466, 6.086563524932173e-05, 7.940843753441172e-05, 0.00020942488568540682, 3.200220108572054e-05, 0.0004150043904897092, 0.0012467000158925634, 0.004213585792894129, 0.0003233556734330304, 0.00044130424084618376, 0.0050263219773355634, 0.004931956975135627, 0.003165025211440381, 0.0125378981775281, 0.000798669549407997, 0.0005563694089623954, 0.0004980374441409727, 3.5495680266730585e-05, 1.0803135246256748e-05, 1.0374606819618032e-07, 9.211161527836923e-06, 2.8627844845458192e-05, 2.4835689816732058e-05, 1.7260027172790697e-05, 1.9800658576362205e-06, 3.5379631089410407e-05, 1.21696216954942e-05, 3.2669471306600742e-06, 8.335991575696155e-05, 5.6736269131118e-06, 2.0773026147750304e-06, 1.2015779062447779e-05, 2.048695334292088e-06, 4.578476733376918e-08, 2.893784155895962e-05, 3.0408898993105518e-05, 2.9422330555477336e-05, 2.542211937834767e-05, 2.5978935469919695e-05, 2.5995945792088647e-05, 4.1514302535247555e-05, 3.683988411819155e-05, 2.6236069240832327e-05, 2.9316333258135154e-05, 8.488092046623791e-06, 7.66968818989084e-05, 99999, 99999]\n",
            "VAR could not solve row number\n",
            "13 48\n",
            "VAR could not solve row number\n",
            "13 49\n",
            "i= 13 SW = 31 [0.0015052409026648191, 9.006451170314276e-05, 5.291683633172463e-06, 3.868574843015448e-05, 3.98547349795634e-05, 0.00038088118060782136, 0.0004992328248246216, 0.0012144334301469374, 3.577443853197863e-07, 0.0021481362936722516, 0.012909971385098225, 0.07844245993125316, 0.01882456460078929, 0.00024089887696818315, 0.003353458519660148, 0.0026316673686532393, 0.0004018080478468676, 7.91337081982959e-05, 3.451735695605203e-05, 3.341435324308523e-07, 1.9253596343881537e-05, 0.00010973541779477635, 1.166766594577522e-06, 5.083336468288725e-05, 0.0005638013730654226, 0.0004116549188107, 0.0003672259935920143, 2.6342356704573403e-05, 9.837417831259169e-05, 2.97765074043648e-07, 4.029575563994453e-07, 2.5559120624423162e-06, 1.0656034778957112e-05, 8.225513554168141e-06, 2.776745628942246e-05, 9.962396067768388e-05, 0.00011781663416271644, 0.00010442597555286224, 0.00012866146266337413, 0.0001226711805352562, 0.00012263414084723946, 0.0001158272228027441, 9.788903499935969e-05, 9.657035576553273e-05, 5.3204756468287595e-05, 0.00021472932248967468, 99999, 99999]\n",
            "VAR could not solve row number\n",
            "14 48\n",
            "VAR could not solve row number\n",
            "14 49\n",
            "i= 14 SW = 28 [0.0008111752644027833, 6.991831887590272e-05, 5.605628386043632e-05, 7.399998305305596e-05, 0.00012392979340990684, 0.0007266043291095883, 0.005650808975828824, 0.000587263992205917, 0.011917436757984342, 0.003961904175031576, 0.03639967296084702, 0.05819289206657914, 0.01940974818873323, 0.008426918291240771, 0.008069017077548748, 0.0004064753203036393, 0.0014473854473363657, 0.00010265480061040367, 0.0006926747301158014, 0.00027690032612326734, 1.3648243800367947e-05, 5.864216429873233e-06, 6.216098664141088e-06, 3.808364668114665e-05, 7.706874052414128e-05, 1.0114279955745123e-05, 1.0076151441307978e-07, 8.642370886417814e-06, 1.198357541188445e-05, 7.799939448656132e-06, 1.6388729601928352e-05, 8.9212160003068e-06, 0.00035842392449679305, 0.0006262254102404474, 0.00011225027849523306, 9.805986537328833e-05, 5.375769266529032e-05, 3.8273362106478094e-05, 3.2818711425043635e-05, 3.187761977197603e-05, 5.5843424294485905e-05, 5.189253226049376e-05, 4.429634248526849e-05, 4.415509162383943e-05, 1.9774893755149788e-05, 0.00010206197841303006, 99999, 99999]\n",
            "VAR could not solve row number\n",
            "15 48\n",
            "VAR could not solve row number\n",
            "15 49\n",
            "i= 15 SW = 31 [0.0004988157106760089, 0.00012491648982713996, 9.292523140385163e-06, 6.370354919206878e-05, 0.0003344172911478296, 2.5727901653899526e-05, 2.52015685967229e-05, 0.0017234176811406678, 0.0023516394056525692, 0.00587042783592029, 0.05131859556556065, 0.013913148346313431, 0.002811140379658014, 0.017329265951065553, 0.006529228709773829, 2.2510812862614075e-05, 0.00022236839414777708, 2.6681958255325808e-05, 0.00045124105181875877, 0.00011950850301467284, 2.1995028511308296e-05, 1.7397819711657936e-05, 1.9774893922037793e-05, 3.3257228227153515e-05, 0.00013284541698159891, 0.00020957596057851114, 1.2936200773424918e-05, 0.00016605027681704265, 0.00014402535216663135, 8.972375321328267e-07, 2.189066510341574e-06, 8.273420176198622e-06, 4.5070661156281206e-05, 0.00011394379760707501, 9.385582767616396e-05, 8.831458612051625e-05, 6.0863628885880265e-05, 4.6425610649341514e-05, 5.2161918594193526e-05, 5.31776928538029e-05, 6.622702615956663e-05, 6.30616979524882e-05, 5.1853672306447696e-05, 5.477744102350784e-05, 2.841513331781562e-05, 0.00012898800673685274, 99999, 99999]\n",
            "VAR could not solve row number\n",
            "16 48\n",
            "VAR could not solve row number\n",
            "16 49\n",
            "i= 16 SW = 4 [0.0021609152093667473, 9.348189619397639e-05, 2.0000219839357928e-07, 2.355419965314376e-06, 5.0569949787493706e-05, 0.00010536905744912713, 4.517221332204979e-06, 0.002188619373613544, 0.0014814617881986896, 0.007119041639322903, 0.004732491025968287, 0.004236846784985109, 0.0008829001318745584, 0.0001282935320110478, 0.01072701899717024, 0.0019259219452645933, 0.0005820863206885851, 0.00020534221869279498, 4.310127615612606e-05, 4.828000972870169e-05, 9.225332122183923e-05, 5.025414445224631e-05, 5.4544927091963886e-05, 2.745746265429793e-05, 2.0490347738342928e-05, 7.613390284159762e-05, 1.4802960466079164e-05, 2.3973223535983573e-05, 0.00011688191020812261, 3.085993549717465e-05, 6.569842514965668e-07, 7.168393391661503e-06, 0.00012025047849703706, 9.038575326087987e-05, 2.8088578421121143e-05, 3.807195422651408e-05, 2.79711696268084e-05, 2.199612522027057e-05, 4.185503847077461e-05, 3.523204849006858e-05, 4.56960128356547e-05, 4.3333584546902846e-05, 3.680229876790802e-05, 4.215188997425227e-05, 1.8818529523584955e-05, 0.00010250242127069881, 99999, 99999]\n",
            "VAR could not solve row number\n",
            "17 48\n",
            "VAR could not solve row number\n",
            "17 49\n",
            "i= 17 SW = 34 [4.5402336419897796e-05, 0.00043594048881245276, 4.617757087274737e-05, 3.843809791663417e-06, 4.4118192418501515e-05, 0.0011482615146891123, 0.002425355285212029, 0.007994974193488649, 0.008028154706152929, 0.0014535959201940382, 0.03164058570684444, 0.040787684694826284, 0.005277165367931288, 0.04308511241982948, 0.022354576923853793, 0.005154919263990093, 0.0003303409203836739, 8.90415702302687e-06, 0.0006280852570664618, 0.0004100253906944572, 0.00011319027552209187, 4.982111851459065e-05, 6.047915125590056e-05, 6.696810469244146e-05, 0.00026839479414906853, 0.0003810262628968237, 0.00010315205419462727, 8.695194364541734e-05, 0.00017768068453623273, 1.0745596450968926e-06, 5.574072091765579e-06, 1.5629333815365025e-05, 1.0490608298523298e-06, 2.432185756617609e-06, 2.1305550607340863e-05, 7.633555463622733e-05, 6.791308426904308e-05, 5.744011498242289e-05, 6.436640594213092e-05, 4.898254633468986e-05, 8.108653195988841e-05, 7.510940689134946e-05, 6.159693596994636e-05, 6.661838452737978e-05, 3.321657149014544e-05, 0.00015802322516675224, 99999, 99999]\n",
            "VAR could not solve row number\n",
            "18 48\n",
            "VAR could not solve row number\n",
            "18 49\n",
            "i= 18 SW = 3 [0.0003228890320892766, 7.418632510489517e-08, 5.594853735205657e-06, 0.0001683503910914765, 0.00023723320814509984, 0.00017486493850674047, 7.407827142182815e-05, 0.0056038711324381705, 0.00735529841062473, 0.006044129287825555, 0.0026989289840185014, 0.009833548790169027, 0.002602122110369029, 0.0017713165330951258, 0.00012564806067105812, 0.0016235126462789845, 0.002205775079903168, 0.0022786035743096776, 2.2152945409068764e-05, 1.1151245938241102e-05, 1.2262965519458346e-06, 5.073833268274161e-06, 6.729727581326784e-06, 4.73912478509186e-06, 4.9627203206888204e-05, 1.3879674557748864e-07, 8.372595926896726e-06, 2.2693819960842366e-07, 2.0494372903857177e-05, 1.9124090408865706e-06, 4.770711440887487e-06, 4.618007236511241e-06, 0.0003444478317751642, 2.8937402598639154e-05, 4.858327645506292e-05, 4.3132730532104115e-05, 3.844202368650322e-05, 3.3873951710407347e-05, 3.3088133291379086e-05, 2.6916164038456038e-05, 4.779980903249084e-05, 4.2799462631582445e-05, 3.280534318174201e-05, 3.297905823520538e-05, 1.1321127416090324e-05, 7.317048029568332e-05, 99999, 99999]\n",
            "VAR could not solve row number\n",
            "19 48\n",
            "VAR could not solve row number\n",
            "19 49\n",
            "i= 19 SW = 26 [0.0020842903512518583, 0.0012752300584510285, 6.252745656291129e-07, 1.8679018058617107e-05, 8.044735518584544e-05, 0.0013731619200884168, 2.6150344553353854e-07, 0.00019659924081936065, 2.2158115084277273e-05, 4.532278281312615e-05, 0.050548185663358544, 0.008367023723531366, 0.0019893026887719796, 0.012183822263542945, 0.012057456014664347, 0.00010187573084937104, 3.68314827934755e-05, 8.334602710781674e-05, 0.00024232470659538537, 4.4817469954620795e-07, 2.728124978530025e-05, 2.5908060226912182e-05, 2.6679976407324673e-05, 1.33517491465176e-05, 1.329273308057727e-07, 3.0060216390625613e-05, 5.179758177529119e-06, 1.1574541493093245e-06, 1.3207361044358712e-05, 6.223550347065566e-07, 6.894416442455408e-06, 7.630013214917795e-06, 7.254150770818524e-05, 0.00011651283295036667, 6.700403812753143e-05, 6.99721910638038e-05, 5.104638978527117e-05, 3.632228470016173e-05, 3.606128922240136e-05, 4.7997321715598126e-05, 6.457283946137492e-05, 6.188454365442597e-05, 5.453672822120535e-05, 5.642550750119958e-05, 3.2667784824949133e-05, 0.0001350717262870852, 99999, 99999]\n",
            "VAR could not solve row number\n",
            "20 48\n",
            "VAR could not solve row number\n",
            "20 49\n",
            "i= 20 SW = 32 [2.3286320036972705e-06, 6.197481176012849e-05, 3.027638368020568e-06, 5.420131384079659e-05, 0.0005647613138197506, 0.00017398303524330898, 4.073325837054798e-05, 0.0012772580998625872, 2.5551459205254947e-05, 0.0011160086207105918, 0.027514145343318218, 0.020555094252545474, 0.011835405771899503, 0.04428877551823538, 0.03490502367782266, 0.017421744214528412, 0.005618411305875687, 0.0025787956537929074, 0.005796506350399063, 0.0005643775254106079, 7.591685751264284e-05, 6.335187689782644e-05, 8.659669964422138e-05, 9.914471736708197e-05, 0.0007235280827692842, 0.0010464221767406171, 0.0006951275335322706, 0.0007354535700099112, 0.00026754612597778817, 1.1703636003665257e-05, 4.96666201706401e-07, 2.9759330583890216e-05, 2.6030479588679435e-05, 0.0002051987234747702, 0.00011995047347271206, 0.00013283153682532177, 9.07443241213476e-05, 7.303400035222384e-05, 7.219535442896458e-05, 5.73061994619966e-05, 9.247363592913068e-05, 8.623088654564025e-05, 7.160314271226582e-05, 8.150253475913379e-05, 4.488065050326521e-05, 0.00018560677302578512, 99999, 99999]\n",
            "VAR could not solve row number\n",
            "21 48\n",
            "VAR could not solve row number\n",
            "21 49\n",
            "i= 21 SW = 17 [0.0010439767214286662, 0.0003533706015678264, 4.086676399992649e-06, 0.0002127139139577529, 0.00010321978033014953, 3.839581474628165e-06, 4.776589745822984e-05, 0.002370871170945842, 0.005627290898843058, 0.0023035958924561787, 0.0023432038976846856, 0.009605260909675294, 0.005656801133615367, 0.00047827787898209776, 0.0008384765371763991, 1.4741095758326032e-07, 8.887931726265167e-05, 0.00040375173721055014, 7.347956323702717e-05, 3.893648052033491e-06, 0.00011580809778554389, 0.00010902887742123831, 6.8077525869909e-05, 4.429534987246326e-05, 3.635008860437643e-05, 3.20471492008109e-05, 7.55463421889675e-05, 5.9312117583433445e-06, 0.0006477572609542856, 5.964396803389004e-05, 5.286175089048222e-07, 9.626902232381046e-06, 9.598529738636832e-05, 0.00011970267867850302, 1.7722791127973093e-05, 3.573499552642737e-05, 2.1989066574234002e-05, 2.1954239392697014e-05, 3.2904093548785785e-05, 1.1988639656635625e-05, 3.839277029412957e-05, 3.114019600450074e-05, 2.7649171095343746e-05, 3.20488896944666e-05, 1.2086800335982031e-05, 8.711618699750298e-05, 99999, 99999]\n",
            "VAR could not solve row number\n",
            "22 48\n",
            "VAR could not solve row number\n",
            "22 49\n",
            "i= 22 SW = 35 [0.0012304958263448832, 0.000724945713272604, 4.917996556280931e-05, 7.382893750106509e-05, 2.1272498035644865e-05, 0.003377987694119774, 0.00020480943132081508, 0.0005829646637945946, 0.0001222365104643226, 0.0017933951088640323, 0.035974593537886394, 0.04634088519038027, 0.010763233076320208, 0.08027816680589908, 0.08170502768593271, 0.016874430184252814, 0.009978721843466673, 0.0023669420233790356, 0.002377244267568742, 0.0011011418002868734, 0.0008890782823003695, 0.0004919240814415175, 0.0005975308287050127, 0.000558736288174248, 0.0009772829140755103, 0.0015412723058502388, 0.00036882564859559784, 0.0001416627401088883, 0.000646918116158746, 1.3716084438965636e-06, 1.004836196542116e-05, 3.98389017145984e-06, 5.834685112902382e-06, 1.880803048479961e-08, 3.095919955709244e-05, 6.589722642660069e-05, 6.563057526197345e-05, 5.847030103129584e-05, 6.57169979946605e-05, 6.329327535849218e-05, 8.679872003705012e-05, 8.205219498277997e-05, 6.581324316467881e-05, 7.3099463936607e-05, 3.660485708601972e-05, 0.00018938870065431047, 99999, 99999]\n",
            "VAR could not solve row number\n",
            "23 48\n",
            "VAR could not solve row number\n",
            "23 49\n",
            "i= 23 SW = 31 [7.273831105472577e-05, 0.00012706666664693338, 3.415805231113656e-05, 0.00023535821549878005, 0.00045125588088129967, 6.266013318058882e-05, 0.0007901626376781728, 0.00014237226608249752, 0.0013962032130799547, 0.004920498635862184, 0.02906593245975087, 0.022069159739935486, 0.005102102945999164, 0.014266659614545334, 0.0018119661816732356, 1.439232828615966e-05, 0.00022940543703101464, 0.00013922731679783041, 0.0003523307171361917, 9.09028205027021e-05, 4.63793699133894e-06, 3.976303421287529e-06, 2.000371626717643e-06, 5.916900990473372e-06, 5.05543752403233e-05, 1.3044262342549246e-05, 9.595050790014476e-07, 2.857320376223451e-06, 1.0323812228313808e-05, 6.157202563996054e-07, 1.1647206064083268e-05, 8.716937641289123e-06, 0.00016393794842313415, 0.0003155921291577988, 0.00010535380559031687, 9.076196270277317e-05, 5.532276529989498e-05, 3.8391756234580076e-05, 3.339942509335495e-05, 4.440605477798472e-05, 6.610933245850552e-05, 6.249601578866296e-05, 5.5241917931427675e-05, 5.5831423319523005e-05, 3.134152131637225e-05, 0.0001326507402762398, 99999, 99999]\n",
            "VAR could not solve row number\n",
            "24 48\n",
            "VAR could not solve row number\n",
            "24 49\n",
            "i= 24 SW = 18 [0.0005464021998627927, 0.0009170402613666, 1.0983377478296365e-06, 3.59517520231158e-05, 1.2659008770797392e-05, 0.00010390539591799189, 0.0004896827589021797, 0.0015855433548991296, 2.7822934225496688e-05, 0.0007366670276269649, 0.01692998499279493, 0.02124687313903923, 0.012953051825034801, 0.03089662224387952, 0.0065359799956900945, 0.0019513885934802824, 2.444171310743402e-08, 9.768241981883153e-05, 0.00017366097018233162, 5.1743597783935155e-05, 1.0017326010798597e-05, 2.608581311470278e-05, 1.0748683857653488e-05, 1.0413769950991888e-06, 5.882741103617139e-06, 0.00011017169026603342, 1.2492881281728205e-05, 8.681269420590383e-06, 7.314086339057858e-05, 4.299578933789892e-06, 5.174648459590645e-07, 5.376598787668708e-06, 3.977687255266097e-05, 9.856012748556002e-05, 1.3507878103021719e-05, 3.0394600198904433e-05, 2.8196104370573306e-05, 2.3223352244912754e-05, 2.696092761012648e-05, 2.5063743387397836e-05, 4.3625751362495235e-05, 3.868795494228588e-05, 3.252266325883903e-05, 3.251703468034371e-05, 1.3352248995393662e-05, 8.355214912203711e-05, 99999, 99999]\n",
            "VAR could not solve row number\n",
            "25 48\n",
            "VAR could not solve row number\n",
            "25 49\n",
            "i= 25 SW = 24 [0.00029221044992629, 1.8251000674279722e-05, 1.1105747903204553e-05, 5.451840285633671e-05, 0.00032871307608547354, 0.0001505734000982321, 6.244744645525926e-05, 0.0015468607365440967, 0.003419778677029453, 0.004254878705251422, 0.001860219544676133, 0.06730947846040419, 0.06849038423115837, 0.049879653762229095, 0.01785270947708981, 0.008581782707282349, 0.007373695830062532, 0.0005120428777647294, 0.00013441711113648867, 6.18975619044653e-05, 5.528655919217933e-05, 4.006485626728292e-06, 4.537652643820225e-07, 1.9075381265053263e-06, 8.384269071490875e-05, 0.0002522973477651935, 2.097216520428214e-06, 8.570345667820359e-06, 3.226271239293575e-06, 8.085625613298829e-07, 5.872845478688988e-06, 1.5660102458449024e-06, 0.0014283171957879095, 6.693981773605867e-05, 9.837329065473258e-05, 5.0642142011192174e-05, 5.674775593639602e-05, 4.6622479393280656e-05, 4.1276068057627584e-05, 4.7939953228873645e-05, 7.652249709968774e-05, 7.216638891857225e-05, 5.9272239256145506e-05, 5.3705251194678564e-05, 2.7153293541617946e-05, 0.00010900866163035875, 99999, 99999]\n",
            "VAR could not solve row number\n",
            "26 48\n",
            "VAR could not solve row number\n",
            "26 49\n",
            "i= 26 SW = 33 [0.0005522950850451255, 0.00036066934487149246, 4.545232400419389e-07, 2.7311220911607065e-06, 1.84416386977169e-05, 3.8606862130971325e-05, 0.00044959479682161904, 0.0015148878636481568, 0.00022561436858482405, 0.004274712360545595, 0.01662288210986201, 0.00981737387053258, 0.02420407773155932, 0.0015084224168637952, 0.0008784887734322522, 0.0010179075941664506, 0.00040228218842932077, 8.535072672471523e-06, 0.00017255454570482307, 0.0002733633268346131, 3.6079918009966913e-06, 7.535509041792332e-07, 6.925909456552854e-06, 7.897817472159772e-06, 0.00020018362424845202, 2.9648939102958942e-05, 4.339066577887144e-05, 1.8273457693321468e-05, 1.915364533596342e-05, 2.6253881881886747e-06, 1.0365558223803094e-05, 1.3952382063009981e-09, 0.0005067812531499475, 0.000456346747371192, 7.167431977259374e-05, 0.0001009592222802218, 7.955000041500582e-05, 5.885281575440218e-05, 6.563573358485934e-05, 6.702190003379556e-05, 7.957065078515054e-05, 7.573091229362642e-05, 6.445758917775561e-05, 5.90946610287659e-05, 2.9887302226738648e-05, 0.00011978804258148911, 99999, 99999]\n",
            "VAR could not solve row number\n",
            "27 48\n",
            "VAR could not solve row number\n",
            "27 49\n",
            "i= 27 SW = 31 [0.00036729265839854013, 0.00020348110802494832, 8.232076729731715e-06, 1.1464184946873325e-05, 5.488802371964153e-06, 0.001666569550451471, 0.006286036327738003, 0.0005042784289607275, 0.0006924493250584482, 0.0026421347983923062, 0.00025982940725365533, 0.04092696047005715, 0.015386126397847836, 0.008630607436346385, 0.0015581828244761384, 2.4811560448899658e-05, 0.00039566657381049156, 0.00017481084119400658, 0.0002720881960224954, 0.0003548173586396854, 5.291262320546631e-06, 1.4637335586170263e-05, 5.482537322027823e-06, 5.1857909664458096e-06, 6.702917358139063e-05, 9.937973972802825e-05, 5.806059017518142e-06, 4.237999814293266e-06, 5.92715924655993e-05, 3.4861047125496716e-06, 6.247831217848683e-06, 5.8681066005735455e-06, 0.0008524920708064534, 0.0005825277413821964, 5.150916678319553e-05, 5.460062341512472e-05, 3.83398950269792e-05, 3.092994665320133e-05, 2.95661934966314e-05, 1.8245246633244842e-05, 4.779086753729067e-05, 4.101371254185464e-05, 3.5769686254291846e-05, 3.7649494943950894e-05, 1.5678118448642155e-05, 9.2773502664058e-05, 99999, 99999]\n",
            "VAR could not solve row number\n",
            "28 48\n",
            "VAR could not solve row number\n",
            "28 49\n",
            "i= 28 SW = 25 [0.0006330926882972717, 9.202659193149163e-05, 1.171625100762184e-06, 3.1779521007809393e-05, 0.0003530260881509646, 6.908204567076975e-05, 4.9447054109379184e-05, 0.0020905341098041577, 0.0004350484842779322, 0.0022126992042856316, 0.09597198426678961, 0.022925014323724378, 0.0006482954336293204, 0.029412669524260915, 0.009629513925253186, 4.976703634877117e-06, 0.00019307858532013848, 9.426626918807817e-07, 0.00028215190140130106, 2.9178869028110328e-05, 2.136360973637539e-06, 1.961061141035993e-06, 2.136623101735625e-06, 1.445504524401481e-07, 3.143960396150791e-05, 6.047702599076589e-05, 1.076471883054457e-05, 1.0967830279430776e-05, 4.9033144697818936e-05, 7.903707580338264e-07, 4.58404600307188e-06, 1.1486434037588202e-05, 8.658277816726816e-05, 0.00017798975355178077, 0.00010260459708687447, 9.786734751458992e-05, 6.824162264065865e-05, 5.034432839228876e-05, 5.4402654491663155e-05, 5.621537897033466e-05, 7.294839565022114e-05, 6.934366610157032e-05, 5.8520723642099045e-05, 6.136256861616508e-05, 3.375358247390999e-05, 0.0001394647636307772, 99999, 99999]\n",
            "VAR could not solve row number\n",
            "29 48\n",
            "VAR could not solve row number\n",
            "29 49\n",
            "i= 29 SW = 31 [4.081184272143435e-05, 0.00029431731306243724, 3.6360258534456347e-06, 0.00024870832618736254, 0.0006372621863344502, 3.048479615537986e-05, 0.0012483511577482636, 8.306401676908666e-05, 3.447209841780095e-05, 0.0038175685299781837, 0.060693226732820654, 0.0251617626404438, 0.022265668467510685, 0.015268929982707761, 0.003174210718579512, 0.0001259088172651702, 7.914504838398354e-05, 2.6569797232725388e-05, 0.00040997862663074753, 9.651958625439464e-05, 1.0223113147455225e-05, 1.0544811289617293e-05, 8.200921494300466e-06, 1.0667353421808456e-05, 6.191535008850503e-05, 3.647682979332345e-05, 6.2995146733135536e-06, 1.563015947739109e-06, 3.0055203101799355e-05, 1.1204414857996558e-06, 6.903089144123832e-06, 1.3257079158059565e-05, 0.00011333814868918586, 0.0002882964453322858, 0.00011425477593960927, 0.00010268052436784607, 6.685832616030568e-05, 4.921198544915403e-05, 4.499532629574792e-05, 4.792141792409169e-05, 7.511905301641448e-05, 6.961678616812598e-05, 5.968609225751852e-05, 6.404918521880016e-05, 3.5105885380439926e-05, 0.00014931341047198413, 99999, 99999]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import math\n",
        "import plotly.graph_objects as go\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout, RepeatVector, TimeDistributed, Input\n",
        "from keras.models import Model\n",
        "from keras import saving\n",
        "\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import Callback\n",
        "import plotly\n",
        "from keras import losses\n",
        "\n",
        "import plotly.express as px # for data visualization\n",
        "#from keras.utils import plot_model\n",
        "#import matplotlib.pyplot as plt\n",
        "\n",
        "#window1 = np.load(r'/content/drive/MyDrive/PHD/2021/multivariate_long_sequences_WINDOW-500.npy')\n",
        "#window2 = np.load(r'/content/drive/MyDrive/PHD/2021/multivariate_long_sequences_WINDOW-1000.npy')\n",
        "#window = np.concatenate((window1, window2), axis=0)\n",
        "#train_data = np.load(r'/content/drive/MyDrive/PHD/2021/multivariate_long_sequences-TRAIN.npy')\n",
        "#test_data = np.load(r'/content/drive/MyDrive/PHD/2021/multivariate_long_sequences-TEST.npy')\n",
        "\n",
        "\n",
        "train_data = np.load(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_METROPM/multivariate_long_sequences-TRAIN-Daily-DIRECT-VAR.npy')\n",
        "\n",
        "\n",
        "n_seq = train_data.shape[0]\n",
        "window_size = train_data.shape[1]\n",
        "n_features = train_data.shape[2]\n",
        "\n",
        "\n",
        "maxval = train_data.shape[0]\n",
        "count_train = int(math.ceil(0.8*maxval))\n",
        "x_train = train_data[:count_train]\n",
        "x_test = train_data[count_train:]\n",
        "#x_test = train_data[count_train:,:,:]\n",
        "\n",
        "# Clear all previously registered custom objects\n",
        "saving.get_custom_objects().clear()\n",
        "# Create a custom layer\n",
        "@saving.register_keras_serializable(package=\"MyLayers\")\n",
        "class Sampling(layers.Layer):\n",
        "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
        "\n",
        "    def __init__(self, factor):\n",
        "        super().__init__()\n",
        "        self.factor = factor\n",
        "\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "    def get_config(self):\n",
        "        return {\"factor\": self.factor}\n",
        "\n",
        "#Build the encoder\n",
        "latent_dim = 5\n",
        "intermediate_dim = 256\n",
        "\n",
        "\n",
        "#Encoder\n",
        "encoder_inputs =  layers.Input(shape=(window_size, n_features),name=\"encoder_input\")\n",
        "x = layers.LSTM(intermediate_dim, activation='tanh', name=\"lstm1\", return_sequences=True)(encoder_inputs)\n",
        "xx = layers.LSTM(int(intermediate_dim/2), activation='tanh', name=\"lstm2\", return_sequences=False)(x)\n",
        "x1 = layers.Dense(int(intermediate_dim/2), name=\"dense\" )(xx)\n",
        "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x1)\n",
        "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x1)\n",
        "z = Sampling(1)([z_mean, z_log_var])\n",
        "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "encoder.summary()\n",
        "\n",
        "\n",
        "#Dcoder\n",
        "\n",
        "inp_z = Input(shape=(latent_dim,),name=\"decoder\")\n",
        "x1 = layers.RepeatVector(window_size, name=\"repeatvect\")(inp_z)\n",
        "x2= layers.Dense(int(intermediate_dim/2),  name=\"Dense2\")(x1)\n",
        "x22= layers.LSTM(int(intermediate_dim/2),activation='tanh', return_sequences=True, name=\"lstm1\")(x2)\n",
        "x3 = layers.LSTM(intermediate_dim,activation='tanh', return_sequences=True, name=\"lstm2\")(x22)\n",
        "decode_out = layers.TimeDistributed(Dense(n_features), name=\"decodeout\")(x3)\n",
        "#decode_out = layers.LSTM(n_features,name='decodeout', return_sequences=True)(x2) #Alternative\n",
        "decoder = keras.Model(inp_z, decode_out, name=\"decoder\")\n",
        "decoder.summary()\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.LearningRateScheduler(lambda x: 1e-3 * 0.90 ** x)\n",
        "\n",
        "\n",
        "#Parameters\n",
        "n_epochs = 150 # total number of epochs\n",
        "klstart = 20 # The number of epochs at which KL loss should be included\n",
        "kl_annealtime = n_epochs-klstart\n",
        "# the starting value of weight is 0\n",
        "# define it as a keras backend variable\n",
        "weight = K.variable(0.0)\n",
        "\n",
        "#Define the VAE as a Model with a custom train_step\n",
        "class VAE(keras.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super(VAE, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
        "            name=\"reconstruction_loss\"\n",
        "        )\n",
        "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.kl_loss_tracker,\n",
        "\n",
        "        ]\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var, z = self.encoder(data)\n",
        "            reconstruction = self.decoder(z)\n",
        "            reconstruction_loss = tf.reduce_mean(\n",
        "                tf.reduce_sum(\n",
        "                    losses.mean_squared_error(data, reconstruction), axis=-1),keepdims=True\n",
        "                )\n",
        "\n",
        "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
        "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
        "            #K.print_tensor(weight)\n",
        "            total_loss = reconstruction_loss + (weight*kl_loss)\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "        return {\n",
        "            \"loss\": self.total_loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "        }\n",
        "\n",
        "    def test_step(self, data):\n",
        "\n",
        "            z_mean, z_log_var, z = self.encoder(data)\n",
        "            reconstruction = self.decoder(z)\n",
        "            reconstruction_loss = tf.reduce_mean(\n",
        "                tf.reduce_sum(\n",
        "                    losses.mean_squared_error(data, reconstruction), axis=-1),keepdims=True\n",
        "                )\n",
        "\n",
        "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
        "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
        "\n",
        "            total_loss = reconstruction_loss + kl_loss\n",
        "\n",
        "            return {\n",
        "                \"loss\": self.total_loss_tracker.result(),\n",
        "                \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "                \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "                  }\n",
        "\n",
        "\n",
        "\n",
        "# CALLBACKS\n",
        "es = keras.callbacks.EarlyStopping(patience=50, verbose=1, min_delta=0.0001, monitor='loss', mode='auto', restore_best_weights=True)\n",
        "\n",
        "class AnnealingCallback(Callback):\n",
        "    def __init__(self, weight):\n",
        "        self.weight = weight\n",
        "    def on_epoch_end (self, epoch, logs={}):\n",
        "        if epoch > klstart and epoch <klstart*1.2:\n",
        "            new_weight = min(K.get_value(self.weight) + (1./ kl_annealtime), 1.)\n",
        "            K.set_value(self.weight, new_weight)\n",
        "        print (\"Current KL Weight is \" + str(K.get_value(self.weight)))\n",
        "\n",
        "#Train the VAE\n",
        "\n",
        "vae = VAE(encoder, decoder)\n",
        "\n",
        "\n",
        "\n",
        "vae.compile(optimizer=keras.optimizers.Adam(clipnorm=1))\n",
        "history=vae.fit( x_train,\n",
        "                 epochs=n_epochs,\n",
        "                 batch_size=32,\n",
        "                 validation_split=0.1,\n",
        "                 #callbacks=[es,AnnealingCallback(weight),reduce_lr])\n",
        "                 callbacks=[AnnealingCallback(weight)])\n",
        "\n",
        "\n",
        "encoder.save(r'/content/drive/MyDrive/PHD/2024/VAE_SIMULATION/METROPM_vae-encoder-latent5-dim256.keras')\n",
        "decoder.save(r'/content/drive/MyDrive/PHD/2024/VAE_SIMULATION/METROPM_vae-decoder-latent5-dim256.keras')\n",
        "\n",
        "encoder = keras.models.load_model(r'/content/drive/MyDrive/PHD/2024/VAE_SIMULATION/METROPM_vae-encoder-latent5-dim256.keras')\n",
        "decoder = keras.models.load_model(r'/content/drive/MyDrive/PHD/2024/VAE_SIMULATION/METROPM_vae-decoder-latent5-dim256.keras')\n",
        "\n",
        "\n",
        "\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['reconstruction_loss'], label='reconstruction_loss')\n",
        "plt.plot(history.history['kl_loss'], label='kl_Loss')\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "#plt.legend(['kl_loss'], loc='upper left')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.ylim(0, 100)\n",
        "plt.show()\n",
        "\n",
        "#Just Loss\n",
        "\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "#plt.legend(['kl_loss'], loc='upper left')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "#plt.ylim(0, 100)\n",
        "plt.show()\n",
        "\n",
        "#PLOT TRAIN RECONSTRUCTION\n",
        "X_test_encoded = encoder.predict(x_train)\n",
        "X_test_predict = decoder(X_test_encoded[2])\n",
        "plt.suptitle('Example Reconstruction of Training Data')\n",
        "plt.xlabel('Time', fontsize ='10')\n",
        "plt.ylabel('Feature 6', fontsize='10')\n",
        "\n",
        "plt.plot(x_train[:,:,5],\"r\", label=\"Actual\")\n",
        "plt.plot(X_test_predict[:,:,5],\"b\", label=\"reconstructed\")\n",
        "#plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#PLOT TEST RECONSTRUCTION\n",
        "X_test_encoded = encoder.predict(x_test[:,:,:])\n",
        "X_test_predict = decoder(X_test_encoded[2])\n",
        "plt.suptitle('Example Reconstruction of Testing Data')\n",
        "plt.xlabel('Time', fontsize ='10')\n",
        "plt.ylabel('Feature 6', fontsize='10')\n",
        "plt.plot(x_test[:,:,5],\"r\")\n",
        "plt.plot(X_test_predict[:,:,5],\"b\")\n",
        "plt.show()\n",
        "\n",
        "fig = px.scatter(None, x=X_test_encoded[2][:,0], y=X_test_encoded[2][:,1],opacity=1, color=window_label.astype(str))\n",
        "fig.update_layout(dict(plot_bgcolor = 'white'))\n",
        "fig.update_traces(marker=dict(size=2))\n",
        "fig.show()\n",
        "\n",
        "#--------------------------------------Trysimple encoder--------------------------------------------------------------------------------------\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import math\n",
        "import plotly.graph_objects as go\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, RepeatVector, TimeDistributed, Input\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import keras.backend as K\n",
        "from keras.callbacks import Callback\n",
        "import plotly\n",
        "import plotly.express as px # for data visualization\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import IsolationForest\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import pylab as pl\n",
        "\n",
        "generator_multiply = 100 #each input record will generate 100 random vectors from the latent space, given the mu and sigma generated by the encoder\n",
        "\n",
        "#from keras.utils import plot_model\n",
        "#import matplotlib.pyplot as plt\n",
        "\n",
        "#window1 = np.load(r'/content/drive/MyDrive/PHD/2021/multivariate_long_sequences_WINDOW-500.npy')\n",
        "#window2 = np.load(r'/content/drive/MyDrive/PHD/2021/multivariate_long_sequences_WINDOW-1000.npy')\n",
        "#window = np.concatenate((window1, window2), axis=0)\n",
        "#train_data = np.load(r'/content/drive/MyDrive/PHD/2021/multivariate_long_sequences-TRAIN.npy')\n",
        "#test_data = np.load(r'/content/drive/MyDrive/PHD/2021/multivariate_long_sequences-TEST.npy')\n",
        "\n",
        "\n",
        "train_data = np.load(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_METROPM/multivariate_long_sequences-TRAIN-Daily-DIRECT-VAR.npy')\n",
        "#test_data = np.load(r'/content/drive/MyDrive/PHD/2024/multivariate_long_sequences-TEST_hourly.npy')\n",
        "window_label = np.load(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_METROPM/multivariate_long_sequences_WINDOW-Daily-DIRECT-VAR.npy')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "n_seq = train_data.shape[0]\n",
        "window_size = train_data.shape[1]\n",
        "n_features = train_data.shape[2]\n",
        "\n",
        "\n",
        "x_train = train_data\n",
        "#x_test = test_data\n",
        "#x_test = train_data[count_train:,:,:]\n",
        "#x_test_final = x_train\n",
        "#window_label_ho = window_label_test\n",
        "\n",
        "\n",
        "\n",
        "#----------------check window distribution - we see upto 20 has very high fequency. so we remove that and take the rest to generate more samples, to create overall uniform distribution...\n",
        "#First we test window 20 to 30 and see if this method can fit the model well\n",
        "\n",
        "plt.figure(figsize=(15,6))\n",
        "plt.subplot(1,2,1)\n",
        "plt.title(\"Distribution before Transformation\", fontsize=15)\n",
        "sns.histplot(window_label, kde=True, color=\"red\")\n",
        "plt.subplot(1,2,2)\n",
        "\n",
        "\n",
        "\n",
        "##---------------------------IGNORE THIS IF NOT GENERATING FRESH VAE DATASET--------------------------------------------------------------------------------------------\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "encoder = keras.models.load_model(r'/content/drive/MyDrive/PHD/2024/VAE_SIMULATION/METROPM_vae-encoder-latent5-dim256.keras')\n",
        "decoder = keras.models.load_model(r'/content/drive/MyDrive/PHD/2024/VAE_SIMULATION/METROPM_vae-decoder-latent5-dim256.keras')\n",
        "\n",
        "X_train_encoded = encoder.predict(train_data)\n",
        "mu, logvar, z = X_train_encoded\n",
        "sigma = tf.exp(0.5 * logvar)\n",
        "batch = tf.shape(mu)[0]  #number of recors / batchs\n",
        "dim = tf.shape(mu)[1] #Ndimension of latent variable\n",
        "store = list()\n",
        "storetemp = list()\n",
        "\n",
        "\n",
        "#For each batch, iterate, get the generator_multipy number of latent vectors with same window_size.\n",
        "#For each z, concatenate z_mean, so it will become 100 dimensional vector\n",
        "\n",
        "for i in range(0,batch):\n",
        "  all_Z_i = tf.random.normal(shape=(generator_multiply,dim), mean = mu[i,:], stddev=sigma[i,:]) #all randorm vectors for this record i\n",
        "  X_train_decoded = decoder.predict(all_Z_i)\n",
        "  X_train_decoded = X_train_decoded.reshape((X_train_decoded.shape[0],window_size*n_features))\n",
        "  #a = np.arange(generator_multiply)\n",
        "  #a.fill(window_label[i])\n",
        "  #c=np.concatenate(((X_train_decoded,a[:,None])),axis=1)\n",
        "  store.append(X_train_decoded)\n",
        "\n",
        "results1=np.concatenate(store,axis=0)\n",
        "np.save(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_METROPM/generated_large_subsquence2_data_V2.npy',results1)\n",
        "\n",
        "\n",
        "#----------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "results1=np.load(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_METROPM/generated_large_subsquence2_data_V2.npy')\n",
        "\n",
        "x=results1\n",
        "\n",
        "\n",
        "rmse_list = list()\n",
        "min_window_list = list()\n",
        "best_window_for_long_seq = list()\n",
        "best_window_for_long_seq.clear()\n",
        "#for i in range(2) :\n",
        "x_3d = x.reshape((x.shape[0],window_size,n_features))\n",
        "n_future = 1\n",
        "K= window_size\n",
        "\n",
        "cohort1 = 50000\n",
        "cohort2 = 100000\n",
        "cohort3 = 150000\n",
        "cohort4 = 200000\n",
        "cohort5 = 250000\n",
        "cohort6 = 300000\n",
        "cohort7 = 350000\n",
        "\n",
        "\n",
        "\n",
        "best_window_for_long_seq.clear()\n",
        "\n",
        "from statsmodels.tsa.api import VAR\n",
        "\n",
        "#Split and process across multiple files-------------------------------------------------------------\n",
        "for i in range(cohort1) :\n",
        "#for i in range(2) :\n",
        "  #iterate over the entire  long sequences of multivariate time series\n",
        "\n",
        "  rmse_list.clear()\n",
        "  for k in range(2,(round(K))):\n",
        "    cur_seq = x_3d[i,:,:]\n",
        "    df = pd.DataFrame(cur_seq, columns=['V1','V2','V3','V4','V5','V6','V7','V8','V9','V10','V11','V12'])\n",
        "    df_train, df_test = df[0:-n_future], df[-n_future:]\n",
        "    model= VAR(df_train)\n",
        "    try:\n",
        "      model_fitted1 = model.fit(k)\n",
        "      forecast_input1 = df_train.values[-k:]\n",
        "      fc1 = model_fitted1.forecast(y=forecast_input1, steps=n_future)\n",
        "      df_forecast1 = pd.DataFrame(fc1, index=df.index[-n_future:], columns=df.columns)\n",
        "      mse =  mean_squared_error(df_test['V1'], df_forecast1['V1'].values)\n",
        "      rmse_list.append(mse)\n",
        "    except:\n",
        "      rmse_list.append(99999)\n",
        "      print('VAR could not solve row number')\n",
        "      print(i, k)\n",
        "\n",
        "  #For this i, find minimum rmse for all sliding window, and corresponding sw size\n",
        "  min_index = rmse_list.index(min(rmse_list))\n",
        "  min_sw = min_index + 2\n",
        "  print('i=', i,'SW =', min_sw, rmse_list)\n",
        "  best_window_for_long_seq.append(min_sw)\n",
        "\n",
        "\n",
        "#OUT OF ALL LOOPS NOW\n",
        "#best_window_for_long_seq now contains the best multivariate window size for each of the long sequence i\n",
        "print(best_window_for_long_seq)\n",
        "Window = np.array(best_window_for_long_seq)\n",
        "y= Window\n",
        "\n",
        "np.save(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_METROPM/generated-data-true-window2-COHORT1.npy',y)\n",
        "np.save(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_METROPM/generated-data2-COHORT1.npy',x)\n",
        "\n",
        "#---------------------------------------------------------Get parts of the results and combine them --------------------------------\n",
        "\n",
        "temp_d1 = x[0:50000,:]\n",
        "temp_d2 = x[50000:100000,:]\n",
        "temp_d3 = x[100000:150000,:]\n",
        "temp_d4 = x[150000:200000,:]\n",
        "temp_d5 = x[200000:250000,:]\n",
        "temp_d6 = x[250000:300000,:]\n",
        "\n",
        "temp_d = np.concatenate((temp_d1,temp_d2,temp_d3,temp_d4, temp_d5, temp_d6),axis=0)\n",
        "                         #5,temp_d67,temp_d89,temp_d1011,temp_d1213,temp_d1415,temp_d1617, temp_d20),axis=0)\n",
        "\n",
        "temp1 = np.load(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_METROPM/generated-data-true-window2-COHORT1.npy')\n",
        "temp2 = np.load(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_METROPM/generated-data-true-window2-COHORT2.npy')\n",
        "temp3 = np.load(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_METROPM/generated-data-true-window2-COHORT3.npy')\n",
        "temp4 =  np.load(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_METROPM/generated-data-true-window2-COHORT4.npy')\n",
        "temp5 =  np.load(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_METROPM/generated-data-true-window2-COHORT5.npy')\n",
        "temp6 =  np.load(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_METROPM/generated-data-true-window2-COHORT6.npy')\n",
        "\n",
        "\n",
        "\n",
        "temp = np.concatenate((temp1,temp2,temp3,temp4, temp5, temp6),axis=0)\n",
        "                       #5,temp67,temp89,temp1011,temp1213,temp1415,temp1617,temp20),axis=0)\n",
        "\n",
        "\n",
        "\n",
        "x=temp_d\n",
        "y=temp\n",
        "\n",
        "np.save(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_METROPM/generated-data-true-window2.npy',y)\n",
        "np.save(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_METROPM/generated-data2.npy',x)\n",
        "\n",
        "\n",
        "\n",
        "#--------------------------------------IF REQUIRED REMOVE outlier....however we are not doing this now.--------------------------------------------------------------------------------------------------------------------------------------\n",
        "from sklearn.ensemble import IsolationForest\n",
        "iso = IsolationForest(contamination=0.4)\n",
        "yhat = iso.fit_predict(x)\n",
        "# select all rows that are not outliers\n",
        "mask = yhat != -1\n",
        "x, y = x[mask, :], y[mask]\n",
        "\n",
        "\n",
        "###############Scale the target and then split the data into train test----------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "y = np.load(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_METROPM/generated-data-true-window2.npy')\n",
        "x = np.load(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_METROPM/generated-data2.npy')\n",
        "\n",
        "\n",
        "#Looking at the dist, we remove al y less than 20\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "transformer = StandardScaler()\n",
        "y_transformed = transformer.fit_transform(y.reshape(-1,1)).flatten()\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y_transformed, test_size = 0.1, random_state = 42)\n",
        "\n",
        "#--------------------------------------------------------------------------------------CONSTRUCT, COMPILE, AND TRAIN THE MODEL------------------------------------------------------------------------------------------------------------------\n",
        "#------------MLP------------------------------------------------------\n",
        "#x_train = x_train.reshape(x_train.shape[0],x_train.shape[1],1)\n",
        "#x_test = x_test.reshape(x_test.shape[0],x_test.shape[1],1)\n",
        "\n",
        "\n",
        "import os\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model\n",
        "checkpoint_path = \"/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_METROPM/ckp2.weights.h5\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "# Create checkpoint  callback\n",
        "cp_callback =ModelCheckpoint(checkpoint_path,\n",
        "     monitor='loss',save_best_only=True,save_weights_only=True)\n",
        "\n",
        "\n",
        "from keras.layers import LeakyReLU\n",
        "\n",
        "neuron = 64\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation = 'relu'))\n",
        "model.add(Dense(16, activation = 'relu'))\n",
        "model.add(Dense(8, activation = 'relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "\n",
        "optimizr = keras.optimizers.Adam(learning_rate=0.0003,clipnorm=1)\n",
        "model.compile(loss='mean_squared_error', optimizer= optimizr, metrics=['mean_squared_error'])\n",
        "\n",
        "#Initial Build\n",
        "model.fit( x_train,y_train,\n",
        "                 epochs=1,\n",
        "                 batch_size=32)\n",
        "                 callbacks=[cp_callback])\n",
        "\n",
        "model.load_weights(checkpoint_path)\n",
        "\n",
        "\n",
        "es = keras.callbacks.EarlyStopping(patience=20, verbose=1, min_delta=0.0001, monitor='loss', mode='min', restore_best_weights=True)\n",
        "n_epochs = 1000\n",
        "\n",
        "history=model.fit( x_train,y_train,\n",
        "                 epochs=n_epochs,\n",
        "                 batch_size=32,\n",
        "                   validation_split=0.1, callbacks = [cp_callback])\n",
        "                 #callbacks=[es])\n",
        "\n",
        "\n",
        "#-------------------------LOSS-------------------------------------\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'], label='Training loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation loss')\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "#-----------------------------------------------------TRAIN EVALUATION----------------------------------------------------------------\n",
        "y_train_pred_raw = model.predict(x_train)\n",
        "y_train_pred = transformer.inverse_transform(y_train_pred_raw)\n",
        "y_train_true = transformer.inverse_transform(y_train.reshape(-1,1)).flatten()\n",
        "\n",
        "score_train= r2_score(y_train_true,y_train_pred)\n",
        "print(\"r2 score is ==\",score_train)\n",
        "\n",
        "plt.plot(y_train_true[0:100], color = 'red', label = 'Real data')\n",
        "plt.plot(y_train_pred[0:100], color = 'blue', label = 'Predicted data')\n",
        "plt.title('Prediction')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#-----------------------------------------------------TEST EVALUATION----------------------------------------------------------------\n",
        "\n",
        "y_pred_raw = model.predict(x_test)\n",
        "y_test_pred = transformer.inverse_transform(y_pred_raw)\n",
        "y_test_true = transformer.inverse_transform(y_test.reshape(-1,1)).flatten()\n",
        "\n",
        "\n",
        "\n",
        "score= r2_score(y_test_true,y_test_pred)\n",
        "print(\"r2 score is ==\",score)\n",
        "\n",
        "\n",
        "plt.plot(y_test_true[100:200], color = 'red', label = 'Real data')\n",
        "plt.plot(y_test_pred[100:200], color = 'blue', label = 'Predicted data')\n",
        "plt.title('Prediction')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#------------------------------------------------------SAVE MODEL AND RESULTS-----------------------------------------------------------------\n",
        "\n",
        "model.save(r'/content/drive/MyDrive/PHD/2024/DGRNet-MLP-Versions/METROPM_MLP_model_Daily.keras')\n",
        "# It can be used to reconstruct the model identically.\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'], label='Training loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation loss')\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#------------------------------------------------------Retrieve Model-----------------------------------------------------------------\n",
        "\n",
        "base_model = keras.models.load_model(r'/content/drive/MyDrive/PHD/2024/DGRNet-MLP-Versions/METROPM_MLP_model_Daily.keras')\n",
        "\n",
        "\n",
        "#-----------------------------------------------------TEST EVALUATION----------------------------------------------------------------\n",
        "\n",
        "y_pred_raw = base_model.predict(x_test)\n",
        "y_test_pred = transformer.inverse_transform(y_pred_raw)\n",
        "y_test_true = transformer.inverse_transform(y_test.reshape(-1,1)).flatten()\n",
        "\n",
        "\n",
        "\n",
        "score= r2_score(y_test_true,y_test_pred)\n",
        "print(\"r2 score is ==\",score)\n",
        "\n",
        "\n",
        "plt.plot(y_test_true[100:200], color = 'red', label = 'Real data')\n",
        "plt.plot(y_test_pred[100:200], color = 'blue', label = 'Predicted data')\n",
        "plt.title('Prediction')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "np.savetxt(r'/content/drive/MyDrive/PHD/2024/MLPOutput/METROPM_predicted_window.csv',y_test_pred)\n",
        "np.savetxt(r'/content/drive/MyDrive/PHD/2024/MLPOutput/METROPM_derived_window_label.csv',y_test_true)\n",
        "np.savetxt(r'/content/drive/MyDrive/PHD/2024/MLPOutput/METROPM_test_data.csv',x_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "nxij89jyeebm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "L4",
      "mount_file_id": "https://github.com/supriyag123/PHD_Pub/blob/main/PAPER_GDRNet_METROPM_Step2-3-Combined%20-%20REGENRATED.ipynb",
      "authorship_tag": "ABX9TyOTMxNf4+keEFh7ES0inaXc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}