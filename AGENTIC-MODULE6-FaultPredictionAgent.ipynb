{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supriyag123/PHD_Pub/blob/main/AGENTIC-MODULE6-FaultPredictionAgent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "HoP7OuWNxlsJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af7d1cc5-e9c5-40e1-af3a-0d51ca123770"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Prototype + Coordinator (Fusion) ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9988    0.8276    0.9052      1995\n",
            "           1     0.0086    0.6000    0.0170         5\n",
            "\n",
            "    accuracy                         0.8270      2000\n",
            "   macro avg     0.5037    0.7138    0.4611      2000\n",
            "weighted avg     0.9963    0.8270    0.9029      2000\n",
            "\n",
            "[[1651  344]\n",
            " [   2    3]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# ============================================================\n",
        "# Fault Classification Pipeline\n",
        "# ============================================================\n",
        "\n",
        "############PASTE ADAPTIVE WINDOW HERE - so everything is in one file - later, we can import as a package#####################\n",
        "\n",
        "\n",
        "# ====== AdaptiveWindowAgent ======\n",
        "# =====================================================\n",
        "# AdaptiveWindowAgent (improved version)\n",
        "# =====================================================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle, os, logging, datetime as dt\n",
        "from collections import deque\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from statsmodels.tsa.vector_ar.var_model import VAR\n",
        "import keras\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class AdaptiveWindowAgent:\n",
        "    \"\"\"\n",
        "    Adaptive Window Agent:\n",
        "    - Predicts window size using MLP\n",
        "    - Evaluates forecast with VAR\n",
        "    - Monitors anomalies & drift with adaptive thresholds\n",
        "    - Outputs severity scores + suppresses redundant events\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, agent_id=\"adaptive_window_agent\",\n",
        "                 model_path=None, checkpoint_path=None):\n",
        "        self.agent_id = agent_id\n",
        "        self.model_path = model_path or \"/content/drive/MyDrive/PHD/2025/DGRNet-MLP-Versions/METROPM_MLP_model_Daily.keras\"\n",
        "        self.checkpoint_path = checkpoint_path\n",
        "\n",
        "        # Core model\n",
        "        self.model = None\n",
        "        self.transformer = StandardScaler()\n",
        "        self.transformer_fitted = False\n",
        "        self.is_model_loaded = False\n",
        "\n",
        "        # Histories\n",
        "        self.prediction_history = deque(maxlen=1000)\n",
        "        self.mse_history = deque(maxlen=200)\n",
        "        self.mae_history = deque(maxlen=200)\n",
        "\n",
        "        # Event detection params\n",
        "        self.drift_detection_window = 20\n",
        "        self.drift_threshold_mse = 1.5   # stricter\n",
        "        self.drift_threshold_mae = 1.5\n",
        "        self.consecutive_poor_predictions = 0\n",
        "        self.cooldown_counter = 0\n",
        "\n",
        "        # Stats\n",
        "        self.performance_stats = {\n",
        "            'total_predictions': 0,\n",
        "            'avg_mse': 0.0,\n",
        "            'avg_mae': 0.0,\n",
        "            'last_retrain_time': None,\n",
        "            'drift_events': 0,\n",
        "            'anomaly_events': 0,\n",
        "            'retraining_events': 0\n",
        "        }\n",
        "\n",
        "        # Retraining buffers\n",
        "        self.retraining_data = {\n",
        "            'x_buffer': deque(maxlen=10000),\n",
        "            'y_buffer': deque(maxlen=10000)\n",
        "        }\n",
        "\n",
        "        self.load_model()\n",
        "        print(f\"AdaptiveWindowAgent {self.agent_id} initialized\")\n",
        "\n",
        "    # ------------------- Model -------------------\n",
        "\n",
        "    def load_model(self):\n",
        "        try:\n",
        "            if os.path.exists(self.model_path):\n",
        "                self.model = keras.models.load_model(self.model_path)\n",
        "                self.is_model_loaded = True\n",
        "                print(f\"✅ Loaded MLP model from {self.model_path}\")\n",
        "\n",
        "                # Try to load transformer\n",
        "                transformer_path = self.model_path.replace('.keras', '_transformer.pkl')\n",
        "                if os.path.exists(transformer_path):\n",
        "                    with open(transformer_path, 'rb') as f:\n",
        "                        self.transformer = pickle.load(f)\n",
        "                    self.transformer_fitted = True\n",
        "                else:\n",
        "                    # Fit transformer from true window labels\n",
        "                    y_original = np.load(\n",
        "                        \"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/generated-data-true-window2.npy\"\n",
        "                    )\n",
        "                    self.transformer.fit(y_original.reshape(-1, 1))\n",
        "                    self.transformer_fitted = True\n",
        "                    with open(transformer_path, 'wb') as f:\n",
        "                        pickle.dump(self.transformer, f)\n",
        "                    print(\"⚠️ No transformer found, fitted a new one.\")\n",
        "            else:\n",
        "                print(f\"❌ Model not found at {self.model_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error loading model: {e}\")\n",
        "\n",
        "    # ------------------- Forecast Eval -------------------\n",
        "    def evaluate_forecast_performance(self, sequence_3d, predicted_window, n_future=1):\n",
        "        try:\n",
        "            df = pd.DataFrame(sequence_3d, columns=[f'V{i+1}' for i in range(sequence_3d.shape[1])])\n",
        "            df_train, df_test = df[:-n_future], df[-n_future:]\n",
        "\n",
        "            # Drop constant cols\n",
        "            constant_cols = [c for c in df_train.columns if df_train[c].nunique() <= 1]\n",
        "            df_train = df_train.drop(columns=constant_cols, errors=\"ignore\")\n",
        "            df_test = df_test.drop(columns=constant_cols, errors=\"ignore\")\n",
        "\n",
        "            # If too few variables, fall back immediately\n",
        "            if len(df_train.columns) < 1:\n",
        "                return self._persistence_forecast(df, df_test)\n",
        "\n",
        "            k = min(predicted_window, len(df_train) - 2)\n",
        "            if k < 1: k = 1\n",
        "\n",
        "            # Try VAR\n",
        "            try:\n",
        "                model = VAR(df_train)\n",
        "                model_fitted = model.fit(maxlags=k, trend=\"c\")\n",
        "                forecast_input = df_train.values[-model_fitted.k_ar:]\n",
        "                fc = model_fitted.forecast(y=forecast_input, steps=n_future)\n",
        "                df_forecast = pd.DataFrame(fc, index=df.index[-n_future:], columns=df_train.columns)\n",
        "\n",
        "                actual = df_test[df_forecast.columns].values.flatten()\n",
        "                predicted = df_forecast.values.flatten()\n",
        "\n",
        "            except Exception:\n",
        "                # Try AutoReg\n",
        "                try:\n",
        "                    from statsmodels.tsa.ar_model import AutoReg\n",
        "                    col = df_train.columns[0]\n",
        "                    model = AutoReg(df_train[col], lags=min(k, len(df_train)//2)).fit()\n",
        "                    predicted = model.predict(start=len(df_train), end=len(df_train)+n_future-1).values\n",
        "                    actual = df_test[col].values\n",
        "                except Exception:\n",
        "                    # Fallback to persistence\n",
        "                    return self._persistence_forecast(df, df_test)\n",
        "\n",
        "            mse = np.mean((actual - predicted) ** 2)\n",
        "            mae = np.mean(np.abs(actual - predicted))\n",
        "\n",
        "            # If forecast is unstable, fallback\n",
        "            if np.isnan(mse) or np.isnan(mae) or mse > 10 or mae > 10:\n",
        "                return self._persistence_forecast(df, df_test)\n",
        "\n",
        "            return {\n",
        "                'mse': float(mse),\n",
        "                'mae': float(mae),\n",
        "                'forecast_success': True,\n",
        "                'actual_values': actual.tolist(),\n",
        "                'predicted_values': predicted.tolist(),\n",
        "                'used_columns': list(df_test.columns)\n",
        "            }\n",
        "\n",
        "        except Exception:\n",
        "            return self._persistence_forecast(df, df_test)\n",
        "\n",
        "# ------------------- Persistence fallback -------------------\n",
        "\n",
        "    def _persistence_forecast(self, df, df_test):\n",
        "        \"\"\"Simple last-value-carried-forward forecast.\"\"\"\n",
        "        try:\n",
        "            last_values = df.iloc[-1].values\n",
        "            predicted = np.tile(last_values, (len(df_test), 1))\n",
        "            actual = df_test.values.flatten()\n",
        "\n",
        "            mse = np.mean((actual - predicted.flatten()) ** 2)\n",
        "            mae = np.mean(np.abs(actual - predicted.flatten()))\n",
        "\n",
        "            return {\n",
        "                'mse': float(mse),\n",
        "                'mae': float(mae),\n",
        "                'forecast_success': True,\n",
        "                'actual_values': actual.tolist(),\n",
        "                'predicted_values': predicted.flatten().tolist(),\n",
        "                'used_columns': list(df_test.columns),\n",
        "                'note': 'persistence_fallback'\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {'mse': 9999, 'mae': 9999, 'forecast_success': True, 'error': str(e), 'note': 'persistence_fallback_failed'}\n",
        "\n",
        "\n",
        "\n",
        "    # ------------------- Prediction -------------------\n",
        "\n",
        "    def predict_window_size(self, feature_vector, sequence_3d):\n",
        "        if not self.is_model_loaded:\n",
        "            return {'predicted_window': 20, 'error': \"Model not loaded\"}\n",
        "\n",
        "        try:\n",
        "            if feature_vector.ndim == 1:\n",
        "                feature_vector = feature_vector.reshape(1, -1)\n",
        "\n",
        "            pred_raw = self.model.predict(feature_vector, verbose=0)\n",
        "            if self.transformer_fitted:\n",
        "                predicted_window = int(round(self.transformer.inverse_transform(pred_raw)[0, 0]))\n",
        "            else:\n",
        "                predicted_window = int(round(pred_raw[0, 0]))\n",
        "\n",
        "            # Evaluate\n",
        "            forecast_metrics = self.evaluate_forecast_performance(sequence_3d, predicted_window, n_future=1)\n",
        "\n",
        "            if forecast_metrics.get(\"forecast_success\", False):\n",
        "                self.mse_history.append(forecast_metrics[\"mse\"])\n",
        "                self.mae_history.append(forecast_metrics[\"mae\"])\n",
        "                self.performance_stats['total_predictions'] += 1\n",
        "                self.performance_stats['avg_mse'] = np.mean(self.mse_history)\n",
        "                self.performance_stats['avg_mae'] = np.mean(self.mae_history)\n",
        "\n",
        "            # Event check\n",
        "            event, sev = self._check_for_event()\n",
        "\n",
        "            # Save history\n",
        "            record = {\n",
        "                'timestamp': dt.datetime.now(),\n",
        "                'predicted_window': predicted_window,\n",
        "                'forecast_metrics': forecast_metrics,\n",
        "                'event_type': event,\n",
        "                'severity': sev\n",
        "            }\n",
        "            self.prediction_history.append(record)\n",
        "\n",
        "            return {\n",
        "                'predicted_window': predicted_window,\n",
        "                'forecast_metrics': forecast_metrics,\n",
        "                'event_type': event,\n",
        "                'severity': sev,\n",
        "                'performance_stats': self.get_recent_performance()\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {'predicted_window': 20, 'error': str(e)}\n",
        "\n",
        "    # ------------------- Event Logic -------------------\n",
        "\n",
        "    def _check_for_event(self):\n",
        "        if len(self.mse_history) < self.drift_detection_window:\n",
        "            return None, 0.0\n",
        "\n",
        "        mse_vals = np.array(self.mse_history)[-self.drift_detection_window:]\n",
        "        mae_vals = np.array(self.mae_history)[-self.drift_detection_window:]\n",
        "\n",
        "        # Rolling stats\n",
        "        mean_mse, std_mse = np.mean(mse_vals), np.std(mse_vals) + 1e-8\n",
        "        last_mse = mse_vals[-1]\n",
        "\n",
        "        # Normalized error\n",
        "        norm_error = (last_mse - mean_mse) / std_mse\n",
        "\n",
        "        # Severity\n",
        "        anomaly_severity = max(0, norm_error)\n",
        "        drift_severity = max(0, (np.mean(mse_vals) / (np.median(mse_vals)+1e-5)) - 1)\n",
        "\n",
        "        # Check anomaly\n",
        "        if last_mse > mean_mse + 2.0 * std_mse:\n",
        "            self.performance_stats['anomaly_events'] += 1\n",
        "            return \"ANOMALY\", anomaly_severity\n",
        "\n",
        "        # Check drift (with persistence + cooldown)\n",
        "        ema_mse = 0.3*np.mean(mse_vals) + 0.7*np.median(mse_vals)\n",
        "        ema_mae = 0.3*np.mean(mae_vals) + 0.7*np.median(mae_vals)\n",
        "        mse_ratio = ema_mse / max(np.median(mse_vals), 1e-5)\n",
        "        mae_ratio = ema_mae / max(np.median(mae_vals), 1e-5)\n",
        "\n",
        "        if mse_ratio > self.drift_threshold_mse and mae_ratio > self.drift_threshold_mae:\n",
        "            self.consecutive_poor_predictions += 1\n",
        "            if self.consecutive_poor_predictions >= 5 and self.cooldown_counter == 0:\n",
        "                self.performance_stats['drift_events'] += 1\n",
        "                self.cooldown_counter = 10\n",
        "                return \"DRIFT\", drift_severity\n",
        "        else:\n",
        "            self.consecutive_poor_predictions = 0\n",
        "\n",
        "        if self.cooldown_counter > 0:\n",
        "            self.cooldown_counter -= 1\n",
        "\n",
        "        return None, 0.0\n",
        "\n",
        "    # ------------------- Helpers -------------------\n",
        "\n",
        "    def get_recent_performance(self):\n",
        "        successful_predictions = [\n",
        "            p for p in list(self.prediction_history)[-50:]\n",
        "            if p.get('forecast_metrics', {}).get('forecast_success', False)\n",
        "        ]\n",
        "        return {\n",
        "            'total_predictions': len(self.prediction_history),\n",
        "            'successful_predictions': len(successful_predictions),\n",
        "            'success_rate': len(successful_predictions) / max(len(self.prediction_history), 1),\n",
        "            'drift_events': self.performance_stats['drift_events'],\n",
        "            'anomaly_events': self.performance_stats['anomaly_events'],\n",
        "            'retraining_events': self.performance_stats['retraining_events'],\n",
        "            'recent_mse': float(np.mean(list(self.mse_history)[-10:])) if self.mse_history else 0,\n",
        "            'avg_mse': float(np.mean(self.mse_history)) if self.mse_history else 0,\n",
        "            'recent_mae': float(np.mean(list(self.mae_history)[-10:])) if self.mae_history else 0,\n",
        "            'avg_mae': float(np.mean(self.mae_history)) if self.mae_history else 0,\n",
        "            'transformer_fitted': self.transformer_fitted\n",
        "        }\n",
        "\n",
        "\n",
        "    def save_performance_state(self, filepath: str):\n",
        "        \"\"\"Save performance statistics + prediction history to JSON\"\"\"\n",
        "        try:\n",
        "            state = {\n",
        "                'performance_stats': self.performance_stats.copy(),\n",
        "                'prediction_history': list(self.prediction_history)[-100:],  # last 100\n",
        "                'mse_history': list(self.mse_history),\n",
        "                'mae_history': list(self.mae_history),\n",
        "                'transformer_fitted': self.transformer_fitted\n",
        "            }\n",
        "            import json\n",
        "            with open(filepath, 'w') as f:\n",
        "                json.dump(state, f, indent=2, default=str)\n",
        "            print(f\"✅ Performance state saved to {filepath}\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to save performance state: {e}\")\n",
        "\n",
        "#===============================================================================================================================================\n",
        "###  PASTE AGENTS HERE TO RUN FROM SINGLE FILES IN COLAB\n",
        "#--------------------------------------==========================================================================================================\n",
        "# ====== Imports ======\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle, json, os, logging, warnings\n",
        "from collections import deque\n",
        "from typing import Dict, Any\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from statsmodels.tsa.vector_ar.var_model import VAR\n",
        "import keras, tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ====== RobustSensorAgent & RobustMasterAgent ======\n",
        "import pickle\n",
        "import os\n",
        "from collections import deque\n",
        "from typing import Dict, List, Tuple\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ML libraries\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from scipy import stats\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "\n",
        "# Deep learning\n",
        "try:\n",
        "    from tensorflow.keras.models import load_model\n",
        "    KERAS_AVAILABLE = True\n",
        "except ImportError:\n",
        "    KERAS_AVAILABLE = False\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# ROBUST SENSOR AGENT - Observes ONE sensor with AE model\n",
        "# =====================================================\n",
        "\n",
        "class RobustSensorAgent:\n",
        "    \"\"\"\n",
        "    Robust Sensor Agent for ONE sensor with advanced anomaly & drift detection.\n",
        "\n",
        "    Loads pretrained AE model + metadata (scaler, baseline errors, rolling stats).\n",
        "    Computes anomaly score via reconstruction error, applies adaptive thresholding,\n",
        "    drift detection, and outputs robust anomaly/drift/retrain flags.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 sensor_id: int,\n",
        "                 model_path: str = None,\n",
        "                 window_length: int = 50,\n",
        "                 memory_size: int = 1000,\n",
        "                 threshold_k: float = 2.0,\n",
        "                 drift_threshold: float = 0.1):\n",
        "\n",
        "        self.sensor_id = sensor_id\n",
        "        self.window_length = window_length\n",
        "        self.threshold_k = threshold_k\n",
        "        self.drift_threshold = drift_threshold\n",
        "\n",
        "        # Model & metadata\n",
        "        self.model = None\n",
        "        self.scaler = None\n",
        "        self.is_model_loaded = False\n",
        "\n",
        "        # Buffers\n",
        "        self.error_memory = deque(maxlen=memory_size)\n",
        "        self.data_memory = deque(maxlen=memory_size)\n",
        "        self.recent_errors = deque(maxlen=100)\n",
        "\n",
        "        # Rolling stats\n",
        "        self.rolling_stats = {'mean': 0.0, 'std': 1.0, 'q95': 0.0, 'q99': 0.0}\n",
        "        self.baseline_errors = None\n",
        "\n",
        "        # Counters\n",
        "        self.total_processed = 0\n",
        "        self.anomalies_detected = 0\n",
        "        self.drift_detected_count = 0\n",
        "        self.last_stats_update = datetime.now()\n",
        "\n",
        "        if model_path:\n",
        "            self.load_model(model_path)\n",
        "\n",
        "    def load_model(self, model_path: str) -> bool:\n",
        "        \"\"\"Load pretrained AE model + metadata.\"\"\"\n",
        "        try:\n",
        "            if KERAS_AVAILABLE and model_path.endswith('.h5'):\n",
        "                self.model = load_model(model_path, compile=False)\n",
        "\n",
        "                # Metadata sidecar file\n",
        "                metadata_path = model_path.replace('.h5', '_metadata.pkl')\n",
        "                if os.path.exists(metadata_path):\n",
        "                    with open(metadata_path, 'rb') as f:\n",
        "                        metadata = pickle.load(f)\n",
        "                   # self.scaler = metadata.get('scaler', StandardScaler())\n",
        "                    self.rolling_stats = metadata.get('rolling_stats', self.rolling_stats)\n",
        "                    if 'error_history' in metadata:\n",
        "                        self.baseline_errors = np.array(metadata['error_history'])\n",
        "            else:\n",
        "                raise ValueError(\"Unsupported model format – expecting .h5 AE model\")\n",
        "\n",
        "            self.is_model_loaded = True\n",
        "            print(f\"✅ AE model loaded for sensor {self.sensor_id}\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to load AE model for sensor {self.sensor_id}: {e}\")\n",
        "            return False\n",
        "\n",
        "    def observe(self, sensor_subsequence: np.ndarray) -> Dict:\n",
        "        \"\"\"Observe subsequence [window_length] and return anomaly/drift flags.\"\"\"\n",
        "        if not self.is_model_loaded:\n",
        "            return {\"sensor_id\": self.sensor_id, \"error\": \"no_model_loaded\", \"timestamp\": datetime.now()}\n",
        "\n",
        "        if len(sensor_subsequence) != self.window_length:\n",
        "            return {\"sensor_id\": self.sensor_id,\n",
        "                    \"error\": f\"invalid_length_expected_{self.window_length}_got_{len(sensor_subsequence)}\",\n",
        "                    \"timestamp\": datetime.now()}\n",
        "\n",
        "        # 1. Anomaly score\n",
        "        anomaly_score = self._compute_robust_anomaly_score(sensor_subsequence)\n",
        "\n",
        "        # 2. Update memory\n",
        "        self.data_memory.append(sensor_subsequence.copy())\n",
        "        self.error_memory.append(anomaly_score)\n",
        "        self.recent_errors.append(anomaly_score)\n",
        "\n",
        "        # 3. Update rolling stats periodically\n",
        "        if len(self.error_memory) >= 50 and len(self.error_memory) % 10 == 0:\n",
        "            self._update_rolling_stats(list(self.error_memory)[-50:])\n",
        "\n",
        "        # 4. Flags\n",
        "        is_anomaly = self._check_adaptive_anomaly(anomaly_score)\n",
        "        drift_flag = self._check_advanced_drift()\n",
        "        needs_retrain = self._check_retrain_need()\n",
        "        confidence = self._compute_robust_confidence(anomaly_score)\n",
        "\n",
        "        # 5. Update counters\n",
        "        self.total_processed += 1\n",
        "        if is_anomaly: self.anomalies_detected += 1\n",
        "        if drift_flag: self.drift_detected_count += 1\n",
        "\n",
        "        return {\n",
        "            \"sensor_id\": self.sensor_id,\n",
        "            \"timestamp\": datetime.now(),\n",
        "            \"is_anomaly\": bool(is_anomaly),\n",
        "            \"drift_flag\": bool(drift_flag),\n",
        "            \"needs_retrain_flag\": bool(needs_retrain),\n",
        "            \"anomaly_score\": float(anomaly_score),\n",
        "            \"confidence\": float(confidence),\n",
        "            \"threshold_used\": float(self.rolling_stats['mean'] + self.threshold_k * self.rolling_stats['std']),\n",
        "            \"anomaly_rate\": self.anomalies_detected / max(1, self.total_processed),\n",
        "            \"drift_rate\": self.drift_detected_count / max(1, self.total_processed)\n",
        "        }\n",
        "\n",
        "    def _compute_robust_anomaly_score(self, subsequence: np.ndarray) -> float:\n",
        "        \"\"\"Compute reconstruction error using AE model.\"\"\"\n",
        "        try:\n",
        "            #data_scaled = self.scaler.transform(subsequence.reshape(-1, 1))\n",
        "            X = subsequence.reshape(1, self.window_length, 1)  # [batch, timesteps, features]\n",
        "            reconstruction = self.model.predict(X, verbose=0)\n",
        "            error = mean_squared_error(subsequence.flatten(), reconstruction.flatten())\n",
        "            return max(0.0, error)\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ AE inference failed for sensor {self.sensor_id}: {e}\")\n",
        "            return np.var(subsequence)\n",
        "\n",
        "    def _update_rolling_stats(self, errors: List[float]):\n",
        "        errors_array = np.array(errors)\n",
        "        self.rolling_stats['mean'] = np.mean(errors_array)\n",
        "        self.rolling_stats['std'] = np.std(errors_array) + 1e-8\n",
        "        self.rolling_stats['q95'] = np.percentile(errors_array, 95)\n",
        "        self.rolling_stats['q99'] = np.percentile(errors_array, 99)\n",
        "        self.last_stats_update = datetime.now()\n",
        "\n",
        "    def _check_adaptive_anomaly(self, score: float) -> bool:\n",
        "        threshold = self.rolling_stats['mean'] + self.threshold_k * self.rolling_stats['std']\n",
        "        return score > threshold\n",
        "\n",
        "    def _check_advanced_drift(self) -> bool:\n",
        "        if self.baseline_errors is None or len(self.recent_errors) < 30:\n",
        "            return False\n",
        "        try:\n",
        "            hist_baseline, bins = np.histogram(self.baseline_errors, bins=20, density=True)\n",
        "            hist_recent, _ = np.histogram(list(self.recent_errors), bins=bins, density=True)\n",
        "            hist_baseline += 1e-10; hist_recent += 1e-10\n",
        "            hist_baseline /= hist_baseline.sum(); hist_recent /= hist_recent.sum()\n",
        "            js_divergence = jensenshannon(hist_baseline, hist_recent)\n",
        "            return js_divergence > self.drift_threshold\n",
        "        except Exception:\n",
        "            try:\n",
        "                _, p_value = stats.ks_2samp(self.baseline_errors, list(self.recent_errors))\n",
        "                return p_value < 0.05\n",
        "            except:\n",
        "                return False\n",
        "\n",
        "    def _check_retrain_need(self) -> bool:\n",
        "        if len(self.error_memory) < 100: return False\n",
        "        recent_errors = list(self.error_memory)[-50:]\n",
        "        threshold = self.rolling_stats['mean'] + self.threshold_k * self.rolling_stats['std']\n",
        "        anomaly_rate = sum(1 for e in recent_errors if e > threshold) / len(recent_errors)\n",
        "        criteria = [\n",
        "            anomaly_rate > 0.3,\n",
        "            self.drift_detected_count > 0.1 * self.total_processed,\n",
        "            np.mean(recent_errors) > 2.0 * self.rolling_stats['mean'] if len(recent_errors) > 0 else False,\n",
        "            (datetime.now() - self.last_stats_update).days > 7\n",
        "        ]\n",
        "        return sum(criteria) >= 2\n",
        "\n",
        "    def _compute_robust_confidence(self, score: float) -> float:\n",
        "        if self.rolling_stats['std'] == 0: return 0.5\n",
        "        threshold = self.rolling_stats['mean'] + self.threshold_k * self.rolling_stats['std']\n",
        "        distance_from_threshold = abs(score - threshold) / self.rolling_stats['std']\n",
        "        return min(1.0, distance_from_threshold / 3.0)\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# ROBUST MASTER AGENT\n",
        "# =====================================================\n",
        "\n",
        "class RobustMasterAgent:\n",
        "    \"\"\"Aggregates sensor results, makes system-level anomaly/drift/retrain decisions.\"\"\"\n",
        "    def __init__(self, sensor_agents: List[RobustSensorAgent],\n",
        "                 system_anomaly_threshold: float = 0.3,\n",
        "                 drift_threshold: float = 0.2,\n",
        "                 retrain_threshold: float = 0.15):\n",
        "        self.sensor_agents = sensor_agents\n",
        "        self.num_sensors = len(sensor_agents)\n",
        "        self.system_anomaly_threshold = system_anomaly_threshold\n",
        "        self.drift_threshold = drift_threshold\n",
        "        self.retrain_threshold = retrain_threshold\n",
        "\n",
        "    def process_system_input(self, system_subsequence: np.ndarray) -> Dict:\n",
        "        \"\"\"Process [window_length, num_sensors] multivariate subsequence.\"\"\"\n",
        "        timestamp = datetime.now()\n",
        "        if system_subsequence.shape[1] != self.num_sensors:\n",
        "            return {\"error\": f\"Expected {self.num_sensors} sensors, got {system_subsequence.shape[1]}\",\n",
        "                    \"timestamp\": timestamp}\n",
        "\n",
        "        # 1. Collect sensor observations\n",
        "        sensor_results = []\n",
        "        for i, agent in enumerate(self.sensor_agents):\n",
        "            sensor_data = system_subsequence[:, i]\n",
        "            result = agent.observe(sensor_data)\n",
        "            sensor_results.append(result)\n",
        "\n",
        "        # 2. Simple aggregation\n",
        "        anomalies = sum(1 for r in sensor_results if r.get(\"is_anomaly\"))\n",
        "        drifts = sum(1 for r in sensor_results if r.get(\"drift_flag\"))\n",
        "        retrains = sum(1 for r in sensor_results if r.get(\"needs_retrain_flag\"))\n",
        "\n",
        "        anomaly_rate = anomalies / max(1, self.num_sensors)\n",
        "        drift_rate = drifts / max(1, self.num_sensors)\n",
        "        retrain_rate = retrains / max(1, self.num_sensors)\n",
        "\n",
        "        system_decisions = {\n",
        "            \"system_anomaly\": anomaly_rate >= self.system_anomaly_threshold,\n",
        "            \"system_drift\": drift_rate >= self.drift_threshold,\n",
        "            \"system_needs_retrain\": retrain_rate >= self.retrain_threshold,\n",
        "            \"anomaly_rate\": anomaly_rate,\n",
        "            \"drift_rate\": drift_rate,\n",
        "            \"retrain_rate\": retrain_rate\n",
        "        }\n",
        "\n",
        "        return {\n",
        "            \"timestamp\": timestamp,\n",
        "            \"sensor_results\": sensor_results,\n",
        "            \"system_decisions\": system_decisions\n",
        "        }\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# SENSOR SYSTEM CREATION\n",
        "# =====================================================\n",
        "\n",
        "def create_robust_system(num_sensors: int, models_dir: str) -> Tuple[List[RobustSensorAgent], RobustMasterAgent]:\n",
        "    \"\"\"Create robust sensor system loading AE models + metadata.\"\"\"\n",
        "    print(f\"🚀 Creating robust system with {num_sensors} sensors\")\n",
        "    sensor_agents = []\n",
        "    for sensor_id in range(num_sensors):\n",
        "        model_path = os.path.join(models_dir, f\"sensor_{sensor_id}_model.h5\")\n",
        "        agent = RobustSensorAgent(sensor_id=sensor_id,\n",
        "                                  model_path=model_path if os.path.exists(model_path) else None,\n",
        "                                  window_length=50,\n",
        "                                  memory_size=1000,\n",
        "                                  threshold_k=2.0,\n",
        "                                  drift_threshold=0.1)\n",
        "        sensor_agents.append(agent)\n",
        "\n",
        "    master = RobustMasterAgent(sensor_agents=sensor_agents,\n",
        "                               system_anomaly_threshold=0.3,\n",
        "                               drift_threshold=0.2,\n",
        "                               retrain_threshold=0.15)\n",
        "    print(f\"✅ Created system: {len([a for a in sensor_agents if a.is_model_loaded])}/{num_sensors} models loaded\")\n",
        "    return sensor_agents, master\n",
        "\n",
        "\n",
        "# ====== CoordinatorAgent ======\n",
        "\n",
        "class CoordinatorAgent:\n",
        "    \"\"\"\n",
        "    Coordinator Agent - orchestrates outputs from:\n",
        "      1. RobustMasterAgent (sensor-level aggregation)\n",
        "      2. AdaptiveWindowAgent (global window-level perspective)\n",
        "\n",
        "    Combines them into a final system decision:\n",
        "      - True anomalies (local + global agreement)\n",
        "      - Concept drift (global window instability)\n",
        "      - Retraining triggers\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, anomaly_weight: float = 0.6, window_weight: float = 0.4):\n",
        "        self.anomaly_weight = anomaly_weight\n",
        "        self.window_weight = window_weight\n",
        "        self.history = []\n",
        "\n",
        "    def fuse(self, master_output: dict, window_output: dict) -> dict:\n",
        "        timestamp = datetime.now()\n",
        "\n",
        "        # Master outputs\n",
        "        sys_dec = master_output.get(\"system_decisions\", {})\n",
        "        sys_anomaly = sys_dec.get(\"system_anomaly\", False)\n",
        "        sys_drift = sys_dec.get(\"system_drift\", False)\n",
        "        sys_retrain = sys_dec.get(\"system_needs_retrain\", False)\n",
        "        anomaly_rate = sys_dec.get(\"anomaly_rate\", 0.0)\n",
        "        drift_rate = sys_dec.get(\"drift_rate\", 0.0)\n",
        "\n",
        "        # Window outputs\n",
        "        win_anomaly = window_output.get(\"window_anomaly_flag\", False) \\\n",
        "                      or (window_output.get(\"event_type\") == \"ANOMALY\")\n",
        "        win_drift = window_output.get(\"window_drift_flag\", False) \\\n",
        "                    or (window_output.get(\"event_type\") == \"DRIFT\")\n",
        "        predicted_window = window_output.get(\"predicted_window\", None)\n",
        "\n",
        "        # Fusion logic\n",
        "        anomaly_score = (\n",
        "            self.anomaly_weight * anomaly_rate +\n",
        "            self.window_weight * (1.0 if win_anomaly else 0.0)\n",
        "        )\n",
        "        drift_score = (\n",
        "            self.anomaly_weight * drift_rate +\n",
        "            self.window_weight * (1.0 if win_drift else 0.0)\n",
        "        )\n",
        "\n",
        "        final_anomaly = anomaly_score >= 0.3 or (sys_anomaly and win_anomaly)\n",
        "        final_drift = drift_score >= 0.2 or (sys_drift or win_drift)\n",
        "        final_retrain = sys_retrain or (win_drift and anomaly_score > 0.2)\n",
        "\n",
        "        if final_anomaly and final_drift:\n",
        "            alert = \"CRITICAL\"\n",
        "        elif final_anomaly:\n",
        "            alert = \"HIGH\"\n",
        "        elif final_drift:\n",
        "            alert = \"MEDIUM\"\n",
        "        else:\n",
        "            alert = \"NORMAL\"\n",
        "\n",
        "        decision = {\n",
        "            \"timestamp\": timestamp,\n",
        "            \"final_anomaly\": final_anomaly,\n",
        "            \"final_drift\": final_drift,\n",
        "            \"final_retrain\": final_retrain,\n",
        "            \"alert_level\": alert,\n",
        "            \"scores\": {\n",
        "                \"anomaly_score\": anomaly_score,\n",
        "                \"drift_score\": drift_score,\n",
        "                \"sensor_anomaly_rate\": anomaly_rate,\n",
        "                \"sensor_drift_rate\": drift_rate\n",
        "            },\n",
        "            \"window_agent\": {\n",
        "                \"predicted_window\": predicted_window,\n",
        "                \"window_anomaly\": win_anomaly,\n",
        "                \"window_drift\": win_drift\n",
        "            }\n",
        "        }\n",
        "\n",
        "        self.history.append(decision)\n",
        "        return decision\n",
        "\n",
        "##################################################\n",
        "def extract_flags(entry):\n",
        "    # Coordinator flags\n",
        "    if \"coordinator\" in entry:\n",
        "        coord = entry[\"coordinator\"]\n",
        "        return int(coord.get(\"final_anomaly\", False)), int(coord.get(\"final_drift\", False))\n",
        "\n",
        "    # Master flags\n",
        "    if \"master\" in entry and \"system_decisions\" in entry[\"master\"]:\n",
        "        sys = entry[\"master\"][\"system_decisions\"]\n",
        "        return int(sys.get(\"system_anomaly\", False)), int(sys.get(\"system_drift\", False))\n",
        "\n",
        "    return 0, 0\n",
        "##################################################\n",
        "\n",
        "##################################################\n",
        "#GROUND TRUTH ANOMALY VS WHICH AGENT AGENT IS RIGHT\n",
        "############################################################\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_agent_vs_groundtruth(\n",
        "    results,\n",
        "    detection_labels=None,\n",
        "    h1_labels=None,\n",
        "    h3_labels=None,\n",
        "    h12_labels=None,\n",
        "    max_samples=200\n",
        "):\n",
        "    \"\"\"\n",
        "    Plot comparison between agent decisions, ground-truth labels,\n",
        "    coordinator outputs, and AdaptiveWindowAgent predictions.\n",
        "    \"\"\"\n",
        "\n",
        "    n = min(max_samples, len(results))\n",
        "    t = np.arange(n)\n",
        "\n",
        "    # Extract coordinator anomaly/drift\n",
        "    agent_anomaly = [1 if r[\"coordinator\"][\"final_anomaly\"] else 0 for r in results[:n]]\n",
        "    agent_drift   = [1 if r[\"coordinator\"][\"final_drift\"] else 0 for r in results[:n]]\n",
        "\n",
        "    # Ground-truth labels\n",
        "    det = detection_labels[:n] if detection_labels is not None else None\n",
        "    h1  = h1_labels[:n] if h1_labels is not None else None\n",
        "    h3  = h3_labels[:n] if h3_labels is not None else None\n",
        "    h12 = h12_labels[:n] if h12_labels is not None else None\n",
        "\n",
        "    # Window agent outputs\n",
        "    window_sizes  = [r[\"window\"][\"predicted_window\"] for r in results[:n]]\n",
        "    window_events = [r[\"window\"].get(\"event_type\") for r in results[:n]]\n",
        "\n",
        "    # ---- Create subplots ----\n",
        "    fig, axes = plt.subplots(5, 1, figsize=(15, 14), sharex=True)\n",
        "\n",
        "    # Agent outputs\n",
        "    axes[0].plot(t, agent_anomaly, label=\"Agent Anomaly\", color=\"red\")\n",
        "    axes[0].plot(t, agent_drift,   label=\"Agent Drift\", color=\"orange\")\n",
        "    axes[0].set_ylabel(\"Agent\")\n",
        "    axes[0].legend()\n",
        "\n",
        "    # Detection labels\n",
        "    if det is not None:\n",
        "        axes[1].plot(t, det, label=\"Detection Labels\", color=\"blue\")\n",
        "        axes[1].set_ylabel(\"Detect\")\n",
        "        axes[1].legend()\n",
        "\n",
        "    # Prediction labels (1h, 3h, 12h)\n",
        "    if h1 is not None:\n",
        "        axes[2].plot(t, h1, label=\"H1\", color=\"green\")\n",
        "    if h3 is not None:\n",
        "        axes[2].plot(t, h3, label=\"H3\", color=\"purple\")\n",
        "    if h12 is not None:\n",
        "        axes[2].plot(t, h12, label=\"H12\", color=\"brown\")\n",
        "    axes[2].set_ylabel(\"Prediction\")\n",
        "    axes[2].legend()\n",
        "\n",
        "    # Coordinator alert level\n",
        "    alert_map = {\"NORMAL\": 0, \"MEDIUM\": 1, \"HIGH\": 2, \"CRITICAL\": 3}\n",
        "    alerts = [alert_map.get(r[\"coordinator\"][\"alert_level\"], 0) for r in results[:n]]\n",
        "    axes[3].plot(t, alerts, label=\"Alert Level\", color=\"black\")\n",
        "    axes[3].set_yticks([0,1,2,3])\n",
        "    axes[3].set_yticklabels([\"NORMAL\",\"MED\",\"HIGH\",\"CRIT\"])\n",
        "    axes[3].set_ylabel(\"Coordinator\")\n",
        "    axes[3].legend()\n",
        "\n",
        "    # AdaptiveWindowAgent subplot\n",
        "    axes[4].plot(t, window_sizes, label=\"Predicted Window\", color=\"blue\")\n",
        "\n",
        "    # Mark drift/anomaly events\n",
        "    for i, evt in enumerate(window_events):\n",
        "        if evt == \"DRIFT\":\n",
        "            axes[4].scatter(i, window_sizes[i], color=\"orange\", marker=\"x\", label=\"Window Drift\" if i==0 else \"\")\n",
        "        elif evt == \"ANOMALY\":\n",
        "            axes[4].scatter(i, window_sizes[i], color=\"red\", marker=\"o\", label=\"Window Anomaly\" if i==0 else \"\")\n",
        "\n",
        "    # Overlay ground-truth fault events (vertical lines)\n",
        "    if det is not None:\n",
        "        for i, val in enumerate(det):\n",
        "            if val == 1:\n",
        "                axes[4].axvline(i, color=\"red\", linestyle=\"--\", alpha=0.3, label=\"Fault (Detection)\" if i==0 else \"\")\n",
        "    if h1 is not None:\n",
        "        for i, val in enumerate(h1):\n",
        "            if val == 1:\n",
        "                axes[4].axvline(i, color=\"green\", linestyle=\"--\", alpha=0.2, label=\"Fault (H1)\" if i==0 else \"\")\n",
        "    if h3 is not None:\n",
        "        for i, val in enumerate(h3):\n",
        "            if val == 1:\n",
        "                axes[4].axvline(i, color=\"purple\", linestyle=\"--\", alpha=0.2, label=\"Fault (H3)\" if i==0 else \"\")\n",
        "    if h12 is not None:\n",
        "        for i, val in enumerate(h12):\n",
        "            if val == 1:\n",
        "                axes[4].axvline(i, color=\"brown\", linestyle=\"--\", alpha=0.2, label=\"Fault (H12)\" if i==0 else \"\")\n",
        "\n",
        "    axes[4].set_ylabel(\"Window Size\")\n",
        "    axes[4].legend()\n",
        "\n",
        "    axes[-1].set_xlabel(\"Sample index\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "#=========================================================================================================================================\n",
        "#=========================================================================================================================================\n",
        "#=========================================================================================================================================\n",
        "#=========================================================================================================================================\n",
        "#############################################\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import joblib\n",
        "\n",
        "# =============================================================================================================================\n",
        "# 1. Load Data - BASELINE MODELS----------------------------\n",
        "# ============================================================-======================================================================\n",
        "# Long subsequences (length=50) and labels\n",
        "long_sequences = np.load(\"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/multivariate_long_sequences-TRAIN-Daily-DIRECT-VAR.npy\")\n",
        "labels_detection = np.load(\"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/anomaly_labels_detection.npy\")  # fault labels\n",
        "labels_h1 = np.load(\"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/anomaly_labels_H1.npy\")  # optional predictive labels\n",
        "\n",
        "H = 1500  # size of holdout (future block)\n",
        "X_holdout = long_sequences[-H:]\n",
        "y_holdout = labels_detection[-H:]\n",
        "\n",
        "long_sequences = long_sequences[:-H]\n",
        "labels_detection = labels_detection[:-H]\n",
        "\n",
        "print(\"Data loaded:\", long_sequences.shape, labels_detection.shape)\n",
        "\n",
        "# ============================================================\n",
        "# 2. Baseline 1 Fixed Window Features (window=50, flattened)\n",
        "# ============================================================\n",
        "X_fixed = long_sequences.reshape(long_sequences.shape[0], -1)\n",
        "y = labels_detection  # detection labels (can switch to h1/h3/h12)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_fixed, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(\"Train/Test shapes:\", X_train.shape, X_test.shape)\n",
        "\n",
        "# Baseline-1: Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42, n_jobs=-1)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "print(\"\\n=== Baseline-1: Fixed Window Random Forest test data ===\")\n",
        "print(classification_report(y_test, y_pred_rf, digits=4))\n",
        "print(confusion_matrix(y_test, y_pred_rf))\n",
        "joblib.dump(rf, \"rf_fixed_window.pkl\")\n",
        "\n",
        "########## HOLDOUT\n",
        "X_fixed_h = X_holdout.reshape(X_holdout.shape[0], -1)\n",
        "y_predh_rf = rf.predict(X_fixed_h)\n",
        "\n",
        "print(\"\\n=== Baseline-1: Fixed Window Random Forest holdout data ===\")\n",
        "print(classification_report(y_holdout, y_predh_rf, digits=4))\n",
        "print(confusion_matrix(y_holdout, y_predh_rf))\n",
        "joblib.dump(rf, \"rf_fixed_window_holdout.pkl\")\n",
        "\n",
        "\n",
        "# ==========================================================================================================================\n",
        "# 3. Dynamic Window Features (using your AdaptiveWindowAgent)\n",
        "# =============================================================================================================================\n",
        "#from agents.adaptive_window_agent import AdaptiveWindowAgent\n",
        "\n",
        "window_agent = AdaptiveWindowAgent(\n",
        "    model_path=\"/content/drive/MyDrive/PHD/2025/DGRNet-MLP-Versions/METROPM_MLP_model_Daily.keras\"\n",
        ")\n",
        "\n",
        "##Load data again, fresh\n",
        "\n",
        "long_sequences = np.load(\"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/multivariate_long_sequences-TRAIN-Daily-DIRECT-VAR.npy\")\n",
        "labels_detection = np.load(\"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/anomaly_labels_detection.npy\")  # fault labels\n",
        "labels_h1 = np.load(\"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/anomaly_labels_H1.npy\")  # optional predictive labels\n",
        "\n",
        "\n",
        "\n",
        "# Generate features for each subsequence using predicted window - including holdout.\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Paths\n",
        "dyn_feat_path = \"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/dynamic_features.npy\"\n",
        "\n",
        "if os.path.exists(dyn_feat_path):\n",
        "    print(f\"✅ Loading existing dynamic features from {dyn_feat_path}\")\n",
        "    dynamic_features = np.load(dyn_feat_path, allow_pickle=True)\n",
        "else:\n",
        "    print(\"⚠️ Dynamic features not found. Generating now...\")\n",
        "\n",
        "    dynamic_features = []\n",
        "    for i, seq in enumerate(long_sequences):\n",
        "        try:\n",
        "            features = seq.flatten()\n",
        "            result = window_agent.predict_window_size(features, seq)\n",
        "            w = result.get(\"predicted_window\", 50)\n",
        "\n",
        "            # Extract last w timesteps from the long sequence\n",
        "            seq_dynamic = seq[-w:].flatten()\n",
        "            dynamic_features.append(seq_dynamic)\n",
        "\n",
        "            if (i + 1) % 100 == 0:\n",
        "                print(f\"Processed {i+1}/{len(long_sequences)} sequences...\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error on sequence {i}: {e}\")\n",
        "            # fallback: use fixed window\n",
        "            seq_dynamic = seq[-50:].flatten()\n",
        "            dynamic_features.append(seq_dynamic)\n",
        "\n",
        "    dynamic_features = np.array(dynamic_features, dtype=object)\n",
        "    np.save(dyn_feat_path, dynamic_features)\n",
        "    print(f\"✅ Saved dynamic features to {dyn_feat_path}\")\n",
        "\n",
        "print(\"Dynamic feature shape:\", np.shape(dynamic_features))\n",
        "\n",
        "# Pad to same length (use max window=50)\n",
        "X_dynamic = np.array([np.pad(f, (0, 50*seq.shape[1] - len(f))) for f in dynamic_features])\n",
        "H = 1500  # size of holdout (future block)\n",
        "X_holdout = X_dynamic[-H:]\n",
        "y_holdout = labels_detection[-H:]\n",
        "\n",
        "long_sequences = X_dynamic[:-H]\n",
        "labels_detection = labels_detection[:-H]\n",
        "\n",
        "X_train_dyn, X_test_dyn, y_train_dyn, y_test_dyn = train_test_split(long_sequences, labels_detection, test_size=0.2, random_state=42, stratify=labels_detection)\n",
        "\n",
        "# Baseline-2: Random Forest + dynamic window - test data\n",
        "rf = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42, n_jobs=-1)\n",
        "rf.fit(X_train_dyn, y_train_dyn)\n",
        "y_pred_rf_dyn = rf.predict(X_test_dyn)\n",
        "\n",
        "print(\"\\n=== Baseline-2: dynamic Window Random Forest ===\")\n",
        "print(classification_report(y_test_dyn, y_pred_rf_dyn, digits=4))\n",
        "print(confusion_matrix(y_test_dyn, y_pred_rf_dyn))\n",
        "joblib.dump(rf, \"rf_dynamic_window.pkl\")\n",
        "\n",
        "\n",
        "########## Baseline-2: Random Forest + dynamic window -HOLDOUT\n",
        "\n",
        "y_predh_rf_dyn_h = rf.predict(X_holdout)\n",
        "\n",
        "print(\"\\n=== Baseline-2: dynamic Window Random Forest holdout data ===\")\n",
        "print(classification_report(y_holdout, y_predh_rf_dyn_h, digits=4))\n",
        "print(confusion_matrix(y_holdout, y_predh_rf_dyn_h))\n",
        "joblib.dump(rf, \"rf_dynamic_window_holdout.pkl\")\n",
        "\n",
        "\n",
        "# Baseline-3: XGBoost dynamic\n",
        "xgb = XGBClassifier(\n",
        "    n_estimators=300, max_depth=8, learning_rate=0.05,\n",
        "    subsample=0.8, colsample_bytree=0.8,\n",
        "    random_state=42, n_jobs=-1\n",
        ")\n",
        "xgb.fit(X_train_dyn, y_train_dyn)\n",
        "y_pred_xgb = xgb.predict(X_test_dyn)\n",
        "\n",
        "print(\"\\n=== Baseline-3: Dynamic Window XGBoost ===\")\n",
        "print(classification_report(y_test_dyn, y_pred_xgb, digits=4))\n",
        "print(confusion_matrix(y_test_dyn, y_pred_xgb))\n",
        "joblib.dump(xgb, \"xgb_dynamic_window.pkl\")\n",
        "\n",
        "########## Baseline-3: XGBoost dynamic HOLDOUT\n",
        "\n",
        "y_predh_xgb_h = xgb.predict(X_holdout)\n",
        "\n",
        "print(\"\\n=== Baseline-3:Dynamic Window XGBoost holdout data ===\")\n",
        "print(classification_report(y_holdout, y_predh_xgb_h, digits=4))\n",
        "print(confusion_matrix(y_holdout, y_predh_xgb_h))\n",
        "joblib.dump(xgb, \"xgb_dynamic_window_holdout.pkl\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Ready for Next Steps\n",
        "# ============================================================\n",
        "print(\"\\n✅ Baseline models trained and evaluated.\")\n",
        "print(\"Next: add Transformer-based sequence classifier, then coordinator features.\")\n",
        "\n",
        "\n",
        "\n",
        "# ========================================================================================\n",
        "# SOTA: Transformer (PatchTST-style) Classifier\n",
        "# =======================================================================================\n",
        "# ========================================================================================\n",
        "# Contrastive Pretraining + Transformer Encoder + kNN Classifier\n",
        "# ========================================================================================\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "import tensorflow.keras.backend as K\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ====================\n",
        "# 1. Mixed Precision\n",
        "# ====================\n",
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy(\"mixed_float16\")\n",
        "\n",
        "# ====================\n",
        "# 2. Transformer Block\n",
        "# ====================\n",
        "def transformer_block(inputs, head_size=32, num_heads=2, ff_dim=64, dropout=0.2):\n",
        "    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads)(inputs, inputs)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x + inputs)\n",
        "\n",
        "    ff = layers.Dense(ff_dim, activation=\"relu\")(x)\n",
        "    ff = layers.Dropout(dropout)(ff)\n",
        "    ff = layers.Dense(inputs.shape[-1])(ff)\n",
        "    out = layers.LayerNormalization(epsilon=1e-6)(x + ff)\n",
        "    return out\n",
        "\n",
        "# ====================\n",
        "# 3. Transformer Encoder (for contrastive pretrain)\n",
        "# ====================\n",
        "def build_transformer_encoder(input_shape, projection_dim=64):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = transformer_block(inputs, 32, 2, 64, 0.2)\n",
        "    x = transformer_block(x, 32, 2, 64, 0.2)\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    outputs = layers.Dense(projection_dim, activation=None)(x)  # projection head\n",
        "    return keras.Model(inputs, outputs, name=\"transformer_encoder\")\n",
        "\n",
        "# ====================\n",
        "# 4. Contrastive Loss (NT-Xent style)\n",
        "# ====================\n",
        "def contrastive_loss(temperature=0.1):\n",
        "    def loss(y_true, y_pred):\n",
        "        y_pred = K.l2_normalize(y_pred, axis=-1)\n",
        "        batch_size = tf.shape(y_pred)[0] // 2\n",
        "        z1, z2 = tf.split(y_pred, 2, axis=0)\n",
        "        sim = tf.matmul(z1, z2, transpose_b=True) / temperature\n",
        "        labels = tf.range(batch_size)\n",
        "        loss1 = keras.losses.sparse_categorical_crossentropy(labels, sim, from_logits=True)\n",
        "        loss2 = keras.losses.sparse_categorical_crossentropy(labels, tf.transpose(sim), from_logits=True)\n",
        "        return tf.reduce_mean(loss1 + loss2)\n",
        "    return loss\n",
        "\n",
        "# ====================\n",
        "# 5. Augmentations for contrastive\n",
        "# ====================\n",
        "def augment_sequence(seq):\n",
        "    noise = np.random.normal(0, 0.01, seq.shape)\n",
        "    scale = np.random.uniform(0.9, 1.1)\n",
        "    mask = np.random.binomial(1, 0.95, seq.shape)\n",
        "    return seq * scale + noise * mask\n",
        "\n",
        "def create_contrastive_pairs(X, batch_size=128):\n",
        "    idx = np.random.choice(len(X), batch_size, replace=False)\n",
        "    x1 = np.array([augment_sequence(X[i]) for i in idx])\n",
        "    x2 = np.array([augment_sequence(X[i]) for i in idx])\n",
        "    return np.concatenate([x1, x2], axis=0)\n",
        "\n",
        "# ====================\n",
        "# 6. Load Data + Holdout\n",
        "# ====================\n",
        "long_sequences = np.load(\"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/multivariate_long_sequences-TRAIN-Daily-DIRECT-VAR.npy\")\n",
        "labels_detection = np.load(\"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/anomaly_labels_detection.npy\")\n",
        "\n",
        "H = 2000   # holdout size (future block, more faults)\n",
        "X_holdout = long_sequences[-H:]\n",
        "y_holdout = labels_detection[-H:]\n",
        "X = long_sequences[:-H]\n",
        "y = labels_detection[:-H]\n",
        "\n",
        "split_point = int(0.8 * len(X))\n",
        "X_train, X_val = X[:split_point], X[split_point:]\n",
        "y_train, y_val = y[:split_point], y[split_point:]\n",
        "\n",
        "#X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "print(\"Train:\", X_train.shape, y_train.shape)\n",
        "print(\"Val:\", X_val.shape, y_val.shape)\n",
        "print(\"Holdout:\", X_holdout.shape, y_holdout.shape)\n",
        "\n",
        "# class weights\n",
        "classes = np.unique(y_train)\n",
        "cw = compute_class_weight(\"balanced\", classes=classes, y=y_train)\n",
        "class_weight_dict = {i: w for i, w in zip(classes, cw)}\n",
        "print(\"Class weights:\", class_weight_dict)\n",
        "\n",
        "# ====================\n",
        "# 7. Contrastive Pretraining\n",
        "# ====================\n",
        "encoder = build_transformer_encoder(X_train.shape[1:], projection_dim=64)\n",
        "contrastive_model = keras.Model(encoder.input, encoder.output)\n",
        "contrastive_model.compile(optimizer=keras.optimizers.Adam(1e-3),\n",
        "                          loss=contrastive_loss(temperature=0.1))\n",
        "\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 128\n",
        "for epoch in range(EPOCHS):\n",
        "    X_batch = create_contrastive_pairs(X_train, batch_size=BATCH_SIZE//2)\n",
        "    y_dummy = np.zeros(len(X_batch))\n",
        "    loss = contrastive_model.train_on_batch(X_batch, y_dummy)\n",
        "    if epoch % 2 == 0:\n",
        "        print(f\"Epoch {epoch}: contrastive loss = {loss:.4f}\")\n",
        "\n",
        "# ====================\n",
        "# 8. Build Classifier (fine-tune encoder)\n",
        "# ====================\n",
        "encoder_backbone = build_transformer_encoder(X_train.shape[1:], projection_dim=64)\n",
        "encoder_backbone.set_weights(encoder.get_weights())  # transfer pretrained weights\n",
        "\n",
        "inputs = keras.Input(shape=X_train.shape[1:])\n",
        "x = encoder_backbone(inputs)\n",
        "x = layers.Dense(64, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\", dtype=\"float32\")(x)\n",
        "\n",
        "classifier = keras.Model(inputs, outputs)\n",
        "\n",
        "# focal loss\n",
        "def focal_loss(gamma=2., alpha=0.25):\n",
        "    def loss(y_true, y_pred):\n",
        "        y_true = tf.cast(y_true, tf.float32)\n",
        "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
        "        bce = K.binary_crossentropy(y_true, y_pred)\n",
        "        p_t = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
        "        alpha_factor = y_true * alpha + (1 - y_true) * (1 - alpha)\n",
        "        modulating = (1 - p_t) ** gamma\n",
        "        return K.mean(alpha_factor * modulating * bce, axis=-1)\n",
        "    return loss\n",
        "\n",
        "classifier.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-3),\n",
        "    loss=focal_loss(),\n",
        "    metrics=[\"accuracy\", Precision(name=\"precision\"), Recall(name=\"recall\")]\n",
        ")\n",
        "\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
        "lr_sched = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-6)\n",
        "\n",
        "history = classifier.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=30,\n",
        "    batch_size=128,\n",
        "    class_weight=class_weight_dict,\n",
        "    callbacks=[early_stop, lr_sched],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# ====================\n",
        "# 9. Evaluate on val\n",
        "# ====================\n",
        "y_probs = classifier.predict(X_val).flatten()\n",
        "y_pred = (y_probs >= 0.5).astype(int)\n",
        "print(\"\\n=== Contrastive Transformer (Validation) ===\")\n",
        "print(classification_report(y_val, y_pred, digits=4))\n",
        "print(confusion_matrix(y_val, y_pred))\n",
        "\n",
        "# ====================\n",
        "# 10. Evaluate on holdout\n",
        "# ====================\n",
        "y_probs = classifier.predict(X_holdout).flatten()\n",
        "y_pred = (y_probs >= 0.5).astype(int)\n",
        "print(\"\\n=== Contrastive Transformer (Holdout) ===\")\n",
        "print(classification_report(y_holdout, y_pred, digits=4))\n",
        "print(confusion_matrix(y_holdout, y_pred))\n",
        "\n",
        "# ==========================================================\n",
        "# Prototype Scoring Evaluation (Contrastive Embeddings)\n",
        "# ==========================================================\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics.pairwise import cosine_distances\n",
        "import numpy as np\n",
        "\n",
        "# Get embeddings from pretrained encoder (without classifier head)\n",
        "def get_embeddings(encoder, X):\n",
        "    return encoder.predict(X, batch_size=128, verbose=0)\n",
        "\n",
        "# ⚠️ IMPORTANT: use the backbone encoder, not classifier\n",
        "emb_train = get_embeddings(encoder_backbone, X_train)\n",
        "emb_val = get_embeddings(encoder_backbone, X_val)\n",
        "emb_holdout = get_embeddings(encoder_backbone, X_holdout)\n",
        "\n",
        "print(\"Embedding shapes:\", emb_train.shape, emb_val.shape, emb_holdout.shape)\n",
        "\n",
        "# Build prototype from normal training embeddings\n",
        "normal_emb = emb_train[y_train == 0]\n",
        "prototype = np.mean(normal_emb, axis=0, keepdims=True)\n",
        "\n",
        "# Function to compute prototype distance scores\n",
        "def prototype_scores(embeddings, prototype):\n",
        "    return cosine_distances(embeddings, prototype).flatten()\n",
        "\n",
        "scores_val = prototype_scores(emb_val, prototype)\n",
        "scores_holdout = prototype_scores(emb_holdout, prototype)\n",
        "\n",
        "# Evaluate at different thresholds\n",
        "def evaluate_prototype(scores, y_true, threshold):\n",
        "    y_pred = (scores > threshold).astype(int)\n",
        "    report = classification_report(y_true, y_pred, digits=4, zero_division=0)\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    return report, cm\n",
        "\n",
        "# Sweep thresholds\n",
        "thresholds = np.linspace(0.1, 0.9, 9)\n",
        "print(\"\\n=== Prototype Scoring Threshold Sweep (Validation) ===\")\n",
        "for th in thresholds:\n",
        "    report, cm = evaluate_prototype(scores_val, y_val, threshold=th)\n",
        "    print(f\"\\nThreshold={th:.2f}\")\n",
        "    print(report)\n",
        "    print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "# Aggressive threshold (say th=0.3)\n",
        "TH = 0.3\n",
        "print(\"\\n=== Prototype Scoring (Validation, th=0.3) ===\")\n",
        "report_val, cm_val = evaluate_prototype(scores_val, y_val, TH)\n",
        "print(report_val)\n",
        "print(cm_val)\n",
        "\n",
        "print(\"\\n=== Prototype Scoring (Holdout, th=0.3) ===\")\n",
        "report_holdout, cm_holdout = evaluate_prototype(scores_holdout, y_holdout, TH)\n",
        "print(report_holdout)\n",
        "print(cm_holdout)\n",
        "#######################################################################################################\n",
        "#Validate with coordination agent###############################\n",
        "#######################################################################################################\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# --------------------------\n",
        "# 1. Validation Function\n",
        "# --------------------------\n",
        "def validate_with_coordinator(\n",
        "    y_probs,\n",
        "    y_true,\n",
        "    coordinator_results,\n",
        "    threshold=0.5,\n",
        "    coord_weight=0.5,           # balance between prototype vs coordinator\n",
        "    conf_mode=\"sensor_rate\"     # options: \"sensor_rate\", \"anomaly_score\", \"hybrid\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Validate Prototype/Transformer predictions against coordinator agent decisions\n",
        "    using confidence-aware fusion.\n",
        "\n",
        "    Args:\n",
        "        y_probs: np.ndarray, predicted probabilities from prototype/transformer\n",
        "        y_true: np.ndarray, ground truth labels\n",
        "        coordinator_results: list of dicts with coordinator outputs\n",
        "        threshold: float, probability cutoff for prototype predictions\n",
        "        coord_weight: float [0,1], weight given to coordinator confidence\n",
        "        conf_mode: str, which confidence source to use\n",
        "                   (\"sensor_rate\", \"anomaly_score\", \"hybrid\")\n",
        "\n",
        "    Returns:\n",
        "        dict with reports, confusion matrices, raw & validated preds\n",
        "    \"\"\"\n",
        "    # Raw prototype predictions\n",
        "    y_pred_raw = (y_probs >= threshold).astype(int)\n",
        "\n",
        "    y_pred_validated = []\n",
        "    for pred, coord in zip(y_pred_raw, coordinator_results):\n",
        "        coord_data = coord.get(\"coordinator\", {})\n",
        "        coord_flag = coord_data.get(\"final_anomaly\", False)\n",
        "        scores = coord_data.get(\"scores\", {})\n",
        "\n",
        "        # -----------------------\n",
        "        # Compute confidence\n",
        "        # -----------------------\n",
        "        if conf_mode == \"sensor_rate\":\n",
        "            coord_conf = scores.get(\"sensor_anomaly_rate\", 0.0)\n",
        "        elif conf_mode == \"anomaly_score\":\n",
        "            coord_conf = scores.get(\"anomaly_score\", 0.0)\n",
        "        elif conf_mode == \"hybrid\":\n",
        "            coord_conf = 0.5 * scores.get(\"sensor_anomaly_rate\", 0.0) + \\\n",
        "                         0.5 * scores.get(\"anomaly_score\", 0.0)\n",
        "        else:\n",
        "            coord_conf = 0.0\n",
        "\n",
        "        # -----------------------\n",
        "        # Fusion Logic\n",
        "        # -----------------------\n",
        "        if pred == 1:\n",
        "            # keep anomaly unless coordinator strongly disagrees\n",
        "            if coord_flag or coord_conf < (1 - coord_weight):\n",
        "                y_pred_validated.append(1)\n",
        "            else:\n",
        "                y_pred_validated.append(0)\n",
        "        else:\n",
        "            # allow coordinator to promote anomaly if confident\n",
        "            if coord_flag and coord_conf > coord_weight:\n",
        "                y_pred_validated.append(1)\n",
        "            else:\n",
        "                y_pred_validated.append(0)\n",
        "\n",
        "    y_pred_validated = np.array(y_pred_validated)\n",
        "\n",
        "    # Reports\n",
        "    report_raw = classification_report(y_true, y_pred_raw, output_dict=True, zero_division=0)\n",
        "    report_validated = classification_report(y_true, y_pred_validated, output_dict=True, zero_division=0)\n",
        "\n",
        "    cm_raw = confusion_matrix(y_true, y_pred_raw)\n",
        "    cm_validated = confusion_matrix(y_true, y_pred_validated)\n",
        "\n",
        "    return {\n",
        "        \"report_raw\": report_raw,\n",
        "        \"report_validated\": report_validated,\n",
        "        \"confusion_matrix_raw\": cm_raw,\n",
        "        \"confusion_matrix_validated\": cm_validated,\n",
        "        \"raw_preds\": y_pred_raw,\n",
        "        \"validated_preds\": y_pred_validated\n",
        "    }\n",
        "\n",
        "# --------------------------\n",
        "# New: Weighted Fusion Validation\n",
        "# --------------------------\n",
        "def validate_with_fusion(y_probs, y_true, coordinator_results,\n",
        "                         proto_weight=0.7, coord_weight=0.3,\n",
        "                         threshold=0.5, persistence=2):\n",
        "    \"\"\"\n",
        "    Validate Prototype/Transformer predictions with weighted fusion + persistence filter.\n",
        "\n",
        "    Args:\n",
        "        y_probs: np.ndarray of anomaly probabilities (from prototype/transformer)\n",
        "        y_true: ground truth labels\n",
        "        coordinator_results: list of dicts with coordinator outputs (len=N)\n",
        "        proto_weight: float, weight for prototype score\n",
        "        coord_weight: float, weight for coordinator confidence (default assumes 0/1)\n",
        "        threshold: float, final decision threshold\n",
        "        persistence: int, number of consecutive anomalies required to flag\n",
        "\n",
        "    Returns:\n",
        "        dict with metrics and predictions\n",
        "    \"\"\"\n",
        "    # Make sure coordinator has confidence (fallback = 1.0 for anomalies, else 0.0)\n",
        "    coord_conf = []\n",
        "    for coord in coordinator_results:\n",
        "        if \"coordinator\" in coord and \"confidence\" in coord[\"coordinator\"]:\n",
        "            coord_conf.append(coord[\"coordinator\"][\"confidence\"])\n",
        "        else:\n",
        "            coord_conf.append(1.0 if coord[\"coordinator\"].get(\"final_anomaly\", False) else 0.0)\n",
        "    coord_conf = np.array(coord_conf)\n",
        "\n",
        "    # Weighted fusion score\n",
        "    fused_score = proto_weight * y_probs + coord_weight * coord_conf\n",
        "\n",
        "    # Apply threshold\n",
        "    fused_pred = (fused_score >= threshold).astype(int)\n",
        "\n",
        "    # Apply persistence smoothing\n",
        "    if persistence > 1:\n",
        "        smoothed = np.zeros_like(fused_pred)\n",
        "        run = 0\n",
        "        for i, val in enumerate(fused_pred):\n",
        "            if val == 1:\n",
        "                run += 1\n",
        "                if run >= persistence:\n",
        "                    smoothed[i] = 1\n",
        "            else:\n",
        "                run = 0\n",
        "        fused_pred = smoothed\n",
        "\n",
        "    # Reports\n",
        "    report_fused = classification_report(y_true, fused_pred, output_dict=True, zero_division=0)\n",
        "    cm_fused = confusion_matrix(y_true, fused_pred)\n",
        "\n",
        "    return {\n",
        "        \"report_fused\": report_fused,\n",
        "        \"confusion_matrix_fused\": cm_fused,\n",
        "        \"fused_preds\": fused_pred,\n",
        "        \"fused_scores\": fused_score\n",
        "    }\n",
        "\n",
        "# --------------------------\n",
        "# 2. Confusion Matrix Plot\n",
        "# --------------------------\n",
        "def plot_confusion_matrices(cm_raw, cm_validated, labels=[0,1]):\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "    sns.heatmap(cm_raw, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "                xticklabels=labels, yticklabels=labels, ax=axes[0])\n",
        "    axes[0].set_title(\"Transformer (Raw)\")\n",
        "    axes[0].set_xlabel(\"Predicted\")\n",
        "    axes[0].set_ylabel(\"True\")\n",
        "\n",
        "    sns.heatmap(cm_validated, annot=True, fmt=\"d\", cmap=\"Greens\",\n",
        "                xticklabels=labels, yticklabels=labels, ax=axes[1])\n",
        "    axes[1].set_title(\"Transformer + Coordinator\")\n",
        "    axes[1].set_xlabel(\"Predicted\")\n",
        "    axes[1].set_ylabel(\"True\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# --------------------------\n",
        "# 3. Run Coordinator on Test Set\n",
        "# --------------------------\n",
        "results = []\n",
        "coordinator_flags = []\n",
        "\n",
        "window_agent = AdaptiveWindowAgent(\n",
        "    model_path=\"/content/drive/MyDrive/PHD/2025/DGRNet-MLP-Versions/METROPM_MLP_model_Daily.keras\"\n",
        ")\n",
        "sensor_agents, master = create_robust_system(num_sensors=12, models_dir=\"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/sensor/model\")\n",
        "\n",
        "\n",
        "coordinator = CoordinatorAgent()\n",
        "print(\"Running Coordinator over test set...\")\n",
        "\n",
        "import os, pickle\n",
        "import numpy as np\n",
        "\n",
        "# --------------------------\n",
        "# 1. Load or Generate Coordinator Results\n",
        "# --------------------------\n",
        "if os.path.exists(\"coordinator_results.pkl\") and os.path.exists(\"coordinator_flags.npy\"):\n",
        "    print(\"📂 Loading saved coordinator results...\")\n",
        "    with open(\"coordinator_results.pkl\", \"rb\") as f:\n",
        "        results = pickle.load(f)\n",
        "    coordinator_flags = np.load(\"coordinator_flags.npy\")\n",
        "else:\n",
        "    print(\"⚡ Running coordinator fresh on holdout set...\")\n",
        "    results = []\n",
        "    coordinator_flags = []\n",
        "\n",
        "    for i, seq in enumerate(X_holdout):   # use holdout as test set\n",
        "        try:\n",
        "            features = seq.flatten()\n",
        "            master_out = master.process_system_input(seq)\n",
        "            window_out = window_agent.predict_window_size(features, seq)\n",
        "            final = coordinator.fuse(master_out, window_out)\n",
        "\n",
        "            results.append({\n",
        "                \"master\": master_out,\n",
        "                \"window\": window_out,\n",
        "                \"coordinator\": final\n",
        "            })\n",
        "            coordinator_flags.append(1 if final[\"final_anomaly\"] else 0)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Sample {i} failed: {e}\")\n",
        "            results.append({\"coordinator\": {\"final_anomaly\": False}})\n",
        "            coordinator_flags.append(0)\n",
        "\n",
        "    coordinator_flags = np.array(coordinator_flags)\n",
        "\n",
        "    # Save for future use\n",
        "    with open(\"coordinator_results.pkl\", \"wb\") as f:\n",
        "        pickle.dump(results, f)\n",
        "    np.save(\"coordinator_flags.npy\", coordinator_flags)\n",
        "\n",
        "print(f\"✅ Coordinator outputs ready: {len(results)} entries\")\n",
        "print(f\"Unique flags: {np.unique(coordinator_flags, return_counts=True)}\")\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 4. Validate Predictions\n",
        "# --------------------------\n",
        "#y_probs = classifier.predict(X_holdout).flatten()   # Transformer predictions\n",
        "scores = prototype_scores(emb_holdout, prototype)\n",
        "y_probs = scores\n",
        "y_true  = y_holdout                               # Ground truth fault labels\n",
        "\n",
        "\n",
        "validation_out = validate_with_coordinator(\n",
        "    y_probs=scores,\n",
        "    y_true=y_holdout,\n",
        "    coordinator_results=results,\n",
        "    threshold=0.1,\n",
        "    coord_weight=1, #make it very high to stop coord to create more false positives\n",
        "    conf_mode=\"hybrid\"   # or \"hybrid\"\n",
        ")\n",
        "\n",
        "\n",
        "#=======================This was added later as a new fusion rule---need to check later which one is better===========================================\n",
        "fusion_out = validate_with_fusion(\n",
        "    y_probs=scores,\n",
        "    y_true=y_holdout,\n",
        "    coordinator_results=results,\n",
        "    proto_weight=0.7,\n",
        "    coord_weight=0.3,\n",
        "    threshold=0.1,      # you can tune this\n",
        "    persistence=2       # require 2 consecutive anomalies\n",
        ")\n",
        "\n",
        "print(\"\\n=== Prototype (Raw) ===\")\n",
        "print(classification_report(y_true, validation_out[\"raw_preds\"], digits=4))\n",
        "print(validation_out[\"confusion_matrix_raw\"])\n",
        "\n",
        "print(\"\\n=== prototype + Coordinator (Validated) ===\")\n",
        "print(classification_report(y_true, validation_out[\"validated_preds\"], digits=4))\n",
        "print(validation_out[\"confusion_matrix_validated\"])\n",
        "\n",
        "#=======================This was added later as a new fusion rule---need to check later which one is better===========================================\n",
        "print(\"\\n=== Prototype + Coordinator (Fusion) ===\")\n",
        "print(classification_report(y_holdout, fusion_out[\"fused_preds\"], digits=4))\n",
        "print(fusion_out[\"confusion_matrix_fused\"])\n",
        "\n",
        "# --------------------------\n",
        "# 5. Coordinator Impact Summary\n",
        "# --------------------------\n",
        "raw = validation_out[\"report_raw\"][\"1\"]\n",
        "val = validation_out[\"report_validated\"][\"1\"]\n",
        "\n",
        "print(\"\\n=== Coordinator Impact on Fault Class (1) ===\")\n",
        "print(f\"Precision: {raw['precision']:.3f} → {val['precision']:.3f}\")\n",
        "print(f\"Recall:    {raw['recall']:.3f} → {val['recall']:.3f}\")\n",
        "print(f\"F1-score:  {raw['f1-score']:.3f} → {val['f1-score']:.3f}\")\n",
        "\n",
        "# --------------------------\n",
        "# 6. Plot Confusion Matrices\n",
        "# --------------------------\n",
        "plot_confusion_matrices(\n",
        "    validation_out[\"confusion_matrix_raw\"],\n",
        "    validation_out[\"confusion_matrix_validated\"]\n",
        ")\n",
        "# ==========================================\n",
        "# 7. Overlay Plot: Prototype vs Coordinator vs Ground Truth\n",
        "# ==========================================\n",
        "def plot_timeline(y_true, raw_preds, validated_preds, coordinator_flags, max_samples=200):\n",
        "    \"\"\"\n",
        "    Visual timeline of ground truth faults, prototype predictions, and coordinator validated results.\n",
        "    \"\"\"\n",
        "    n = min(max_samples, len(y_true))\n",
        "    t = np.arange(n)\n",
        "\n",
        "    plt.figure(figsize=(14, 5))\n",
        "\n",
        "    # Ground truth faults\n",
        "    plt.plot(t, y_true[:n], label=\"Ground Truth\", color=\"black\", linewidth=2, alpha=0.7)\n",
        "\n",
        "    # Prototype raw predictions\n",
        "    plt.plot(t, raw_preds[:n], label=\"Prototype Raw\", color=\"red\", linestyle=\"--\", alpha=0.6)\n",
        "\n",
        "    # Coordinator validated predictions\n",
        "    plt.plot(t, validated_preds[:n], label=\"Validated (Prototype+Coordinator)\",\n",
        "             color=\"green\", linewidth=2, alpha=0.7)\n",
        "\n",
        "    # Coordinator anomaly flags only\n",
        "    plt.scatter(t, coordinator_flags[:n], label=\"Coordinator Final Anomaly\",\n",
        "                marker=\"x\", color=\"blue\", alpha=0.8)\n",
        "\n",
        "    plt.xlabel(\"Sample Index\")\n",
        "    plt.ylabel(\"Fault / Anomaly Flag\")\n",
        "    plt.title(\"Timeline: Prototype vs Coordinator vs Ground Truth\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n",
        "\n",
        "# ==========================================\n",
        "# Call Timeline Plot (with prototype outputs)\n",
        "# ==========================================\n",
        "plot_timeline(\n",
        "    y_true=y_true,\n",
        "    raw_preds=validation_out[\"raw_preds\"],        # Prototype raw predictions\n",
        "    validated_preds=validation_out[\"validated_preds\"],  # Prototype + Coordinator\n",
        "    coordinator_flags=coordinator_flags,\n",
        "    max_samples=200\n",
        ")\n",
        "\n",
        "# ==========================================\n",
        "# 8. Quantify False Positive Suppression (Prototype-based)\n",
        "# ==========================================\n",
        "def analyze_false_positive_suppression(y_true, raw_preds, validated_preds):\n",
        "    \"\"\"\n",
        "    Compare raw vs validated prototype predictions to quantify false positive suppression.\n",
        "    \"\"\"\n",
        "    # False positives = predicted 1, but true = 0\n",
        "    fp_raw = np.sum((raw_preds == 1) & (y_true == 0))\n",
        "    fp_validated = np.sum((validated_preds == 1) & (y_true == 0))\n",
        "\n",
        "    # False negatives = predicted 0, but true = 1\n",
        "    fn_raw = np.sum((raw_preds == 0) & (y_true == 1))\n",
        "    fn_validated = np.sum((validated_preds == 0) & (y_true == 1))\n",
        "\n",
        "    suppression_rate = (fp_raw - fp_validated) / max(fp_raw, 1)\n",
        "\n",
        "    return {\n",
        "        \"false_positives_raw\": int(fp_raw),\n",
        "        \"false_positives_validated\": int(fp_validated),\n",
        "        \"false_negatives_raw\": int(fn_raw),\n",
        "        \"false_negatives_validated\": int(fn_validated),\n",
        "        \"suppression_rate\": suppression_rate\n",
        "    }\n",
        "\n",
        "# Run analysis\n",
        "fp_analysis = analyze_false_positive_suppression(\n",
        "    y_true=y_true,\n",
        "    raw_preds=validation_out[\"raw_preds\"],         # Prototype raw\n",
        "    validated_preds=validation_out[\"validated_preds\"]  # Prototype + Coordinator\n",
        ")\n",
        "\n",
        "print(\"\\n=== False Positive Suppression Analysis (Prototype) ===\")\n",
        "print(f\"False Positives (Raw Prototype): {fp_analysis['false_positives_raw']}\")\n",
        "print(f\"False Positives (Validated): {fp_analysis['false_positives_validated']}\")\n",
        "print(f\"False Negatives (Raw Prototype): {fp_analysis['false_negatives_raw']}\")\n",
        "print(f\"False Negatives (Validated): {fp_analysis['false_negatives_validated']}\")\n",
        "print(f\"Suppression Rate: {fp_analysis['suppression_rate']*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "v_5iji919H_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8OtWHK--uG6W"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "https://github.com/supriyag123/PHD_Pub/blob/main/AGENTIC-MODULE6-FaultPredictionAgent.ipynb",
      "authorship_tag": "ABX9TyNJemhUk7xy8lwrnREIN/KQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}