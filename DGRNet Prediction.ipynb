{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supriyag123/PHD_Pub/blob/main/DGRNet%20Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bx-5b_puABG1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ea5cc3b-6b21-4773-ddf5-691a6a3147f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21373.739515681591001 > -21390.938916375762346). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21331.276223826243950 > -21332.982501732825767). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21366.919406484677893 > -21368.674930685083382). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21338.775318491778307 > -21343.834433646130492). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21400.826627500293398 > -21404.656586344626703). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21360.891837949522596 > -21361.998652927006333). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21315.800162370287580 > -21333.557162300148775). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21417.094325262081838 > -21422.129393505416374). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21357.204759351734538 > -21366.961270952866471). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21425.608889150404138 > -21438.166071375369938). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21388.710559372775606 > -21397.437543847976485). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21378.586601708761009 > -21379.938196400573361). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21323.792002966769360 > -21333.655759629211389). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21325.716038055234094 > -21334.127911780236900). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21369.519628732716228 > -21372.267779903191695). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21343.393712155510002 > -21352.501857432060206). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21329.426447256519168 > -21331.375065248226747). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21272.064746644093248 > -21277.277227722868702). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21280.989530216029380 > -21288.543133590981597). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21267.981341494512890 > -21279.320841884469701). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21341.113433323745994 > -21342.343795003522246). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21368.288230325772020 > -21370.072809982622857). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21374.922898730212182 > -21383.013443319250655). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21345.857047645462444 > -21355.955900146105705). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21334.337879192076798 > -21359.459429738282779). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21387.994979206927383 > -21392.362633082648244). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21351.855143052285712 > -21362.093132359135780). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21329.290160497817851 > -21337.135364545683842). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21344.810119619614852 > -21362.813536007379298). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21378.336340795951401 > -21381.447379218225251). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21363.225023596340179 > -21372.637621259018488). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21412.833583840070787 > -21419.044019922228472). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21422.844364424894593 > -21426.556117555406672). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21375.008431591530098 > -21380.901373064505606). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21408.959526141119568 > -21419.199887646656862). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21381.088110475360736 > -21382.145908804661303). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21407.880138869440998 > -21410.294263837662584). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21388.313487305251329 > -21396.102938171865389). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21454.300884291056718 > -21458.056771033985569). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21327.808301431607106 > -21329.484675218624034). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21358.250851518529089 > -21360.975151485359675). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21347.152707392790035 > -21348.443045274776523). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21358.967914485088841 > -21363.863960723385389). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21390.300362418696750 > -21396.608675433370081). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21318.916660074566607 > -21326.036414136757230). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21317.172010471767862 > -21317.714669949145900). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21350.344013470563368 > -21355.169074188765080). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21411.957192359855981 > -21420.115064240304491). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21385.892708685256366 > -21396.213258149084140). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21369.739565719071834 > -21373.516553529152588). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21331.315674786510499 > -21344.155616901676694). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21372.300816277205740 > -21376.561359168474155). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/covariance/_robust_covariance.py:184: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-21372.205711044964119 > -21376.767757338988304). You may want to try with a higher value of support_fraction (current value: 0.510).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import math\n",
        "import plotly.graph_objects as go\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, RepeatVector, TimeDistributed, Input\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import keras.backend as K\n",
        "from keras.callbacks import Callback\n",
        "import plotly\n",
        "import plotly.express as px # for data visualization\n",
        "import seaborn as sns\n",
        "\n",
        "generator_multiply = 1 #each input record will generate 100 random vectors from the latent space, given the mu and sigma generated by the encoder\n",
        "\n",
        "#from keras.utils import plot_model\n",
        "#import matplotlib.pyplot as plt\n",
        "\n",
        "#window1 = np.load(r'/content/drive/MyDrive/PHD/2021/multivariate_long_sequences_WINDOW-500.npy')\n",
        "#window2 = np.load(r'/content/drive/MyDrive/PHD/2021/multivariate_long_sequences_WINDOW-1000.npy')\n",
        "#window = np.concatenate((window1, window2), axis=0)\n",
        "#train_data = np.load(r'/content/drive/MyDrive/PHD/2021/multivariate_long_sequences-TRAIN.npy')\n",
        "#test_data = np.load(r'/content/drive/MyDrive/PHD/2021/multivariate_long_sequences-TEST.npy')\n",
        "\n",
        "\n",
        "\n",
        "#get data\n",
        "train_data = np.load(r'/content/drive/MyDrive/PHD/2024/multivariate_long_sequences-TRAIN_hourly.npy')\n",
        "index = 500\n",
        "#We missed i=500 from processing the iosw. So here we are dropping row with index =500\n",
        "train_data= np.delete(train_data, index, axis=0)\n",
        "\n",
        "#test_data = np.load(r'/content/drive/MyDrive/PHD/2024/multivariate_long_sequences-TEST_hourly.npy')\n",
        "#all_data = np.concatenate((train_data,test_data),axis=0)\n",
        "window_label = np.load(r'/content/drive/MyDrive/PHD/2024/multivariate_long_sequences_WINDOW-TRAIN_hourly.npy')\n",
        "n_seq = train_data.shape[0]\n",
        "window_size = train_data.shape[1]\n",
        "n_features = train_data.shape[2]\n",
        "\n",
        "\n",
        "plt.suptitle('Sub sequence plotting', fontsize='30')\n",
        "plt.xlabel('Time', fontsize ='20')\n",
        "plt.ylabel('Feature 1', fontsize='20')\n",
        "plt.plot(train_data[:,:,1])\n",
        "plt.show()\n",
        "\n",
        "#---------------------------------Without VAE------------------------------------\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(train_data, window_label, test_size = 0.2, random_state = 42)\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1]*n_features))\n",
        "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1]*n_features))\n",
        "\n",
        "from sklearn.covariance import EllipticEnvelope\n",
        "ee = EllipticEnvelope(contamination=0.05)\n",
        "yhat = ee.fit_predict(x_train)\n",
        "# select all rows that are not outliers\n",
        "mask = yhat != -1\n",
        "x_train, y_train = x_train[mask, :], y_train[mask]\n",
        "\n",
        "\n",
        "x_train = x_train.reshape((x_train.shape[0], window_size, n_features))\n",
        "x_test = x_test.reshape((x_test.shape[0], window_size, n_features))\n",
        "\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.models import Sequential\n",
        "##!pip uninstall tensorflow\n",
        "#!pip install tensorflow==2.12.0\n",
        "#from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(1000, input_shape=(x_train.shape[1],x_train.shape[2])))\n",
        "model.add(Dense(1000, activation = 'relu'))\n",
        "model.add(Dense(units = 512, activation = 'relu'))\n",
        "model.add(Dense(units = 512, activation = 'relu'))\n",
        "#model.add(Dense(units = 128, activation = 'relu'))\n",
        "#model.add(Dense(units = 128, activation = 'relu'))\n",
        "model.add(Dense(units = 1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
        "\n",
        "#model.fit(x_train, y_train,epochs=5, batch_size=50, verbose=True)\n",
        "\n",
        "#y_pred = model.predict(x_test)\n",
        "\n",
        "#transform\n",
        "\n",
        "model.fit(x_train, y_train,epochs=100, batch_size=50, verbose=True)\n",
        "y_pred = model.predict(x_test)\n",
        "score= r2_score(y_test,y_pred)\n",
        "print(\"r2 score is ==\",score)\n",
        "print(\"mean_sqrd_error is==\",mean_squared_error(y_test,y_pred))\n",
        "print(\"root_mean_squared error of is==\",np.sqrt(mean_squared_error(y_test,y_pred)))\n",
        "\n",
        "#plt.scatter(y_test,y_pred);\n",
        "#plt.xlabel('Actual');\n",
        "#plt.ylabel('Predicted');\n",
        "plt.plot(y_test[0:100], color = 'red', label = 'Real data')\n",
        "plt.plot(y_pred[0:100], color = 'blue', label = 'Predicted data')\n",
        "plt.title('Prediction')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "\n",
        "np.savetxt(r'/content/drive/MyDrive/PHD/2024/MLPOutput/pred_2.csv',y_pred_t)\n",
        "np.savetxt(r'/content/drive/MyDrive/PHD/2024/MLPOutput/real_2.csv',y_test)\n",
        "print(\"MAE is==\",mean_absolute_error(y_test,y_pred))\n",
        "\n",
        "#########Isolation forest-------------------------#\n",
        "iso = IsolationForest(contamination=0.1)\n",
        "x_train, x_test, y_train, y_test = train_test_split(train_data, window_label, test_size = 0.2, random_state = 42)\n",
        "\n",
        "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1]*n_features))\n",
        "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1]*n_features))\n",
        "yhat = iso.fit_predict(x_train)\n",
        "mask = yhat != -1\n",
        "x_train, y_train = x_train[mask, :], y_train[mask]\n",
        "x_train = x_train.reshape((x_train.shape[0], window_size, n_features))\n",
        "x_test = x_test.reshape((x_test.shape[0], window_size, n_features))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(1000, input_shape=(x_train.shape[1],x_train.shape[2])))\n",
        "model.add(Dense(1000, activation = 'relu'))\n",
        "model.add(Dense(units = 512, activation = 'relu'))\n",
        "model.add(Dense(units = 512, activation = 'relu'))\n",
        "#model.add(Dense(units = 128, activation = 'relu'))\n",
        "#model.add(Dense(units = 128, activation = 'relu'))\n",
        "model.add(Dense(units = 1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
        "\n",
        "#model.fit(x_train, y_train,epochs=5, batch_size=50, verbose=True)\n",
        "\n",
        "#y_pred = model.predict(x_test)\n",
        "\n",
        "#transform\n",
        "\n",
        "model.fit(x_train, y_train,epochs=100, batch_size=50, verbose=True)\n",
        "\n",
        "#remove outlier from test data to get a better prediction\n",
        "\n",
        "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1]*n_features))\n",
        "yhat = iso.fit_predict(x_test)\n",
        "mask = yhat != -1\n",
        "x_test, y_test = x_test[mask, :], y_test[mask]\n",
        "x_test = x_test.reshape((x_test.shape[0], window_size, n_features))\n",
        "y_pred = model.predict(x_test)\n",
        "score= r2_score(y_test,y_pred)\n",
        "print(\"r2 score is ==\",score)\n",
        "print(\"mean_sqrd_error is==\",mean_squared_error(y_test,y_pred))\n",
        "print(\"root_mean_squared error of is==\",np.sqrt(mean_squared_error(y_test,y_pred)))\n",
        "\n",
        "\n",
        "np.savetxt(r'/content/drive/MyDrive/PHD/2024/MLPOutput/pred_wo-vae2.csv',y_pred)\n",
        "np.savetxt(r'/content/drive/MyDrive/PHD/2024/MLPOutput/real_wo-vae2.csv',y_test)\n",
        "\n",
        "#########----------------------------------  Now run the VAE to general more sample -------------------------------------------------------------------------#\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(train_data, window_label, test_size = 0.2, random_state = 42)\n",
        "\n",
        "encoder = keras.models.load_model(r'/content/drive/MyDrive/PHD/2024/VAE_SIMULATION/vae-encoder-saved-round5-latent50-dim1000.model')\n",
        "decoder = keras.models.load_model(r'/content/drive/MyDrive/PHD/2024/VAE_SIMULATION/vae-decoder-saved-round5-latent50-dim1000.model')\n",
        "\n",
        "#Encode x_train\n",
        "X_train_encoded = encoder.predict(x_train)\n",
        "#Decode X_train_encoded\n",
        "\n",
        "#Calculate reconstruction error\n",
        "mu, logvar, z = X_train_encoded\n",
        "sigma = tf.exp(0.5 * logvar)\n",
        "X_train_decoded = decoder.predict(z)\n",
        "reconstruction_loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(x_train, X_train_decoded))\n",
        "\n",
        "batch = tf.shape(mu)[0]  #number of recors / batchs\n",
        "dim = tf.shape(mu)[1] #Ndimension of latent variable\n",
        "#store = list()\n",
        "#storetemp = list()\n",
        "\n",
        "#Merge x_train, and also output of decoder (sample generated with VAE)\n",
        "x_train_total = np.vstack((x_train, X_train_decoded))\n",
        "\n",
        "#Now generate window label for VAE data - basically same as original window size array, vstacked\n",
        "y_train_total = np.vstack((y_train, y_train)).flatten().reshape(x_train_total.shape[0],1)\n",
        "\n",
        "x_train = x_train_total.reshape((x_train_total.shape[0], x_train_total.shape[1]*n_features))\n",
        "\n",
        "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1]*n_features))\n",
        "\n",
        "from sklearn.covariance import EllipticEnvelope\n",
        "ee = EllipticEnvelope(contamination=0.1)\n",
        "yhat = ee.fit_predict(x_train)\n",
        "# select all rows that are not outliers\n",
        "mask = yhat != -1\n",
        "x_train, y_train = x_train[mask, :], y_train[mask]\n",
        "\n",
        "\n",
        "x_train = x_train.reshape((x_train.shape[0], window_size, n_features))\n",
        "x_test = x_test.reshape((x_test.shape[0], window_size, n_features))\n",
        "\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.models import Sequential\n",
        "##!pip uninstall tensorflow\n",
        "#!pip install tensorflow==2.12.0\n",
        "#from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(1000, input_shape=(x_train.shape[1],x_train.shape[2])))\n",
        "model.add(Dense(1000, activation = 'relu'))\n",
        "model.add(Dense(units = 512, activation = 'relu'))\n",
        "model.add(Dense(units = 512, activation = 'relu'))\n",
        "#model.add(Dense(units = 128, activation = 'relu'))\n",
        "#model.add(Dense(units = 128, activation = 'relu'))\n",
        "model.add(Dense(units = 1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
        "\n",
        "#model.fit(x_train, y_train,epochs=5, batch_size=50, verbose=True)\n",
        "\n",
        "#y_pred = model.predict(x_test)\n",
        "\n",
        "#transform\n",
        "\n",
        "model.fit(x_train, y_train,epochs=100, batch_size=50, verbose=True)\n",
        "y_pred = model.predict(x_test)\n",
        "score= r2_score(y_test,y_pred)\n",
        "print(\"r2 score is ==\",score)\n",
        "print(\"mean_sqrd_error is==\",mean_squared_error(y_test,y_pred))\n",
        "print(\"root_mean_squared error of is==\",np.sqrt(mean_squared_error(y_test,y_pred)))\n",
        "\n",
        "#plt.scatter(y_test,y_pred);\n",
        "#plt.xlabel('Actual');\n",
        "#plt.ylabel('Predicted');\n",
        "plt.plot(y_test[0:100], color = 'red', label = 'Real data')\n",
        "plt.plot(y_pred[0:100], color = 'blue', label = 'Predicted data')\n",
        "plt.title('Prediction')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "\n",
        "np.savetxt(r'/content/drive/MyDrive/PHD/2024/MLPOutput/pred_2.csv',y_pred_t)\n",
        "np.savetxt(r'/content/drive/MyDrive/PHD/2024/MLPOutput/real_2.csv',y_test)\n",
        "print(\"MAE is==\",mean_absolute_error(y_test,y_pred))\n",
        "\n",
        "\n",
        "#----------------Random forest ----------------------------------\n",
        "###### Random forrest ergression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "from sklearn.linear_model import HuberRegressor\n",
        " # create regressor object\n",
        "#regressor = RandomForestRegressor(n_estimators = 50, random_state = 0)\n",
        "# prepare the model with input scaling\n",
        "pipeline = Pipeline(steps=[('power', PowerTransformer()), ('model',RandomForestRegressor(n_estimators = 100, random_state = 0))])\n",
        "#pipeline = Pipeline(steps=[('power', PowerTransformer()), ('model',HuberRegressor())])\n",
        "\n",
        "# prepare the model with target scaling\n",
        "model = TransformedTargetRegressor(regressor=pipeline, transformer=PowerTransformer())\n",
        "\n",
        "# fit the regressor with x and y data\n",
        "pipeline.fit(x_train,y_train)\n",
        "y_pred = pipeline.predict(x_test)  # test the output by changing values\n",
        "# creating an object of LinearRegression class\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "# predicting the accuracy score\n",
        "\n",
        "score=r2_score(y_test,y_pred)\n",
        "print(\"r2 score is ==\",score)\n",
        "print(\"mean_sqrd_error is==\",mean_squared_error(y_test,y_pred))\n",
        "print(\"root_mean_squared error of is==\",np.sqrt(mean_squared_error(y_test,y_pred)))\n",
        "plt.scatter(y_test,y_pred);\n",
        "plt.xlabel('Actual');\n",
        "plt.ylabel('Predicted');\n",
        "\n",
        "\n",
        "plt.plot(y_test[5000:5049], color = 'red', label = 'Real data')\n",
        "plt.plot(y_pred_t[5000:5049], color = 'blue', label = 'Predicted data')\n",
        "plt.title('Prediction')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8OtWHK--uG6W"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/supriyag123/PHD_Pub/blob/main/DGRNet%20Prediction.ipynb",
      "authorship_tag": "ABX9TyOi2rNHxcuc2BSArS/P1f1h",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}