{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supriyag123/PHD_Pub/blob/main/DGRNet%20STEP3-%20Hourly%20Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoP7OuWNxlsJ",
        "outputId": "3426591a-c4e7-4531-bae4-2a058d8cbf1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "51/51 [==============================] - 0s 8ms/step - loss: 18.9850 - mean_squared_error: 18.9850 - val_loss: 20.4836 - val_mean_squared_error: 20.4836\n",
            "Epoch 2/100\n",
            "51/51 [==============================] - 0s 10ms/step - loss: 19.1221 - mean_squared_error: 19.1221 - val_loss: 21.1521 - val_mean_squared_error: 21.1521\n",
            "Epoch 3/100\n",
            "51/51 [==============================] - 1s 10ms/step - loss: 19.0547 - mean_squared_error: 19.0547 - val_loss: 20.6740 - val_mean_squared_error: 20.6740\n",
            "Epoch 4/100\n",
            "51/51 [==============================] - 0s 8ms/step - loss: 19.3265 - mean_squared_error: 19.3265 - val_loss: 20.4805 - val_mean_squared_error: 20.4805\n",
            "Epoch 5/100\n",
            "51/51 [==============================] - 0s 7ms/step - loss: 18.9439 - mean_squared_error: 18.9439 - val_loss: 20.6081 - val_mean_squared_error: 20.6081\n",
            "Epoch 6/100\n",
            "51/51 [==============================] - 0s 7ms/step - loss: 19.5127 - mean_squared_error: 19.5127 - val_loss: 20.6994 - val_mean_squared_error: 20.6994\n",
            "Epoch 7/100\n",
            "51/51 [==============================] - 0s 10ms/step - loss: 18.9741 - mean_squared_error: 18.9741 - val_loss: 20.4409 - val_mean_squared_error: 20.4409\n",
            "Epoch 8/100\n",
            "51/51 [==============================] - 0s 7ms/step - loss: 19.0063 - mean_squared_error: 19.0063 - val_loss: 20.3130 - val_mean_squared_error: 20.3130\n",
            "Epoch 9/100\n",
            "51/51 [==============================] - 0s 9ms/step - loss: 19.1030 - mean_squared_error: 19.1030 - val_loss: 20.3007 - val_mean_squared_error: 20.3007\n",
            "Epoch 10/100\n",
            "51/51 [==============================] - 0s 10ms/step - loss: 19.2732 - mean_squared_error: 19.2732 - val_loss: 20.3263 - val_mean_squared_error: 20.3263\n",
            "Epoch 11/100\n",
            "51/51 [==============================] - 1s 11ms/step - loss: 19.0062 - mean_squared_error: 19.0062 - val_loss: 20.5682 - val_mean_squared_error: 20.5682\n",
            "Epoch 12/100\n",
            "51/51 [==============================] - 1s 11ms/step - loss: 19.0002 - mean_squared_error: 19.0002 - val_loss: 20.3321 - val_mean_squared_error: 20.3321\n",
            "Epoch 13/100\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 18.8664 - mean_squared_error: 18.8664 - val_loss: 20.7374 - val_mean_squared_error: 20.7374\n",
            "Epoch 14/100\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 19.0400 - mean_squared_error: 19.0400 - val_loss: 20.3098 - val_mean_squared_error: 20.3098\n",
            "Epoch 15/100\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 19.0053 - mean_squared_error: 19.0053 - val_loss: 21.2936 - val_mean_squared_error: 21.2936\n",
            "Epoch 16/100\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 19.0658 - mean_squared_error: 19.0658 - val_loss: 20.7943 - val_mean_squared_error: 20.7943\n",
            "Epoch 17/100\n",
            "51/51 [==============================] - 1s 12ms/step - loss: 19.0367 - mean_squared_error: 19.0367 - val_loss: 20.2974 - val_mean_squared_error: 20.2974\n",
            "Epoch 18/100\n",
            "51/51 [==============================] - 1s 12ms/step - loss: 18.9688 - mean_squared_error: 18.9688 - val_loss: 20.3088 - val_mean_squared_error: 20.3088\n",
            "Epoch 19/100\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 18.8488 - mean_squared_error: 18.8488 - val_loss: 20.2973 - val_mean_squared_error: 20.2973\n",
            "Epoch 20/100\n",
            "51/51 [==============================] - 1s 12ms/step - loss: 18.8397 - mean_squared_error: 18.8397 - val_loss: 20.2975 - val_mean_squared_error: 20.2975\n",
            "Epoch 21/100\n",
            "51/51 [==============================] - 1s 12ms/step - loss: 19.1437 - mean_squared_error: 19.1437 - val_loss: 20.3924 - val_mean_squared_error: 20.3924\n",
            "Epoch 22/100\n",
            "51/51 [==============================] - 1s 10ms/step - loss: 19.1714 - mean_squared_error: 19.1714 - val_loss: 20.3082 - val_mean_squared_error: 20.3082\n",
            "Epoch 23/100\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 18.9658 - mean_squared_error: 18.9658 - val_loss: 20.3163 - val_mean_squared_error: 20.3163\n",
            "Epoch 24/100\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 19.1233 - mean_squared_error: 19.1233 - val_loss: 20.7356 - val_mean_squared_error: 20.7356\n",
            "Epoch 25/100\n",
            "51/51 [==============================] - 1s 11ms/step - loss: 19.2574 - mean_squared_error: 19.2574 - val_loss: 20.3354 - val_mean_squared_error: 20.3354\n",
            "Epoch 26/100\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 19.3670 - mean_squared_error: 19.3670 - val_loss: 20.2989 - val_mean_squared_error: 20.2989\n",
            "Epoch 27/100\n",
            "51/51 [==============================] - 1s 12ms/step - loss: 19.0092 - mean_squared_error: 19.0092 - val_loss: 20.7857 - val_mean_squared_error: 20.7857\n",
            "Epoch 28/100\n",
            "51/51 [==============================] - 1s 12ms/step - loss: 19.1990 - mean_squared_error: 19.1990 - val_loss: 20.4446 - val_mean_squared_error: 20.4446\n",
            "Epoch 29/100\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 19.0402 - mean_squared_error: 19.0402 - val_loss: 20.3158 - val_mean_squared_error: 20.3158\n",
            "Epoch 30/100\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 19.1953 - mean_squared_error: 19.1953 - val_loss: 20.2975 - val_mean_squared_error: 20.2975\n",
            "Epoch 31/100\n",
            "51/51 [==============================] - 1s 19ms/step - loss: 19.1416 - mean_squared_error: 19.1416 - val_loss: 20.2983 - val_mean_squared_error: 20.2983\n",
            "Epoch 32/100\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 18.9059 - mean_squared_error: 18.9059 - val_loss: 20.7787 - val_mean_squared_error: 20.7787\n",
            "Epoch 33/100\n",
            "51/51 [==============================] - 1s 21ms/step - loss: 19.3425 - mean_squared_error: 19.3425 - val_loss: 21.3347 - val_mean_squared_error: 21.3347\n",
            "Epoch 34/100\n",
            "51/51 [==============================] - 1s 17ms/step - loss: 19.0979 - mean_squared_error: 19.0979 - val_loss: 20.3962 - val_mean_squared_error: 20.3962\n",
            "Epoch 35/100\n",
            "51/51 [==============================] - 1s 18ms/step - loss: 19.0238 - mean_squared_error: 19.0238 - val_loss: 20.3904 - val_mean_squared_error: 20.3904\n",
            "Epoch 36/100\n",
            "51/51 [==============================] - 1s 19ms/step - loss: 19.3271 - mean_squared_error: 19.3271 - val_loss: 20.3057 - val_mean_squared_error: 20.3057\n",
            "Epoch 37/100\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 19.0325 - mean_squared_error: 19.0325 - val_loss: 20.5018 - val_mean_squared_error: 20.5018\n",
            "Epoch 38/100\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 18.9651 - mean_squared_error: 18.9651 - val_loss: 20.4334 - val_mean_squared_error: 20.4334\n",
            "Epoch 39/100\n",
            "51/51 [==============================] - 1s 12ms/step - loss: 18.9419 - mean_squared_error: 18.9419 - val_loss: 20.3343 - val_mean_squared_error: 20.3343\n",
            "Epoch 40/100\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 19.0219 - mean_squared_error: 19.0219 - val_loss: 20.4216 - val_mean_squared_error: 20.4216\n",
            "Epoch 41/100\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 18.8613 - mean_squared_error: 18.8613 - val_loss: 20.6024 - val_mean_squared_error: 20.6024\n",
            "Epoch 42/100\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 19.0634 - mean_squared_error: 19.0634 - val_loss: 20.2977 - val_mean_squared_error: 20.2977\n",
            "Epoch 43/100\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 18.8501 - mean_squared_error: 18.8501 - val_loss: 20.6075 - val_mean_squared_error: 20.6075\n",
            "Epoch 44/100\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 19.0482 - mean_squared_error: 19.0482 - val_loss: 20.4088 - val_mean_squared_error: 20.4088\n",
            "Epoch 45/100\n",
            "51/51 [==============================] - 1s 11ms/step - loss: 19.0040 - mean_squared_error: 19.0040 - val_loss: 20.6192 - val_mean_squared_error: 20.6192\n",
            "Epoch 46/100\n",
            "51/51 [==============================] - 1s 12ms/step - loss: 19.0126 - mean_squared_error: 19.0126 - val_loss: 20.4010 - val_mean_squared_error: 20.4010\n",
            "Epoch 47/100\n",
            "51/51 [==============================] - 1s 12ms/step - loss: 19.2276 - mean_squared_error: 19.2276 - val_loss: 20.5963 - val_mean_squared_error: 20.5963\n",
            "Epoch 48/100\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 19.1048 - mean_squared_error: 19.1048 - val_loss: 20.6307 - val_mean_squared_error: 20.6307\n",
            "Epoch 49/100\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 19.1751 - mean_squared_error: 19.1751 - val_loss: 20.4323 - val_mean_squared_error: 20.4323\n",
            "Epoch 50/100\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 19.0640 - mean_squared_error: 19.0640 - val_loss: 20.3159 - val_mean_squared_error: 20.3159\n",
            "Epoch 51/100\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 18.8610 - mean_squared_error: 18.8610 - val_loss: 20.3109 - val_mean_squared_error: 20.3109\n",
            "Epoch 52/100\n",
            "51/51 [==============================] - 1s 17ms/step - loss: 18.9571 - mean_squared_error: 18.9571 - val_loss: 20.6911 - val_mean_squared_error: 20.6911\n",
            "Epoch 53/100\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 18.9452 - mean_squared_error: 18.9452 - val_loss: 20.4110 - val_mean_squared_error: 20.4110\n",
            "Epoch 54/100\n",
            "51/51 [==============================] - 1s 18ms/step - loss: 19.1576 - mean_squared_error: 19.1576 - val_loss: 20.5375 - val_mean_squared_error: 20.5375\n",
            "Epoch 55/100\n",
            "51/51 [==============================] - 1s 11ms/step - loss: 19.0830 - mean_squared_error: 19.0830 - val_loss: 20.4479 - val_mean_squared_error: 20.4479\n",
            "Epoch 56/100\n",
            "51/51 [==============================] - 0s 9ms/step - loss: 19.0016 - mean_squared_error: 19.0016 - val_loss: 20.3124 - val_mean_squared_error: 20.3124\n",
            "Epoch 57/100\n",
            "51/51 [==============================] - 0s 7ms/step - loss: 19.1248 - mean_squared_error: 19.1248 - val_loss: 20.3366 - val_mean_squared_error: 20.3366\n",
            "Epoch 58/100\n",
            "51/51 [==============================] - 0s 9ms/step - loss: 18.9014 - mean_squared_error: 18.9014 - val_loss: 20.2988 - val_mean_squared_error: 20.2988\n",
            "Epoch 59/100\n",
            "51/51 [==============================] - 0s 8ms/step - loss: 18.8998 - mean_squared_error: 18.8998 - val_loss: 20.3497 - val_mean_squared_error: 20.3497\n",
            "Epoch 60/100\n",
            "51/51 [==============================] - 0s 7ms/step - loss: 19.0629 - mean_squared_error: 19.0629 - val_loss: 20.3333 - val_mean_squared_error: 20.3333\n",
            "Epoch 61/100\n",
            "51/51 [==============================] - 0s 7ms/step - loss: 19.0741 - mean_squared_error: 19.0741 - val_loss: 20.3023 - val_mean_squared_error: 20.3023\n",
            "Epoch 62/100\n",
            "51/51 [==============================] - 0s 7ms/step - loss: 18.8818 - mean_squared_error: 18.8818 - val_loss: 20.9724 - val_mean_squared_error: 20.9724\n",
            "Epoch 63/100\n",
            "51/51 [==============================] - 0s 8ms/step - loss: 19.0062 - mean_squared_error: 19.0062 - val_loss: 20.2981 - val_mean_squared_error: 20.2981\n",
            "Epoch 64/100\n",
            "51/51 [==============================] - 0s 7ms/step - loss: 18.8565 - mean_squared_error: 18.8565 - val_loss: 20.3112 - val_mean_squared_error: 20.3112\n",
            "Epoch 65/100\n",
            "51/51 [==============================] - 0s 7ms/step - loss: 18.9487 - mean_squared_error: 18.9487 - val_loss: 21.1408 - val_mean_squared_error: 21.1408\n",
            "Epoch 66/100\n",
            "51/51 [==============================] - 0s 8ms/step - loss: 19.2196 - mean_squared_error: 19.2196 - val_loss: 20.2979 - val_mean_squared_error: 20.2979\n",
            "Epoch 67/100\n",
            "51/51 [==============================] - 0s 7ms/step - loss: 19.1502 - mean_squared_error: 19.1502 - val_loss: 20.7401 - val_mean_squared_error: 20.7401\n",
            "Epoch 68/100\n",
            "51/51 [==============================] - 0s 7ms/step - loss: 18.9920 - mean_squared_error: 18.9920 - val_loss: 20.9383 - val_mean_squared_error: 20.9383\n",
            "Epoch 69/100\n",
            "51/51 [==============================] - 0s 8ms/step - loss: 19.0934 - mean_squared_error: 19.0934 - val_loss: 20.3300 - val_mean_squared_error: 20.3300\n",
            "Epoch 70/100\n",
            "51/51 [==============================] - 0s 7ms/step - loss: 19.1542 - mean_squared_error: 19.1542 - val_loss: 20.3556 - val_mean_squared_error: 20.3556\n",
            "Epoch 71/100\n",
            "51/51 [==============================] - 0s 7ms/step - loss: 19.0743 - mean_squared_error: 19.0743 - val_loss: 20.7250 - val_mean_squared_error: 20.7250\n",
            "Epoch 72/100\n",
            "51/51 [==============================] - 0s 7ms/step - loss: 18.9355 - mean_squared_error: 18.9355 - val_loss: 20.2998 - val_mean_squared_error: 20.2998\n",
            "Epoch 73/100\n",
            "51/51 [==============================] - 0s 7ms/step - loss: 18.9771 - mean_squared_error: 18.9771 - val_loss: 20.2989 - val_mean_squared_error: 20.2989\n",
            "Epoch 74/100\n",
            "51/51 [==============================] - 0s 8ms/step - loss: 18.9885 - mean_squared_error: 18.9885 - val_loss: 20.3064 - val_mean_squared_error: 20.3064\n",
            "Epoch 75/100\n",
            "51/51 [==============================] - 0s 8ms/step - loss: 18.9655 - mean_squared_error: 18.9655 - val_loss: 20.8474 - val_mean_squared_error: 20.8474\n",
            "Epoch 76/100\n",
            "51/51 [==============================] - 0s 7ms/step - loss: 18.8585 - mean_squared_error: 18.8585 - val_loss: 20.3178 - val_mean_squared_error: 20.3178\n",
            "Epoch 77/100\n",
            "51/51 [==============================] - 0s 7ms/step - loss: 18.8983 - mean_squared_error: 18.8983 - val_loss: 20.3416 - val_mean_squared_error: 20.3416\n",
            "Epoch 78/100\n",
            "51/51 [==============================] - 0s 7ms/step - loss: 18.9202 - mean_squared_error: 18.9202 - val_loss: 20.3280 - val_mean_squared_error: 20.3280\n",
            "Epoch 79/100\n",
            "51/51 [==============================] - 0s 7ms/step - loss: 18.9403 - mean_squared_error: 18.9403 - val_loss: 20.3540 - val_mean_squared_error: 20.3540\n",
            "Epoch 80/100\n",
            "51/51 [==============================] - 0s 7ms/step - loss: 18.9246 - mean_squared_error: 18.9246 - val_loss: 20.3755 - val_mean_squared_error: 20.3755\n",
            "Epoch 81/100\n",
            "51/51 [==============================] - 0s 7ms/step - loss: 19.2130 - mean_squared_error: 19.2130 - val_loss: 20.4317 - val_mean_squared_error: 20.4317\n",
            "Epoch 82/100\n",
            "51/51 [==============================] - 0s 9ms/step - loss: 19.0262 - mean_squared_error: 19.0262 - val_loss: 20.2997 - val_mean_squared_error: 20.2997\n",
            "Epoch 83/100\n",
            "51/51 [==============================] - 1s 11ms/step - loss: 18.9725 - mean_squared_error: 18.9725 - val_loss: 20.5029 - val_mean_squared_error: 20.5029\n",
            "Epoch 84/100\n",
            "51/51 [==============================] - 1s 11ms/step - loss: 18.9825 - mean_squared_error: 18.9825 - val_loss: 20.3682 - val_mean_squared_error: 20.3682\n",
            "Epoch 85/100\n",
            "51/51 [==============================] - 0s 9ms/step - loss: 18.8368 - mean_squared_error: 18.8368 - val_loss: 20.3135 - val_mean_squared_error: 20.3135\n",
            "Epoch 86/100\n",
            "51/51 [==============================] - 1s 10ms/step - loss: 19.1406 - mean_squared_error: 19.1406 - val_loss: 20.4016 - val_mean_squared_error: 20.4016\n",
            "Epoch 87/100\n",
            "51/51 [==============================] - 1s 11ms/step - loss: 18.9008 - mean_squared_error: 18.9008 - val_loss: 20.2995 - val_mean_squared_error: 20.2995\n",
            "Epoch 88/100\n",
            "51/51 [==============================] - 1s 11ms/step - loss: 18.9270 - mean_squared_error: 18.9270 - val_loss: 20.3004 - val_mean_squared_error: 20.3004\n",
            "Epoch 89/100\n",
            "51/51 [==============================] - 1s 11ms/step - loss: 18.9433 - mean_squared_error: 18.9433 - val_loss: 20.3186 - val_mean_squared_error: 20.3186\n",
            "Epoch 90/100\n",
            "51/51 [==============================] - 0s 8ms/step - loss: 18.9186 - mean_squared_error: 18.9186 - val_loss: 20.3707 - val_mean_squared_error: 20.3707\n",
            "Epoch 91/100\n",
            "51/51 [==============================] - 0s 8ms/step - loss: 18.9017 - mean_squared_error: 18.9017 - val_loss: 20.4181 - val_mean_squared_error: 20.4181\n",
            "Epoch 92/100\n",
            "51/51 [==============================] - 0s 7ms/step - loss: 19.1240 - mean_squared_error: 19.1240 - val_loss: 20.3519 - val_mean_squared_error: 20.3519\n",
            "Epoch 93/100\n",
            "51/51 [==============================] - 0s 8ms/step - loss: 18.8739 - mean_squared_error: 18.8739 - val_loss: 20.3038 - val_mean_squared_error: 20.3038\n",
            "Epoch 94/100\n",
            "51/51 [==============================] - 0s 8ms/step - loss: 18.9978 - mean_squared_error: 18.9978 - val_loss: 20.2982 - val_mean_squared_error: 20.2982\n",
            "Epoch 95/100\n",
            "51/51 [==============================] - 0s 8ms/step - loss: 19.2418 - mean_squared_error: 19.2418 - val_loss: 20.6123 - val_mean_squared_error: 20.6123\n",
            "Epoch 96/100\n",
            "51/51 [==============================] - 0s 8ms/step - loss: 18.9839 - mean_squared_error: 18.9839 - val_loss: 20.5729 - val_mean_squared_error: 20.5729\n",
            "Epoch 97/100\n",
            "51/51 [==============================] - 0s 8ms/step - loss: 18.8694 - mean_squared_error: 18.8694 - val_loss: 20.3892 - val_mean_squared_error: 20.3892\n",
            "Epoch 98/100\n",
            "51/51 [==============================] - 0s 8ms/step - loss: 18.9707 - mean_squared_error: 18.9707 - val_loss: 20.3795 - val_mean_squared_error: 20.3795\n",
            "Epoch 99/100\n",
            "51/51 [==============================] - 0s 7ms/step - loss: 18.9292 - mean_squared_error: 18.9292 - val_loss: 20.3322 - val_mean_squared_error: 20.3322\n",
            "Epoch 100/100\n",
            "51/51 [==============================] - 0s 8ms/step - loss: 19.0827 - mean_squared_error: 19.0827 - val_loss: 20.2980 - val_mean_squared_error: 20.2980\n",
            "9/9 [==============================] - 0s 3ms/step\n",
            "r2 score is == -0.02203276544871091\n",
            "mean_sqrd_error is== 25.31018056798351\n",
            "root_mean_squared error of is== 5.030922437086812\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import math\n",
        "import plotly.graph_objects as go\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, RepeatVector, TimeDistributed, Input\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import keras.backend as K\n",
        "from keras.callbacks import Callback\n",
        "import plotly\n",
        "import plotly.express as px # for data visualization\n",
        "import seaborn as sns\n",
        "\n",
        "generator_multiply = 2 #each input record will generate 100 random vectors from the latent space, given the mu and sigma generated by the encoder\n",
        "\n",
        "#from keras.utils import plot_model\n",
        "#import matplotlib.pyplot as plt\n",
        "\n",
        "#window1 = np.load(r'/content/drive/MyDrive/PHD/2021/multivariate_long_sequences_WINDOW-500.npy')\n",
        "#window2 = np.load(r'/content/drive/MyDrive/PHD/2021/multivariate_long_sequences_WINDOW-1000.npy')\n",
        "#window = np.concatenate((window1, window2), axis=0)\n",
        "#train_data = np.load(r'/content/drive/MyDrive/PHD/2021/multivariate_long_sequences-TRAIN.npy')\n",
        "#test_data = np.load(r'/content/drive/MyDrive/PHD/2021/multivariate_long_sequences-TEST.npy')\n",
        "\n",
        "\n",
        "\n",
        "#get data\n",
        "train_data = np.load(r'/content/drive/MyDrive/PHD/2024/multivariate_long_sequences-TRAIN-Daily-May2024.npy')\n",
        "\n",
        "\n",
        "#test_data = np.load(r'/content/drive/MyDrive/PHD/2024/multivariate_long_sequences-TEST_hourly.npy')\n",
        "#all_data = np.concatenate((train_data,test_data),axis=0)\n",
        "window_label = np.load(r'/content/drive/MyDrive/PHD/2024/multivariate_long_sequences_WINDOW-Daily-May2024.npy')\n",
        "n_seq = train_data.shape[0]\n",
        "window_size = train_data.shape[1]\n",
        "n_features = train_data.shape[2]\n",
        "\n",
        "\n",
        "plt.suptitle('Sub sequence plotting', fontsize='30')\n",
        "plt.xlabel('Time', fontsize ='20')\n",
        "plt.ylabel('Feature 1', fontsize='20')\n",
        "plt.plot(train_data[:,:,1])\n",
        "plt.show()\n",
        "\n",
        "#---------------------------VAE ------------------------------------------\n",
        "#from sklearn.model_selection import train_test_split\n",
        "#x_train, x_test, y_train, y_test = train_test_split(train_data, window_label, test_size = 0.2, random_state = 42)\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "encoder = keras.models.load_model(r'/content/drive/MyDrive/PHD/2024/VAE_SIMULATION/vae-encoder-saved-round4-latent5-dim256.model')\n",
        "decoder = keras.models.load_model(r'/content/drive/MyDrive/PHD/2024/VAE_SIMULATION/vae-decoder-saved-round4-latent5-dim256.model')\n",
        "\n",
        "X_train_encoded = encoder.predict(train_data)\n",
        "mu, logvar, z = X_train_encoded\n",
        "sigma = tf.exp(0.5 * logvar)\n",
        "batch = tf.shape(mu)[0]  #number of recors / batchs\n",
        "dim = tf.shape(mu)[1] #Ndimension of latent variable\n",
        "store = list()\n",
        "storetemp = list()\n",
        "\n",
        "\n",
        "#For each batch, iterate, get the generator_multipy number of latent vectors with same window_size.\n",
        "#For each z, concatenate z_mean, so it will become 100 dimensional vector\n",
        "\n",
        "for i in range(0,batch):\n",
        "  all_Z_i = tf.random.normal(shape=(generator_multiply,dim), mean = mu[i,:], stddev=sigma[i,:]) #all randorm vectors for this record i\n",
        "  X_train_decoded = decoder.predict(all_Z_i)\n",
        "  X_train_decoded = X_train_decoded.reshape((X_train_decoded.shape[0],window_size*n_features))\n",
        "  a = np.arange(generator_multiply)\n",
        "  a.fill(window_label[i])\n",
        "  c=np.concatenate(((X_train_decoded,a[:,None])),axis=1)\n",
        "  store.append(c)\n",
        "\n",
        "results1=np.concatenate(store,axis=0)\n",
        "np.save(r'/content/drive/MyDrive/PHD/2024/labelled_subsquence_data_daily',results1)\n",
        "\n",
        "\n",
        "#Regression fitting\n",
        "x=results1[:,:-1]\n",
        "y=results1[:,window_size*n_features]\n",
        "\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "#----- get a test set from this data, to avoid further wrangling----------------\n",
        "#x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.1, random_state = 42)\n",
        "\n",
        "\n",
        "maxval = x.shape[0]\n",
        "count_train = int(math.ceil(0.9*maxval))\n",
        "x_train = x[:count_train]\n",
        "x_test = x[count_train:]\n",
        "\n",
        "y_train = y[:count_train]\n",
        "y_test = y[count_train:]\n",
        "\n",
        "\n",
        "from sklearn.ensemble import IsolationForest\n",
        "iso = IsolationForest(contamination=0.1)\n",
        "yhat = iso.fit_predict(x_train)\n",
        "# select all rows that are not outliers\n",
        "mask = yhat != -1\n",
        "x_train, y_train = x_train[mask, :], y_train[mask]\n",
        "\n",
        "x_train = x_train.reshape((x_train.shape[0], window_size, n_features))  #DONT RUN IF MLP\n",
        "x_test = x_test.reshape((x_test.shape[0], window_size, n_features))    #DONT RUN IF MLP\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(x_train.shape[1],x_train.shape[2])))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "model.add(Dense(units = 64, activation = 'relu'))\n",
        "model.add(Dense(units = 32, activation = 'relu'))\n",
        "model.add(Dense(units = 16, activation = 'relu'))\n",
        "#model.add(Dense(units = 16, activation = 'relu'))\n",
        "model.add(Dense(units = 1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
        "\n",
        "\n",
        "#reduce_lr = tf.keras.callbacks.LearningRateScheduler(lambda x: 1e-3 * 0.90 ** x)\n",
        "es = keras.callbacks.EarlyStopping(patience=20, verbose=1, min_delta=0.0001, monitor='loss', mode='auto', restore_best_weights=True)\n",
        "n_epochs = 100\n",
        "#model.fit(x_train, y_train,epochs=5, batch_size=50, verbose=True)\n",
        "\n",
        "#y_pred = model.predict(x_test)\n",
        "\n",
        "#transform\n",
        "\n",
        "\n",
        "history=model.fit( x_train,y_train,\n",
        "                 epochs=n_epochs,\n",
        "                 batch_size=50,\n",
        "                   validation_split=0.1,\n",
        "                 callbacks=[es])\n",
        "\n",
        "y_train_pred = model.predict(x_train)\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "score_train= r2_score(y_train,y_train_pred)\n",
        "print(\"r2 score is ==\",score_train)\n",
        "score= r2_score(y_test,y_pred)\n",
        "print(\"r2 score is ==\",score)\n",
        "print(\"mean_sqrd_error is==\",mean_squared_error(y_test,y_pred))\n",
        "print(\"root_mean_squared error of is==\",np.sqrt(mean_squared_error(y_test,y_pred)))\n",
        "\n",
        "#plt.scatter(y_test,y_pred);\n",
        "#plt.xlabel('Actual');\n",
        "#plt.ylabel('Predicted');\n",
        "plt.plot(y_test[0:100], color = 'red', label = 'Real data')\n",
        "plt.plot(y_pred[0:100], color = 'blue', label = 'Predicted data')\n",
        "plt.title('Prediction')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "np.savetxt(r'/content/drive/MyDrive/PHD/2024/MLPOutput/preduber_2.csv',y_pred)\n",
        "np.savetxt(r'/content/drive/MyDrive/PHD/2024/MLPOutput/realuber_2.csv',y_test)\n",
        "print(\"MAE is==\",mean_absolute_error(y_test,y_pred))\n",
        "\n",
        "#---------------------------------Without VAE------------------------------------\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "\n",
        "maxval = train_data.shape[0]\n",
        "count_train = int(math.ceil(0.9*maxval))\n",
        "x_train = train_data[:count_train]\n",
        "x_test = train_data[count_train:]\n",
        "\n",
        "y_train = window_label[:count_train]\n",
        "y_test = window_label[count_train:]\n",
        "\n",
        "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1]*n_features))\n",
        "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1]*n_features))\n",
        "\n",
        "from sklearn.ensemble import IsolationForest\n",
        "iso = IsolationForest(contamination=0.1)\n",
        "yhat = iso.fit_predict(x_train)\n",
        "# select all rows that are not outliers\n",
        "mask = yhat != -1\n",
        "x_train, y_train = x_train[mask, :], y_train[mask]\n",
        "\n",
        "\n",
        "x_train = x_train.reshape((x_train.shape[0], window_size, n_features))  #DONT RUN IF MLP\n",
        "x_test = x_test.reshape((x_test.shape[0], window_size, n_features))    #DONT RUN IF MLP\n",
        "\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.models import Sequential\n",
        "##!pip uninstall tensorflow\n",
        "#!pip install tensorflow==2.12.0\n",
        "#from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "\n",
        "#reduce_lr = tf.keras.callbacks.LearningRateScheduler(lambda x: 1e-3 * 0.90 ** x)\n",
        "es = keras.callbacks.EarlyStopping(patience=10, verbose=1, min_delta=0.01, monitor='loss', mode='auto', restore_best_weights=True)\n",
        "n_epochs = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(512, input_shape=(x_train.shape[1],x_train.shape[2])))\n",
        "model.add(Dense(512, activation = 'relu'))\n",
        "model.add(Dense(units = 128, activation = 'relu'))\n",
        "model.add(Dense(units = 64, activation = 'relu'))\n",
        "model.add(Dense(units = 32, activation = 'relu'))\n",
        "model.add(Dense(units = 16, activation = 'relu'))\n",
        "model.add(Dense(units = 1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
        "\n",
        "history=model.fit( x_train,y_train,\n",
        "                 epochs=n_epochs,\n",
        "                 batch_size=32,\n",
        "                   validation_split=0.1,\n",
        "                 callbacks=[es])\n",
        "\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "\n",
        "score= r2_score(y_test,y_pred)\n",
        "print(\"r2 score is ==\",score)\n",
        "print(\"mean_sqrd_error is==\",mean_squared_error(y_test,y_pred))\n",
        "print(\"root_mean_squared error of is==\",np.sqrt(mean_squared_error(y_test,y_pred)))\n",
        "\n",
        "#plt.scatter(y_test,y_pred);\n",
        "#plt.xlabel('Actual');\n",
        "#plt.ylabel('Predicted');\n",
        "plt.plot(y_test[0:100], color = 'red', label = 'Real data')\n",
        "plt.plot(y_pred[0:100], color = 'blue', label = 'Predicted data')\n",
        "plt.title('Prediction')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "v_5iji919H_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8OtWHK--uG6W"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/supriyag123/PHD_Pub/blob/main/DGRNet%20STEP3-%20Daily%20Data.ipynb",
      "authorship_tag": "ABX9TyPxw3SGK+q8xVwrlytwlBOw",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}