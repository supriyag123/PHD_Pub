{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supriyag123/PHD_Pub/blob/main/AGENTIC-MODULE6-FaultPredictionAgent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "HoP7OuWNxlsJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72853631-d8e9-4642-dd9a-d55a63491f7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (901, 50, 12) (901,)\n",
            "Val shape: (226, 50, 12) (226,)\n",
            "Epoch 0: contrastive loss = 6.6508\n",
            "Epoch 2: contrastive loss = 6.3960\n",
            "Epoch 4: contrastive loss = 6.0980\n",
            "Epoch 6: contrastive loss = 5.7791\n",
            "Epoch 8: contrastive loss = 5.5074\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 164ms/step\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
            "\n",
            "=== Contrastive Transformer + kNN (Validation) ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9822    1.0000    0.9910       221\n",
            "           1     1.0000    0.2000    0.3333         5\n",
            "\n",
            "    accuracy                         0.9823       226\n",
            "   macro avg     0.9911    0.6000    0.6622       226\n",
            "weighted avg     0.9826    0.9823    0.9765       226\n",
            "\n",
            "[[221   0]\n",
            " [  4   1]]\n",
            "\n",
            "=== Contrastive Transformer + kNN (Holdout) ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9738    0.9906    0.9821      2435\n",
            "           1     0.0000    0.0000    0.0000        65\n",
            "\n",
            "    accuracy                         0.9648      2500\n",
            "   macro avg     0.4869    0.4953    0.4910      2500\n",
            "weighted avg     0.9484    0.9648    0.9566      2500\n",
            "\n",
            "[[2412   23]\n",
            " [  65    0]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# ============================================================\n",
        "# Fault Classification Pipeline\n",
        "# ============================================================\n",
        "\n",
        "############PASTE ADAPTIVE WINDOW HERE - so everything is in one file - later, we can import as a package#####################\n",
        "\n",
        "\n",
        "# ====== AdaptiveWindowAgent ======\n",
        "# =====================================================\n",
        "# AdaptiveWindowAgent (improved version)\n",
        "# =====================================================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle, os, logging, datetime as dt\n",
        "from collections import deque\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from statsmodels.tsa.vector_ar.var_model import VAR\n",
        "import keras\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class AdaptiveWindowAgent:\n",
        "    \"\"\"\n",
        "    Adaptive Window Agent:\n",
        "    - Predicts window size using MLP\n",
        "    - Evaluates forecast with VAR\n",
        "    - Monitors anomalies & drift with adaptive thresholds\n",
        "    - Outputs severity scores + suppresses redundant events\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, agent_id=\"adaptive_window_agent\",\n",
        "                 model_path=None, checkpoint_path=None):\n",
        "        self.agent_id = agent_id\n",
        "        self.model_path = model_path or \"/content/drive/MyDrive/PHD/2025/DGRNet-MLP-Versions/METROPM_MLP_model_Daily.keras\"\n",
        "        self.checkpoint_path = checkpoint_path\n",
        "\n",
        "        # Core model\n",
        "        self.model = None\n",
        "        self.transformer = StandardScaler()\n",
        "        self.transformer_fitted = False\n",
        "        self.is_model_loaded = False\n",
        "\n",
        "        # Histories\n",
        "        self.prediction_history = deque(maxlen=1000)\n",
        "        self.mse_history = deque(maxlen=200)\n",
        "        self.mae_history = deque(maxlen=200)\n",
        "\n",
        "        # Event detection params\n",
        "        self.drift_detection_window = 20\n",
        "        self.drift_threshold_mse = 1.5   # stricter\n",
        "        self.drift_threshold_mae = 1.5\n",
        "        self.consecutive_poor_predictions = 0\n",
        "        self.cooldown_counter = 0\n",
        "\n",
        "        # Stats\n",
        "        self.performance_stats = {\n",
        "            'total_predictions': 0,\n",
        "            'avg_mse': 0.0,\n",
        "            'avg_mae': 0.0,\n",
        "            'last_retrain_time': None,\n",
        "            'drift_events': 0,\n",
        "            'anomaly_events': 0,\n",
        "            'retraining_events': 0\n",
        "        }\n",
        "\n",
        "        # Retraining buffers\n",
        "        self.retraining_data = {\n",
        "            'x_buffer': deque(maxlen=10000),\n",
        "            'y_buffer': deque(maxlen=10000)\n",
        "        }\n",
        "\n",
        "        self.load_model()\n",
        "        print(f\"AdaptiveWindowAgent {self.agent_id} initialized\")\n",
        "\n",
        "    # ------------------- Model -------------------\n",
        "\n",
        "    def load_model(self):\n",
        "        try:\n",
        "            if os.path.exists(self.model_path):\n",
        "                self.model = keras.models.load_model(self.model_path)\n",
        "                self.is_model_loaded = True\n",
        "                print(f\"✅ Loaded MLP model from {self.model_path}\")\n",
        "\n",
        "                # Try to load transformer\n",
        "                transformer_path = self.model_path.replace('.keras', '_transformer.pkl')\n",
        "                if os.path.exists(transformer_path):\n",
        "                    with open(transformer_path, 'rb') as f:\n",
        "                        self.transformer = pickle.load(f)\n",
        "                    self.transformer_fitted = True\n",
        "                else:\n",
        "                    # Fit transformer from true window labels\n",
        "                    y_original = np.load(\n",
        "                        \"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/generated-data-true-window2.npy\"\n",
        "                    )\n",
        "                    self.transformer.fit(y_original.reshape(-1, 1))\n",
        "                    self.transformer_fitted = True\n",
        "                    with open(transformer_path, 'wb') as f:\n",
        "                        pickle.dump(self.transformer, f)\n",
        "                    print(\"⚠️ No transformer found, fitted a new one.\")\n",
        "            else:\n",
        "                print(f\"❌ Model not found at {self.model_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error loading model: {e}\")\n",
        "\n",
        "    # ------------------- Forecast Eval -------------------\n",
        "    def evaluate_forecast_performance(self, sequence_3d, predicted_window, n_future=1):\n",
        "        try:\n",
        "            df = pd.DataFrame(sequence_3d, columns=[f'V{i+1}' for i in range(sequence_3d.shape[1])])\n",
        "            df_train, df_test = df[:-n_future], df[-n_future:]\n",
        "\n",
        "            # Drop constant cols\n",
        "            constant_cols = [c for c in df_train.columns if df_train[c].nunique() <= 1]\n",
        "            df_train = df_train.drop(columns=constant_cols, errors=\"ignore\")\n",
        "            df_test = df_test.drop(columns=constant_cols, errors=\"ignore\")\n",
        "\n",
        "            # If too few variables, fall back immediately\n",
        "            if len(df_train.columns) < 1:\n",
        "                return self._persistence_forecast(df, df_test)\n",
        "\n",
        "            k = min(predicted_window, len(df_train) - 2)\n",
        "            if k < 1: k = 1\n",
        "\n",
        "            # Try VAR\n",
        "            try:\n",
        "                model = VAR(df_train)\n",
        "                model_fitted = model.fit(maxlags=k, trend=\"c\")\n",
        "                forecast_input = df_train.values[-model_fitted.k_ar:]\n",
        "                fc = model_fitted.forecast(y=forecast_input, steps=n_future)\n",
        "                df_forecast = pd.DataFrame(fc, index=df.index[-n_future:], columns=df_train.columns)\n",
        "\n",
        "                actual = df_test[df_forecast.columns].values.flatten()\n",
        "                predicted = df_forecast.values.flatten()\n",
        "\n",
        "            except Exception:\n",
        "                # Try AutoReg\n",
        "                try:\n",
        "                    from statsmodels.tsa.ar_model import AutoReg\n",
        "                    col = df_train.columns[0]\n",
        "                    model = AutoReg(df_train[col], lags=min(k, len(df_train)//2)).fit()\n",
        "                    predicted = model.predict(start=len(df_train), end=len(df_train)+n_future-1).values\n",
        "                    actual = df_test[col].values\n",
        "                except Exception:\n",
        "                    # Fallback to persistence\n",
        "                    return self._persistence_forecast(df, df_test)\n",
        "\n",
        "            mse = np.mean((actual - predicted) ** 2)\n",
        "            mae = np.mean(np.abs(actual - predicted))\n",
        "\n",
        "            # If forecast is unstable, fallback\n",
        "            if np.isnan(mse) or np.isnan(mae) or mse > 10 or mae > 10:\n",
        "                return self._persistence_forecast(df, df_test)\n",
        "\n",
        "            return {\n",
        "                'mse': float(mse),\n",
        "                'mae': float(mae),\n",
        "                'forecast_success': True,\n",
        "                'actual_values': actual.tolist(),\n",
        "                'predicted_values': predicted.tolist(),\n",
        "                'used_columns': list(df_test.columns)\n",
        "            }\n",
        "\n",
        "        except Exception:\n",
        "            return self._persistence_forecast(df, df_test)\n",
        "\n",
        "# ------------------- Persistence fallback -------------------\n",
        "\n",
        "    def _persistence_forecast(self, df, df_test):\n",
        "        \"\"\"Simple last-value-carried-forward forecast.\"\"\"\n",
        "        try:\n",
        "            last_values = df.iloc[-1].values\n",
        "            predicted = np.tile(last_values, (len(df_test), 1))\n",
        "            actual = df_test.values.flatten()\n",
        "\n",
        "            mse = np.mean((actual - predicted.flatten()) ** 2)\n",
        "            mae = np.mean(np.abs(actual - predicted.flatten()))\n",
        "\n",
        "            return {\n",
        "                'mse': float(mse),\n",
        "                'mae': float(mae),\n",
        "                'forecast_success': True,\n",
        "                'actual_values': actual.tolist(),\n",
        "                'predicted_values': predicted.flatten().tolist(),\n",
        "                'used_columns': list(df_test.columns),\n",
        "                'note': 'persistence_fallback'\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {'mse': 9999, 'mae': 9999, 'forecast_success': True, 'error': str(e), 'note': 'persistence_fallback_failed'}\n",
        "\n",
        "\n",
        "\n",
        "    # ------------------- Prediction -------------------\n",
        "\n",
        "    def predict_window_size(self, feature_vector, sequence_3d):\n",
        "        if not self.is_model_loaded:\n",
        "            return {'predicted_window': 20, 'error': \"Model not loaded\"}\n",
        "\n",
        "        try:\n",
        "            if feature_vector.ndim == 1:\n",
        "                feature_vector = feature_vector.reshape(1, -1)\n",
        "\n",
        "            pred_raw = self.model.predict(feature_vector, verbose=0)\n",
        "            if self.transformer_fitted:\n",
        "                predicted_window = int(round(self.transformer.inverse_transform(pred_raw)[0, 0]))\n",
        "            else:\n",
        "                predicted_window = int(round(pred_raw[0, 0]))\n",
        "\n",
        "            # Evaluate\n",
        "            forecast_metrics = self.evaluate_forecast_performance(sequence_3d, predicted_window, n_future=1)\n",
        "\n",
        "            if forecast_metrics.get(\"forecast_success\", False):\n",
        "                self.mse_history.append(forecast_metrics[\"mse\"])\n",
        "                self.mae_history.append(forecast_metrics[\"mae\"])\n",
        "                self.performance_stats['total_predictions'] += 1\n",
        "                self.performance_stats['avg_mse'] = np.mean(self.mse_history)\n",
        "                self.performance_stats['avg_mae'] = np.mean(self.mae_history)\n",
        "\n",
        "            # Event check\n",
        "            event, sev = self._check_for_event()\n",
        "\n",
        "            # Save history\n",
        "            record = {\n",
        "                'timestamp': dt.datetime.now(),\n",
        "                'predicted_window': predicted_window,\n",
        "                'forecast_metrics': forecast_metrics,\n",
        "                'event_type': event,\n",
        "                'severity': sev\n",
        "            }\n",
        "            self.prediction_history.append(record)\n",
        "\n",
        "            return {\n",
        "                'predicted_window': predicted_window,\n",
        "                'forecast_metrics': forecast_metrics,\n",
        "                'event_type': event,\n",
        "                'severity': sev,\n",
        "                'performance_stats': self.get_recent_performance()\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {'predicted_window': 20, 'error': str(e)}\n",
        "\n",
        "    # ------------------- Event Logic -------------------\n",
        "\n",
        "    def _check_for_event(self):\n",
        "        if len(self.mse_history) < self.drift_detection_window:\n",
        "            return None, 0.0\n",
        "\n",
        "        mse_vals = np.array(self.mse_history)[-self.drift_detection_window:]\n",
        "        mae_vals = np.array(self.mae_history)[-self.drift_detection_window:]\n",
        "\n",
        "        # Rolling stats\n",
        "        mean_mse, std_mse = np.mean(mse_vals), np.std(mse_vals) + 1e-8\n",
        "        last_mse = mse_vals[-1]\n",
        "\n",
        "        # Normalized error\n",
        "        norm_error = (last_mse - mean_mse) / std_mse\n",
        "\n",
        "        # Severity\n",
        "        anomaly_severity = max(0, norm_error)\n",
        "        drift_severity = max(0, (np.mean(mse_vals) / (np.median(mse_vals)+1e-5)) - 1)\n",
        "\n",
        "        # Check anomaly\n",
        "        if last_mse > mean_mse + 2.0 * std_mse:\n",
        "            self.performance_stats['anomaly_events'] += 1\n",
        "            return \"ANOMALY\", anomaly_severity\n",
        "\n",
        "        # Check drift (with persistence + cooldown)\n",
        "        ema_mse = 0.3*np.mean(mse_vals) + 0.7*np.median(mse_vals)\n",
        "        ema_mae = 0.3*np.mean(mae_vals) + 0.7*np.median(mae_vals)\n",
        "        mse_ratio = ema_mse / max(np.median(mse_vals), 1e-5)\n",
        "        mae_ratio = ema_mae / max(np.median(mae_vals), 1e-5)\n",
        "\n",
        "        if mse_ratio > self.drift_threshold_mse and mae_ratio > self.drift_threshold_mae:\n",
        "            self.consecutive_poor_predictions += 1\n",
        "            if self.consecutive_poor_predictions >= 5 and self.cooldown_counter == 0:\n",
        "                self.performance_stats['drift_events'] += 1\n",
        "                self.cooldown_counter = 10\n",
        "                return \"DRIFT\", drift_severity\n",
        "        else:\n",
        "            self.consecutive_poor_predictions = 0\n",
        "\n",
        "        if self.cooldown_counter > 0:\n",
        "            self.cooldown_counter -= 1\n",
        "\n",
        "        return None, 0.0\n",
        "\n",
        "    # ------------------- Helpers -------------------\n",
        "\n",
        "    def get_recent_performance(self):\n",
        "        successful_predictions = [\n",
        "            p for p in list(self.prediction_history)[-50:]\n",
        "            if p.get('forecast_metrics', {}).get('forecast_success', False)\n",
        "        ]\n",
        "        return {\n",
        "            'total_predictions': len(self.prediction_history),\n",
        "            'successful_predictions': len(successful_predictions),\n",
        "            'success_rate': len(successful_predictions) / max(len(self.prediction_history), 1),\n",
        "            'drift_events': self.performance_stats['drift_events'],\n",
        "            'anomaly_events': self.performance_stats['anomaly_events'],\n",
        "            'retraining_events': self.performance_stats['retraining_events'],\n",
        "            'recent_mse': float(np.mean(list(self.mse_history)[-10:])) if self.mse_history else 0,\n",
        "            'avg_mse': float(np.mean(self.mse_history)) if self.mse_history else 0,\n",
        "            'recent_mae': float(np.mean(list(self.mae_history)[-10:])) if self.mae_history else 0,\n",
        "            'avg_mae': float(np.mean(self.mae_history)) if self.mae_history else 0,\n",
        "            'transformer_fitted': self.transformer_fitted\n",
        "        }\n",
        "\n",
        "\n",
        "    def save_performance_state(self, filepath: str):\n",
        "        \"\"\"Save performance statistics + prediction history to JSON\"\"\"\n",
        "        try:\n",
        "            state = {\n",
        "                'performance_stats': self.performance_stats.copy(),\n",
        "                'prediction_history': list(self.prediction_history)[-100:],  # last 100\n",
        "                'mse_history': list(self.mse_history),\n",
        "                'mae_history': list(self.mae_history),\n",
        "                'transformer_fitted': self.transformer_fitted\n",
        "            }\n",
        "            import json\n",
        "            with open(filepath, 'w') as f:\n",
        "                json.dump(state, f, indent=2, default=str)\n",
        "            print(f\"✅ Performance state saved to {filepath}\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to save performance state: {e}\")\n",
        "\n",
        "\n",
        "#############################################\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import joblib\n",
        "\n",
        "# =============================================================================================================================\n",
        "# 1. Load Data - BASELINE MODELS----------------------------\n",
        "# ============================================================-======================================================================\n",
        "# Long subsequences (length=50) and labels\n",
        "long_sequences = np.load(\"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/multivariate_long_sequences-TRAIN-Daily-DIRECT-VAR.npy\")\n",
        "labels_detection = np.load(\"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/anomaly_labels_detection.npy\")  # fault labels\n",
        "labels_h1 = np.load(\"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/anomaly_labels_H1.npy\")  # optional predictive labels\n",
        "\n",
        "H = 1500  # size of holdout (future block)\n",
        "X_holdout = long_sequences[-H:]\n",
        "y_holdout = labels_detection[-H:]\n",
        "\n",
        "long_sequences = long_sequences[:-H]\n",
        "labels_detection = labels_detection[:-H]\n",
        "\n",
        "print(\"Data loaded:\", long_sequences.shape, labels_detection.shape)\n",
        "\n",
        "# ============================================================\n",
        "# 2. Baseline 1 Fixed Window Features (window=50, flattened)\n",
        "# ============================================================\n",
        "X_fixed = long_sequences.reshape(long_sequences.shape[0], -1)\n",
        "y = labels_detection  # detection labels (can switch to h1/h3/h12)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_fixed, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(\"Train/Test shapes:\", X_train.shape, X_test.shape)\n",
        "\n",
        "# Baseline-1: Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42, n_jobs=-1)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "print(\"\\n=== Baseline-1: Fixed Window Random Forest test data ===\")\n",
        "print(classification_report(y_test, y_pred_rf, digits=4))\n",
        "print(confusion_matrix(y_test, y_pred_rf))\n",
        "joblib.dump(rf, \"rf_fixed_window.pkl\")\n",
        "\n",
        "########## HOLDOUT\n",
        "X_fixed_h = X_holdout.reshape(X_holdout.shape[0], -1)\n",
        "y_predh_rf = rf.predict(X_fixed_h)\n",
        "\n",
        "print(\"\\n=== Baseline-1: Fixed Window Random Forest holdout data ===\")\n",
        "print(classification_report(y_holdout, y_predh_rf, digits=4))\n",
        "print(confusion_matrix(y_holdout, y_predh_rf))\n",
        "joblib.dump(rf, \"rf_fixed_window_holdout.pkl\")\n",
        "\n",
        "\n",
        "# ==========================================================================================================================\n",
        "# 3. Dynamic Window Features (using your AdaptiveWindowAgent)\n",
        "# =============================================================================================================================\n",
        "#from agents.adaptive_window_agent import AdaptiveWindowAgent\n",
        "\n",
        "window_agent = AdaptiveWindowAgent(\n",
        "    model_path=\"/content/drive/MyDrive/PHD/2025/DGRNet-MLP-Versions/METROPM_MLP_model_Daily.keras\"\n",
        ")\n",
        "\n",
        "##Load data again, fresh\n",
        "\n",
        "long_sequences = np.load(\"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/multivariate_long_sequences-TRAIN-Daily-DIRECT-VAR.npy\")\n",
        "labels_detection = np.load(\"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/anomaly_labels_detection.npy\")  # fault labels\n",
        "labels_h1 = np.load(\"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/anomaly_labels_H1.npy\")  # optional predictive labels\n",
        "\n",
        "\n",
        "\n",
        "# Generate features for each subsequence using predicted window - including holdout.\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Paths\n",
        "dyn_feat_path = \"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/dynamic_features.npy\"\n",
        "\n",
        "if os.path.exists(dyn_feat_path):\n",
        "    print(f\"✅ Loading existing dynamic features from {dyn_feat_path}\")\n",
        "    dynamic_features = np.load(dyn_feat_path, allow_pickle=True)\n",
        "else:\n",
        "    print(\"⚠️ Dynamic features not found. Generating now...\")\n",
        "\n",
        "    dynamic_features = []\n",
        "    for i, seq in enumerate(long_sequences):\n",
        "        try:\n",
        "            features = seq.flatten()\n",
        "            result = window_agent.predict_window_size(features, seq)\n",
        "            w = result.get(\"predicted_window\", 50)\n",
        "\n",
        "            # Extract last w timesteps from the long sequence\n",
        "            seq_dynamic = seq[-w:].flatten()\n",
        "            dynamic_features.append(seq_dynamic)\n",
        "\n",
        "            if (i + 1) % 100 == 0:\n",
        "                print(f\"Processed {i+1}/{len(long_sequences)} sequences...\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error on sequence {i}: {e}\")\n",
        "            # fallback: use fixed window\n",
        "            seq_dynamic = seq[-50:].flatten()\n",
        "            dynamic_features.append(seq_dynamic)\n",
        "\n",
        "    dynamic_features = np.array(dynamic_features, dtype=object)\n",
        "    np.save(dyn_feat_path, dynamic_features)\n",
        "    print(f\"✅ Saved dynamic features to {dyn_feat_path}\")\n",
        "\n",
        "print(\"Dynamic feature shape:\", np.shape(dynamic_features))\n",
        "\n",
        "# Pad to same length (use max window=50)\n",
        "X_dynamic = np.array([np.pad(f, (0, 50*seq.shape[1] - len(f))) for f in dynamic_features])\n",
        "H = 1500  # size of holdout (future block)\n",
        "X_holdout = X_dynamic[-H:]\n",
        "y_holdout = labels_detection[-H:]\n",
        "\n",
        "long_sequences = X_dynamic[:-H]\n",
        "labels_detection = labels_detection[:-H]\n",
        "\n",
        "X_train_dyn, X_test_dyn, y_train_dyn, y_test_dyn = train_test_split(long_sequences, labels_detection, test_size=0.2, random_state=42, stratify=labels_detection)\n",
        "\n",
        "# Baseline-2: Random Forest + dynamic window - test data\n",
        "rf = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42, n_jobs=-1)\n",
        "rf.fit(X_train_dyn, y_train_dyn)\n",
        "y_pred_rf_dyn = rf.predict(X_test_dyn)\n",
        "\n",
        "print(\"\\n=== Baseline-2: dynamic Window Random Forest ===\")\n",
        "print(classification_report(y_test_dyn, y_pred_rf_dyn, digits=4))\n",
        "print(confusion_matrix(y_test_dyn, y_pred_rf_dyn))\n",
        "joblib.dump(rf, \"rf_dynamic_window.pkl\")\n",
        "\n",
        "\n",
        "########## Baseline-2: Random Forest + dynamic window -HOLDOUT\n",
        "\n",
        "y_predh_rf_dyn_h = rf.predict(X_holdout)\n",
        "\n",
        "print(\"\\n=== Baseline-2: dynamic Window Random Forest holdout data ===\")\n",
        "print(classification_report(y_holdout, y_predh_rf_dyn_h, digits=4))\n",
        "print(confusion_matrix(y_holdout, y_predh_rf_dyn_h))\n",
        "joblib.dump(rf, \"rf_dynamic_window_holdout.pkl\")\n",
        "\n",
        "\n",
        "# Baseline-3: XGBoost dynamic\n",
        "xgb = XGBClassifier(\n",
        "    n_estimators=300, max_depth=8, learning_rate=0.05,\n",
        "    subsample=0.8, colsample_bytree=0.8,\n",
        "    random_state=42, n_jobs=-1\n",
        ")\n",
        "xgb.fit(X_train_dyn, y_train_dyn)\n",
        "y_pred_xgb = xgb.predict(X_test_dyn)\n",
        "\n",
        "print(\"\\n=== Baseline-3: Dynamic Window XGBoost ===\")\n",
        "print(classification_report(y_test_dyn, y_pred_xgb, digits=4))\n",
        "print(confusion_matrix(y_test_dyn, y_pred_xgb))\n",
        "joblib.dump(xgb, \"xgb_dynamic_window.pkl\")\n",
        "\n",
        "########## Baseline-3: XGBoost dynamic HOLDOUT\n",
        "\n",
        "y_predh_xgb_h = xgb.predict(X_holdout)\n",
        "\n",
        "print(\"\\n=== Baseline-3:Dynamic Window XGBoost holdout data ===\")\n",
        "print(classification_report(y_holdout, y_predh_xgb_h, digits=4))\n",
        "print(confusion_matrix(y_holdout, y_predh_xgb_h))\n",
        "joblib.dump(xgb, \"xgb_dynamic_window_holdout.pkl\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Ready for Next Steps\n",
        "# ============================================================\n",
        "print(\"\\n✅ Baseline models trained and evaluated.\")\n",
        "print(\"Next: add Transformer-based sequence classifier, then coordinator features.\")\n",
        "\n",
        "\n",
        "\n",
        "# ========================================================================================\n",
        "# SOTA: Transformer (PatchTST-style) Classifier\n",
        "# =======================================================================================\n",
        "# ========================================================================================\n",
        "# Contrastive Pretraining + Transformer Encoder + kNN Classifier\n",
        "# ========================================================================================\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "import tensorflow.keras.backend as K\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ====================\n",
        "# 1. Mixed Precision\n",
        "# ====================\n",
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy(\"mixed_float16\")\n",
        "\n",
        "# ====================\n",
        "# 2. Transformer Block\n",
        "# ====================\n",
        "def transformer_block(inputs, head_size=32, num_heads=2, ff_dim=64, dropout=0.2):\n",
        "    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads)(inputs, inputs)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x + inputs)\n",
        "\n",
        "    ff = layers.Dense(ff_dim, activation=\"relu\")(x)\n",
        "    ff = layers.Dropout(dropout)(ff)\n",
        "    ff = layers.Dense(inputs.shape[-1])(ff)\n",
        "    out = layers.LayerNormalization(epsilon=1e-6)(x + ff)\n",
        "    return out\n",
        "\n",
        "# ====================\n",
        "# 3. Transformer Encoder (for contrastive pretrain)\n",
        "# ====================\n",
        "def build_transformer_encoder(input_shape, projection_dim=64):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = transformer_block(inputs, 32, 2, 64, 0.2)\n",
        "    x = transformer_block(x, 32, 2, 64, 0.2)\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    outputs = layers.Dense(projection_dim, activation=None)(x)  # projection head\n",
        "    return keras.Model(inputs, outputs, name=\"transformer_encoder\")\n",
        "\n",
        "# ====================\n",
        "# 4. Contrastive Loss (NT-Xent style)\n",
        "# ====================\n",
        "def contrastive_loss(temperature=0.1):\n",
        "    def loss(y_true, y_pred):\n",
        "        y_pred = K.l2_normalize(y_pred, axis=-1)\n",
        "        batch_size = tf.shape(y_pred)[0] // 2\n",
        "        z1, z2 = tf.split(y_pred, 2, axis=0)\n",
        "        sim = tf.matmul(z1, z2, transpose_b=True) / temperature\n",
        "        labels = tf.range(batch_size)\n",
        "        loss1 = keras.losses.sparse_categorical_crossentropy(labels, sim, from_logits=True)\n",
        "        loss2 = keras.losses.sparse_categorical_crossentropy(labels, tf.transpose(sim), from_logits=True)\n",
        "        return tf.reduce_mean(loss1 + loss2)\n",
        "    return loss\n",
        "\n",
        "# ====================\n",
        "# 5. Augmentations for contrastive\n",
        "# ====================\n",
        "def augment_sequence(seq):\n",
        "    noise = np.random.normal(0, 0.01, seq.shape)\n",
        "    scale = np.random.uniform(0.9, 1.1)\n",
        "    mask = np.random.binomial(1, 0.95, seq.shape)\n",
        "    return seq * scale + noise * mask\n",
        "\n",
        "def create_contrastive_pairs(X, batch_size=128):\n",
        "    idx = np.random.choice(len(X), batch_size, replace=False)\n",
        "    x1 = np.array([augment_sequence(X[i]) for i in idx])\n",
        "    x2 = np.array([augment_sequence(X[i]) for i in idx])\n",
        "    return np.concatenate([x1, x2], axis=0)\n",
        "\n",
        "# ====================\n",
        "# 6. Load Data + Holdout\n",
        "# ====================\n",
        "long_sequences = np.load(\"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/multivariate_long_sequences-TRAIN-Daily-DIRECT-VAR.npy\")\n",
        "labels_detection = np.load(\"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/anomaly_labels_detection.npy\")\n",
        "\n",
        "H = 2000   # holdout size (future block, more faults)\n",
        "X_holdout = long_sequences[-H:]\n",
        "y_holdout = labels_detection[-H:]\n",
        "X = long_sequences[:-H]\n",
        "y = labels_detection[:-H]\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "print(\"Train:\", X_train.shape, y_train.shape)\n",
        "print(\"Val:\", X_val.shape, y_val.shape)\n",
        "print(\"Holdout:\", X_holdout.shape, y_holdout.shape)\n",
        "\n",
        "# class weights\n",
        "classes = np.unique(y_train)\n",
        "cw = compute_class_weight(\"balanced\", classes=classes, y=y_train)\n",
        "class_weight_dict = {i: w for i, w in zip(classes, cw)}\n",
        "print(\"Class weights:\", class_weight_dict)\n",
        "\n",
        "# ====================\n",
        "# 7. Contrastive Pretraining\n",
        "# ====================\n",
        "encoder = build_transformer_encoder(X_train.shape[1:], projection_dim=64)\n",
        "contrastive_model = keras.Model(encoder.input, encoder.output)\n",
        "contrastive_model.compile(optimizer=keras.optimizers.Adam(1e-3),\n",
        "                          loss=contrastive_loss(temperature=0.1))\n",
        "\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 128\n",
        "for epoch in range(EPOCHS):\n",
        "    X_batch = create_contrastive_pairs(X_train, batch_size=BATCH_SIZE//2)\n",
        "    y_dummy = np.zeros(len(X_batch))\n",
        "    loss = contrastive_model.train_on_batch(X_batch, y_dummy)\n",
        "    if epoch % 2 == 0:\n",
        "        print(f\"Epoch {epoch}: contrastive loss = {loss:.4f}\")\n",
        "\n",
        "# ====================\n",
        "# 8. Build Classifier (fine-tune encoder)\n",
        "# ====================\n",
        "encoder_backbone = build_transformer_encoder(X_train.shape[1:], projection_dim=64)\n",
        "encoder_backbone.set_weights(encoder.get_weights())  # transfer pretrained weights\n",
        "\n",
        "inputs = keras.Input(shape=X_train.shape[1:])\n",
        "x = encoder_backbone(inputs)\n",
        "x = layers.Dense(64, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\", dtype=\"float32\")(x)\n",
        "\n",
        "classifier = keras.Model(inputs, outputs)\n",
        "\n",
        "# focal loss\n",
        "def focal_loss(gamma=2., alpha=0.25):\n",
        "    def loss(y_true, y_pred):\n",
        "        y_true = tf.cast(y_true, tf.float32)\n",
        "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
        "        bce = K.binary_crossentropy(y_true, y_pred)\n",
        "        p_t = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
        "        alpha_factor = y_true * alpha + (1 - y_true) * (1 - alpha)\n",
        "        modulating = (1 - p_t) ** gamma\n",
        "        return K.mean(alpha_factor * modulating * bce, axis=-1)\n",
        "    return loss\n",
        "\n",
        "classifier.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-3),\n",
        "    loss=focal_loss(),\n",
        "    metrics=[\"accuracy\", Precision(name=\"precision\"), Recall(name=\"recall\")]\n",
        ")\n",
        "\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
        "lr_sched = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-6)\n",
        "\n",
        "history = classifier.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=30,\n",
        "    batch_size=128,\n",
        "    class_weight=class_weight_dict,\n",
        "    callbacks=[early_stop, lr_sched],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# ====================\n",
        "# 9. Evaluate on val\n",
        "# ====================\n",
        "y_probs = classifier.predict(X_val).flatten()\n",
        "y_pred = (y_probs >= 0.5).astype(int)\n",
        "print(\"\\n=== Contrastive Transformer (Validation) ===\")\n",
        "print(classification_report(y_val, y_pred, digits=4))\n",
        "print(confusion_matrix(y_val, y_pred))\n",
        "\n",
        "# ====================\n",
        "# 10. Evaluate on holdout\n",
        "# ====================\n",
        "y_probs = classifier.predict(X_holdout).flatten()\n",
        "y_pred = (y_probs >= 0.5).astype(int)\n",
        "print(\"\\n=== Contrastive Transformer (Holdout) ===\")\n",
        "print(classification_report(y_holdout, y_pred, digits=4))\n",
        "print(confusion_matrix(y_holdout, y_pred))\n",
        "#######################################################################################################\n",
        "#Validate with coordination agent###############################\n",
        "#######################################################################################################\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# --------------------------\n",
        "# 1. Validation Function\n",
        "# --------------------------\n",
        "def validate_with_coordinator(y_probs, y_true, coordinator_results, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Validate Transformer predictions against coordinator agent decisions.\n",
        "    \"\"\"\n",
        "    # Transformer raw predictions\n",
        "    y_pred_raw = (y_probs >= threshold).astype(int)\n",
        "\n",
        "    # Apply coordinator filter\n",
        "    y_pred_validated = []\n",
        "    for pred, coord in zip(y_pred_raw, coordinator_results):\n",
        "        coord_flag = coord[\"coordinator\"].get(\"final_anomaly\", False)\n",
        "        if pred == 1 and coord_flag:\n",
        "            y_pred_validated.append(1)   # confirmed\n",
        "        else:\n",
        "            y_pred_validated.append(0)   # suppress FP or keep 0\n",
        "\n",
        "    y_pred_validated = np.array(y_pred_validated)\n",
        "\n",
        "    # Reports\n",
        "    report_raw = classification_report(y_true, y_pred_raw, output_dict=True, zero_division=0)\n",
        "    report_validated = classification_report(y_true, y_pred_validated, output_dict=True, zero_division=0)\n",
        "\n",
        "    cm_raw = confusion_matrix(y_true, y_pred_raw)\n",
        "    cm_validated = confusion_matrix(y_true, y_pred_validated)\n",
        "\n",
        "    return {\n",
        "        \"report_raw\": report_raw,\n",
        "        \"report_validated\": report_validated,\n",
        "        \"confusion_matrix_raw\": cm_raw,\n",
        "        \"confusion_matrix_validated\": cm_validated,\n",
        "        \"raw_preds\": y_pred_raw,\n",
        "        \"validated_preds\": y_pred_validated\n",
        "    }\n",
        "\n",
        "# --------------------------\n",
        "# 2. Confusion Matrix Plot\n",
        "# --------------------------\n",
        "def plot_confusion_matrices(cm_raw, cm_validated, labels=[0,1]):\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "    sns.heatmap(cm_raw, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "                xticklabels=labels, yticklabels=labels, ax=axes[0])\n",
        "    axes[0].set_title(\"Transformer (Raw)\")\n",
        "    axes[0].set_xlabel(\"Predicted\")\n",
        "    axes[0].set_ylabel(\"True\")\n",
        "\n",
        "    sns.heatmap(cm_validated, annot=True, fmt=\"d\", cmap=\"Greens\",\n",
        "                xticklabels=labels, yticklabels=labels, ax=axes[1])\n",
        "    axes[1].set_title(\"Transformer + Coordinator\")\n",
        "    axes[1].set_xlabel(\"Predicted\")\n",
        "    axes[1].set_ylabel(\"True\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# --------------------------\n",
        "# 3. Run Coordinator on Test Set\n",
        "# --------------------------\n",
        "results = []\n",
        "coordinator_flags = []\n",
        "\n",
        "print(\"Running Coordinator over test set...\")\n",
        "\n",
        "for i, seq in enumerate(X_test_long):   # X_test_long must match X_val / y_val split\n",
        "    try:\n",
        "        features = seq.flatten()\n",
        "\n",
        "        master_out = master.process_system_input(seq)\n",
        "        window_out = window_agent.predict_window_size(features, seq)\n",
        "        final = coordinator.fuse(master_out, window_out)\n",
        "\n",
        "        results.append({\n",
        "            \"master\": master_out,\n",
        "            \"window\": window_out,\n",
        "            \"coordinator\": final\n",
        "        })\n",
        "\n",
        "        coordinator_flags.append(1 if final[\"final_anomaly\"] else 0)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Sample {i} failed: {e}\")\n",
        "        results.append({\"coordinator\": {\"final_anomaly\": False}})\n",
        "        coordinator_flags.append(0)\n",
        "\n",
        "coordinator_flags = np.array(coordinator_flags)\n",
        "print(f\"✅ Coordinator outputs generated: {coordinator_flags.shape}\")\n",
        "print(f\"Unique flags: {np.unique(coordinator_flags, return_counts=True)}\")\n",
        "\n",
        "# --------------------------\n",
        "# 4. Validate Predictions\n",
        "# --------------------------\n",
        "y_probs = model.predict(X_test_long).flatten()   # Transformer predictions\n",
        "y_true  = y_test                                # Ground truth fault labels\n",
        "\n",
        "validation_out = validate_with_coordinator(\n",
        "    y_probs=y_probs,\n",
        "    y_true=y_true,\n",
        "    coordinator_results=results,\n",
        "    threshold=0.5\n",
        ")\n",
        "\n",
        "print(\"\\n=== Transformer (Raw) ===\")\n",
        "print(classification_report(y_true, validation_out[\"raw_preds\"], digits=4))\n",
        "print(validation_out[\"confusion_matrix_raw\"])\n",
        "\n",
        "print(\"\\n=== Transformer + Coordinator (Validated) ===\")\n",
        "print(classification_report(y_true, validation_out[\"validated_preds\"], digits=4))\n",
        "print(validation_out[\"confusion_matrix_validated\"])\n",
        "\n",
        "# --------------------------\n",
        "# 5. Coordinator Impact Summary\n",
        "# --------------------------\n",
        "raw = validation_out[\"report_raw\"][\"1\"]\n",
        "val = validation_out[\"report_validated\"][\"1\"]\n",
        "\n",
        "print(\"\\n=== Coordinator Impact on Fault Class (1) ===\")\n",
        "print(f\"Precision: {raw['precision']:.3f} → {val['precision']:.3f}\")\n",
        "print(f\"Recall:    {raw['recall']:.3f} → {val['recall']:.3f}\")\n",
        "print(f\"F1-score:  {raw['f1-score']:.3f} → {val['f1-score']:.3f}\")\n",
        "\n",
        "# --------------------------\n",
        "# 6. Plot Confusion Matrices\n",
        "# --------------------------\n",
        "plot_confusion_matrices(\n",
        "    validation_out[\"confusion_matrix_raw\"],\n",
        "    validation_out[\"confusion_matrix_validated\"]\n",
        ")\n",
        "\n",
        "# ==========================================\n",
        "# 7. Overlay Plot: Transformer vs Coordinator vs Ground Truth\n",
        "# ==========================================\n",
        "def plot_timeline(y_true, raw_preds, validated_preds, coordinator_flags, max_samples=200):\n",
        "    \"\"\"\n",
        "    Visual timeline of ground truth faults, transformer predictions, and coordinator validated results.\n",
        "    \"\"\"\n",
        "    n = min(max_samples, len(y_true))\n",
        "    t = np.arange(n)\n",
        "\n",
        "    plt.figure(figsize=(14, 5))\n",
        "\n",
        "    # Ground truth faults\n",
        "    plt.plot(t, y_true[:n], label=\"Ground Truth\", color=\"black\", linewidth=2, alpha=0.7)\n",
        "\n",
        "    # Transformer raw predictions\n",
        "    plt.plot(t, raw_preds[:n], label=\"Transformer Raw\", color=\"red\", linestyle=\"--\", alpha=0.6)\n",
        "\n",
        "    # Coordinator validated predictions\n",
        "    plt.plot(t, validated_preds[:n], label=\"Validated (Transformer+Coordinator)\",\n",
        "             color=\"green\", linewidth=2, alpha=0.7)\n",
        "\n",
        "    # Coordinator anomaly flags only\n",
        "    plt.scatter(t, coordinator_flags[:n], label=\"Coordinator Final Anomaly\",\n",
        "                marker=\"x\", color=\"blue\", alpha=0.8)\n",
        "\n",
        "    plt.xlabel(\"Sample Index\")\n",
        "    plt.ylabel(\"Fault / Anomaly Flag\")\n",
        "    plt.title(\"Timeline: Transformer vs Coordinator vs Ground Truth\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n",
        "\n",
        "# ==========================================\n",
        "# Call Timeline Plot\n",
        "# ==========================================\n",
        "plot_timeline(\n",
        "    y_true=y_true,\n",
        "    raw_preds=validation_out[\"raw_preds\"],\n",
        "    validated_preds=validation_out[\"validated_preds\"],\n",
        "    coordinator_flags=coordinator_flags,\n",
        "    max_samples=200\n",
        ")\n",
        "\n",
        "# ==========================================\n",
        "# 8. Quantify False Positive Suppression\n",
        "# ==========================================\n",
        "def analyze_false_positive_suppression(y_true, raw_preds, validated_preds):\n",
        "    \"\"\"\n",
        "    Compare raw vs validated predictions to quantify false positive suppression.\n",
        "    \"\"\"\n",
        "    # False positives = predicted 1, but true = 0\n",
        "    fp_raw = np.sum((raw_preds == 1) & (y_true == 0))\n",
        "    fp_validated = np.sum((validated_preds == 1) & (y_true == 0))\n",
        "\n",
        "    # False negatives = predicted 0, but true = 1\n",
        "    fn_raw = np.sum((raw_preds == 0) & (y_true == 1))\n",
        "    fn_validated = np.sum((validated_preds == 0) & (y_true == 1))\n",
        "\n",
        "    suppression_rate = (fp_raw - fp_validated) / max(fp_raw, 1)\n",
        "\n",
        "    return {\n",
        "        \"false_positives_raw\": int(fp_raw),\n",
        "        \"false_positives_validated\": int(fp_validated),\n",
        "        \"false_negatives_raw\": int(fn_raw),\n",
        "        \"false_negatives_validated\": int(fn_validated),\n",
        "        \"suppression_rate\": suppression_rate\n",
        "    }\n",
        "\n",
        "# Run analysis\n",
        "fp_analysis = analyze_false_positive_suppression(\n",
        "    y_true=y_true,\n",
        "    raw_preds=validation_out[\"raw_preds\"],\n",
        "    validated_preds=validation_out[\"validated_preds\"]\n",
        ")\n",
        "\n",
        "print(\"\\n=== False Positive Suppression Analysis ===\")\n",
        "print(f\"False Positives (Raw Transformer): {fp_analysis['false_positives_raw']}\")\n",
        "print(f\"False Positives (Validated): {fp_analysis['false_positives_validated']}\")\n",
        "print(f\"False Negatives (Raw Transformer): {fp_analysis['false_negatives_raw']}\")\n",
        "print(f\"False Negatives (Validated): {fp_analysis['false_negatives_validated']}\")\n",
        "print(f\"Suppression Rate: {fp_analysis['suppression_rate']*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "v_5iji919H_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8OtWHK--uG6W"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "https://github.com/supriyag123/PHD_Pub/blob/main/AGENTIC-MODULE6-FaultPredictionAgent.ipynb",
      "authorship_tag": "ABX9TyPEBZCprfjML02vcUL+u1NK",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}