{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supriyag123/PHD_Pub/blob/main/AGENTIC-MODULE1-METROPM-LARGE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "T-BJGPTX7XS5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "outputId": "b4826e94-c5f3-423e-d608-91d7eaca0b48"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     Unnamed: 0       TP2       TP3        H1  DV_pressure  \\\n",
              "datetime                                                                     \n",
              "2020-02-01 00:00:00      1815.0  0.502011  8.881566  8.364978    -0.022951   \n",
              "2020-02-01 01:00:00      5450.0  0.241003  8.984066  8.720182    -0.023030   \n",
              "2020-02-01 02:00:00      9080.0  0.485587  9.014171  8.500303    -0.023427   \n",
              "2020-02-01 03:00:00     12710.0  0.492347  8.981570  8.443317    -0.023559   \n",
              "2020-02-01 04:00:00     16345.0  0.508242  8.996973  8.458462    -0.023797   \n",
              "\n",
              "                     Reservoirs  Oil_temperature  Motor_current      COMP  \\\n",
              "datetime                                                                    \n",
              "2020-02-01 00:00:00    8.881995        51.893750       0.897370  0.942308   \n",
              "2020-02-01 01:00:00    8.984551        51.912397       1.009373  0.972452   \n",
              "2020-02-01 02:00:00    9.014320        51.719008       1.281343  0.944904   \n",
              "2020-02-01 03:00:00    8.982066        51.396763       1.286625  0.942149   \n",
              "2020-02-01 04:00:00    8.997637        52.172802       1.265721  0.942308   \n",
              "\n",
              "                     DV_eletric    Towers       MPG  LPS  \n",
              "datetime                                                  \n",
              "2020-02-01 00:00:00    0.057692  0.972527  0.942308  0.0  \n",
              "2020-02-01 01:00:00    0.027548  0.983471  0.972452  0.0  \n",
              "2020-02-01 02:00:00    0.055096  0.969697  0.944904  0.0  \n",
              "2020-02-01 03:00:00    0.057851  0.975207  0.942149  0.0  \n",
              "2020-02-01 04:00:00    0.057692  0.972527  0.942308  0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-546a4ca0-c569-4797-9978-02c159588988\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>TP2</th>\n",
              "      <th>TP3</th>\n",
              "      <th>H1</th>\n",
              "      <th>DV_pressure</th>\n",
              "      <th>Reservoirs</th>\n",
              "      <th>Oil_temperature</th>\n",
              "      <th>Motor_current</th>\n",
              "      <th>COMP</th>\n",
              "      <th>DV_eletric</th>\n",
              "      <th>Towers</th>\n",
              "      <th>MPG</th>\n",
              "      <th>LPS</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>datetime</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2020-02-01 00:00:00</th>\n",
              "      <td>1815.0</td>\n",
              "      <td>0.502011</td>\n",
              "      <td>8.881566</td>\n",
              "      <td>8.364978</td>\n",
              "      <td>-0.022951</td>\n",
              "      <td>8.881995</td>\n",
              "      <td>51.893750</td>\n",
              "      <td>0.897370</td>\n",
              "      <td>0.942308</td>\n",
              "      <td>0.057692</td>\n",
              "      <td>0.972527</td>\n",
              "      <td>0.942308</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-02-01 01:00:00</th>\n",
              "      <td>5450.0</td>\n",
              "      <td>0.241003</td>\n",
              "      <td>8.984066</td>\n",
              "      <td>8.720182</td>\n",
              "      <td>-0.023030</td>\n",
              "      <td>8.984551</td>\n",
              "      <td>51.912397</td>\n",
              "      <td>1.009373</td>\n",
              "      <td>0.972452</td>\n",
              "      <td>0.027548</td>\n",
              "      <td>0.983471</td>\n",
              "      <td>0.972452</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-02-01 02:00:00</th>\n",
              "      <td>9080.0</td>\n",
              "      <td>0.485587</td>\n",
              "      <td>9.014171</td>\n",
              "      <td>8.500303</td>\n",
              "      <td>-0.023427</td>\n",
              "      <td>9.014320</td>\n",
              "      <td>51.719008</td>\n",
              "      <td>1.281343</td>\n",
              "      <td>0.944904</td>\n",
              "      <td>0.055096</td>\n",
              "      <td>0.969697</td>\n",
              "      <td>0.944904</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-02-01 03:00:00</th>\n",
              "      <td>12710.0</td>\n",
              "      <td>0.492347</td>\n",
              "      <td>8.981570</td>\n",
              "      <td>8.443317</td>\n",
              "      <td>-0.023559</td>\n",
              "      <td>8.982066</td>\n",
              "      <td>51.396763</td>\n",
              "      <td>1.286625</td>\n",
              "      <td>0.942149</td>\n",
              "      <td>0.057851</td>\n",
              "      <td>0.975207</td>\n",
              "      <td>0.942149</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-02-01 04:00:00</th>\n",
              "      <td>16345.0</td>\n",
              "      <td>0.508242</td>\n",
              "      <td>8.996973</td>\n",
              "      <td>8.458462</td>\n",
              "      <td>-0.023797</td>\n",
              "      <td>8.997637</td>\n",
              "      <td>52.172802</td>\n",
              "      <td>1.265721</td>\n",
              "      <td>0.942308</td>\n",
              "      <td>0.057692</td>\n",
              "      <td>0.972527</td>\n",
              "      <td>0.942308</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-546a4ca0-c569-4797-9978-02c159588988')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-546a4ca0-c569-4797-9978-02c159588988 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-546a4ca0-c569-4797-9978-02c159588988');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b1c8a5b3-d7dc-424a-8376-395f39d0770e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b1c8a5b3-d7dc-424a-8376-395f39d0770e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b1c8a5b3-d7dc-424a-8376-395f39d0770e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "daily_df",
              "summary": "{\n  \"name\": \"daily_df\",\n  \"rows\": 5116,\n  \"fields\": [\n    {\n      \"column\": \"datetime\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2020-02-01 00:00:00\",\n        \"max\": \"2020-09-01 03:00:00\",\n        \"num_unique_values\": 5116,\n        \"samples\": [\n          \"2020-02-23 02:00:00\",\n          \"2020-08-27 10:00:00\",\n          \"2020-08-22 13:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4338586.158400382,\n        \"min\": 1815.0,\n        \"max\": 15167660.0,\n        \"num_unique_values\": 4416,\n        \"samples\": [\n          5630545.0,\n          5059940.0,\n          13667780.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TP2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.8453899010638455,\n        \"min\": -0.0199999999999995,\n        \"max\": 9.476038567493113,\n        \"num_unique_values\": 4251,\n        \"samples\": [\n          0.6395537190082654,\n          1.6152231404958683,\n          0.9938512396694219\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TP3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7863891967072474,\n        \"min\": 1.6597333333333333,\n        \"max\": 10.14,\n        \"num_unique_values\": 4174,\n        \"samples\": [\n          9.158391184573002,\n          8.85163085399449,\n          8.9412782369146\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"H1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.28020024719362,\n        \"min\": -0.014137931034481983,\n        \"max\": 10.144,\n        \"num_unique_values\": 4232,\n        \"samples\": [\n          8.102962121212121,\n          8.130473829201103,\n          8.388956043956044\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DV_pressure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.33199656937196415,\n        \"min\": -0.029146198830409947,\n        \"max\": 2.3524022038567494,\n        \"num_unique_values\": 4212,\n        \"samples\": [\n          -0.0158898071625335,\n          -0.004032967032965718,\n          -0.019823691460055682\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Reservoirs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7869948145318298,\n        \"min\": 1.6558000000000002,\n        \"max\": 10.138,\n        \"num_unique_values\": 4180,\n        \"samples\": [\n          9.145867768595041,\n          9.072567493112947,\n          9.090650137741047\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Oil_temperature\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.009092813915554,\n        \"min\": 23.03846153846154,\n        \"max\": 87.60730027548209,\n        \"num_unique_values\": 4237,\n        \"samples\": [\n          67.074173553719,\n          60.971831955922866,\n          64.31425619834711\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Motor_current\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.232117425734574,\n        \"min\": 0.02187908496732006,\n        \"max\": 5.859649725274725,\n        \"num_unique_values\": 4250,\n        \"samples\": [\n          1.3401101928374652,\n          2.9224449035812676,\n          1.3819696969696968\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"COMP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2522031734012151,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 600,\n        \"samples\": [\n          0.8264462809917356,\n          0.8289473684210527,\n          0.8794117647058823\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DV_eletric\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2505135249755203,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 594,\n        \"samples\": [\n          0.04013377926421405,\n          0.07106598984771574,\n          0.875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Towers\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.124939765670063,\n        \"min\": 0.25,\n        \"max\": 1.0,\n        \"num_unique_values\": 552,\n        \"samples\": [\n          0.9414634146341463,\n          0.9544159544159544,\n          0.5041322314049587\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MPG\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2587446736924417,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 596,\n        \"samples\": [\n          0.9226519337016574,\n          0.5403899721448467,\n          0.8958333333333334\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LPS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14931679261629138,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 125,\n        \"samples\": [\n          0.0521978021978022,\n          0.044444444444444446,\n          0.27184466019417475\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "!pip install statsmodels --upgrade\n",
        "!pip install -U lingam\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import math\n",
        "import plotly.graph_objects as go\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, RepeatVector, TimeDistributed, Input\n",
        "from keras.models import Model\n",
        "from statsmodels.tsa.api import VAR\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.tools.eval_measures import rmse, aic\n",
        "import ast\n",
        "from statsmodels.tsa.ar_model import AutoReg\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from matplotlib import pyplot\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import linear_model\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from numpy import arange\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from statsmodels.tsa.stattools import grangercausalitytests\n",
        "from importlib.metadata import version\n",
        "\n",
        "#MetroPT dataset: https://archive.ics.uci.edu/dataset/791/metropt+3+dataset\n",
        "\n",
        "\n",
        "df=pd.read_csv(r'/content/drive/MyDrive/PHD/metropt+3+dataset (1).zip (Unzipped Files)/MetroPT3(AirCompressor).csv', parse_dates={'datetime':[1]}, index_col=['datetime'])\n",
        "df.head()\n",
        "df.drop(['Pressure_switch','Caudal_impulses','Oil_level'], axis=1, inplace=True) #remove columns\n",
        "\n",
        "\n",
        "\n",
        "##########Based on analyses we see following features can be removed for various reasons###################################################\n",
        "#########-------------DV Pressure, Oil level, Caudal impulses, pressure switch, MPG, H1, Oil temp.\n",
        "#############------------------- we also exclude data before April 2020 as some features have no values before this.\n",
        "\n",
        "\n",
        "#df = df[['Global_active_power','Global_reactive_power','Global_intensity']]\n",
        "#Imputing NULL\n",
        "df = df.replace('?', np.nan)\n",
        "df.isnull().sum()\n",
        "\n",
        "\n",
        "\n",
        "def fill_missing(values):\n",
        "    one_day = 24*6\n",
        "    for row in range(df.shape[0]):\n",
        "        for col in range(df.shape[1]):\n",
        "            if np.isnan(values[row][col]):\n",
        "                values[row,col] = values[row-one_day,col]\n",
        "df = df.astype('float32')\n",
        "fill_missing(df.values)\n",
        "df.isnull().sum()\n",
        "\n",
        "\n",
        "# --------------------------- to perform granger causality on the entire time series history------------------------------to reduce computation--------------####\n",
        "daily_df = df.resample('1H').mean().backfill()\n",
        "daily_df.head()\n",
        "\n",
        "\n",
        "\n",
        "#daily_df = daily_df.dropna(how='any')\n",
        "\n",
        "ts_len = daily_df.shape[0]\n",
        "\n",
        "#Now convert index to column\n",
        "daily_df['datetime']=daily_df.index\n",
        "\n",
        "#take data from April 2020, as March is mostly constant for many variables\n",
        "daily_df  = daily_df.loc[(daily_df['datetime'] >= '2020-04-01')]\n",
        "\n",
        "#VISUALISE THE TIMESERIES\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=daily_df['datetime'], y=daily_df['Reservoirs'], name='CO(GT)'))\n",
        "\n",
        "fig.update_layout(showlegend=True, title='Air Quality')\n",
        "fig.show()\n",
        "\n",
        "#remove index column unless required.\n",
        "\n",
        "daily_df.drop(daily_df.columns[0], axis=1, inplace=True) #remove ID column\n",
        "daily_df.drop(daily_df.columns[12], axis=1, inplace=True) #remove datetime\n",
        "#daily_df.drop(daily_df.columns[2], axis=1, inplace=True) #dropped Voltage\n",
        "#Scaling the values\n",
        "\n",
        "whole_series  = daily_df\n",
        "\n",
        "scalers={}\n",
        "for i in daily_df.columns:\n",
        "    scaler = MinMaxScaler(feature_range=(-1,1))\n",
        "    s_s = scaler.fit_transform(whole_series[i].values.reshape(-1,1))\n",
        "    s_s=np.reshape(s_s,len(s_s))\n",
        "    scalers['scaler_'+ i] = scaler\n",
        "    whole_series[i]=s_s\n",
        "\n",
        "# ================================================================================\n",
        "# ANOMALY LABELING ADDITION - NEW SECTION\n",
        "# ================================================================================\n",
        "\n",
        "def create_detection_labels(df):\n",
        "    \"\"\"\n",
        "    Detection labels - mark periods when failures are currently happening\n",
        "    \"\"\"\n",
        "    print(\"Creating DETECTION labels (current failures)...\")\n",
        "\n",
        "    labels = np.zeros(len(df))\n",
        "    failure_periods = [\n",
        "        ('2020-04-18 00:00:00', '2020-04-18 23:59:59', 'Air_leak_1'),\n",
        "        ('2020-05-29 23:30:00', '2020-05-30 06:00:00', 'Air_leak_2'),\n",
        "        ('2020-06-05 10:00:00', '2020-06-07 14:30:00', 'Air_leak_3'),\n",
        "        ('2020-07-15 14:30:00', '2020-07-15 19:00:00', 'Air_leak_4')\n",
        "    ]\n",
        "\n",
        "    for start_time, end_time, failure_type in failure_periods:\n",
        "        failure_mask = (df.index >= start_time) & (df.index <= end_time)\n",
        "        failure_indices = np.where(failure_mask)[0]\n",
        "        if len(failure_indices) > 0:\n",
        "            labels[failure_indices] = 1\n",
        "            print(f\"  {failure_type}: {len(failure_indices)} points\")\n",
        "\n",
        "    failure_count = np.sum(labels)\n",
        "    print(f\"Detection labels: {failure_count}/{len(labels)} ({failure_count/len(labels)*100:.2f}%)\")\n",
        "    return labels.astype(int)\n",
        "\n",
        "def create_prediction_labels(df, horizons=[1, 3, 12]):\n",
        "    \"\"\"\n",
        "    Prediction labels - mark periods that should trigger early warnings\n",
        "    \"\"\"\n",
        "    print(\"Creating PREDICTION labels (early warnings)...\")\n",
        "\n",
        "    failure_periods = [\n",
        "        ('2020-04-18 00:00:00', '2020-04-18 23:59:59', 'Air_leak_1'),\n",
        "        ('2020-05-29 23:30:00', '2020-05-30 06:00:00', 'Air_leak_2'),\n",
        "        ('2020-06-05 10:00:00', '2020-06-07 14:30:00', 'Air_leak_3'),\n",
        "        ('2020-07-15 14:30:00', '2020-07-15 19:00:00', 'Air_leak_4')\n",
        "    ]\n",
        "\n",
        "    prediction_labels = {}\n",
        "\n",
        "    for H in horizons:\n",
        "        print(f\"  Creating H{H} (warn {H}h before failure)...\")\n",
        "        labels = np.zeros(len(df))\n",
        "\n",
        "        for start_time, end_time, failure_type in failure_periods:\n",
        "            failure_start = pd.to_datetime(start_time)\n",
        "            warning_start = failure_start - pd.Timedelta(hours=H)\n",
        "\n",
        "            warning_mask = (df.index >= warning_start) & (df.index < start_time)\n",
        "            warning_indices = np.where(warning_mask)[0]\n",
        "\n",
        "            if len(warning_indices) > 0:\n",
        "                labels[warning_indices] = 1\n",
        "\n",
        "        warning_count = np.sum(labels)\n",
        "        prediction_labels[f'H{H}'] = labels.astype(int)\n",
        "        print(f\"    H{H}: {warning_count}/{len(labels)} ({warning_count/len(labels)*100:.2f}%)\")\n",
        "\n",
        "    return prediction_labels\n",
        "\n",
        "# Create anomaly labels before continuing with original code\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"CREATING ANOMALY LABELS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Create labels using the datetime index from daily_df before it gets modified\n",
        "temp_df_with_datetime = daily_df.copy()\n",
        "temp_df_with_datetime['datetime'] = temp_df_with_datetime.index  # Add datetime back temporarily\n",
        "\n",
        "detection_labels = create_detection_labels(temp_df_with_datetime)\n",
        "prediction_labels = create_prediction_labels(temp_df_with_datetime, [1, 3, 12])\n",
        "\n",
        "print(\"Anomaly labeling completed!\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# ================================================================================\n",
        "# CONTINUE WITH ORIGINAL CODE\n",
        "# ================================================================================\n",
        "\n",
        "def augmented_dickey_fuller_statistics(time_series):\n",
        "  result = adfuller(time_series.values)\n",
        "  ADF_Statistic = result[0]\n",
        "  p_value = result[1]\n",
        "  Critical_values_1 = result[4][\"1%\"]\n",
        "  Critical_values_5 = result[4][\"5%\"]\n",
        "  Critical_values_10 = result[4][\"10%\"]\n",
        "\n",
        "  # We take that p-value should be less than 0.05 and ADF_statistic should be less than critical value at 5% confidence Critical_value_5\n",
        "  if p_value <0.05 and ADF_Statistic < Critical_values_5:\n",
        "    return \"stationary\"\n",
        "  else:\n",
        "    return \"non-stationary\"\n",
        "\n",
        "for i in range(0,whole_series.shape[1]):\n",
        "  print('Augmented Dickey-Fuller Test Result:', whole_series.iloc[:,i].name)\n",
        "  x= augmented_dickey_fuller_statistics(whole_series.iloc[:,i])\n",
        "  print(x)\n",
        "  #if any of the x is \"non-stationary\": df_difference = whole_series.diff() -- and then deal with df_difference\n",
        "\n",
        "#Granger Causality\n",
        "\n",
        "max_lag_GC = 30\n",
        "\n",
        "#https://phdinds-aim.github.io/time_series_handbook/04_GrangerCausality/04_GrangerCausality.html\n",
        "\n",
        "def granger_causation_matrix(data, variables, p, test = 'ssr_chi2test', verbose=False):\n",
        "    \"\"\"Check Granger Causality of all possible combinations of the time series.\n",
        "    The rows are the response variables, columns are predictors. The values in the table\n",
        "    are the P-Values. P-Values lesser than the significance level (0.05), implies\n",
        "    the Null Hypothesis that the coefficients of the corresponding past values is\n",
        "    zero, that is, the X does not cause Y can be rejected.\n",
        "\n",
        "    data      : pandas dataframe containing the time series variables\n",
        "    variables : list containing names of the time series variables.\n",
        "    \"\"\"\n",
        "    df = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)\n",
        "    for c in df.columns:\n",
        "        for r in df.index:\n",
        "            test_result = grangercausalitytests(data[[r, c]], p, verbose=False)\n",
        "            p_values = [round(test_result[i+1][0][test][1],4) for i in range(p)]\n",
        "            if verbose: print(f'Y = {r}, X = {c}, P Values = {p_values}')\n",
        "            min_p_value = np.min(p_values)\n",
        "            df.loc[r, c] = min_p_value\n",
        "    df.columns = [var + '_x' for var in variables]\n",
        "    df.index = [var + '_y' for var in variables]\n",
        "    return df\n",
        "\n",
        "granger_causation_matrix(whole_series, whole_series.columns, max_lag_GC)\n",
        "\n",
        "###############Recall: If a given p-value is < significance level (0.05), then, the corresponding X series (column) causes the Y (row).\n",
        "\n",
        "#### GRANGER CAUSALITY PROVES that following features are very weakly related with most (almost no ausal effect) hence will be removed. Oil_level was dropped. Two more features were dropped for same reason.\n",
        "\n",
        "\n",
        "#Better to run GC again as 3 columns have been removed\n",
        "\n",
        "def extract_windows_vectorized(array, large_seq_size):\n",
        "    start = 0\n",
        "    last_index = len(array)-1\n",
        "    max_time =  last_index - large_seq_size +1  ##last index upto which sliding windoe begining can go\n",
        "\n",
        "    sub_windows = (\n",
        "        start +\n",
        "        # expand_dims are used to convert a 1D array to 2D array.\n",
        "        np.expand_dims(np.arange(large_seq_size), 0) +\n",
        "        np.expand_dims(np.arange(max_time + 1), 0).T\n",
        "    ).astype(int)\n",
        "\n",
        "    return array[sub_windows]\n",
        "\n",
        "\n",
        "#DEFINE K - User parameter - length of the LONG time series sequence.\n",
        "K = 50 #taking 1 day of hourly data\n",
        "\n",
        "large_seq_size = K\n",
        "n_features = whole_series.shape[1]\n",
        "\n",
        "Long = extract_windows_vectorized(whole_series.values,large_seq_size)\n",
        "\n",
        "Long_train = Long\n",
        "\n",
        "\n",
        "#First, define a function that can generate small subsequences for all the large K sequences\n",
        "\n",
        "def generate_small_seq(series, n_past, n_future):\n",
        "  #\n",
        "  # n_past ==> no of past observations -- OR -- sliding window\n",
        "  #\n",
        "  # n_future ==> no of future observations -- prediction variable y\n",
        "  #\n",
        "  X, y = list(), list()\n",
        "  for window_start in range(len(series)):\n",
        "    past_end = window_start + n_past\n",
        "    future_end = past_end + n_future\n",
        "    if future_end > len(series):\n",
        "      break\n",
        "    # slicing the past and future parts of the window\n",
        "    past, future = series[window_start:past_end, :], series[past_end:future_end, :]\n",
        "    X.append(past)\n",
        "    y.append(future)\n",
        "  return np.array(X), np.array(y)\n",
        "\n",
        "\n",
        "n_future=1\n",
        "predictions = list()\n",
        "\n",
        "rmse_list = list()\n",
        "min_window_list = list()\n",
        "best_window_for_long_seq = list()\n",
        "AIC = list()\n",
        "n_fold = 6 # 5 fold plus 1 for test)\n",
        "# evaluate a logistic regression model using k-fold cross-validation\n",
        "n_future=1\n",
        "predictions = list()\n",
        "\n",
        "rmse_list = list()\n",
        "min_window_list = list()\n",
        "best_window_for_long_seq = list()\n",
        "AIC = list()\n",
        "n_fold = 6 # 5 fold plus 1 for test)\n",
        "# evaluate a logistic regression model using k-fold cross-validation\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "\n",
        "\n",
        "best_window_for_long_seq.clear()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#------------------------NEW JUNE 2024 --------------------------------SKIP INDIVIDUAL IOSW--- GO TO COSW DIRECT----------------------------------------------------------------------------------------------------\n",
        "for i in range(Long_train.shape[0]) :\n",
        "#for i in range(10) :\n",
        "  cur_seq = Long_train[i,:,:]\n",
        "  AIC.clear()\n",
        "  try:\n",
        "    selector = VarianceThreshold(0.00002)\n",
        "    cur_seq = selector.fit_transform(cur_seq)\n",
        "    model = VAR(cur_seq)\n",
        "    for m in range(K) :\n",
        "    #print(Long_train)\n",
        "      try:\n",
        "        results = model.fit(m)\n",
        "        print('Order =', m)\n",
        "        print('AIC: ', results.aic)\n",
        "        print('BIC: ', results.bic)\n",
        "        AIC.append(results.aic)\n",
        "      except:\n",
        "        AIC.append(99999)\n",
        "        print('VAR could not solve row number')\n",
        "        print(i, m)\n",
        "\n",
        "    minAIC_index = AIC.index(min(AIC))+1\n",
        "    print(AIC)\n",
        "    print('Minimum lag = ', minAIC_index)\n",
        "    best_window_for_long_seq.append(minAIC_index)\n",
        "\n",
        "  except:\n",
        "    print('NOT ENOUGH FEATURES')\n",
        "    print(i)\n",
        "    minAIC_index = 99999\n",
        "    best_window_for_long_seq.append(minAIC_index)\n",
        "\n",
        "\n",
        "#OUT OF ALL LOOPS NOW\n",
        "#best_window_for_long_seq now contains the best multivariate window size for each of the long sequence i\n",
        "print(best_window_for_long_seq)\n",
        "Window = np.array(best_window_for_long_seq)\n",
        "\n",
        "# ================================================================================\n",
        "# MAP LABELS TO WINDOWS - NEW SECTION\n",
        "# ================================================================================\n",
        "\n",
        "def map_labels_to_windows(windows, labels):\n",
        "    \"\"\"Map labels to existing windows based on end timestep\"\"\"\n",
        "    # Assuming windows shape is (n_windows, window_size, n_features)\n",
        "    n_windows = windows.shape[0]\n",
        "    window_size = windows.shape[1]\n",
        "\n",
        "    # Get the end index for each window\n",
        "    end_indices = np.arange(window_size - 1, window_size - 1 + n_windows)\n",
        "\n",
        "    # Return labels at those end positions\n",
        "    return labels[end_indices]\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"MAPPING LABELS TO WINDOWS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Map anomaly labels to windows\n",
        "detection_window_labels = map_labels_to_windows(Long_train, detection_labels)\n",
        "h1_window_labels = map_labels_to_windows(Long_train, prediction_labels['H1'])\n",
        "h3_window_labels = map_labels_to_windows(Long_train, prediction_labels['H3'])\n",
        "h12_window_labels = map_labels_to_windows(Long_train, prediction_labels['H12'])\n",
        "\n",
        "print(f\"Created {len(Long_train):,} windowed sequences\")\n",
        "print(f\"Detection labels: {np.sum(detection_window_labels):,} positive ({np.mean(detection_window_labels)*100:.2f}%)\")\n",
        "print(f\"H1 labels: {np.sum(h1_window_labels):,} positive ({np.mean(h1_window_labels)*100:.2f}%)\")\n",
        "print(f\"H3 labels: {np.sum(h3_window_labels):,} positive ({np.mean(h3_window_labels)*100:.2f}%)\")\n",
        "print(f\"H12 labels: {np.sum(h12_window_labels):,} positive ({np.mean(h12_window_labels)*100:.2f}%)\")\n",
        "\n",
        "print(\"Label mapping completed!\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# ================================================================================\n",
        "# CONTINUE WITH ORIGINAL SAVING CODE\n",
        "# ================================================================================\n",
        "\n",
        "np.save(r'/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/multivariate_long_sequences-TRAIN-Daily-DIRECT-VAR.npy',Long_train)\n",
        "np.save(r'/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/multivariate_long_sequences_WINDOW-Daily-DIRECT-VAR.npy',Window)\n",
        "\n",
        "# SAVE ANOMALY LABELS - NEW SAVES\n",
        "np.save(r'/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/anomaly_labels_detection.npy', detection_window_labels)\n",
        "np.save(r'/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/anomaly_labels_H1.npy', h1_window_labels)\n",
        "np.save(r'/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/anomaly_labels_H3.npy', h3_window_labels)\n",
        "np.save(r'/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/anomaly_labels_H12.npy', h12_window_labels)\n",
        "\n",
        "print('saving completed (including anomaly labels)')\n",
        "\n",
        "# ================================================================================\n",
        "# FINISH HERE FOR NOW _ NO FILTERING\n",
        "# ================================================================================\n",
        "\n",
        "tdata=np.load(r'/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/multivariate_long_sequences-TRAIN-Daily-DIRECT-VAR.npy')\n",
        "wdata = np.load(r'/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/multivariate_long_sequences_WINDOW-Daily-DIRECT-VAR.npy')\n",
        "\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(15,6))\n",
        "plt.subplot(1,2,1)\n",
        "plt.title(\"Distribution before Transformation\", fontsize=15)\n",
        "sns.histplot(wdata, kde=True, color=\"red\")\n",
        "plt.subplot(1,2,2)\n",
        "\n",
        "\n",
        "\n",
        "p = np.argwhere((9<wdata) & (17>wdata)).flatten()\n",
        "wdata_new= np.take(wdata, p, 0)\n",
        "tdata_new= np.take(tdata,p,0)\n",
        "\n",
        "# FILTER ANOMALY LABELS TOO - NEW FILTERING\n",
        "detection_labels_filtered = np.take(detection_window_labels, p, 0)\n",
        "h1_labels_filtered = np.take(h1_window_labels, p, 0)\n",
        "h3_labels_filtered = np.take(h3_window_labels, p, 0)\n",
        "h12_labels_filtered = np.take(h12_window_labels, p, 0)\n",
        "\n",
        "print(f\"After filtering: {tdata_new.shape[0]} sequences\")\n",
        "print(f\"Filtered detection labels: {np.sum(detection_labels_filtered)} positive\")\n",
        "print(f\"Filtered H1 labels: {np.sum(h1_labels_filtered)} positive\")\n",
        "print(f\"Filtered H3 labels: {np.sum(h3_labels_filtered)} positive\")\n",
        "print(f\"Filtered H12 labels: {np.sum(h12_labels_filtered)} positive\")\n",
        "\n",
        "tdata_new.shape\n",
        "wdata_new.shape\n",
        "\n",
        "np.save(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_METROPM/multivariate_long_sequences-TRAIN-Daily-DIRECT-VAR.npy',tdata_new)\n",
        "np.save(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_METROPM/multivariate_long_sequences_WINDOW-Daily-DIRECT-VAR.npy',wdata_new)\n",
        "\n",
        "# SAVE FILTERED ANOMALY LABELS - NEW SAVES\n",
        "np.save(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_METROPM/anomaly_labels_detection_filtered.npy', detection_labels_filtered)\n",
        "np.save(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_METROPM/anomaly_labels_H1_filtered.npy', h1_labels_filtered)\n",
        "np.save(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_METROPM/anomaly_labels_H3_filtered.npy', h3_labels_filtered)\n",
        "np.save(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_METROPM/anomaly_labels_H12_filtered.npy', h12_labels_filtered)\n",
        "\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(15,6))\n",
        "plt.subplot(1,2,1)\n",
        "plt.title(\"Distribution before Transformation\", fontsize=15)\n",
        "sns.histplot(wdata_new, kde=True, color=\"red\")\n",
        "plt.subplot(1,2,2)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"COMPLETED: ORIGINAL CODE + ANOMALY LABELS\")\n",
        "print(\"=\"*60)\n",
        "print(\"✅ All original functionality preserved\")\n",
        "print(\"✅ Added detection labels (current failures)\")\n",
        "print(\"✅ Added prediction labels (H1, H3, H12 early warnings)\")\n",
        "print(\"✅ Labels properly mapped to windows\")\n",
        "print(\"✅ Labels filtered along with sequences\")\n",
        "print(\"✅ All data saved with anomaly labels\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "W-RMQkgLak9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Xp-Mv3Ksamxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0zEUESMBM_Eo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQ6ZgIvrdRNp"
      },
      "source": [
        "# New Section"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "https://github.com/supriyag123/PHD_Pub/blob/main/AGENTIC-MODULE1.ipynb",
      "authorship_tag": "ABX9TyOoYhCh7NOrk4s0VrmHGRam",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}