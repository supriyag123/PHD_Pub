{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supriyag123/PHD_Pub/blob/main/PAPER_GDRNet_ELECTRICITY_Step4-VAR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "HoP7OuWNxlsJ",
        "outputId": "7c478572-61de-43bf-94f1-a4a92e17058d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.008901944382957761\n",
            "0.008901944382957761\n",
            "0.008901944382957761\n",
            "0.008901944382957761\n",
            "0.00013073473588468156\n",
            "0.00013073473588468156\n",
            "0.00013073473588468156\n",
            "0.00013073473588468156\n",
            "0.003725935493742829\n",
            "0.003725935493742829\n",
            "0.003725935493742829\n",
            "0.003725935493742829\n",
            "0.0012642379914154748\n",
            "0.0012642379914154748\n",
            "0.0012642379914154748\n",
            "0.0012642379914154748\n",
            "0.2509393546472456\n",
            "0.2509393546472456\n",
            "0.2509393546472456\n",
            "0.2509393546472456\n",
            "0.01439065818516775\n",
            "0.01439065818516775\n",
            "0.01439065818516775\n",
            "0.01439065818516775\n",
            "0.0010622331185394184\n",
            "0.0010622331185394184\n",
            "0.0010622331185394184\n",
            "0.0010622331185394184\n",
            "0.012949231461814406\n",
            "0.012949231461814406\n",
            "0.012949231461814406\n",
            "0.012949231461814406\n",
            "0.004217757343214367\n",
            "0.004217757343214367\n",
            "0.004217757343214367\n",
            "0.004217757343214367\n",
            "0.002137462683357628\n",
            "0.002137462683357628\n",
            "0.002137462683357628\n",
            "0.002137462683357628\n",
            "0.03953403811381492\n",
            "0.03953403811381492\n",
            "0.03953403811381492\n",
            "0.03953403811381492\n",
            "0.26128497775852594\n",
            "0.26128497775852594\n",
            "0.26128497775852594\n",
            "0.26128497775852594\n",
            "8.69650543073058e-05\n",
            "8.69650543073058e-05\n",
            "8.69650543073058e-05\n",
            "8.69650543073058e-05\n",
            "0.050842794776615005\n",
            "0.050842794776615005\n",
            "0.050842794776615005\n",
            "0.050842794776615005\n",
            "0.22705668491332098\n",
            "0.22705668491332098\n",
            "0.22705668491332098\n",
            "0.22705668491332098\n",
            "0.000987898979901788\n",
            "0.000987898979901788\n",
            "0.000987898979901788\n",
            "0.000987898979901788\n",
            "0.030090711323684804\n",
            "0.030090711323684804\n",
            "0.030090711323684804\n",
            "0.030090711323684804\n",
            "0.0033614021611940827\n",
            "0.0033614021611940827\n",
            "0.0033614021611940827\n",
            "0.0033614021611940827\n",
            "0.11654309592882124\n",
            "0.11654309592882124\n",
            "0.11654309592882124\n",
            "0.11654309592882124\n",
            "0.020702838996274425\n",
            "0.020702838996274425\n",
            "0.020702838996274425\n",
            "0.020702838996274425\n",
            "0.001196066431205118\n",
            "0.001196066431205118\n",
            "0.001196066431205118\n",
            "0.001196066431205118\n",
            "0.00016494151049348686\n",
            "0.00016494151049348686\n",
            "0.00016494151049348686\n",
            "0.00016494151049348686\n",
            "0.043771987652172974\n",
            "0.043771987652172974\n",
            "0.043771987652172974\n",
            "0.043771987652172974\n",
            "0.3440185886177779\n",
            "0.3440185886177779\n",
            "0.3440185886177779\n",
            "0.3440185886177779\n",
            "0.4458802409861091\n",
            "0.4458802409861091\n",
            "0.4458802409861091\n",
            "0.4458802409861091\n",
            "0.024373667162767836\n",
            "0.024373667162767836\n",
            "0.024373667162767836\n",
            "0.024373667162767836\n",
            "0.010670389203801195\n",
            "0.010670389203801195\n",
            "0.010670389203801195\n",
            "0.010670389203801195\n",
            "0.4760996561920196\n",
            "0.4760996561920196\n",
            "0.4760996561920196\n",
            "0.4760996561920196\n",
            "0.021880699113391727\n",
            "0.021880699113391727\n",
            "0.021880699113391727\n",
            "0.021880699113391727\n",
            "0.03242118040551218\n",
            "0.03242118040551218\n",
            "0.03242118040551218\n",
            "0.03242118040551218\n",
            "0.000542205035179427\n",
            "0.000542205035179427\n",
            "0.000542205035179427\n",
            "0.000542205035179427\n",
            "8.634959360590038e-05\n",
            "8.634959360590038e-05\n",
            "8.634959360590038e-05\n",
            "8.634959360590038e-05\n",
            "0.004464751487505207\n",
            "0.004464751487505207\n",
            "0.004464751487505207\n",
            "0.004464751487505207\n",
            "0.3790888487605135\n",
            "0.3790888487605135\n",
            "0.3790888487605135\n",
            "0.3790888487605135\n",
            "0.002218503656689821\n",
            "0.002218503656689821\n",
            "0.002218503656689821\n",
            "0.002218503656689821\n",
            "0.04351277468895127\n",
            "0.04351277468895127\n",
            "0.04351277468895127\n",
            "0.04351277468895127\n",
            "0.08303908720788777\n",
            "0.08303908720788777\n",
            "0.08303908720788777\n",
            "0.08303908720788777\n",
            "0.34356877923652046\n",
            "0.34356877923652046\n",
            "0.34356877923652046\n",
            "0.34356877923652046\n",
            "0.023570690687453995\n",
            "0.023570690687453995\n",
            "0.023570690687453995\n",
            "0.023570690687453995\n",
            "0.00845378620053601\n",
            "0.00845378620053601\n",
            "0.00845378620053601\n",
            "0.00845378620053601\n",
            "0.10699485991485488\n",
            "0.10699485991485488\n",
            "0.10699485991485488\n",
            "0.10699485991485488\n",
            "0.0010640882673989991\n",
            "0.0010640882673989991\n",
            "0.0010640882673989991\n",
            "0.0010640882673989991\n",
            "0.07581247989230239\n",
            "0.07581247989230239\n",
            "0.07581247989230239\n",
            "0.07581247989230239\n",
            "0.016357036172585722\n",
            "0.016357036172585722\n",
            "0.016357036172585722\n",
            "0.016357036172585722\n",
            "0.04024793400916136\n",
            "0.04024793400916136\n",
            "0.04024793400916136\n",
            "0.04024793400916136\n",
            "0.0018204800455856578\n",
            "0.0018204800455856578\n",
            "0.0018204800455856578\n",
            "0.0018204800455856578\n",
            "0.032840203484684895\n",
            "0.032840203484684895\n",
            "0.032840203484684895\n",
            "0.032840203484684895\n",
            "0.028153677097008646\n",
            "0.028153677097008646\n",
            "0.028153677097008646\n",
            "0.028153677097008646\n",
            "0.03248126867962172\n",
            "0.03248126867962172\n",
            "0.03248126867962172\n",
            "0.03248126867962172\n",
            "0.03409599325349922\n",
            "0.03409599325349922\n",
            "0.03409599325349922\n",
            "0.03409599325349922\n",
            "0.031839855174322515\n",
            "0.031839855174322515\n",
            "0.031839855174322515\n",
            "0.031839855174322515\n",
            "0.0013945255405301117\n",
            "0.0013945255405301117\n",
            "0.0013945255405301117\n",
            "0.0013945255405301117\n",
            "0.1963234639784615\n",
            "0.1963234639784615\n",
            "0.1963234639784615\n",
            "0.1963234639784615\n",
            "0.3439788507607315\n",
            "0.3439788507607315\n",
            "0.3439788507607315\n",
            "0.3439788507607315\n",
            "0.031125135380354118\n",
            "0.031125135380354118\n",
            "0.031125135380354118\n",
            "0.031125135380354118\n",
            "0.1161921078806003\n",
            "0.1161921078806003\n",
            "0.1161921078806003\n",
            "0.1161921078806003\n",
            "0.043717128562147566\n",
            "0.043717128562147566\n",
            "0.043717128562147566\n",
            "0.043717128562147566\n",
            "0.001674678725120169\n",
            "0.001674678725120169\n",
            "0.001674678725120169\n",
            "0.001674678725120169\n",
            "0.01677850130170257\n",
            "0.01677850130170257\n",
            "0.01677850130170257\n",
            "0.01677850130170257\n",
            "0.060168373204140084\n",
            "0.060168373204140084\n",
            "0.060168373204140084\n",
            "0.060168373204140084\n",
            "0.03139234007339713\n",
            "0.03139234007339713\n",
            "0.03139234007339713\n",
            "0.03139234007339713\n",
            "0.46547191438036245\n",
            "0.46547191438036245\n",
            "0.46547191438036245\n",
            "0.46547191438036245\n",
            "0.0010719692320643169\n",
            "0.0010719692320643169\n",
            "0.0010719692320643169\n",
            "0.0010719692320643169\n",
            "0.030524905040747157\n",
            "0.030524905040747157\n",
            "0.030524905040747157\n",
            "0.030524905040747157\n",
            "0.0006389145793537017\n",
            "0.0006389145793537017\n",
            "0.0006389145793537017\n",
            "0.0006389145793537017\n",
            "0.01475632476537894\n",
            "0.01475632476537894\n",
            "0.01475632476537894\n",
            "0.01475632476537894\n",
            "0.0009593925379610342\n",
            "0.0009593925379610342\n",
            "0.0009593925379610342\n",
            "0.0009593925379610342\n",
            "0.004411835976288407\n",
            "0.004411835976288407\n",
            "0.004411835976288407\n",
            "0.004411835976288407\n",
            "0.03231486814556218\n",
            "0.03231486814556218\n",
            "0.03231486814556218\n",
            "0.03231486814556218\n",
            "0.0028070165912565306\n",
            "0.0028070165912565306\n",
            "0.0028070165912565306\n",
            "0.0028070165912565306\n",
            "0.040491512450471535\n",
            "0.040491512450471535\n",
            "0.040491512450471535\n",
            "0.040491512450471535\n",
            "0.0023406144107113976\n",
            "0.0023406144107113976\n",
            "0.0023406144107113976\n",
            "0.0023406144107113976\n",
            "0.04018121211832271\n",
            "0.04018121211832271\n",
            "0.04018121211832271\n",
            "0.04018121211832271\n",
            "0.32063547477502624\n",
            "0.32063547477502624\n",
            "0.32063547477502624\n",
            "0.32063547477502624\n",
            "0.023000181994431577\n",
            "0.023000181994431577\n",
            "0.023000181994431577\n",
            "0.023000181994431577\n",
            "0.20413339979456546\n",
            "0.20413339979456546\n",
            "0.20413339979456546\n",
            "0.20413339979456546\n",
            "4.463471700535501e-06\n",
            "4.463471700535501e-06\n",
            "4.463471700535501e-06\n",
            "4.463471700535501e-06\n",
            "0.00012634357898932372\n",
            "0.00012634357898932372\n",
            "0.00012634357898932372\n",
            "0.00012634357898932372\n",
            "0.023759743395158756\n",
            "0.023759743395158756\n",
            "0.023759743395158756\n",
            "0.023759743395158756\n",
            "0.13731024411934095\n",
            "0.13731024411934095\n",
            "0.13731024411934095\n",
            "0.13731024411934095\n",
            "0.02152459241170613\n",
            "0.02152459241170613\n",
            "0.02152459241170613\n",
            "0.02152459241170613\n",
            "0.11089792804037302\n",
            "0.11089792804037302\n",
            "0.11089792804037302\n",
            "0.11089792804037302\n",
            "0.22165595895003865\n",
            "0.22165595895003865\n",
            "0.22165595895003865\n",
            "0.22165595895003865\n",
            "0.016064619406062124\n",
            "0.016064619406062124\n",
            "0.016064619406062124\n",
            "0.016064619406062124\n",
            "0.021425886077228597\n",
            "0.021425886077228597\n",
            "0.021425886077228597\n",
            "0.021425886077228597\n",
            "0.033896511432218786\n",
            "0.033896511432218786\n",
            "0.033896511432218786\n",
            "0.033896511432218786\n",
            "0.3053933447565324\n",
            "0.3053933447565324\n",
            "0.3053933447565324\n",
            "0.3053933447565324\n",
            "0.0019303547678948946\n",
            "0.0019303547678948946\n",
            "0.0019303547678948946\n",
            "0.0019303547678948946\n",
            "0.012053876275551413\n",
            "0.012053876275551413\n",
            "0.012053876275551413\n",
            "0.012053876275551413\n",
            "0.0021107902956158725\n",
            "0.0021107902956158725\n",
            "0.0021107902956158725\n",
            "0.0021107902956158725\n",
            "0.047609262588732056\n",
            "0.047609262588732056\n",
            "0.047609262588732056\n",
            "0.047609262588732056\n",
            "0.36524306001057\n",
            "0.36524306001057\n",
            "0.36524306001057\n",
            "0.36524306001057\n",
            "0.0006913968533212477\n",
            "0.0006913968533212477\n",
            "0.0006913968533212477\n",
            "0.0006913968533212477\n",
            "0.01269262236005003\n",
            "0.01269262236005003\n",
            "0.01269262236005003\n",
            "0.01269262236005003\n",
            "0.34597747499316267\n",
            "0.34597747499316267\n",
            "0.34597747499316267\n",
            "0.34597747499316267\n",
            "0.014970536681633128\n",
            "0.014970536681633128\n",
            "0.014970536681633128\n",
            "0.014970536681633128\n",
            "0.003790765408173869\n",
            "0.003790765408173869\n",
            "0.003790765408173869\n",
            "0.003790765408173869\n",
            "0.26353226055795675\n",
            "0.26353226055795675\n",
            "0.26353226055795675\n",
            "0.26353226055795675\n",
            "0.09764688550840268\n",
            "0.09764688550840268\n",
            "0.09764688550840268\n",
            "0.09764688550840268\n",
            "0.1232646805853984\n",
            "0.1232646805853984\n",
            "0.1232646805853984\n",
            "0.1232646805853984\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import math\n",
        "import plotly.graph_objects as go\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, RepeatVector, TimeDistributed, Input\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import keras.backend as K\n",
        "from keras.callbacks import Callback\n",
        "import plotly\n",
        "import plotly.express as px # for data visualization\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import IsolationForest\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "from numpy import array\n",
        "from numpy import hstack\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LassoCV, MultiTaskLassoCV\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from math import sqrt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from keras.models import Model\n",
        "from statsmodels.tsa.api import VAR\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.tools.eval_measures import rmse, aic\n",
        "from statsmodels.tsa.stattools import acf\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from numpy import arange\n",
        "#-----------------------------------------------------GET DATA - X, Predicted Wndow from MLP, and Derived Labels, for the entire dataset that was gennerated through VAE-----------------------------------\n",
        "\n",
        "#-----------for whole dataset-----------------------------------------------------------------------\n",
        "y_pred = np.loadtxt(r'/content/drive/MyDrive/PHD/2024/MLPOutput/predicted_COSW_V3.csv')\n",
        "y_true = np.loadtxt(r'/content/drive/MyDrive/PHD/2024/MLPOutput/Calculated_label_COSW_V3.csv')\n",
        "x_orig = np.loadtxt(r'/content/drive/MyDrive/PHD/2024/MLPOutput/whole_data_V3.csv')\n",
        "\n",
        "\n",
        "#-----------for test dataset-----------------------------------------------------------------------\n",
        "y_pred = np.loadtxt(r'/content/drive/MyDrive/PHD/2024/MLPOutput/predicted_window_V3.csv')\n",
        "y_true = np.loadtxt(r'/content/drive/MyDrive/PHD/2024/MLPOutput/derived_window_label_V3.csv')\n",
        "x_orig = np.loadtxt(r'/content/drive/MyDrive/PHD/2024/MLPOutput/test_data_V3.csv')\n",
        "\n",
        "n_features = 5\n",
        "window_size = int(x_orig.shape[1]/n_features)\n",
        "x = x_orig.reshape((x_orig.shape[0],window_size,n_features))\n",
        "\n",
        "sample_size = 100\n",
        "#-----------------------------------------------CASES - pot window values and pick a few fixed window sizes -------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "plt.figure(figsize=(15,6))\n",
        "plt.subplot(1,2,1)\n",
        "plt.title(\"Distribution before Transformation\", fontsize=15)\n",
        "sns.histplot(y_true, kde=True, color=\"red\")\n",
        "plt.subplot(1,2,2)\n",
        "\n",
        "# Import libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "fig = plt.figure(figsize =(10, 7))\n",
        "# Creating plot\n",
        "plt.boxplot(y_pred)\n",
        "# show plot\n",
        "plt.show()\n",
        "\n",
        "fx_window1 = 4\n",
        "fx_window2 = 7\n",
        "fx_window3 = 9\n",
        "fx_window4 = 11\n",
        "\n",
        "\n",
        "pred_step =1\n",
        "\n",
        "############################METHOD 1---------------- GO BY AIC ---------------------------------------------------------------------------------\n",
        "\n",
        "aic1_count = list()\n",
        "aic2_count = list()\n",
        "aic3_count = list()\n",
        "aic4_count = list()\n",
        "aic5_count = list()\n",
        "aic6_count = list()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for i in range(sample_size) :\n",
        "\n",
        "  x1 = x[i]\n",
        "  x_train=x1[:-pred_step]\n",
        "  x_test=x1[-pred_step:]\n",
        "  regressor= VAR(x_train)\n",
        "  results1 = regressor.fit(fx_window1)\n",
        "  results2 = regressor.fit(fx_window2)\n",
        "  results3 = regressor.fit(fx_window3)\n",
        "  results4 = regressor.fit(fx_window4)\n",
        "  #results5 = regressor.fit(fx_window5)\n",
        "  results6 = regressor.fit(int(y_pred[i]))\n",
        "\n",
        "#Calculate AIC for ach case--------------\n",
        "  try:\n",
        "    aic1 = results1.aic\n",
        "  except:\n",
        "    aic1 = 9999\n",
        "  aic1_count.append(aic1)\n",
        "\n",
        "  try:\n",
        "    aic2 = results2.aic\n",
        "  except:\n",
        "    aic2 = 9999\n",
        "  aic2_count.append(aic2)\n",
        "\n",
        "  try:\n",
        "    aic3 = results3.aic\n",
        "  except:\n",
        "    aic3 = 9999\n",
        "  aic3_count.append(aic3)\n",
        "\n",
        "  try:\n",
        "    aic4 = results4.aic\n",
        "  except:\n",
        "    aic4 = 9999\n",
        "  aic4_count.append(aic4)\n",
        "\n",
        "  #try:\n",
        "  #  aic5 = results5.aic\n",
        "  #except:\n",
        "  #  aic5 = 9999\n",
        "  #aic5_count.append(aic5)\n",
        "\n",
        "\n",
        "  try:\n",
        "    aic6 = results6.aic\n",
        "  except:\n",
        "    aic6 = 9999\n",
        "  aic6_count.append(aic6)\n",
        "\n",
        "\n",
        "print(\"aic1_count : \", aic1_count)\n",
        "print(\"aic2_count : \", aic2_count)\n",
        "print(\"aic3_count : \", aic3_count)\n",
        "print(\"aic4_count : \", aic4_count)\n",
        "#print(\"aic5_count : \", aic5_count)\n",
        "print(\"aic6_count : \", aic6_count)\n",
        "\n",
        "df = pd.DataFrame({'AIC1' : aic1_count, 'AIC2' : aic2_count, 'AIC3' : aic3_count,  'AIC4':aic4_count, 'AIC6 - Predicted' : aic6_count})\n",
        "df[0:1000].plot(figsize=(15,6))\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "df.to_csv('/content/drive/MyDrive/PHD/2024/PREDICTION_COMPARISON/Electricity_AIC_comparison.csv', index = False)\n",
        "\n",
        "\n",
        "################---------------------------METHOD 2- -GO BY RMSE----------------------------------------------------####################\n",
        "rmse_V1 = list()\n",
        "rmse_V2 = list()\n",
        "rmse_V3 = list()\n",
        "rmse_V4 = list()\n",
        "rmse_V5 = list()\n",
        "rmse_V6 = list()\n",
        "\n",
        "for i in range(100) :\n",
        "  x1 = x[i]\n",
        "  df = pd.DataFrame(x1, columns=['V1','V2','V3','V4','V5'])\n",
        "  df_train, df_test = df[0:-pred_step], df[-pred_step:]\n",
        "  model= VAR(df_train)\n",
        "\n",
        "  model_fitted1 = model.fit(fx_window1)\n",
        "  lag_order1 = model_fitted1.k_ar\n",
        "  forecast_input1 = df.values[-lag_order1:]\n",
        "  fc1 = model_fitted1.forecast(y=forecast_input1, steps=pred_step)\n",
        "  df_forecast1 = pd.DataFrame(fc1, index=df.index[-pred_step:], columns=df.columns)\n",
        "  rmse_V1_1 =  mean_squared_error(df_test['V1'], df_forecast1['V1'].values)\n",
        "  rmse_V1.append(rmse_V1_1)\n",
        "  print(rmse_V1_1)\n",
        "\n",
        "  model_fitted2 = model.fit(fx_window2)\n",
        "  lag_order2 = model_fitted2.k_ar\n",
        "  forecast_input2 = df.values[-lag_order2:]\n",
        "  fc2 = model_fitted2.forecast(y=forecast_input2, steps=pred_step)\n",
        "  df_forecast2 = pd.DataFrame(fc2, index=df.index[-pred_step:], columns=df.columns)\n",
        "  rmse_V1_2 =  mean_squared_error(df_test['V1'], df_forecast1['V1'].values)\n",
        "  rmse_V2.append(rmse_V1_2)\n",
        "  print(rmse_V1_2)\n",
        "\n",
        "  model_fitted3 = model.fit(fx_window3)\n",
        "  lag_order3 = model_fitted3.k_ar\n",
        "  forecast_input3 = df.values[-lag_order3:]\n",
        "  fc3 = model_fitted3.forecast(y=forecast_input3, steps=pred_step)\n",
        "  df_forecast3 = pd.DataFrame(fc3, index=df.index[-pred_step:], columns=df.columns)\n",
        "  rmse_V1_3 =  mean_squared_error(df_test['V1'], df_forecast1['V1'].values)\n",
        "  rmse_V3.append(rmse_V1_3)\n",
        "  print(rmse_V1_3)\n",
        "\n",
        "  model_fittedX = model.fit(int(y_pred[i]))\n",
        "  lag_orderX = model_fittedX.k_ar\n",
        "  forecast_inputX = df.values[-lag_orderX:]\n",
        "  fcX = model_fittedX.forecast(y=forecast_inputX, steps=pred_step)\n",
        "  df_forecastX = pd.DataFrame(fcX, index=df.index[-pred_step:], columns=df.columns)\n",
        "  rmse_V1_x =  mean_squared_error(df_test['V1'], df_forecast1['V1'].values)\n",
        "  rmse_V4.append(rmse_V1_x)\n",
        "  print(rmse_V1_x)\n",
        "\n",
        "print(np.mean(rmse_V1), np.mean(rmse_V2),  np.mean(rmse_V3), np.mean(rmse_V4))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df.to_csv('/content/drive/MyDrive/PHD/2024/PREDICTION_COMPARISON/Electricity_mse_comparison.csv', index = False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "v_5iji919H_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8OtWHK--uG6W"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "https://github.com/supriyag123/PHD_Pub/blob/main/PAPER_GDRNet_ELECTRICITY_Step4-VAR.ipynb",
      "authorship_tag": "ABX9TyP3C9EIqYocmrYiejR79QEl",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}