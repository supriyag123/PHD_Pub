{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supriyag123/PHD_Pub/blob/main/AGENTIC-MODULE3-AdaptiveWindowAgent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bx-5b_puABG1",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ee66f2c-ef27-4963-abbf-bd408a960350"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using NORMAL sequences for baseline: 1038419\n",
            "✅ Loaded baseline error + window distribution.\n",
            "   Error median=0.380833, MAD=0.011504\n",
            "   Window mean=2.000, std=0.000\n",
            "✅ Loaded MLP model from /content/drive/MyDrive/PHD/2025/DGRNet-MLP-Versions/METROPM_MLP_model_10Sec.keras\n",
            "AdaptiveWindowAgent adaptive_window_agent initialized\n",
            "✅ Loaded NSP LSTM next-step predictor\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [12:04<00:00,  6.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ CLEAN NSP BASELINE SAVED: /content/drive/MyDrive/PHD/2025/DGRNet-MLP-Versions/METROPM_MLP_baseline.pkl\n",
            "\n",
            "---- ERROR (NSP) ----\n",
            "Median: 0.0011534937075339258\n",
            "MAD: 0.00043960518087260425\n",
            "Count: 5000\n",
            "\n",
            "---- WINDOW (MLP) ----\n",
            "Mean: 67.2578\n",
            "Std: 22.841158893909547\n",
            "Min: 2\n",
            "Max: 99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import json\n",
        "import os\n",
        "from collections import deque\n",
        "from typing import Dict, Any\n",
        "import datetime as dt\n",
        "import logging\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from statsmodels.tsa.vector_ar.var_model import VAR\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import warnings\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "class AdaptiveWindowAgent:\n",
        "    \"\"\"\n",
        "    Adaptive Window Agent:\n",
        "    - Predicts window size using MLP\n",
        "    - Evaluates forecast with RF/persistence\n",
        "    - Computes:\n",
        "        * FDS: Forecast Deviation Score (normalized error)\n",
        "        * FDI: Forecast Drift Index (JSD over FDS distribution)\n",
        "        * WSS: Window Shift Score (normalized window size)\n",
        "        * WDI: Window Drift Index (JSD over window size distribution)\n",
        "    - Detects anomaly (local) + drift (regime) events.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, agent_id=\"adaptive_window_agent\",\n",
        "                 model_path=None, checkpoint_path=None):\n",
        "        self.agent_id = agent_id\n",
        "        self.model_path = model_path or \"/content/drive/MyDrive/PHD/2025/DGRNet-MLP-Versions/METROPM_MLP_model_10Sec.keras\"\n",
        "\n",
        "        self.baseline_path = \"/content/drive/MyDrive/PHD/2025/DGRNet-MLP-Versions/METROPM_MLP_baseline.pkl\"\n",
        "        self.checkpoint_path = checkpoint_path\n",
        "\n",
        "        # --------------------------------------------------\n",
        "        # Core model\n",
        "        # --------------------------------------------------\n",
        "        self.model = None\n",
        "        self.transformer = StandardScaler()\n",
        "        self.transformer_fitted = False\n",
        "        self.is_model_loaded = False\n",
        "\n",
        "        # Baseline error stats (median / MAD) – filled from baseline file\n",
        "        self.rolling_stats = {\n",
        "            'median': 0.0,\n",
        "            'mad': 1.0,\n",
        "        }\n",
        "\n",
        "        # --------------------------------------------------\n",
        "        # Metrics memory\n",
        "        # --------------------------------------------------\n",
        "        # Raw error\n",
        "        self.error_memory = deque(maxlen=300)     # long-term errors\n",
        "        self.recent_errors = deque(maxlen=50)     # kept for backward compat (not central now)\n",
        "\n",
        "        # FDS (Forecast Deviation Score) history\n",
        "        self.fds_memory = deque(maxlen=300)\n",
        "        self.recent_fds = deque(maxlen=50)\n",
        "\n",
        "        # Window history\n",
        "        self.window_memory = deque(maxlen=300)\n",
        "        self.recent_windows = deque(maxlen=50)\n",
        "\n",
        "        # Last-step metrics (for returning)\n",
        "        self.last_fds = 0.0\n",
        "        self.last_fdi = 0.0\n",
        "        self.last_wss = 0.0\n",
        "        self.last_wdi = 0.0\n",
        "\n",
        "        # Baseline distributions\n",
        "        self.baseline_errors = None\n",
        "        self.baseline_fds = None\n",
        "        self.baseline_windows = None\n",
        "        self.window_mean = 50.0    # a reasonable mid value\n",
        "        self.window_std = 10.0     # non-zero, avoids div-by-zero\n",
        "\n",
        "        # Optional histogram bins stored in baseline\n",
        "        self.window_hist_bins = None\n",
        "        self.window_hist_counts = None\n",
        "\n",
        "        # Debug flag (OFF by default)\n",
        "        self.debug = False\n",
        "\n",
        "        # --------------------------------------------------\n",
        "        # Anomaly / drift settings\n",
        "        # --------------------------------------------------\n",
        "        self.threshold_k = 3.0\n",
        "        self.anomaly_cooldown = 0\n",
        "        self.anomaly_cooldown_steps = 5\n",
        "\n",
        "        # Drift detection\n",
        "        self.drift_threshold = 0.10          # for FDI (JSD over FDS)\n",
        "        self.window_drift_threshold = 0.10   # for WDI (JSD over window sizes)\n",
        "        self.consecutive_drift_votes = 0\n",
        "        self.drift_cooldown = 0\n",
        "        self.drift_cooldown_steps = 10\n",
        "\n",
        "        # --------------------------------------------------\n",
        "        # Retraining buffer (unchanged)\n",
        "        # --------------------------------------------------\n",
        "        self.performance_stats = {\n",
        "            'total_predictions': 0,\n",
        "            'avg_mse': 0.0,\n",
        "            'avg_mae': 0.0,\n",
        "            'last_retrain_time': None,\n",
        "            'drift_events': 0,\n",
        "            'anomaly_events': 0,\n",
        "            'retraining_events': 0\n",
        "        }\n",
        "\n",
        "        self.retraining_data = {\n",
        "            'x_buffer': deque(maxlen=10000),\n",
        "            'y_buffer': deque(maxlen=10000)\n",
        "        }\n",
        "\n",
        "        # --------------------------------------------------\n",
        "        # Prediction history (for reporting)\n",
        "        # --------------------------------------------------\n",
        "        self.prediction_history = deque(maxlen=1000)\n",
        "        self.mse_history = deque(maxlen=200)\n",
        "        self.mae_history = deque(maxlen=200)\n",
        "\n",
        "        # --------------------------------------------------\n",
        "        # Load baseline (errors + windows)\n",
        "        # --------------------------------------------------\n",
        "        self._load_baseline()\n",
        "\n",
        "        # --------------------------------------------------\n",
        "        # Load model last\n",
        "        # --------------------------------------------------\n",
        "        self.load_model()\n",
        "        print(f\"AdaptiveWindowAgent {self.agent_id} initialized\")\n",
        "\n",
        "        # --------------------------------------------------\n",
        "        # Load NSP (Next-Step Predictor)\n",
        "        # --------------------------------------------------\n",
        "        self.nsp_model_path = \"/content/drive/MyDrive/PHD/2025/NSP_LSTM_next_step.keras\"\n",
        "        self.nsp_model = keras.models.load_model(self.nsp_model_path)\n",
        "        print(\"✅ Loaded NSP LSTM next-step predictor\")\n",
        "\n",
        "    # =================== BASELINE LOADING ===================\n",
        "\n",
        "    def _load_baseline(self):\n",
        "        \"\"\"\n",
        "        Load baseline stats:\n",
        "          - baseline_errors, median, mad\n",
        "          - baseline_windows, window_mean, window_std\n",
        "          - optional histogram bins/counts for windows\n",
        "        \"\"\"\n",
        "        if os.path.exists(self.baseline_path):\n",
        "            with open(self.baseline_path, \"rb\") as f:\n",
        "                base = pickle.load(f)\n",
        "\n",
        "            # Error baseline\n",
        "            self.baseline_errors = np.array(base[\"baseline_errors\"])\n",
        "            self.rolling_stats[\"median\"] = base[\"median\"]\n",
        "            self.rolling_stats[\"mad\"] = base[\"mad\"]\n",
        "\n",
        "            # Precompute baseline FDS distribution\n",
        "            med = self.rolling_stats[\"median\"]\n",
        "            mad = self.rolling_stats[\"mad\"] if self.rolling_stats[\"mad\"] > 0 else 1e-6\n",
        "            self.baseline_fds = (self.baseline_errors - med) / (mad + 1e-8)\n",
        "\n",
        "            # Window baseline (may or may not exist)\n",
        "            if \"baseline_windows\" in base:\n",
        "                self.baseline_windows = np.array(base[\"baseline_windows\"])\n",
        "                self.window_mean = float(base.get(\"window_mean\", np.mean(self.baseline_windows)))\n",
        "                self.window_std = float(base.get(\"window_std\", np.std(self.baseline_windows) + 1e-8))\n",
        "                self.window_hist_bins = np.array(base.get(\"window_hist_bins\", [])) if \"window_hist_bins\" in base else None\n",
        "                self.window_hist_counts = np.array(base.get(\"window_hist_counts\", [])) if \"window_hist_counts\" in base else None\n",
        "            else:\n",
        "                self.baseline_windows = None\n",
        "                self.window_mean = 0.0\n",
        "                self.window_std = 1.0\n",
        "                self.window_hist_bins = None\n",
        "                self.window_hist_counts = None\n",
        "\n",
        "            print(\"✅ Loaded baseline error + window distribution.\")\n",
        "            print(f\"   Error median={self.rolling_stats['median']:.6f}, MAD={self.rolling_stats['mad']:.6f}\")\n",
        "            if self.baseline_windows is not None:\n",
        "                print(f\"   Window mean={self.window_mean:.3f}, std={self.window_std:.3f}\")\n",
        "        else:\n",
        "            print(\"⚠️ No baseline found. Using live history only.\")\n",
        "            self.baseline_errors = None\n",
        "            self.baseline_fds = None\n",
        "            self.baseline_windows = None\n",
        "\n",
        "    # =================== MODEL LOADING ===================\n",
        "\n",
        "    def load_model(self):\n",
        "        try:\n",
        "            if os.path.exists(self.model_path):\n",
        "                self.model = keras.models.load_model(self.model_path)\n",
        "                self.is_model_loaded = True\n",
        "                print(f\"✅ Loaded MLP model from {self.model_path}\")\n",
        "\n",
        "                # Try to load transformer\n",
        "                transformer_path = self.model_path.replace('.keras', '_transformer.pkl')\n",
        "                if os.path.exists(transformer_path):\n",
        "                    with open(transformer_path, 'rb') as f:\n",
        "                        self.transformer = pickle.load(f)\n",
        "                    self.transformer_fitted = True\n",
        "                else:\n",
        "                    # Fit transformer from true window labels\n",
        "                    y_original = np.load(\n",
        "                        \"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/generated-data-true-window2.npy\"\n",
        "                    )\n",
        "                    self.transformer.fit(y_original.reshape(-1, 1))\n",
        "                    self.transformer_fitted = True\n",
        "                    with open(transformer_path, 'wb') as f:\n",
        "                        pickle.dump(self.transformer, f)\n",
        "                    print(\"⚠️ No transformer found, fitted a new one.\")\n",
        "            else:\n",
        "                print(f\"❌ Model not found at {self.model_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error loading model: {e}\")\n",
        "\n",
        "    # =================== FORECAST EVALUATION ===================\n",
        "\n",
        "    def evaluate_forecast_performance(self, sequence_3d, predicted_window, n_future=1):\n",
        "        try:\n",
        "            seq = np.asarray(sequence_3d)\n",
        "            T, F = seq.shape\n",
        "\n",
        "            W = int(predicted_window)\n",
        "            if W < 2:\n",
        "                W = 2\n",
        "            if W > T - n_future - 1:\n",
        "                W = max(2, T - n_future - 1)\n",
        "\n",
        "            # --- Prepare NSP input ---\n",
        "            window = seq[-W:-n_future, :]   # shape (W-1, F)\n",
        "            x = window[np.newaxis, ...]      # shape (1, W-1, F)\n",
        "\n",
        "            # --- NSP prediction ---\n",
        "            y_pred = self.nsp_model.predict(x, verbose=0)[0]  # (F,)\n",
        "            y_true = seq[-n_future, :]                        # (F,)\n",
        "\n",
        "            mse = float(np.mean((y_true - y_pred) ** 2))\n",
        "            mae = float(np.mean(np.abs(y_true - y_pred)))\n",
        "\n",
        "            return {\n",
        "                \"mse\": mse,\n",
        "                \"mae\": mae,\n",
        "                \"forecast_success\": True,\n",
        "                \"actual_values\": y_true.tolist(),\n",
        "                \"predicted_values\": y_pred.tolist(),\n",
        "                \"window_size_used\": W,\n",
        "                \"method\": \"NSP_LSTM\"\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                \"mse\": 9999.0,\n",
        "                \"mae\": 9999.0,\n",
        "                \"forecast_success\": False,\n",
        "                \"error\": str(e),\n",
        "                \"method\": \"NSP_LSTM\"\n",
        "            }\n",
        "\n",
        "    # =================== PERSISTENCE FALLBACK ===================\n",
        "\n",
        "    def _persistence_forecast(self, seq, target_sensor_index, n_future):\n",
        "        \"\"\"\n",
        "        Persistence fallback for RF evaluation.\n",
        "        Last-value-carried-forward for target sensor.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            seq = np.asarray(seq)\n",
        "            if len(seq) < 2:\n",
        "                return {\n",
        "                    'mse': 9999,\n",
        "                    'mae': 9999,\n",
        "                    'forecast_success': False,\n",
        "                    'error': 'Sequence too short',\n",
        "                    'method': 'Persistence'\n",
        "                }\n",
        "\n",
        "            last_value = seq[-1, target_sensor_index]\n",
        "            predicted_vals = [last_value]\n",
        "            actual = [seq[-1, target_sensor_index]]\n",
        "\n",
        "            mse = 0.0\n",
        "            mae = 0.0\n",
        "\n",
        "            return {\n",
        "                'mse': mse,\n",
        "                'mae': mae,\n",
        "                'forecast_success': True,\n",
        "                'actual_values': actual,\n",
        "                'predicted_values': predicted_vals,\n",
        "                'target_sensor_index': target_sensor_index,\n",
        "                'method': 'Persistence',\n",
        "                'note': 'persistence_fallback'\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'mse': 9999,\n",
        "                'mae': 9999,\n",
        "                'forecast_success': False,\n",
        "                'error': str(e),\n",
        "                'method': 'Persistence',\n",
        "                'note': 'persistence_fallback_failed'\n",
        "            }\n",
        "\n",
        "    # =================== PREDICTION PIPELINE ===================\n",
        "\n",
        "    def predict_window_size(self, feature_vector, sequence_3d):\n",
        "        \"\"\"\n",
        "        Main entrypoint:\n",
        "          - Predict window W_t\n",
        "          - Evaluate forecast error e_t\n",
        "          - Compute FDS (S_t) and WSS (Z_t)\n",
        "          - Update drift/anomaly logic (FDI, WDI, events)\n",
        "          - Return full metrics packet\n",
        "        \"\"\"\n",
        "        if not self.is_model_loaded:\n",
        "            return {'predicted_window': 20, 'error': \"Model not loaded\"}\n",
        "\n",
        "        try:\n",
        "            if feature_vector.ndim == 1:\n",
        "                feature_vector = feature_vector.reshape(1, -1)\n",
        "\n",
        "            pred_raw = self.model.predict(feature_vector, verbose=0)\n",
        "\n",
        "            if self.transformer_fitted:\n",
        "                predicted_window = int(round(self.transformer.inverse_transform(pred_raw)[0, 0]))\n",
        "            else:\n",
        "                predicted_window = int(round(pred_raw[0, 0]))\n",
        "\n",
        "            # ----------------------------------------\n",
        "            # WINDOW CLAMP — HARD SAFETY FIX\n",
        "            # ----------------------------------------\n",
        "            # Prevent negative, zero, or extreme window sizes\n",
        "            predicted_window = max(2, predicted_window)        # lower bound\n",
        "\n",
        "            # Forecast evaluation\n",
        "            forecast_metrics = self.evaluate_forecast_performance(sequence_3d, predicted_window, n_future=1)\n",
        "\n",
        "            fds = None\n",
        "            wss = None\n",
        "\n",
        "            if forecast_metrics.get(\"forecast_success\", False):\n",
        "                mse = forecast_metrics[\"mse\"]\n",
        "                mae = forecast_metrics[\"mae\"]\n",
        "\n",
        "                # Basic stats\n",
        "                self.mse_history.append(mse)\n",
        "                self.mae_history.append(mae)\n",
        "                self.error_memory.append(mse)\n",
        "\n",
        "                self.performance_stats['total_predictions'] += 1\n",
        "                self.performance_stats['avg_mse'] = float(np.mean(self.mse_history))\n",
        "                self.performance_stats['avg_mae'] = float(np.mean(self.mae_history))\n",
        "\n",
        "                # ---------- Forecast Deviation Score (FDS) ----------\n",
        "                baseline_median = self.rolling_stats[\"median\"]\n",
        "                baseline_mad = self.rolling_stats[\"mad\"] if self.rolling_stats[\"mad\"] > 0 else 1e-6\n",
        "                fds = (mse - baseline_median) / (baseline_mad + 1e-8)\n",
        "                fds = float(fds) if fds is not None and not np.isnan(fds) else 0.0\n",
        "\n",
        "\n",
        "                self.last_fds = fds\n",
        "                self.fds_memory.append(fds)\n",
        "                self.recent_fds.append(fds)\n",
        "\n",
        "                # ---------- Window Shift Score (WSS) ----------\n",
        "                if self.baseline_windows is not None and self.window_std > 0:\n",
        "                    wss = (predicted_window - self.window_mean) / (self.window_std + 1e-8)\n",
        "                else:\n",
        "                    wss = 0.0\n",
        "\n",
        "                wss = float(wss)\n",
        "                self.last_wss = wss\n",
        "                self.window_memory.append(predicted_window)\n",
        "                self.recent_windows.append(predicted_window)\n",
        "\n",
        "            # Event (ANOMALY / DRIFT) + Drift indices\n",
        "            event, sev, fdi, wdi = self._check_for_event()\n",
        "            self.last_fdi = fdi\n",
        "            self.last_wdi = wdi\n",
        "\n",
        "            # Save history for reporting\n",
        "            record = {\n",
        "                'timestamp': dt.datetime.now(),\n",
        "                'predicted_window': predicted_window,\n",
        "                'forecast_metrics': forecast_metrics,\n",
        "                'fds': self.last_fds,\n",
        "                'wss': self.last_wss,\n",
        "                'fdi': self.last_fdi,\n",
        "                'wdi': self.last_wdi,\n",
        "                'event_type': event,\n",
        "                'severity': sev\n",
        "            }\n",
        "            self.prediction_history.append(record)\n",
        "\n",
        "            return {\n",
        "                'predicted_window': predicted_window,\n",
        "                'forecast_metrics': forecast_metrics,\n",
        "                'fds': self.last_fds,\n",
        "                'fdi': self.last_fdi,\n",
        "                'wss': self.last_wss,\n",
        "                'wdi': self.last_wdi,\n",
        "                'event_type': event,\n",
        "                'severity': sev,\n",
        "                'performance_stats': self.get_recent_performance()\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {'predicted_window': 20, 'error': str(e)}\n",
        "\n",
        "    # =================== EVENT LOGIC (ANOMALY + DRIFT) ===================\n",
        "\n",
        "    def _check_for_event(self):\n",
        "        \"\"\"\n",
        "        Event detection for the Adaptive Window Agent.\n",
        "\n",
        "        - ANOMALY: deviation of last MSE from baseline (median + k * MAD)\n",
        "        - DRIFT:\n",
        "            * FDI: JSD between recent FDS distribution and baseline FDS\n",
        "            * WDI: JSD between recent window distribution and baseline window distribution\n",
        "        \"\"\"\n",
        "        # Require enough history\n",
        "        if len(self.error_memory) < 30:\n",
        "            return None, 0.0, None, None\n",
        "\n",
        "        last_mse = float(self.error_memory[-1])\n",
        "        live_errors = np.array(self.error_memory)\n",
        "\n",
        "        # ---------- BASELINE STATS ----------\n",
        "        if self.baseline_errors is not None and len(self.baseline_errors) > 10:\n",
        "            base_errors = np.array(self.baseline_errors)\n",
        "            baseline_median = np.median(base_errors)\n",
        "            baseline_mad = np.median(np.abs(base_errors - baseline_median)) + 1e-8\n",
        "        else:\n",
        "            baseline_median = np.median(live_errors)\n",
        "            baseline_mad = np.median(np.abs(live_errors - baseline_median)) + 1e-8\n",
        "\n",
        "        # Update rolling_stats so other components can see latest baseline-ish values\n",
        "        self.rolling_stats[\"median\"] = baseline_median\n",
        "        self.rolling_stats[\"mad\"] = baseline_mad\n",
        "\n",
        "        # ---------- LIVE STATS ----------\n",
        "        live_median = np.median(live_errors)\n",
        "        live_mad = np.median(np.abs(live_errors - live_median)) + 1e-8\n",
        "\n",
        "        # ---------- ANOMALY THRESHOLD ----------\n",
        "        baseline_threshold = baseline_median + self.threshold_k * baseline_mad\n",
        "        live_threshold = live_median + self.threshold_k * live_mad\n",
        "\n",
        "        anomaly_threshold = 0.8 * baseline_threshold + 0.2 * live_threshold\n",
        "\n",
        "        is_anomaly = last_mse > anomaly_threshold\n",
        "\n",
        "        if self.anomaly_cooldown > 0:\n",
        "            self.anomaly_cooldown -= 1\n",
        "            is_anomaly = False\n",
        "        elif is_anomaly:\n",
        "            self.anomaly_cooldown = self.anomaly_cooldown_steps\n",
        "\n",
        "        if is_anomaly:\n",
        "            severity = (last_mse - anomaly_threshold) / (baseline_mad + 1e-6)\n",
        "            severity = float(severity)\n",
        "            self.performance_stats[\"anomaly_events\"] += 1\n",
        "            if self.debug:\n",
        "                print(f\"[ANOMALY] mse={last_mse:.6f}, thr={anomaly_threshold:.6f}, sev={severity:.3f}\")\n",
        "            return \"ANOMALY\", severity, 0.0, 0.0\n",
        "\n",
        "        # ---------- DRIFT (FDI + WDI) ----------\n",
        "        fdi = None\n",
        "        wdi = None\n",
        "\n",
        "        # FDI: JSD over FDS distribution\n",
        "        if self.baseline_fds is not None and len(self.recent_fds) >= 30:\n",
        "            base_fds = np.asarray(self.baseline_fds)\n",
        "            recent_fds = np.asarray(self.recent_fds)\n",
        "\n",
        "            hist_base, bins = np.histogram(base_fds, bins=25, density=True)\n",
        "            hist_recent, _ = np.histogram(recent_fds, bins=bins, density=True)\n",
        "\n",
        "            hist_base = hist_base / (hist_base.sum() + 1e-12)\n",
        "            hist_recent = hist_recent / (hist_recent.sum() + 1e-12)\n",
        "\n",
        "            fdi = float(jensenshannon(hist_base + 1e-12, hist_recent + 1e-12))\n",
        "\n",
        "        # WDI: JSD over window-size distribution\n",
        "        if self.baseline_windows is not None and len(self.recent_windows) >= 30:\n",
        "            base_win = np.asarray(self.baseline_windows)\n",
        "            recent_win = np.asarray(self.recent_windows)\n",
        "\n",
        "            hist_w_base, bins_w = np.histogram(base_win, bins=20, density=True)\n",
        "            hist_w_recent, _ = np.histogram(recent_win, bins=bins_w, density=True)\n",
        "\n",
        "            hist_w_base = hist_w_base / (hist_w_base.sum() + 1e-12)\n",
        "            hist_w_recent = hist_w_recent / (hist_w_recent.sum() + 1e-12)\n",
        "\n",
        "            wdi = float(jensenshannon(hist_w_base + 1e-12, hist_w_recent + 1e-12))\n",
        "\n",
        "        # Decide drift if either index is high\n",
        "        is_drift_fdi = fdi is not None and fdi > self.drift_threshold\n",
        "        is_drift_wdi = wdi is not None and wdi > self.window_drift_threshold\n",
        "\n",
        "        is_drift = is_drift_fdi or is_drift_wdi\n",
        "\n",
        "        if self.drift_cooldown > 0:\n",
        "            self.drift_cooldown -= 1\n",
        "            is_drift = False\n",
        "        else:\n",
        "            if is_drift:\n",
        "                self.consecutive_drift_votes += 1\n",
        "            else:\n",
        "                self.consecutive_drift_votes = 0\n",
        "\n",
        "        if self.consecutive_drift_votes >= 3:\n",
        "            self.consecutive_drift_votes = 0\n",
        "            self.drift_cooldown = self.drift_cooldown_steps\n",
        "            self.performance_stats[\"drift_events\"] += 1\n",
        "            if self.debug:\n",
        "                print(f\"[DRIFT] FDI={fdi:.4f} WDI={wdi:.4f}\")\n",
        "            fdi = float(fdi) if fdi is not None else 0.0\n",
        "            wdi = float(wdi) if wdi is not None else 0.0\n",
        "            return \"DRIFT\", fdi, fdi, wdi\n",
        "\n",
        "        # Make safe for printing\n",
        "        fdi = float(fdi) if fdi is not None else 0.0\n",
        "        wdi = float(wdi) if wdi is not None else 0.0\n",
        "\n",
        "        return None, 0.0, fdi, wdi\n",
        "\n",
        "\n",
        "    # =================== HELPERS ===================\n",
        "\n",
        "    def get_recent_performance(self):\n",
        "        all_preds = list(self.prediction_history)\n",
        "\n",
        "        successful_predictions = [\n",
        "            p for p in all_preds\n",
        "            if p.get('forecast_metrics', {}).get('forecast_success', False)\n",
        "        ]\n",
        "\n",
        "        return {\n",
        "            'total_predictions': len(all_preds),\n",
        "            'successful_predictions': len(successful_predictions),\n",
        "            'success_rate': len(successful_predictions) / max(len(all_preds), 1),\n",
        "            'drift_events': self.performance_stats['drift_events'],\n",
        "            'anomaly_events': self.performance_stats['anomaly_events'],\n",
        "            'retraining_events': self.performance_stats['retraining_events'],\n",
        "            'recent_mse': float(np.mean(list(self.mse_history)[-10:])) if self.mse_history else 0,\n",
        "            'avg_mse': float(np.mean(self.mse_history)) if self.mse_history else 0,\n",
        "            'recent_mae': float(np.mean(list(self.mae_history)[-10:])) if self.mae_history else 0,\n",
        "            'avg_mae': float(np.mean(self.mae_history)) if self.mae_history else 0,\n",
        "            'transformer_fitted': self.transformer_fitted,\n",
        "            'last_fdi': self.last_fdi,\n",
        "            'last_wdi': self.last_wdi,\n",
        "        }\n",
        "\n",
        "    def save_performance_state(self, filepath: str):\n",
        "        \"\"\"Save performance statistics + prediction history to JSON\"\"\"\n",
        "        try:\n",
        "            state = {\n",
        "                'performance_stats': self.performance_stats.copy(),\n",
        "                'prediction_history': list(self.prediction_history)[-100:],\n",
        "                'mse_history': list(self.mse_history),\n",
        "                'mae_history': list(self.mae_history),\n",
        "                'transformer_fitted': self.transformer_fitted\n",
        "            }\n",
        "            with open(filepath, 'w') as f:\n",
        "                json.dump(state, f, indent=2, default=str)\n",
        "            print(f\"✅ Performance state saved to {filepath}\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to save performance state: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "# ==================== PLOTTING ====================\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_target_sensor_forecasts(test_sequences, agent, target_idx=1):\n",
        "    actual_vals = []\n",
        "    forecast_vals = []\n",
        "    event_points = []     # (timestep, event_type)\n",
        "    timesteps_list = []\n",
        "\n",
        "    # ====== COLLECT ALL FORECAST RESULTS ======\n",
        "    for i, seq in enumerate(test_sequences):\n",
        "        result = agent.predict_window_size(seq.flatten(), seq)\n",
        "        fm = result.get(\"forecast_metrics\", {})\n",
        "\n",
        "        if not fm.get(\"forecast_success\", False):\n",
        "            continue\n",
        "\n",
        "        # Extract actual & forecasted value for target sensor\n",
        "        act = np.mean(fm[\"actual_values\"])\n",
        "        pred = np.mean(fm[\"predicted_values\"])\n",
        "\n",
        "        actual_vals.append(act)\n",
        "        forecast_vals.append(pred)\n",
        "        timesteps_list.append(i)\n",
        "\n",
        "        # Track anomaly / drift events\n",
        "        if result.get(\"event_type\"):\n",
        "            event_points.append((i, result[\"event_type\"]))\n",
        "\n",
        "    # ====== PREPARE DATA ======\n",
        "    actual_vals = np.array(actual_vals)\n",
        "    forecast_vals = np.array(forecast_vals)\n",
        "    timesteps = np.array(timesteps_list)\n",
        "\n",
        "    # ====== PLOT ======\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    plt.plot(\n",
        "        timesteps, actual_vals,\n",
        "        label=\"Actual (Sensor V2)\",\n",
        "        marker=\"o\", linestyle=\"-\", color=\"blue\"\n",
        "    )\n",
        "    plt.plot(\n",
        "        timesteps, forecast_vals,\n",
        "        label=\"Forecast (Sensor V2)\",\n",
        "        marker=\"x\", linestyle=\"--\", color=\"green\"\n",
        "    )\n",
        "\n",
        "    # ====== MARK EVENTS WITH CLEAR LEGENDS ======\n",
        "    anomaly_plotted = False\n",
        "    drift_plotted = False\n",
        "\n",
        "    for (t, ev) in event_points:\n",
        "        if ev == \"ANOMALY\":\n",
        "            plt.scatter(\n",
        "                t, actual_vals[timesteps == t],\n",
        "                color=\"red\", marker=\"D\", s=120,\n",
        "                label=\"Anomaly\" if not anomaly_plotted else \"\"\n",
        "            )\n",
        "            anomaly_plotted = True\n",
        "\n",
        "        elif ev == \"DRIFT\":\n",
        "            plt.scatter(\n",
        "                t, actual_vals[timesteps == t],\n",
        "                color=\"orange\", marker=\"^\", s=120,\n",
        "                label=\"Drift\" if not drift_plotted else \"\"\n",
        "            )\n",
        "            drift_plotted = True\n",
        "\n",
        "    # ====== FINAL DECORATION ======\n",
        "    plt.title(\"Forecast vs Actual for Sensor V2 (target_sensor_index = 1)\")\n",
        "    plt.xlabel(\"Sequence Index\")\n",
        "    plt.ylabel(\"Sensor Value\")\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_mse_and_window(test_sequences, agent):\n",
        "    mse_list = []\n",
        "    window_list = []\n",
        "    anomaly_points = []\n",
        "    drift_points = []\n",
        "    persistence_points = []\n",
        "\n",
        "    for i, seq in enumerate(test_sequences):\n",
        "        result = agent.predict_window_size(seq.flatten(), seq)\n",
        "        fm = result.get(\"forecast_metrics\", {})\n",
        "        event = result.get(\"event_type\", None)\n",
        "\n",
        "        # Only count valid forecasts\n",
        "        if not fm.get(\"forecast_success\", False):\n",
        "            mse_list.append(np.nan)\n",
        "            window_list.append(np.nan)\n",
        "            continue\n",
        "\n",
        "        mse = fm.get(\"mse\", np.nan)\n",
        "        window = result.get(\"predicted_window\", np.nan)\n",
        "\n",
        "        mse_list.append(mse)\n",
        "        window_list.append(window)\n",
        "\n",
        "        # Event markers\n",
        "        if event == \"ANOMALY\":\n",
        "            anomaly_points.append((i, mse))\n",
        "        elif event == \"DRIFT\":\n",
        "            drift_points.append((i, mse))\n",
        "\n",
        "        # Method markers\n",
        "        if fm.get(\"method\", \"\") == \"Persistence\":\n",
        "            persistence_points.append((i, mse))\n",
        "\n",
        "    # X-axis\n",
        "    x = np.arange(len(mse_list))\n",
        "\n",
        "    # ============= Create Plot =============\n",
        "    fig, ax1 = plt.subplots(figsize=(14, 6))\n",
        "\n",
        "    # --- MSE Line ---\n",
        "    ax1.plot(x, mse_list, label=\"MSE\", color=\"blue\", linewidth=2)\n",
        "    ax1.set_xlabel(\"Sequence Index\", fontsize=12)\n",
        "    ax1.set_ylabel(\"MSE\", color=\"blue\", fontsize=12)\n",
        "    ax1.tick_params(axis='y', labelcolor='blue')\n",
        "\n",
        "    # --- Anomalies ---\n",
        "    if anomaly_points:\n",
        "        ax1.scatter(\n",
        "            [p[0] for p in anomaly_points],\n",
        "            [p[1] for p in anomaly_points],\n",
        "            color=\"red\", marker=\"X\", s=120, label=\"ANOMALY\"\n",
        "        )\n",
        "\n",
        "    # --- Drift ---\n",
        "    if drift_points:\n",
        "        ax1.scatter(\n",
        "            [p[0] for p in drift_points],\n",
        "            [p[1] for p in drift_points],\n",
        "            color=\"orange\", marker=\"D\", s=100, label=\"DRIFT\"\n",
        "        )\n",
        "\n",
        "    # --- Persistence Fallback ---\n",
        "    if persistence_points:\n",
        "        ax1.scatter(\n",
        "            [p[0] for p in persistence_points],\n",
        "            [p[1] for p in persistence_points],\n",
        "            color=\"green\", marker=\"^\", s=80, label=\"Persistence Used\"\n",
        "        )\n",
        "\n",
        "    # --- Secondary axis for window size ---\n",
        "    ax2 = ax1.twinx()\n",
        "    ax2.plot(\n",
        "        x, window_list,\n",
        "        label=\"Predicted Window Size\",\n",
        "        color=\"purple\",\n",
        "        linewidth=2,\n",
        "        linestyle=\"--\"\n",
        "    )\n",
        "    ax2.set_ylabel(\"Predicted Window Size\", color=\"purple\", fontsize=12)\n",
        "    ax2.tick_params(axis='y', labelcolor='purple')\n",
        "\n",
        "    # Legends\n",
        "    lines1, labels1 = ax1.get_legend_handles_labels()\n",
        "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
        "\n",
        "    ax1.legend(lines1 + lines2, labels1 + labels2, loc=\"upper left\", fontsize=11)\n",
        "\n",
        "    plt.title(\"Forecast Error (MSE) vs Predicted Window Size with Drift & Anomaly Events\",\n",
        "              fontsize=14, weight=\"bold\")\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "###########disgnostics#############\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_mse_drift_anomaly_with_labels(mse_list, drift_flags, anomaly_flags, labels, start=0, end=None):\n",
        "    \"\"\"\n",
        "    Plots:\n",
        "      - MSE curve\n",
        "      - Drift detections\n",
        "      - Anomaly detections\n",
        "      - Label transitions (0=normal, 1=warning, 2=fault) as colored background bands\n",
        "    \"\"\"\n",
        "\n",
        "    if end is None:\n",
        "        end = len(mse_list)\n",
        "\n",
        "    # Slice region\n",
        "    mse = np.array(mse_list[start:end])\n",
        "    drift_flags = np.array(drift_flags[start:end])\n",
        "    anomaly_flags = np.array(anomaly_flags[start:end])\n",
        "    labels = np.array(labels[start:end])\n",
        "\n",
        "    x = np.arange(start, end)\n",
        "\n",
        "    # -------------------- Plot --------------------\n",
        "    plt.figure(figsize=(18, 5))\n",
        "\n",
        "    # 1. Background color for labels\n",
        "    for label_value, color, name in [\n",
        "        (0, \"#d0ffd0\", \"Normal\"),\n",
        "        (1, \"#fff4c2\", \"Warning\"),\n",
        "        (2, \"#ffd6d6\", \"Fault\"),\n",
        "    ]:\n",
        "        regions = np.where(labels == label_value)[0]\n",
        "        if len(regions) > 0:\n",
        "            plt.axvspan(\n",
        "                regions[0] + start,\n",
        "                regions[-1] + start,\n",
        "                color=color,\n",
        "                alpha=0.3,\n",
        "                label=f\"Label {label_value} ({name})\" if label_value in np.unique(labels) else \"\"\n",
        "            )\n",
        "\n",
        "    # 2. MSE curve\n",
        "    plt.plot(x, mse, color=\"blue\", linewidth=1.8, label=\"MSE\")\n",
        "\n",
        "    # 3. Drift events\n",
        "    drift_idx = np.where(drift_flags == 1)[0]\n",
        "    if len(drift_idx) > 0:\n",
        "        plt.scatter(\n",
        "            drift_idx + start, mse[drift_idx],\n",
        "            color=\"orange\", marker=\"^\", s=120,\n",
        "            label=\"DRIFT\"\n",
        "        )\n",
        "\n",
        "    # 4. Anomaly events\n",
        "    anomaly_idx = np.where(anomaly_flags == 1)[0]\n",
        "    if len(anomaly_idx) > 0:\n",
        "        plt.scatter(\n",
        "            anomaly_idx + start, mse[anomaly_idx],\n",
        "            color=\"red\", marker=\"X\", s=140,\n",
        "            label=\"ANOMALY\"\n",
        "        )\n",
        "\n",
        "    # -------------------- Labels --------------------\n",
        "    plt.title(\"MLP/Forecast Agent – MSE vs Drift/Anomaly vs Labels\", fontsize=14)\n",
        "    plt.xlabel(\"Time Step\")\n",
        "    plt.ylabel(\"Forecast MSE\")\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_full_diagnostics(agent, mse_list, win_list, fds_list, fdi_list, wss_list, wdi_list,\n",
        "                          drift_flags, anomaly_flags, labels,\n",
        "                          start=0, end=None):\n",
        "    \"\"\"\n",
        "    Four-panel diagnostic plot:\n",
        "      1) MSE + anomaly + drift + labels\n",
        "      2) FDS (Forecast Deviation Score) + FDI threshold\n",
        "      3) Predicted window size + WSS\n",
        "      4) WDI (Window Drift Index)\n",
        "    \"\"\"\n",
        "\n",
        "    if end is None:\n",
        "        end = len(mse_list)\n",
        "\n",
        "    # Slice everything\n",
        "    x = np.arange(start, end)\n",
        "    mse = np.array(mse_list[start:end])\n",
        "    win = np.array(win_list[start:end])\n",
        "    fds = np.array(fds_list[start:end])\n",
        "    fdi = np.array(fdi_list[start:end])\n",
        "    wss = np.array(wss_list[start:end])\n",
        "    wdi = np.array(wdi_list[start:end])\n",
        "    drift_flags = np.array(drift_flags[start:end])\n",
        "    anomaly_flags = np.array(anomaly_flags[start:end])\n",
        "    labels = np.array(labels[start:end])\n",
        "\n",
        "    # ===========================================\n",
        "    # BUILD FIGURE\n",
        "    # ===========================================\n",
        "    fig, axs = plt.subplots(4, 1, figsize=(22, 18), sharex=True)\n",
        "    fig.suptitle(\"Adaptive Window Agent – Full Diagnostics\", fontsize=18, weight=\"bold\")\n",
        "\n",
        "    # ---------------------------------------------------\n",
        "    # (1) MSE + events + label shading\n",
        "    # ---------------------------------------------------\n",
        "    ax = axs[0]\n",
        "\n",
        "    # Background shading for labels (0 normal, 1 warn, 2 fault)\n",
        "    for label_value, color, name in [\n",
        "        (0, \"#d0ffd0\", \"Normal\"),\n",
        "        (1, \"#fff4c2\", \"Warning\"),\n",
        "        (2, \"#ffd6d6\", \"Fault\"),\n",
        "    ]:\n",
        "        idx = np.where(labels == label_value)[0]\n",
        "        if len(idx) > 0:\n",
        "            ax.axvspan(idx[0] + start, idx[-1] + start, color=color, alpha=0.25)\n",
        "\n",
        "    ax.plot(x, mse, label=\"MSE\", color=\"blue\", linewidth=1.8)\n",
        "\n",
        "    # Events\n",
        "    ax.scatter(x[anomaly_flags == 1], mse[anomaly_flags == 1],\n",
        "               color=\"red\", marker=\"X\", s=120, label=\"ANOMALY\")\n",
        "    ax.scatter(x[drift_flags == 1], mse[drift_flags == 1],\n",
        "               color=\"orange\", marker=\"^\", s=120, label=\"DRIFT\")\n",
        "\n",
        "    ax.set_ylabel(\"MSE\", fontsize=12)\n",
        "    ax.legend(fontsize=12)\n",
        "    ax.grid(alpha=0.3)\n",
        "\n",
        "    # ---------------------------------------------------\n",
        "    # (2) FDS + Drift threshold (FDI)\n",
        "    # ---------------------------------------------------\n",
        "    ax = axs[1]\n",
        "    ax.plot(x, fds, label=\"FDS (Forecast Deviation Score)\", color=\"purple\")\n",
        "\n",
        "    # Optional: Highlight when FDI is above threshold\n",
        "    if agent.drift_threshold:\n",
        "        ax.axhline(agent.threshold_k, color=\"gray\", linestyle=\"--\",\n",
        "                   label=\"Anomaly threshold (k*MAD)\")\n",
        "\n",
        "    # Drift detection marker when FDI rises\n",
        "    ax2 = ax.twinx()\n",
        "    ax2.plot(x, fdi, label=\"FDI (Forecast Drift Index)\", color=\"orange\", linewidth=2, alpha=0.7)\n",
        "    ax2.axhline(agent.drift_threshold, color=\"red\", linestyle=\"--\", alpha=0.5,\n",
        "                label=\"FDI Drift Threshold\")\n",
        "\n",
        "    ax.set_ylabel(\"FDS\", fontsize=12)\n",
        "    ax2.set_ylabel(\"FDI\", fontsize=12, color=\"orange\")\n",
        "    ax.grid(alpha=0.3)\n",
        "\n",
        "    # Legends merged\n",
        "    h1, l1 = ax.get_legend_handles_labels()\n",
        "    h2, l2 = ax2.get_legend_handles_labels()\n",
        "    ax.legend(h1 + h2, l1 + l2, fontsize=12, loc=\"upper left\")\n",
        "\n",
        "    # ---------------------------------------------------\n",
        "    # (3) Window size + WSS\n",
        "    # ---------------------------------------------------\n",
        "    ax = axs[2]\n",
        "    ax.plot(x, win, color=\"green\", label=\"Predicted Window Size (W_t)\")\n",
        "\n",
        "    ax2 = ax.twinx()\n",
        "    ax2.plot(x, wss, color=\"blue\", linestyle=\"--\", label=\"WSS (Window Shift Score)\")\n",
        "\n",
        "    ax.set_ylabel(\"Window Size\", fontsize=12)\n",
        "    ax2.set_ylabel(\"WSS\", fontsize=12, color=\"blue\")\n",
        "    ax.grid(alpha=0.3)\n",
        "\n",
        "    h1, l1 = ax.get_legend_handles_labels()\n",
        "    h2, l2 = ax2.get_legend_handles_labels()\n",
        "    ax.legend(h1 + h2, l1 + l2, fontsize=12, loc=\"upper left\")\n",
        "\n",
        "    # ---------------------------------------------------\n",
        "    # (4) WDI (Window Drift Index)\n",
        "    # ---------------------------------------------------\n",
        "    ax = axs[3]\n",
        "    ax.plot(x, wdi, color=\"brown\", linewidth=2, label=\"WDI (Window Drift Index)\")\n",
        "    ax.axhline(agent.window_drift_threshold, color=\"red\", linestyle=\"--\",\n",
        "               label=\"WDI Drift Threshold\")\n",
        "\n",
        "    ax.set_ylabel(\"WDI\", fontsize=12)\n",
        "    ax.set_xlabel(\"Time Step\", fontsize=14)\n",
        "    ax.grid(alpha=0.3)\n",
        "    ax.legend(fontsize=12)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def safe(x, default=0.0):\n",
        "    \"\"\"\n",
        "    Safely convert None / NaN to a printable float.\n",
        "    \"\"\"\n",
        "    if x is None:\n",
        "        return default\n",
        "    if isinstance(x, float) and np.isnan(x):\n",
        "        return default\n",
        "    return x\n",
        "# ==================== MAIN TEST LOOP ====================\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # 0. INITIALISE AGENT\n",
        "    # -------------------------------------------------\n",
        "    agent = AdaptiveWindowAgent(\n",
        "        model_path=\"/content/drive/MyDrive/PHD/2025/DGRNet-MLP-Versions/METROPM_MLP_model_10Sec.keras\"\n",
        "    )\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # 1. LOAD DATA + MASK + LABELS\n",
        "    # -------------------------------------------------\n",
        "    data_path      = \"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/multivariate_long_sequences-TRAIN-10Sec-DIRECT-VAR.npy\"\n",
        "    label_path     = \"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/window_labels_3class.npy\"\n",
        "    test_mask_path = \"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/test_mask.npy\"\n",
        "\n",
        "    print(\"Loading data...\")\n",
        "    data     = np.load(data_path)\n",
        "    labels   = np.load(label_path)\n",
        "    tmask    = np.load(test_mask_path).astype(bool)\n",
        "\n",
        "    # APPLY MASK\n",
        "    test_sequences = data[tmask]\n",
        "    test_labels    = labels[tmask]\n",
        "\n",
        "    test_samples = min(1000, len(test_sequences))\n",
        "    test_sequences = test_sequences[:test_samples]\n",
        "    test_labels    = test_labels[:test_samples]\n",
        "\n",
        "    print(f\"Loaded TEST: {test_sequences.shape}, labels: {test_labels.shape}\")\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # 2. TRACKING ARRAYS FOR PLOTS\n",
        "    # -------------------------------------------------\n",
        "    mse_list = []\n",
        "    win_list = []\n",
        "    drift_flags = []\n",
        "    anomaly_flags = []\n",
        "\n",
        "    # NEW ARRAYS FOR NEW METRICS\n",
        "    fds_list = []   # Forecast Deviation Score\n",
        "    fdi_list = []   # Forecast Drift Index\n",
        "    wss_list = []   # Window Shift Score\n",
        "    wdi_list = []   # Window Drift Index\n",
        "\n",
        "    print(\"\\nStarting real-time forecasting...\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # 3. MAIN LOOP\n",
        "    # -------------------------------------------------\n",
        "    for i, sequence_3d in enumerate(test_sequences, start=1):\n",
        "\n",
        "        features = sequence_3d.flatten()\n",
        "        result = agent.predict_window_size(features, sequence_3d)\n",
        "\n",
        "        fm = result.get(\"forecast_metrics\", {})\n",
        "        event = result.get(\"event_type\", None)\n",
        "\n",
        "        # If forecast failed → fill placeholders\n",
        "        if not fm.get(\"forecast_success\", False):\n",
        "            mse_list.append(np.nan)\n",
        "            win_list.append(np.nan)\n",
        "            drift_flags.append(0)\n",
        "            anomaly_flags.append(0)\n",
        "\n",
        "            fds_list.append(np.nan)\n",
        "            fdi_list.append(np.nan)\n",
        "            wss_list.append(np.nan)\n",
        "            wdi_list.append(np.nan)\n",
        "\n",
        "            print(f\"[{i}] Forecast failed\")\n",
        "            continue\n",
        "\n",
        "        # -----------------------------\n",
        "        # Extract forecast metrics\n",
        "        # -----------------------------\n",
        "        mse_val = fm[\"mse\"]\n",
        "        win_val = result[\"predicted_window\"]\n",
        "\n",
        "        mse_list.append(mse_val)\n",
        "        win_list.append(win_val)\n",
        "\n",
        "        # -----------------------------\n",
        "        # Extract new DRIFT/ANOMALY metrics\n",
        "        # -----------------------------\n",
        "        fds_list.append(result.get(\"fds\", np.nan))\n",
        "        fdi_list.append(result.get(\"fdi\", np.nan))\n",
        "        wss_list.append(result.get(\"wss\", np.nan))\n",
        "        wdi_list.append(result.get(\"wdi\", np.nan))\n",
        "\n",
        "        drift_flags.append(1 if event == \"DRIFT\" else 0)\n",
        "        anomaly_flags.append(1 if event == \"ANOMALY\" else 0)\n",
        "\n",
        "        # Short print for monitoring\n",
        "        print(\n",
        "            f\"[{i:03d}] \"\n",
        "            f\"win={win_val:2d} \"\n",
        "            f\"| mse={mse_val:.6f} \"\n",
        "            f\"| FDS={safe(fds_list[-1]):.3f} \"\n",
        "            f\"| FDI={safe(fdi_list[-1]):.3f} \"\n",
        "            f\"| WSS={safe(wss_list[-1]):.3f} \"\n",
        "            f\"| WDI={safe(wdi_list[-1]):.3f} \"\n",
        "            f\"| event={event}\"\n",
        "        )\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # 4. SUMMARY\n",
        "    # -------------------------------------------------\n",
        "    print(\"\\n=== FINAL SUMMARY ===\")\n",
        "    perf = agent.get_recent_performance()\n",
        "    for k, v in perf.items():\n",
        "        print(f\"{k}: {v}\")\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # 5. PLOTTING\n",
        "    # -------------------------------------------------\n",
        "\n",
        "    # Legacy plot\n",
        "    plot_mse_and_window(test_sequences, agent)\n",
        "\n",
        "    # NEW 4-panel diagnostics plot\n",
        "    plot_full_diagnostics(\n",
        "        agent,\n",
        "        mse_list, win_list,\n",
        "        fds_list, fdi_list,\n",
        "        wss_list, wdi_list,\n",
        "        drift_flags, anomaly_flags, test_labels,\n",
        "        start=0, end=test_samples\n",
        "    )\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # 6. SAVE STATE\n",
        "    # -------------------------------------------------\n",
        "    agent.save_performance_state(\"real_data_test_results.json\")\n",
        "    print(\"Saved test results.\")\n",
        "\n",
        "# # ########################### BUILD BASELINE WITH NORMAL DATA -- NEED IT ONLY ONCE ###########################\n",
        "\n",
        "# import numpy as np\n",
        "# import pickle\n",
        "# from tqdm import trange\n",
        "\n",
        "# # paths\n",
        "# data_path  = \"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/multivariate_long_sequences-TRAIN-10Sec-DIRECT-VAR.npy\"\n",
        "# label_path = \"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/window_labels_3class.npy\"\n",
        "\n",
        "# data   = np.load(data_path)\n",
        "# labels = np.load(label_path)\n",
        "\n",
        "# # keep only NORMAL samples\n",
        "# normal_mask = labels == 0\n",
        "# normal_sequences = data[normal_mask]\n",
        "\n",
        "# print(\"Using NORMAL sequences for baseline:\", len(normal_sequences))\n",
        "\n",
        "# # IMPORTANT: use the SAME agent as runtime\n",
        "# agent = AdaptiveWindowAgent(\n",
        "#     model_path=\"/content/drive/MyDrive/PHD/2025/DGRNet-MLP-Versions/METROPM_MLP_model_10Sec.keras\"\n",
        "# )\n",
        "\n",
        "# baseline_errors = []\n",
        "# baseline_windows = []\n",
        "\n",
        "# # -------- BASELINE LOOP --------\n",
        "# for i in trange(min(5000, len(normal_sequences))):\n",
        "#     seq = normal_sequences[i]\n",
        "#     features = seq.flatten()\n",
        "\n",
        "#     # Call normal pipeline\n",
        "#     result = agent.predict_window_size(features, seq)\n",
        "#     fm = result.get(\"forecast_metrics\", {})\n",
        "\n",
        "#     # ✅ CHANGE: baseline error now comes from NSP MSE\n",
        "#     if fm.get(\"forecast_success\", False) and fm.get(\"method\") == \"NSP_LSTM\":\n",
        "#         baseline_errors.append(fm[\"mse\"])\n",
        "#         baseline_windows.append(result[\"predicted_window\"])\n",
        "\n",
        "# baseline_errors  = np.asarray(baseline_errors)\n",
        "# baseline_windows = np.asarray(baseline_windows)\n",
        "\n",
        "# # ------------------ STATS ------------------\n",
        "# window_mean = float(np.mean(baseline_windows))\n",
        "# window_std  = float(np.std(baseline_windows) + 1e-8)\n",
        "\n",
        "# hist_counts, hist_bins = np.histogram(baseline_windows, bins=20, density=True)\n",
        "\n",
        "# baseline_stats = {\n",
        "#     # ERROR DISTRIBUTION (NSP)\n",
        "#     \"baseline_errors\": baseline_errors,\n",
        "#     \"median\": float(np.median(baseline_errors)),\n",
        "#     \"mad\": float(np.median(np.abs(baseline_errors - np.median(baseline_errors)))),\n",
        "\n",
        "#     # WINDOW DISTRIBUTION (MLP)\n",
        "#     \"baseline_windows\": baseline_windows.tolist(),\n",
        "#     \"window_mean\": window_mean,\n",
        "#     \"window_std\": window_std,\n",
        "\n",
        "#     # HISTOGRAM FOR WDI\n",
        "#     \"window_hist_bins\": hist_bins.tolist(),\n",
        "#     \"window_hist_counts\": hist_counts.tolist(),\n",
        "# }\n",
        "\n",
        "# save_path = \"/content/drive/MyDrive/PHD/2025/DGRNet-MLP-Versions/METROPM_MLP_baseline.pkl\"\n",
        "\n",
        "# with open(save_path, \"wb\") as f:\n",
        "#     pickle.dump(baseline_stats, f)\n",
        "\n",
        "# print(\"✅ CLEAN NSP BASELINE SAVED:\", save_path)\n",
        "\n",
        "# print(\"\\n---- ERROR (NSP) ----\")\n",
        "# print(\"Median:\", baseline_stats[\"median\"])\n",
        "# print(\"MAD:\", baseline_stats[\"mad\"])\n",
        "# print(\"Count:\", len(baseline_errors))\n",
        "\n",
        "# print(\"\\n---- WINDOW (MLP) ----\")\n",
        "# print(\"Mean:\", window_mean)\n",
        "# print(\"Std:\", window_std)\n",
        "# print(\"Min:\", np.min(baseline_windows))\n",
        "# print(\"Max:\", np.max(baseline_windows))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "nxij89jyeebm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "mount_file_id": "https://github.com/supriyag123/PHD_Pub/blob/main/AGENTIC-MODULE3-AdaptiveWindowAgent.ipynb",
      "authorship_tag": "ABX9TyOBngh2ml+vhwAPQe0rDy7y",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}