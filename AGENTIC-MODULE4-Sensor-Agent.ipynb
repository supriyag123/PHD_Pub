{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supriyag123/PHD_Pub/blob/main/AGENTIC-MODULE4-Sensor-Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HoP7OuWNxlsJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4fd4909-c480-4040-93c1-02734abd6bd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "from collections import deque\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Tuple\n",
        "import warnings\n",
        "import pandas as pd\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ML libraries\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from scipy import stats\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "\n",
        "# Deep learning\n",
        "try:\n",
        "    from tensorflow.keras.models import load_model\n",
        "    KERAS_AVAILABLE = True\n",
        "except ImportError:\n",
        "    KERAS_AVAILABLE = False\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        "    roc_auc_score,\n",
        "    average_precision_score,\n",
        "    precision_recall_curve,\n",
        "    roc_curve\n",
        ")\n",
        "\n",
        "# =====================================================\n",
        "# ROBUST SENSOR AGENT - Observes ONE sensor with AE model\n",
        "# =====================================================\n",
        "\n",
        "class RobustSensorAgent:\n",
        "    \"\"\"\n",
        "    Robust Sensor Agent for ONE sensor with advanced anomaly & drift detection.\n",
        "\n",
        "    Loads pretrained AE model + metadata (scaler, baseline errors, rolling stats).\n",
        "    Computes anomaly score via reconstruction error, applies adaptive thresholding,\n",
        "    drift detection, and outputs robust anomaly/drift/retrain flags.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 sensor_id: int,\n",
        "                 model_path: str = None,\n",
        "                 window_length: int = 10, #K\n",
        "                 memory_size: int = 1000,\n",
        "                 threshold_k: float = 2.0,\n",
        "                 drift_threshold: float = 0.1,\n",
        "                warmup_steps: int = 100):    # <â”€â”€ NEW PARAM\n",
        "\n",
        "        self.sensor_id = sensor_id\n",
        "        self.window_length = window_length\n",
        "        self.threshold_k = threshold_k\n",
        "        self.drift_threshold = drift_threshold\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "        # Model & metadata\n",
        "        self.model = None\n",
        "        self.scaler = None\n",
        "        self.is_model_loaded = False\n",
        "\n",
        "        # Buffers\n",
        "        self.error_memory = deque(maxlen=memory_size)\n",
        "        self.data_memory = deque(maxlen=memory_size)\n",
        "        self.recent_errors = deque(maxlen=100)\n",
        "\n",
        "        # Rolling stats\n",
        "        self.rolling_stats = {\n",
        "            'median': 0.0,\n",
        "            'mad': 1.0,\n",
        "            'mean': 0.0,   # backward compatibility\n",
        "            'std': 1.0,    # backward compatibility\n",
        "            'q95': 0.0,\n",
        "            'q99': 0.0\n",
        "        }\n",
        "        self.baseline_errors = None\n",
        "\n",
        "        # Counters\n",
        "        self.total_processed = 0\n",
        "        self.anomalies_detected = 0\n",
        "        self.drift_detected_count = 0\n",
        "        self.last_stats_update = datetime.now()\n",
        "\n",
        "        self.anomaly_cooldown = 0\n",
        "        self.drift_cooldown = 0\n",
        "\n",
        "        self.anomaly_cooldown_steps = 5    # you can tune\n",
        "        self.drift_cooldown_steps = 10     # you can tune\n",
        "\n",
        "        self.consecutive_drift_votes = 0\n",
        "        self.consecutive_anomaly_votes = 0\n",
        "\n",
        "        if model_path:\n",
        "            self.load_model(model_path)\n",
        "\n",
        "    def load_model(self, model_path: str) -> bool:\n",
        "        \"\"\"Load pretrained AE model + metadata.\"\"\"\n",
        "        try:\n",
        "            if KERAS_AVAILABLE and model_path.endswith('.h5'):\n",
        "                self.model = load_model(model_path, compile=False)\n",
        "\n",
        "                # Correct metadata file\n",
        "                metadata_path = model_path.replace('_model.h5', '_metadata.pkl')\n",
        "\n",
        "                if os.path.exists(metadata_path):\n",
        "                    with open(metadata_path, 'rb') as f:\n",
        "                        metadata = pickle.load(f)\n",
        "\n",
        "                    baseline = metadata.get('baseline_stats', None)\n",
        "\n",
        "                    if baseline is not None:\n",
        "                        # Initialize rolling stats from training\n",
        "                        # Load robust baseline stats\n",
        "                        self.rolling_stats['median'] = baseline.get('median')\n",
        "                        self.rolling_stats['mad']    = baseline.get('mad')\n",
        "\n",
        "                        # Backward compatibility for other parts of system\n",
        "                        self.rolling_stats['mean'] = self.rolling_stats['median']\n",
        "                        self.rolling_stats['std']  = self.rolling_stats['mad']\n",
        "\n",
        "                        self.rolling_stats['q95']  = baseline['q95']\n",
        "                        self.rolling_stats['q99']  = baseline['q99']\n",
        "\n",
        "                        # Save baseline distribution for drift detection\n",
        "                        self.baseline_errors = np.array(baseline['baseline_errors'])\n",
        "\n",
        "                # AE was trained on raw, NOT scaled\n",
        "                self.scaler = None\n",
        "\n",
        "            else:\n",
        "                raise ValueError(\"Unsupported model format â€“ expecting .h5 AE model\")\n",
        "\n",
        "            self.is_model_loaded = True\n",
        "            print(f\"âœ… AE model loaded for sensor {self.sensor_id}\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Failed to load AE model for sensor {self.sensor_id}: {e}\")\n",
        "            return False\n",
        "\n",
        "\n",
        "    def observe(self, sensor_subsequence: np.ndarray) -> Dict:\n",
        "        \"\"\"Observe subsequence [window_length] and return anomaly/drift flags.\"\"\"\n",
        "        if not self.is_model_loaded:\n",
        "            return {\"sensor_id\": self.sensor_id, \"error\": \"no_model_loaded\", \"timestamp\": datetime.now()}\n",
        "\n",
        "        if len(sensor_subsequence) != self.window_length:\n",
        "            return {\"sensor_id\": self.sensor_id,\n",
        "                    \"error\": f\"invalid_length_expected_{self.window_length}_got_{len(sensor_subsequence)}\",\n",
        "                    \"timestamp\": datetime.now()}\n",
        "\n",
        "        # 1. Anomaly score\n",
        "        anomaly_score = self._compute_robust_anomaly_score(sensor_subsequence)\n",
        "\n",
        "        # 2. Update memory\n",
        "        self.data_memory.append(sensor_subsequence.copy())\n",
        "        self.error_memory.append(anomaly_score)\n",
        "        self.recent_errors.append(anomaly_score)\n",
        "\n",
        "        # 3\n",
        "\n",
        "        # --------------- WARM-UP PHASE -----------------\n",
        "        # During warm-up, rolling stats ignore live data and stay fixed\n",
        "        if self.total_processed < self.warmup_steps:\n",
        "            med = np.median(self.baseline_errors)\n",
        "            mad = np.median(np.abs(self.baseline_errors - med)) + 1e-8\n",
        "\n",
        "            self.rolling_stats['median'] = med\n",
        "            self.rolling_stats['mad'] = mad\n",
        "            self.rolling_stats['mean'] = med     # backward compatibility\n",
        "            self.rolling_stats['std'] = mad\n",
        "        else:\n",
        "            # After warm-up, rolling stats evolve normally\n",
        "            if len(self.error_memory) >= 50 and len(self.error_memory) % 10 == 0:\n",
        "                self._update_rolling_stats(list(self.error_memory)[-50:])\n",
        "\n",
        "        # 4. Flags\n",
        "        is_anomaly = self._check_adaptive_anomaly(anomaly_score)\n",
        "        drift_flag = self._check_advanced_drift()\n",
        "        needs_retrain = self._check_retrain_need()\n",
        "        confidence = self._compute_robust_confidence(anomaly_score)\n",
        "\n",
        "        # 5. Update counters\n",
        "        self.total_processed += 1\n",
        "        if is_anomaly: self.anomalies_detected += 1\n",
        "        if drift_flag: self.drift_detected_count += 1\n",
        "\n",
        "        return {\n",
        "            \"sensor_id\": self.sensor_id,\n",
        "            \"timestamp\": datetime.now(),\n",
        "            \"is_anomaly\": bool(is_anomaly),\n",
        "            \"drift_flag\": bool(drift_flag),\n",
        "            \"needs_retrain_flag\": bool(needs_retrain),\n",
        "            \"anomaly_score\": float(anomaly_score),\n",
        "            \"confidence\": float(confidence),\n",
        "            \"threshold_used\": float(self.rolling_stats['median'] + self.threshold_k * self.rolling_stats['mad']),\n",
        "            \"anomaly_rate\": self.anomalies_detected / max(1, self.total_processed),\n",
        "            \"drift_rate\": self.drift_detected_count / max(1, self.total_processed)\n",
        "        }\n",
        "\n",
        "    def _compute_robust_anomaly_score(self, subsequence: np.ndarray) -> float:\n",
        "        \"\"\"Compute reconstruction error using AE model on RAW values.\"\"\"\n",
        "        try:\n",
        "            # Ensure shape: [1, window_length, 1]\n",
        "            X = subsequence.reshape(1, self.window_length, 1)\n",
        "            reconstruction = self.model.predict(X, verbose=0)\n",
        "\n",
        "            error = mean_squared_error(\n",
        "                subsequence.flatten(),\n",
        "                reconstruction.flatten()\n",
        "            )\n",
        "            return max(0.0, error)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ AE inference failed for sensor {self.sensor_id}: {e}\")\n",
        "            # Fallback: variance of raw subsequence\n",
        "            return float(np.var(subsequence))\n",
        "\n",
        "    def _update_rolling_stats(self, errors: List[float]):\n",
        "        errors_array = np.array(errors)\n",
        "\n",
        "        median = np.median(errors_array)\n",
        "        mad = np.median(np.abs(errors_array - median)) + 1e-8  # avoid zero\n",
        "\n",
        "        # Store\n",
        "        self.rolling_stats['median'] = median\n",
        "        self.rolling_stats['mad'] = mad\n",
        "\n",
        "        # Backward compatibility fields (for plotting)\n",
        "        self.rolling_stats['mean'] = median\n",
        "        self.rolling_stats['std'] = mad\n",
        "\n",
        "        # Percentile bands (unchanged; good for drift & visualization)\n",
        "        self.rolling_stats['q95'] = np.percentile(errors_array, 95)\n",
        "        self.rolling_stats['q99'] = np.percentile(errors_array, 99)\n",
        "\n",
        "        self.last_stats_update = datetime.now()\n",
        "\n",
        "    def _check_adaptive_anomaly(self, score: float) -> bool:\n",
        "        median = self.rolling_stats.get('median', self.rolling_stats['mean'])\n",
        "        mad = self.rolling_stats.get('mad', self.rolling_stats['std'])\n",
        "        threshold = median + self.threshold_k * mad\n",
        "        is_anomaly_now = score > threshold\n",
        "\n",
        "        # Cooldown active â†’ suppress anomaly\n",
        "        if self.anomaly_cooldown > 0:\n",
        "            self.anomaly_cooldown -= 1\n",
        "            return False\n",
        "\n",
        "        # No cooldown and anomaly happened â†’ activate cooldown\n",
        "        if is_anomaly_now:\n",
        "            self.anomaly_cooldown = self.anomaly_cooldown_steps\n",
        "            return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def _check_advanced_drift(self) -> bool:\n",
        "        if self.baseline_errors is None or len(self.recent_errors) < 30:\n",
        "            return False\n",
        "        try:\n",
        "            hist_baseline, bins = np.histogram(self.baseline_errors, bins=20, density=True)\n",
        "            hist_recent, _ = np.histogram(list(self.recent_errors), bins=bins, density=True)\n",
        "            hist_baseline += 1e-10; hist_recent += 1e-10\n",
        "            hist_baseline /= hist_baseline.sum(); hist_recent /= hist_recent.sum()\n",
        "            js_divergence = jensenshannon(hist_baseline, hist_recent)\n",
        "            is_drift_now = js_divergence > self.drift_threshold\n",
        "\n",
        "            # Cooldown active â†’ suppress\n",
        "            if self.drift_cooldown > 0:\n",
        "                self.drift_cooldown -= 1\n",
        "                return False\n",
        "\n",
        "            # Multi-step confirmation: require 3 drift votes in last few steps\n",
        "            if is_drift_now:\n",
        "                self.consecutive_drift_votes += 1\n",
        "            else:\n",
        "                self.consecutive_drift_votes = 0\n",
        "\n",
        "            if self.consecutive_drift_votes >= 3:\n",
        "                self.drift_cooldown = self.drift_cooldown_steps\n",
        "                self.consecutive_drift_votes = 0\n",
        "                return True\n",
        "\n",
        "            return False\n",
        "\n",
        "        except Exception:\n",
        "            try:\n",
        "                _, p_value = stats.ks_2samp(self.baseline_errors, list(self.recent_errors))\n",
        "                return p_value < 0.05\n",
        "            except:\n",
        "                return False\n",
        "\n",
        "    def _check_retrain_need(self) -> bool:\n",
        "        if len(self.error_memory) < 100: return False\n",
        "        recent_errors = list(self.error_memory)[-50:]\n",
        "        threshold = self.rolling_stats['mean'] + self.threshold_k * self.rolling_stats['std']\n",
        "        anomaly_rate = sum(1 for e in recent_errors if e > threshold) / len(recent_errors)\n",
        "        criteria = [\n",
        "            anomaly_rate > 0.3,\n",
        "            self.drift_detected_count > 0.1 * self.total_processed,\n",
        "            np.mean(recent_errors) > 2.0 * self.rolling_stats['mean'] if len(recent_errors) > 0 else False,\n",
        "            (datetime.now() - self.last_stats_update).days > 7\n",
        "        ]\n",
        "        return sum(criteria) >= 2\n",
        "\n",
        "    def _compute_robust_confidence(self, score: float) -> float:\n",
        "        median = self.rolling_stats.get('median')\n",
        "        mad = self.rolling_stats.get('mad')\n",
        "\n",
        "        if mad == 0:\n",
        "            return 0.5\n",
        "\n",
        "        threshold = median + self.threshold_k * mad\n",
        "\n",
        "        z = (score - threshold) / mad  # how far beyond threshold?\n",
        "\n",
        "        # Smooth probability-like mapping\n",
        "        confidence = 1 / (1 + np.exp(-z))\n",
        "\n",
        "        return float(np.clip(confidence, 0.0, 1.0))\n",
        "\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# ROBUST MASTER AGENT\n",
        "# =====================================================\n",
        "\n",
        "class RobustMasterAgent:\n",
        "    \"\"\"Aggregates sensor results, makes system-level anomaly/drift/retrain decisions.\"\"\"\n",
        "    def __init__(self, sensor_agents: List[RobustSensorAgent],\n",
        "                 system_anomaly_threshold: float = 0.3,\n",
        "                 drift_threshold: float = 0.2,\n",
        "                 retrain_threshold: float = 0.15):\n",
        "        self.sensor_agents = sensor_agents\n",
        "        self.num_sensors = len(sensor_agents)\n",
        "        self.system_anomaly_threshold = system_anomaly_threshold\n",
        "        self.drift_threshold = drift_threshold\n",
        "        self.retrain_threshold = retrain_threshold\n",
        "\n",
        "    def process_system_input(self, system_subsequence: np.ndarray) -> Dict:\n",
        "        \"\"\"Process [window_length, num_sensors] multivariate subsequence.\"\"\"\n",
        "        timestamp = datetime.now()\n",
        "        if system_subsequence.shape[1] != self.num_sensors:\n",
        "            return {\"error\": f\"Expected {self.num_sensors} sensors, got {system_subsequence.shape[1]}\",\n",
        "                    \"timestamp\": timestamp}\n",
        "\n",
        "        # 1. Collect sensor observations\n",
        "        sensor_results = []\n",
        "        for i, agent in enumerate(self.sensor_agents):\n",
        "            sensor_data = system_subsequence[:, i]\n",
        "            result = agent.observe(sensor_data)\n",
        "            sensor_results.append(result)\n",
        "\n",
        "        # 2. Simple aggregation\n",
        "        anomalies = sum(1 for r in sensor_results if r.get(\"is_anomaly\"))\n",
        "        drifts = sum(1 for r in sensor_results if r.get(\"drift_flag\"))\n",
        "        retrains = sum(1 for r in sensor_results if r.get(\"needs_retrain_flag\"))\n",
        "\n",
        "        anomaly_rate = anomalies / max(1, self.num_sensors)\n",
        "        drift_rate = drifts / max(1, self.num_sensors)\n",
        "        retrain_rate = retrains / max(1, self.num_sensors)\n",
        "\n",
        "        system_decisions = {\n",
        "            \"system_anomaly\": anomaly_rate >= self.system_anomaly_threshold,\n",
        "            \"system_drift\": drift_rate >= self.drift_threshold,\n",
        "            \"system_needs_retrain\": retrain_rate >= self.retrain_threshold,\n",
        "            \"anomaly_rate\": anomaly_rate,\n",
        "            \"drift_rate\": drift_rate,\n",
        "            \"retrain_rate\": retrain_rate\n",
        "        }\n",
        "\n",
        "        return {\n",
        "            \"timestamp\": timestamp,\n",
        "            \"sensor_results\": sensor_results,\n",
        "            \"system_decisions\": system_decisions\n",
        "        }\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# SYSTEM CREATION\n",
        "# =====================================================\n",
        "\n",
        "def create_robust_system(num_sensors: int, models_dir: str, win_length: int, warmup_steps: int = 100) -> Tuple[List[RobustSensorAgent], RobustMasterAgent]:\n",
        "    \"\"\"Create robust sensor system loading AE models + metadata.\"\"\"\n",
        "    print(f\"ðŸš€ Creating robust system with {num_sensors} sensors\")\n",
        "    sensor_agents = []\n",
        "    for sensor_id in range(num_sensors):\n",
        "        model_path = os.path.join(models_dir, f\"sensor_{sensor_id}_model.h5\")\n",
        "        agent = RobustSensorAgent(sensor_id=sensor_id,\n",
        "                                  model_path=model_path if os.path.exists(model_path) else None,\n",
        "                                  window_length=win_length,\n",
        "                                  memory_size=1000,\n",
        "                                  threshold_k=2.0,\n",
        "                                  drift_threshold=0.1,\n",
        "                                  warmup_steps=warmup_steps)       # <â”€â”€ NEW\n",
        "        sensor_agents.append(agent)\n",
        "\n",
        "    master = RobustMasterAgent(sensor_agents=sensor_agents,\n",
        "                               system_anomaly_threshold=0.3,\n",
        "                               drift_threshold=0.2,\n",
        "                               retrain_threshold=0.15)\n",
        "    print(f\"âœ… Created system: {len([a for a in sensor_agents if a.is_model_loaded])}/{num_sensors} models loaded\")\n",
        "\n",
        "    return sensor_agents, master\n",
        "\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def plot_sensor_drift_trends(sensor_logs, metadata_list, window_size=20):\n",
        "    \"\"\"\n",
        "    Plot reconstruction error and drift/anomaly markers for each sensor.\n",
        "    Uses robust baselines: median + MAD.\n",
        "    \"\"\"\n",
        "\n",
        "    num_sensors = len(sensor_logs)\n",
        "    cols = 3\n",
        "    rows = int(np.ceil(num_sensors / cols))\n",
        "\n",
        "    plt.figure(figsize=(18, 5 * rows))\n",
        "\n",
        "    for sid, log in enumerate(sensor_logs):\n",
        "\n",
        "        scores    = np.array(log[\"scores\"])\n",
        "        anomalies = np.array(log[\"anomalies\"])\n",
        "        drift     = np.array(log[\"drift\"])\n",
        "\n",
        "        # --- Extract robust baseline stats ---\n",
        "        median = metadata_list[sid].get(\"median\", metadata_list[sid].get(\"mean\", 0))\n",
        "        mad    = metadata_list[sid].get(\"mad\", metadata_list[sid].get(\"std\", 1))\n",
        "        q95    = metadata_list[sid].get(\"q95\", 0)\n",
        "        q99    = metadata_list[sid].get(\"q99\", 0)\n",
        "\n",
        "        threshold = median + 2 * mad\n",
        "\n",
        "        ema = pd.Series(scores).ewm(span=window_size, adjust=False).mean()\n",
        "\n",
        "        ax = plt.subplot(rows, cols, sid + 1)\n",
        "\n",
        "        # --- Raw reconstruction error ---\n",
        "        ax.plot(scores, color=\"blue\", alpha=0.35, label=\"Reconstruction Error\")\n",
        "\n",
        "        # --- EMA trend ---\n",
        "        ax.plot(ema, color=\"black\", linewidth=2, label=\"EMA Trend\")\n",
        "\n",
        "        # --- Robust baseline lines ---\n",
        "        ax.axhline(median, color=\"green\", linestyle=\"--\", label=\"Median (Baseline)\")\n",
        "        ax.axhline(threshold, color=\"red\", linestyle=\"--\", label=\"Median + 2*MAD\")\n",
        "        ax.axhline(q95, color=\"orange\", linestyle=\":\", label=\"95th Percentile\")\n",
        "        ax.axhline(q99, color=\"purple\", linestyle=\":\", label=\"99th Percentile\")\n",
        "\n",
        "        # --- Mark anomalies ---\n",
        "        anomaly_idx = np.where(anomalies == 1)[0]\n",
        "        ax.scatter(anomaly_idx, scores[anomaly_idx], color=\"red\", s=40,\n",
        "                   marker=\"x\", label=\"Anomaly\" if sid == 0 else \"\")\n",
        "\n",
        "        # --- Mark drifts ---\n",
        "        drift_idx = np.where(drift == 1)[0]\n",
        "        ax.scatter(drift_idx, scores[drift_idx], color=\"purple\", s=60,\n",
        "                   marker=\"D\", label=\"Drift\" if sid == 0 else \"\")\n",
        "\n",
        "        ax.set_title(f\"Sensor {sid} Drift Trend\", fontsize=12)\n",
        "        ax.set_xlabel(\"Time Step\")\n",
        "        ax.set_ylabel(\"Reconstruction Error\")\n",
        "        ax.grid(alpha=0.3)\n",
        "\n",
        "        if sid == 0:\n",
        "            ax.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_system_level(y_true_bin, y_pred_bin, y_scores, title_prefix=\"System\"):\n",
        "    \"\"\"\n",
        "    y_true_bin : list/array of 0/1 (0=normal, 1=fault)\n",
        "    y_pred_bin : list/array of 0/1 from your system_anomaly\n",
        "    y_scores   : list/array of continuous scores (e.g., anomaly_rate or max score)\n",
        "    \"\"\"\n",
        "\n",
        "    y_true_bin = np.array(y_true_bin)\n",
        "    y_pred_bin = np.array(y_pred_bin)\n",
        "    y_scores   = np.array(y_scores)\n",
        "\n",
        "    print(f\"\\n========== {title_prefix} â€“ Confusion Matrix ==========\")\n",
        "    cm = confusion_matrix(y_true_bin, y_pred_bin, labels=[0, 1])\n",
        "    print(\"Labels: 0=Normal, 1=Fault\")\n",
        "    print(cm)\n",
        "\n",
        "    print(f\"\\n========== {title_prefix} â€“ Classification Report ==========\")\n",
        "    print(classification_report(y_true_bin, y_pred_bin, target_names=[\"Normal\", \"Fault\"], digits=3))\n",
        "\n",
        "    # ROC AUC / PR AUC â€“ only if both classes exist\n",
        "    if len(np.unique(y_true_bin)) == 2:\n",
        "        try:\n",
        "            roc_auc = roc_auc_score(y_true_bin, y_scores)\n",
        "            pr_auc  = average_precision_score(y_true_bin, y_scores)\n",
        "            print(f\"{title_prefix} ROC AUC: {roc_auc:.3f}\")\n",
        "            print(f\"{title_prefix} PR  AUC: {pr_auc:.3f}\")\n",
        "        except Exception as e:\n",
        "            print(f\"{title_prefix} AUC computation error: {e}\")\n",
        "    else:\n",
        "        print(f\"{title_prefix}: Only one class present in y_true â€“ ROC/PR AUC not defined.\")\n",
        "\n",
        "    # --- ROC Curve ---\n",
        "    if len(np.unique(y_true_bin)) == 2:\n",
        "        fpr, tpr, _ = roc_curve(y_true_bin, y_scores)\n",
        "        plt.figure(figsize=(6, 5))\n",
        "        plt.plot(fpr, tpr, label=f\"{title_prefix} ROC\")\n",
        "        plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
        "        plt.xlabel(\"False Positive Rate\")\n",
        "        plt.ylabel(\"True Positive Rate\")\n",
        "        plt.title(f\"{title_prefix} ROC Curve\")\n",
        "        plt.legend()\n",
        "        plt.grid(alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # --- Precisionâ€“Recall Curve ---\n",
        "        precision, recall, _ = precision_recall_curve(y_true_bin, y_scores)\n",
        "        plt.figure(figsize=(6, 5))\n",
        "        plt.plot(recall, precision, label=f\"{title_prefix} PR\")\n",
        "        plt.xlabel(\"Recall\")\n",
        "        plt.ylabel(\"Precision\")\n",
        "        plt.title(f\"{title_prefix} Precisionâ€“Recall Curve\")\n",
        "        plt.legend()\n",
        "        plt.grid(alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def evaluate_per_sensor(sensor_logs, holdout_labels_bin):\n",
        "    \"\"\"\n",
        "    Evaluate each sensor as an anomaly detector vs. binary labels.\n",
        "    sensor_logs: list of dicts (one per sensor) with:\n",
        "        'scores': [score_t]\n",
        "        'anomalies': [0/1]\n",
        "    holdout_labels_bin: array of 0/1, length = num_steps\n",
        "    \"\"\"\n",
        "    num_sensors = len(sensor_logs)\n",
        "    print(\"\\n================ PER-SENSOR EVALUATION ================\")\n",
        "\n",
        "    for sid in range(num_sensors):\n",
        "        scores = np.array(sensor_logs[sid]['scores'])\n",
        "        preds  = np.array(sensor_logs[sid]['anomalies'])  # 0/1 from your agent\n",
        "        y_true = np.array(holdout_labels_bin[:len(scores)])\n",
        "\n",
        "        print(f\"\\n----- Sensor {sid} -----\")\n",
        "        if len(scores) == 0:\n",
        "            print(\"No data for this sensor.\")\n",
        "            continue\n",
        "\n",
        "        cm = confusion_matrix(y_true, preds, labels=[0, 1])\n",
        "        print(\"Confusion Matrix (0=Normal, 1=Fault):\")\n",
        "        print(cm)\n",
        "\n",
        "        print(\"Classification Report:\")\n",
        "        print(classification_report(y_true, preds, target_names=[\"Normal\", \"Fault\"], digits=3))\n",
        "\n",
        "        if len(np.unique(y_true)) == 2:\n",
        "            try:\n",
        "                roc_auc = roc_auc_score(y_true, scores)\n",
        "                pr_auc  = average_precision_score(y_true, scores)\n",
        "                print(f\"Sensor {sid} ROC AUC: {roc_auc:.3f}\")\n",
        "                print(f\"Sensor {sid} PR  AUC: {pr_auc:.3f}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Sensor {sid} AUC error: {e}\")\n",
        "        else:\n",
        "            print(\"Only one class present â€“ ROC/PR AUC not defined.\")\n",
        "\n",
        "\n",
        "def save_stepwise_results_csv(step_records, out_path):\n",
        "    \"\"\"\n",
        "    step_records: list of dicts, one per timestep:\n",
        "      {\n",
        "        'step': int,\n",
        "        'true_label': int,\n",
        "        'true_label_bin': int,\n",
        "        'system_anomaly': int,\n",
        "        'system_drift': int,\n",
        "        'system_needs_retrain': int,\n",
        "        'anomaly_rate': float,\n",
        "        'drift_rate': float,\n",
        "        'retrain_rate': float\n",
        "      }\n",
        "    \"\"\"\n",
        "    import pandas as pd\n",
        "    df = pd.DataFrame(step_records)\n",
        "    df.to_csv(out_path, index=False)\n",
        "    print(f\"ðŸ’¾ Saved stepwise evaluation to: {out_path}\")\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "def evaluate_per_label_class(y_true, y_scores):\n",
        "    \"\"\"\n",
        "    y_true: true labels 0/1/2\n",
        "    y_scores: anomaly_rate per step (float 0..1)\n",
        "    \"\"\"\n",
        "\n",
        "    # ----- Define thresholds ----------\n",
        "    # System anomaly rate:\n",
        "    # 0â€“0.2  â†’ Normal (0)\n",
        "    # 0.2â€“0.5 â†’ Warning (1)\n",
        "    # >0.5   â†’ Fault (2)\n",
        "\n",
        "    y_pred = []\n",
        "    for score in y_scores:\n",
        "        if score < 0.2:\n",
        "            y_pred.append(0)\n",
        "        elif score < 0.5:\n",
        "            y_pred.append(1)\n",
        "        else:\n",
        "            y_pred.append(2)\n",
        "\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    print(\"\\n=================== MULTI-CLASS CONFUSION MATRIX (0,1,2) ===================\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "    print(\"\\n=================== CLASSIFICATION REPORT (0,1,2) ===================\")\n",
        "    print(classification_report(y_true, y_pred, digits=4))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_error_vs_labels(sensor_logs, labels, sensor_id, start=0, end=500):\n",
        "    def safe_slice(arr, start, end):\n",
        "        start = max(0, start)\n",
        "        end   = min(end, len(arr))\n",
        "        return np.array(arr[start:end])\n",
        "\n",
        "    # Safe slicing\n",
        "    scores = safe_slice(sensor_logs[sensor_id][\"scores\"], start, end)\n",
        "    lbls   = safe_slice(labels, start, end)\n",
        "\n",
        "    # Match lengths\n",
        "    L = min(len(scores), len(lbls))\n",
        "    scores = scores[:L]\n",
        "    lbls   = lbls[:L]\n",
        "\n",
        "    # Prepare indices\n",
        "    normal_idx  = np.where(lbls == 0)[0]\n",
        "    warning_idx = np.where(lbls == 1)[0]\n",
        "    fault_idx   = np.where(lbls == 2)[0]\n",
        "\n",
        "    plt.figure(figsize=(16,5))\n",
        "    plt.plot(scores, label=\"Reconstruction Error\", color='blue')\n",
        "\n",
        "    plt.scatter(normal_idx,  scores[normal_idx],  s=20, color='green',  label=\"Normal (0)\")\n",
        "    plt.scatter(warning_idx, scores[warning_idx], s=20, color='orange', label=\"Warning (1)\")\n",
        "    plt.scatter(fault_idx,   scores[fault_idx],   s=20, color='red',    label=\"Fault (2)\")\n",
        "\n",
        "    plt.title(f\"Sensor {sensor_id} Error vs Labels\")\n",
        "    plt.xlabel(\"Time step\")\n",
        "    plt.ylabel(\"Reconstruction Error\")\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def plot_system_diagnostics(\n",
        "    labels,\n",
        "    sensor_logs,\n",
        "    system_decisions,\n",
        "    start=0,\n",
        "    end=2000,\n",
        "    sensors_to_plot=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Creates a unified diagnostic timeline:\n",
        "      - Label classes (0 = normal, 1 = warning, 2 = fault)\n",
        "      - Sensor-level anomalies\n",
        "      - Sensor-level drift flags\n",
        "      - System-level anomaly & drift flags.\n",
        "\n",
        "    labels: array of true labels (0/1/2)\n",
        "    sensor_logs: list of dicts, each with\n",
        "         {'scores': [...], 'anomalies': [...], 'drift': [...]}\n",
        "    system_decisions: list of dicts from step_records\n",
        "         each has {'system_anomaly', 'system_drift'}\n",
        "    sensors_to_plot: list of sensor IDs to include (default = all sensors)\n",
        "    \"\"\"\n",
        "\n",
        "    # Slice region\n",
        "    L = labels[start:end]\n",
        "    steps = np.arange(start, end)\n",
        "\n",
        "    # Prep system anomaly/drift arrays\n",
        "    sys_anom = np.array([s[\"system_anomaly\"] for s in system_decisions])[start:end]\n",
        "    sys_drift = np.array([s[\"system_drift\"] for s in system_decisions])[start:end]\n",
        "\n",
        "    # If user didnâ€™t pick sensors, include all\n",
        "    if sensors_to_plot is None:\n",
        "        sensors_to_plot = list(range(len(sensor_logs)))\n",
        "\n",
        "    plt.figure(figsize=(22, 10))\n",
        "\n",
        "    # -------------------------------\n",
        "    # 1. Plot Label Regions\n",
        "    # -------------------------------\n",
        "    # Normal (0)\n",
        "    plt.fill_between(\n",
        "        steps, 0, 1,\n",
        "        where=(L == 0),\n",
        "        color=\"green\", alpha=0.15, label=\"Normal (0)\"\n",
        "    )\n",
        "    # Warning (1)\n",
        "    plt.fill_between(\n",
        "        steps, 0, 1,\n",
        "        where=(L == 1),\n",
        "        color=\"orange\", alpha=0.15, label=\"Warning (1)\"\n",
        "    )\n",
        "    # Fault (2)\n",
        "    plt.fill_between(\n",
        "        steps, 0, 1,\n",
        "        where=(L == 2),\n",
        "        color=\"red\", alpha=0.15, label=\"Fault (2)\"\n",
        "    )\n",
        "\n",
        "    # -------------------------------\n",
        "    # 2. Plot System-level Flags\n",
        "    # -------------------------------\n",
        "    plt.plot(\n",
        "        steps, sys_anom * 1.05,\n",
        "        color=\"black\", linewidth=2, label=\"System Anomaly\"\n",
        "    )\n",
        "    plt.plot(\n",
        "        steps, sys_drift * 0.95,\n",
        "        color=\"purple\", linewidth=2, label=\"System Drift\"\n",
        "    )\n",
        "\n",
        "    # -------------------------------\n",
        "    # 3. Plot Sensor-level Signals\n",
        "    # -------------------------------\n",
        "    y_offset = 1.2   # vertical offset for stacking\n",
        "\n",
        "    for sid in sensors_to_plot:\n",
        "        logs = sensor_logs[sid]\n",
        "        anom = np.array(logs[\"anomalies\"])[start:end]\n",
        "        drift = np.array(logs[\"drift\"])[start:end]\n",
        "\n",
        "        plt.scatter(\n",
        "            steps,\n",
        "            anom * (y_offset),\n",
        "            s=12, label=f\"Sensor {sid} Anomaly\" if sid == sensors_to_plot[0] else \"\",\n",
        "            color=\"blue\"\n",
        "        )\n",
        "        plt.scatter(\n",
        "            steps,\n",
        "            drift * (y_offset + 0.1),\n",
        "            s=12, label=f\"Sensor {sid} Drift\" if sid == sensors_to_plot[0] else \"\",\n",
        "            color=\"purple\"\n",
        "        )\n",
        "\n",
        "        y_offset += 0.15  # shift next sensor up slightly\n",
        "\n",
        "    # -------------------------------\n",
        "    # Final Plot Settings\n",
        "    # -------------------------------\n",
        "    plt.title(f\"Diagnostics Timeline (steps {start} â†’ {end})\", fontsize=16)\n",
        "    plt.xlabel(\"Step\", fontsize=14)\n",
        "    plt.yticks([])  # hide Y-axis since itâ€™s categorical layering\n",
        "    plt.legend(loc=\"upper right\", fontsize=10)\n",
        "    plt.grid(alpha=0.3)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# =====================================================\n",
        "# DEMO ENTRYPOINT\n",
        "# =====================================================\n",
        "\n",
        "import numpy as np\n",
        "# =====================================================\n",
        "# DEMO ENTRYPOINT + EVALUATION\n",
        "# =====================================================\n",
        "\n",
        "#                     FULL MAIN (CLEAN)\n",
        "# =====================================================\n",
        "\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # 1. LOAD DATA + TEST MASK\n",
        "    # -------------------------------------------------\n",
        "    models_dir     = \"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/sensor/model\"\n",
        "    data_path      = \"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/multivariate_long_sequences-TRAIN-10Sec-DIRECT-VAR.npy\"\n",
        "    label_path     = \"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/window_labels_3class.npy\"\n",
        "    test_mask_path = \"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/test_mask.npy\"\n",
        "\n",
        "    print(\"Loading data...\")\n",
        "    data     = np.load(data_path)     # [N, W, S]\n",
        "    labels   = np.load(label_path)    # [N]  â†’ {0,1,2}\n",
        "    tmask    = np.load(test_mask_path)\n",
        "\n",
        "    tmask = tmask.astype(bool)\n",
        "    subsequences = data[tmask]\n",
        "    test_labels  = labels[tmask]\n",
        "\n",
        "  ##################Find minimum test sample size#############################\n",
        "\n",
        "    found0 = found1 = found2 = False\n",
        "    first0_idx = first1_idx = first2_idx = None\n",
        "    prefix_len = None\n",
        "\n",
        "    for i, lbl in enumerate(test_labels):\n",
        "        if not found0:\n",
        "            if lbl == 0:\n",
        "                found0 = True\n",
        "                first0_idx = i\n",
        "        elif not found1:\n",
        "            if lbl == 1:\n",
        "                found1 = True\n",
        "                first1_idx = i\n",
        "        elif not found2:\n",
        "            if lbl == 2:\n",
        "                found2 = True\n",
        "                first2_idx = i\n",
        "                prefix_len = i + 1\n",
        "                break\n",
        "\n",
        "    print(\"\\n=== 0 â†’ 1 â†’ 2 progression inside TEST subset ===\")\n",
        "    print(\"First 0 in TEST:\", first0_idx)\n",
        "    print(\"First 1 after that in TEST:\", first1_idx)\n",
        "    print(\"First 2 after that in TEST:\", first2_idx)\n",
        "\n",
        "    if prefix_len is not None:\n",
        "        print(f\"\\nWithin TEST, you need the first {prefix_len} contiguous TEST windows \"\n",
        "              f\"(test indices 0..{first2_idx}) to cover one 0â†’1â†’2 progression.\")\n",
        "    else:\n",
        "        print(\"\\nWithin TEST, no full 0â†’1â†’2 progression found.\")\n",
        "\n",
        "\n",
        "\n",
        "    print(f\"âœ… Loaded TEST subsequences: {subsequences.shape}\")\n",
        "    num_samples, window_length, num_sensors = subsequences.shape\n",
        "\n",
        "    # Binary (0 = normal, 1 = warning/fault)\n",
        "    test_labels_bin = (test_labels != 0).astype(int)\n",
        "\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # 2. CREATE SENSOR & MASTER AGENTS\n",
        "    # -------------------------------------------------\n",
        "    sensor_agents, master = create_robust_system(\n",
        "        num_sensors=num_sensors,\n",
        "        models_dir=models_dir,\n",
        "        win_length=window_length\n",
        "    )\n",
        "\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # 3. CREATE LOG STRUCTURE FOR TREND PLOTS\n",
        "    # -------------------------------------------------\n",
        "    sensor_logs = [\n",
        "        {\"sensor_id\": sid, \"scores\": [], \"anomalies\": [], \"drift\": []}\n",
        "        for sid in range(num_sensors)\n",
        "    ]\n",
        "\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # 4. LOAD BASELINE METADATA FOR DRIFT PLOTS\n",
        "    # -------------------------------------------------\n",
        "    metadata_list = []\n",
        "    for sid in range(num_sensors):\n",
        "        meta_path = os.path.join(models_dir, f\"sensor_{sid}_metadata.pkl\")\n",
        "        if os.path.exists(meta_path):\n",
        "            with open(meta_path, \"rb\") as f:\n",
        "                metadata_list.append(pickle.load(f)[\"baseline_stats\"])\n",
        "        else:\n",
        "            metadata_list.append({\"mean\": 0, \"q95\": 0, \"q99\": 0})\n",
        "\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # 5. STREAMING EVALUATION\n",
        "    # -------------------------------------------------\n",
        "    test_samples = min(1000, len(subsequences))\n",
        "    print(f\"â–¶ï¸ Streaming evaluation on {test_samples} samples\")\n",
        "\n",
        "    y_true_sys_bin = []\n",
        "    y_pred_sys_bin = []\n",
        "    y_score_sys    = []\n",
        "\n",
        "    step_records = []\n",
        "\n",
        "    for i in range(test_samples):\n",
        "\n",
        "        seq = subsequences[i]\n",
        "        y_true = test_labels[i]\n",
        "        y_true_b = test_labels_bin[i]\n",
        "\n",
        "        # --- Run system ---\n",
        "        result = master.process_system_input(seq)\n",
        "        sys_dec = result[\"system_decisions\"]\n",
        "\n",
        "        anomaly_rate = float(sys_dec[\"anomaly_rate\"])\n",
        "\n",
        "        # --- Save system-level prediction ---\n",
        "        y_true_sys_bin.append(y_true_b)\n",
        "        y_pred_sys_bin.append(int(sys_dec[\"system_anomaly\"]))\n",
        "        y_score_sys.append(anomaly_rate)\n",
        "\n",
        "        # --- Save row for CSV ---\n",
        "        step_records.append({\n",
        "            \"step\": i,\n",
        "            \"true_label\": int(y_true),\n",
        "            \"true_label_bin\": int(y_true_b),\n",
        "            \"system_anomaly\": int(sys_dec[\"system_anomaly\"]),\n",
        "            \"system_drift\": int(sys_dec[\"system_drift\"]),\n",
        "            \"system_needs_retrain\": int(sys_dec[\"system_needs_retrain\"]),\n",
        "            \"anomaly_rate\": anomaly_rate,\n",
        "            \"drift_rate\": float(sys_dec[\"drift_rate\"]),\n",
        "            \"retrain_rate\": float(sys_dec[\"retrain_rate\"])\n",
        "        })\n",
        "\n",
        "        # --- Log detail for per-sensor analysis ---\n",
        "        for r in result[\"sensor_results\"]:\n",
        "            sid = r[\"sensor_id\"]\n",
        "            sensor_logs[sid][\"scores\"].append(r[\"anomaly_score\"])\n",
        "            sensor_logs[sid][\"anomalies\"].append(int(r[\"is_anomaly\"]))\n",
        "            sensor_logs[sid][\"drift\"].append(int(r[\"drift_flag\"]))\n",
        "\n",
        "        # --- Console ---\n",
        "        print(f\"\\nStep {i+1}/{test_samples}\")\n",
        "        print(f\"Label={y_true} (bin={y_true_b})\")\n",
        "        print(\"System:\", sys_dec)\n",
        "\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # 6. SYSTEM-LEVEL METRICS\n",
        "    # -------------------------------------------------\n",
        "    evaluate_system_level(\n",
        "        y_true_bin=y_true_sys_bin,\n",
        "        y_pred_bin=y_pred_sys_bin,\n",
        "        y_scores=y_score_sys,\n",
        "        title_prefix=\"System (Anomaly Rate)\"\n",
        "    )\n",
        "\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # 7. PER-SENSOR METRICS\n",
        "    # -------------------------------------------------\n",
        "    evaluate_per_sensor(sensor_logs, test_labels_bin)\n",
        "\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # 8. SAVE STEPWISE CSV\n",
        "    # -------------------------------------------------\n",
        "    csv_out = \"/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/test_eval_stepwise.csv\"\n",
        "    save_stepwise_results_csv(step_records, csv_out)\n",
        "    print(f\"ðŸ’¾ Saved step-by-step results to: {csv_out}\")\n",
        "\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # 9. SENSOR DRIFT TRENDS\n",
        "    # -------------------------------------------------\n",
        "    print(\"\\nðŸ“ˆ Plotting sensor drift trends...\")\n",
        "    plot_sensor_drift_trends(sensor_logs, metadata_list, window_size=20)\n",
        "\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # 10. MULTI-CLASS LABEL (0/1/2) ANALYSIS\n",
        "    # -------------------------------------------------\n",
        "    evaluate_per_label_class(test_labels[:test_samples], y_score_sys)\n",
        "\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # 11. TRANSITION-PLOT DIAGNOSTICS\n",
        "    # -------------------------------------------------\n",
        "    N = min(len(sensor_logs[0][\"scores\"]), len(test_labels))\n",
        "    print(\"\\nðŸ“ˆ Plotting label-aligned error transitions...\")\n",
        "    plot_error_vs_labels(sensor_logs, test_labels, sensor_id=0,  start=0, end=N)\n",
        "    plot_error_vs_labels(sensor_logs, test_labels, sensor_id=5,  start=0, end=N)\n",
        "    plot_error_vs_labels(sensor_logs, test_labels, sensor_id=11, start=0, end=N)\n",
        "\n",
        "\n",
        "        # --- 11. UNIFIED DIAGNOSTIC TIMELINE ---\n",
        "    print(\"\\nðŸ“ˆ Unified diagnostic plot...\")\n",
        "\n",
        "    # You can zoom to any region you want:\n",
        "    plot_system_diagnostics(\n",
        "        labels=test_labels,\n",
        "        sensor_logs=sensor_logs,\n",
        "        system_decisions=step_records,\n",
        "        start=150,         # adjust these\n",
        "        end=350,        # adjust these\n",
        "        sensors_to_plot=[0, 5, 11]  # sensors of interest\n",
        "    )\n",
        "\n",
        "    plot_system_diagnostics(\n",
        "        labels=test_labels,\n",
        "        sensor_logs=sensor_logs,\n",
        "        system_decisions=step_records,\n",
        "        start=800,         # adjust these\n",
        "        end=1100,        # adjust these\n",
        "        sensors_to_plot=[0, 5, 11]  # sensors of interest\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# RUN MAIN\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "v_5iji919H_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8OtWHK--uG6W"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "mount_file_id": "https://github.com/supriyag123/PHD_Pub/blob/main/AGENTIC-MODULE4-Sensor-Agent.ipynb",
      "authorship_tag": "ABX9TyOThHb9FWJcyCi8fXUImX+i",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}