{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supriyag123/PHD_Pub/blob/main/DGRNet%20Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "bx-5b_puABG1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0b7528c7-65da-40c1-9a13-8d56de4cf404"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "447/447 [==============================] - 203s 304ms/step - loss: 1378.6129 - mean_squared_error: 1378.6129\n",
            "Epoch 2/100\n",
            "447/447 [==============================] - 141s 315ms/step - loss: 1357.6791 - mean_squared_error: 1357.6791\n",
            "Epoch 3/100\n",
            "447/447 [==============================] - 141s 315ms/step - loss: 1352.6522 - mean_squared_error: 1352.6522\n",
            "Epoch 4/100\n",
            "447/447 [==============================] - 141s 315ms/step - loss: 1354.0934 - mean_squared_error: 1354.0934\n",
            "Epoch 5/100\n",
            "447/447 [==============================] - 141s 315ms/step - loss: 1352.6384 - mean_squared_error: 1352.6384\n",
            "Epoch 6/100\n",
            "447/447 [==============================] - 141s 315ms/step - loss: 1352.2834 - mean_squared_error: 1352.2834\n",
            "Epoch 7/100\n",
            "447/447 [==============================] - 141s 315ms/step - loss: 1353.1068 - mean_squared_error: 1353.1068\n",
            "Epoch 8/100\n",
            "447/447 [==============================] - 141s 315ms/step - loss: 1353.2866 - mean_squared_error: 1353.2866\n",
            "Epoch 9/100\n",
            "447/447 [==============================] - 141s 315ms/step - loss: 1349.9277 - mean_squared_error: 1349.9277\n",
            "Epoch 10/100\n",
            "447/447 [==============================] - 141s 315ms/step - loss: 1350.1249 - mean_squared_error: 1350.1249\n",
            "Epoch 11/100\n",
            "447/447 [==============================] - 141s 315ms/step - loss: 1349.4218 - mean_squared_error: 1349.4218\n",
            "Epoch 12/100\n",
            "447/447 [==============================] - 141s 316ms/step - loss: 1351.7305 - mean_squared_error: 1351.7305\n",
            "Epoch 13/100\n",
            "447/447 [==============================] - 141s 315ms/step - loss: 1351.6038 - mean_squared_error: 1351.6038\n",
            "Epoch 14/100\n",
            "447/447 [==============================] - 141s 315ms/step - loss: 1351.6311 - mean_squared_error: 1351.6311\n",
            "Epoch 15/100\n",
            "447/447 [==============================] - 141s 315ms/step - loss: 1348.8904 - mean_squared_error: 1348.8904\n",
            "Epoch 16/100\n",
            "447/447 [==============================] - 141s 315ms/step - loss: 1348.6290 - mean_squared_error: 1348.6290\n",
            "Epoch 17/100\n",
            "447/447 [==============================] - 141s 315ms/step - loss: 1350.1173 - mean_squared_error: 1350.1173\n",
            "Epoch 18/100\n",
            "447/447 [==============================] - 141s 315ms/step - loss: 1350.4196 - mean_squared_error: 1350.4196\n",
            "Epoch 19/100\n",
            "447/447 [==============================] - 141s 315ms/step - loss: 1349.2480 - mean_squared_error: 1349.2480\n",
            "Epoch 20/100\n",
            "447/447 [==============================] - 141s 315ms/step - loss: 1350.7549 - mean_squared_error: 1350.7549\n",
            "Epoch 21/100\n",
            "447/447 [==============================] - 141s 315ms/step - loss: 1348.5789 - mean_squared_error: 1348.5789\n",
            "Epoch 22/100\n",
            "447/447 [==============================] - 141s 314ms/step - loss: 1350.6212 - mean_squared_error: 1350.6212\n",
            "Epoch 23/100\n",
            "447/447 [==============================] - 141s 314ms/step - loss: 1349.8715 - mean_squared_error: 1349.8715\n",
            "Epoch 24/100\n",
            "447/447 [==============================] - 141s 315ms/step - loss: 1349.8567 - mean_squared_error: 1349.8567\n",
            "Epoch 25/100\n",
            "447/447 [==============================] - 141s 315ms/step - loss: 1347.8090 - mean_squared_error: 1347.8090\n",
            "Epoch 26/100\n",
            "241/447 [===============>..............] - ETA: 1:04 - loss: 1350.7942 - mean_squared_error: 1350.7942"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-d4d700325778>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import math\n",
        "import plotly.graph_objects as go\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, RepeatVector, TimeDistributed, Input\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import keras.backend as K\n",
        "from keras.callbacks import Callback\n",
        "import plotly\n",
        "import plotly.express as px # for data visualization\n",
        "import seaborn as sns\n",
        "\n",
        "generator_multiply = 1 #each input record will generate 100 random vectors from the latent space, given the mu and sigma generated by the encoder\n",
        "\n",
        "#from keras.utils import plot_model\n",
        "#import matplotlib.pyplot as plt\n",
        "\n",
        "#window1 = np.load(r'/content/drive/MyDrive/PHD/2021/multivariate_long_sequences_WINDOW-500.npy')\n",
        "#window2 = np.load(r'/content/drive/MyDrive/PHD/2021/multivariate_long_sequences_WINDOW-1000.npy')\n",
        "#window = np.concatenate((window1, window2), axis=0)\n",
        "#train_data = np.load(r'/content/drive/MyDrive/PHD/2021/multivariate_long_sequences-TRAIN.npy')\n",
        "#test_data = np.load(r'/content/drive/MyDrive/PHD/2021/multivariate_long_sequences-TEST.npy')\n",
        "\n",
        "\n",
        "\n",
        "#get data\n",
        "train_data = np.load(r'/content/drive/MyDrive/PHD/2024/multivariate_long_sequences-TRAIN_hourly.npy')\n",
        "index = 500\n",
        "#We missed i=500 from processing the iosw. So here we are dropping row with index =500\n",
        "train_data= np.delete(train_data, index, axis=0)\n",
        "\n",
        "#test_data = np.load(r'/content/drive/MyDrive/PHD/2024/multivariate_long_sequences-TEST_hourly.npy')\n",
        "#all_data = np.concatenate((train_data,test_data),axis=0)\n",
        "window_label = np.load(r'/content/drive/MyDrive/PHD/2024/multivariate_long_sequences_WINDOW-TRAIN_hourly.npy')\n",
        "n_seq = train_data.shape[0]\n",
        "window_size = train_data.shape[1]\n",
        "n_features = train_data.shape[2]\n",
        "\n",
        "\n",
        "plt.suptitle('Sub sequence plotting', fontsize='30')\n",
        "plt.xlabel('Time', fontsize ='20')\n",
        "plt.ylabel('Feature 1', fontsize='20')\n",
        "plt.plot(train_data[:,:,1])\n",
        "plt.show()\n",
        "\n",
        "#---------------------------------Without VAE------------------------------------\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(train_data, window_label, test_size = 0.2, random_state = 42)\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1]*n_features))\n",
        "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1]*n_features))\n",
        "\n",
        "from sklearn.covariance import EllipticEnvelope\n",
        "ee = EllipticEnvelope(contamination=0.05)\n",
        "yhat = ee.fit_predict(x_train)\n",
        "# select all rows that are not outliers\n",
        "mask = yhat != -1\n",
        "x_train, y_train = x_train[mask, :], y_train[mask]\n",
        "\n",
        "\n",
        "x_train = x_train.reshape((x_train.shape[0], window_size, n_features))\n",
        "x_test = x_test.reshape((x_test.shape[0], window_size, n_features))\n",
        "\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.models import Sequential\n",
        "##!pip uninstall tensorflow\n",
        "#!pip install tensorflow==2.12.0\n",
        "#from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(1000, input_shape=(x_train.shape[1],x_train.shape[2])))\n",
        "model.add(Dense(1000, activation = 'relu'))\n",
        "model.add(Dense(units = 512, activation = 'relu'))\n",
        "model.add(Dense(units = 512, activation = 'relu'))\n",
        "#model.add(Dense(units = 128, activation = 'relu'))\n",
        "#model.add(Dense(units = 128, activation = 'relu'))\n",
        "model.add(Dense(units = 1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
        "\n",
        "#model.fit(x_train, y_train,epochs=5, batch_size=50, verbose=True)\n",
        "\n",
        "#y_pred = model.predict(x_test)\n",
        "\n",
        "#transform\n",
        "\n",
        "model.fit(x_train, y_train,epochs=100, batch_size=50, verbose=True)\n",
        "y_pred = model.predict(x_test)\n",
        "score= r2_score(y_test,y_pred)\n",
        "print(\"r2 score is ==\",score)\n",
        "print(\"mean_sqrd_error is==\",mean_squared_error(y_test,y_pred))\n",
        "print(\"root_mean_squared error of is==\",np.sqrt(mean_squared_error(y_test,y_pred)))\n",
        "\n",
        "#plt.scatter(y_test,y_pred);\n",
        "#plt.xlabel('Actual');\n",
        "#plt.ylabel('Predicted');\n",
        "plt.plot(y_test[0:100], color = 'red', label = 'Real data')\n",
        "plt.plot(y_pred[0:100], color = 'blue', label = 'Predicted data')\n",
        "plt.title('Prediction')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "\n",
        "np.savetxt(r'/content/drive/MyDrive/PHD/2024/MLPOutput/pred_2.csv',y_pred_t)\n",
        "np.savetxt(r'/content/drive/MyDrive/PHD/2024/MLPOutput/real_2.csv',y_test)\n",
        "print(\"MAE is==\",mean_absolute_error(y_test,y_pred))\n",
        "\n",
        "#########Isolation forest-------------------------#\n",
        "iso = IsolationForest(contamination=0.1)\n",
        "x_train, x_test, y_train, y_test = train_test_split(train_data, window_label, test_size = 0.2, random_state = 42)\n",
        "\n",
        "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1]*n_features))\n",
        "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1]*n_features))\n",
        "yhat = iso.fit_predict(x_train)\n",
        "mask = yhat != -1\n",
        "x_train, y_train = x_train[mask, :], y_train[mask]\n",
        "x_train = x_train.reshape((x_train.shape[0], window_size, n_features))\n",
        "x_test = x_test.reshape((x_test.shape[0], window_size, n_features))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(1000, input_shape=(x_train.shape[1],x_train.shape[2])))\n",
        "model.add(Dense(1000, activation = 'relu'))\n",
        "model.add(Dense(units = 512, activation = 'relu'))\n",
        "model.add(Dense(units = 512, activation = 'relu'))\n",
        "#model.add(Dense(units = 128, activation = 'relu'))\n",
        "#model.add(Dense(units = 128, activation = 'relu'))\n",
        "model.add(Dense(units = 1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
        "\n",
        "#model.fit(x_train, y_train,epochs=5, batch_size=50, verbose=True)\n",
        "\n",
        "#y_pred = model.predict(x_test)\n",
        "\n",
        "#transform\n",
        "\n",
        "model.fit(x_train, y_train,epochs=100, batch_size=50, verbose=True)\n",
        "\n",
        "#remove outlier from test data to get a better prediction\n",
        "\n",
        "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1]*n_features))\n",
        "yhat = iso.fit_predict(x_test)\n",
        "mask = yhat != -1\n",
        "x_test, y_test = x_test[mask, :], y_test[mask]\n",
        "x_test = x_test.reshape((x_test.shape[0], window_size, n_features))\n",
        "y_pred = model.predict(x_test)\n",
        "score= r2_score(y_test,y_pred)\n",
        "print(\"r2 score is ==\",score)\n",
        "print(\"mean_sqrd_error is==\",mean_squared_error(y_test,y_pred))\n",
        "print(\"root_mean_squared error of is==\",np.sqrt(mean_squared_error(y_test,y_pred)))\n",
        "\n",
        "\n",
        "np.savetxt(r'/content/drive/MyDrive/PHD/2024/MLPOutput/pred_wo-vae2.csv',y_pred)\n",
        "np.savetxt(r'/content/drive/MyDrive/PHD/2024/MLPOutput/real_wo-vae2.csv',y_test)\n",
        "\n",
        "#########----------------------------------  Now run the VAE to general more sample -------------------------------------------------------------------------#\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(train_data, window_label, test_size = 0.2, random_state = 42)\n",
        "\n",
        "encoder = keras.models.load_model(r'/content/drive/MyDrive/PHD/2024/VAE_SIMULATION/vae-encoder-saved-round5-latent50-dim1000.model')\n",
        "decoder = keras.models.load_model(r'/content/drive/MyDrive/PHD/2024/VAE_SIMULATION/vae-decoder-saved-round5-latent50-dim1000.model')\n",
        "\n",
        "#Encode x_train\n",
        "X_train_encoded = encoder.predict(x_train)\n",
        "#Decode X_train_encoded\n",
        "\n",
        "#Calculate reconstruction error\n",
        "mu, logvar, z = X_train_encoded\n",
        "sigma = tf.exp(0.5 * logvar)\n",
        "X_train_decoded = decoder.predict(z)\n",
        "reconstruction_loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(x_train, X_train_decoded))\n",
        "\n",
        "batch = tf.shape(mu)[0]  #number of recors / batchs\n",
        "dim = tf.shape(mu)[1] #Ndimension of latent variable\n",
        "#store = list()\n",
        "#storetemp = list()\n",
        "\n",
        "#Merge x_train, and also output of decoder (sample generated with VAE)\n",
        "x_train_total = np.vstack((x_train, X_train_decoded))\n",
        "\n",
        "#Now generate window label for VAE data - basically same as original window size array, vstacked\n",
        "y_train_total = np.vstack((y_train, y_train)).flatten().reshape(x_train_total.shape[0],1)\n",
        "\n",
        "x_train = x_train_total.reshape((x_train_total.shape[0], x_train_total.shape[1]*n_features))\n",
        "y_train = y_train_total\n",
        "\n",
        "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1]*n_features))\n",
        "\n",
        "from sklearn.covariance import EllipticEnvelope\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "iso = IsolationForest(contamination=0.1)\n",
        "yhat = iso.fit_predict(x_train)\n",
        "#ee = EllipticEnvelope(contamination=0.1)\n",
        "#yhat = ee.fit_predict(x_train)\n",
        "# select all rows that are not outliers\n",
        "mask = yhat != -1\n",
        "x_train, y_train = x_train[mask, :], y_train[mask]\n",
        "\n",
        "\n",
        "x_train = x_train.reshape((x_train.shape[0], window_size, n_features))\n",
        "x_test = x_test.reshape((x_test.shape[0], window_size, n_features))\n",
        "\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.models import Sequential\n",
        "##!pip uninstall tensorflow\n",
        "#!pip install tensorflow==2.12.0\n",
        "#from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "\n",
        "\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "\n",
        "np.savetxt(r'/content/drive/MyDrive/PHD/2024/MLPOutput/pred_2.csv',y_pred_t)\n",
        "np.savetxt(r'/content/drive/MyDrive/PHD/2024/MLPOutput/real_2.csv',y_test)\n",
        "print(\"MAE is==\",mean_absolute_error(y_test,y_pred))\n",
        "\n",
        "\n",
        "#----------------Random forest ----------------------------------\n",
        "###### Random forrest ergression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "from sklearn.linear_model import HuberRegressor\n",
        " # create regressor object\n",
        "#regressor = RandomForestRegressor(n_estimators = 50, random_state = 0)\n",
        "# prepare the model with input scaling\n",
        "pipeline = Pipeline(steps=[('power', PowerTransformer()), ('model',RandomForestRegressor(n_estimators = 100, random_state = 0))])\n",
        "#pipeline = Pipeline(steps=[('power', PowerTransformer()), ('model',HuberRegressor())])\n",
        "\n",
        "# prepare the model with target scaling\n",
        "model = TransformedTargetRegressor(regressor=pipeline, transformer=PowerTransformer())\n",
        "\n",
        "# fit the regressor with x and y data\n",
        "pipeline.fit(x_train,y_train)\n",
        "y_pred = pipeline.predict(x_test)  # test the output by changing values\n",
        "# creating an object of LinearRegression class\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "# predicting the accuracy score\n",
        "\n",
        "score=r2_score(y_test,y_pred)\n",
        "print(\"r2 score is ==\",score)\n",
        "print(\"mean_sqrd_error is==\",mean_squared_error(y_test,y_pred))\n",
        "print(\"root_mean_squared error of is==\",np.sqrt(mean_squared_error(y_test,y_pred)))\n",
        "plt.scatter(y_test,y_pred);\n",
        "plt.xlabel('Actual');\n",
        "plt.ylabel('Predicted');\n",
        "\n",
        "\n",
        "plt.plot(y_test[5000:5049], color = 'red', label = 'Real data')\n",
        "plt.plot(y_pred_t[5000:5049], color = 'blue', label = 'Predicted data')\n",
        "plt.title('Prediction')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8OtWHK--uG6W"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/supriyag123/PHD_Pub/blob/main/DGRNet%20Prediction.ipynb",
      "authorship_tag": "ABX9TyMk7lAaQ4PBgqDEQxjJZS0L",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}