{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supriyag123/PHD_Pub/blob/main/PAPER_GDRNet_PREDMAINT_Step1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "T-BJGPTX7XS5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f429dbf-a22f-482f-e022-ef80e5749a09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Order = 0\n",
            "AIC:  -145.0613853495918\n",
            "BIC:  -144.59358509686484\n",
            "VAR could not solve row number\n",
            "3544 1\n",
            "VAR could not solve row number\n",
            "3544 2\n",
            "VAR could not solve row number\n",
            "3544 3\n",
            "VAR could not solve row number\n",
            "3544 4\n",
            "VAR could not solve row number\n",
            "3544 5\n",
            "VAR could not solve row number\n",
            "3544 6\n",
            "VAR could not solve row number\n",
            "3544 7\n",
            "VAR could not solve row number\n",
            "3544 8\n",
            "VAR could not solve row number\n",
            "3544 9\n",
            "VAR could not solve row number\n",
            "3544 10\n",
            "VAR could not solve row number\n",
            "3544 11\n",
            "VAR could not solve row number\n",
            "3544 12\n",
            "VAR could not solve row number\n",
            "3544 13\n",
            "VAR could not solve row number\n",
            "3544 14\n",
            "VAR could not solve row number\n",
            "3544 15\n",
            "VAR could not solve row number\n",
            "3544 16\n",
            "VAR could not solve row number\n",
            "3544 17\n",
            "VAR could not solve row number\n",
            "3544 18\n",
            "VAR could not solve row number\n",
            "3544 19\n",
            "VAR could not solve row number\n",
            "3544 20\n",
            "VAR could not solve row number\n",
            "3544 21\n",
            "VAR could not solve row number\n",
            "3544 22\n",
            "VAR could not solve row number\n",
            "3544 23\n",
            "VAR could not solve row number\n",
            "3544 24\n",
            "VAR could not solve row number\n",
            "3544 25\n",
            "VAR could not solve row number\n",
            "3544 26\n",
            "VAR could not solve row number\n",
            "3544 27\n",
            "VAR could not solve row number\n",
            "3544 28\n",
            "VAR could not solve row number\n",
            "3544 29\n",
            "VAR could not solve row number\n",
            "3544 30\n",
            "VAR could not solve row number\n",
            "3544 31\n",
            "VAR could not solve row number\n",
            "3544 32\n",
            "VAR could not solve row number\n",
            "3544 33\n",
            "VAR could not solve row number\n",
            "3544 34\n",
            "VAR could not solve row number\n",
            "3544 35\n",
            "VAR could not solve row number\n",
            "3544 36\n",
            "VAR could not solve row number\n",
            "3544 37\n",
            "VAR could not solve row number\n",
            "3544 38\n",
            "VAR could not solve row number\n",
            "3544 39\n",
            "VAR could not solve row number\n",
            "3544 40\n",
            "VAR could not solve row number\n",
            "3544 41\n",
            "VAR could not solve row number\n",
            "3544 42\n",
            "VAR could not solve row number\n",
            "3544 43\n",
            "VAR could not solve row number\n",
            "3544 44\n",
            "VAR could not solve row number\n",
            "3544 45\n",
            "VAR could not solve row number\n",
            "3544 46\n",
            "VAR could not solve row number\n",
            "3544 47\n",
            "[-145.0613853495918, 99999, 99999, 99999, 99999, 99999, 99999, 99999, 99999, 99999, 99999, 99999, 99999, 99999, 99999, 99999, 99999, 99999, 99999, 99999, 99999, 99999, 99999, 99999, 99999, 99999, 99999, 99999, 99999, 99999, 99999, 99999, 99999, 99999, 99999, 99999, 99999, 99999, 99999, 99999, 99999, 99999, 99999, 99999, 99999, 99999, 99999, 99999]\n",
            "Minimum lag =  1\n",
            "[1]\n"
          ]
        }
      ],
      "source": [
        "!pip install statsmodels --upgrade\n",
        "!pip install -U lingam\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import math\n",
        "import plotly.graph_objects as go\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, RepeatVector, TimeDistributed, Input\n",
        "from keras.models import Model\n",
        "from statsmodels.tsa.api import VAR\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.tools.eval_measures import rmse, aic\n",
        "import ast\n",
        "from statsmodels.tsa.ar_model import AutoReg\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from matplotlib import pyplot\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import linear_model\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from numpy import arange\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#from keras.utils import plot_model\n",
        "#import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.stattools import grangercausalitytests\n",
        "\n",
        "#Air quality dataset - https://archive.ics.uci.edu/dataset/360/air+quality########################################\n",
        "#Analysis of raw data - https://github.com/Gauhar1107/AirQualityUCI/blob/master/Air%20Quality.ipynb################\n",
        "\n",
        "#df=pd.read_csv(r'/content/drive/MyDrive/PHD/2024/AirQualityUCI.csv', sep=';', header=0, low_memory=False, infer_datetime_format=True, parse_dates={'datetime':[0,1]}, index_col=['datetime'])\n",
        "df=pd.read_csv(r'/content/drive/MyDrive/PHD/2024/AirQualityUCI.csv', parse_dates={'datetime':[0,1]}, index_col=['datetime'])\n",
        "df.head()\n",
        "\n",
        "#df = df[['Global_active_power','Global_reactive_power','Global_intensity']]\n",
        "#Imputing NULL\n",
        "df = df.replace('?', np.nan)\n",
        "df.isnull().sum()\n",
        "\n",
        "#IMputing missing value\n",
        "\n",
        "def fill_missing(values):\n",
        "    one_day = 60*24\n",
        "    for row in range(df.shape[0]):\n",
        "        for col in range(df.shape[1]):\n",
        "            if np.isnan(values[row][col]):\n",
        "                values[row,col] = values[row-one_day,col]\n",
        "df = df.astype('float32')\n",
        "fill_missing(df.values)\n",
        "df.isnull().sum()\n",
        "\n",
        "#Downsampling to Days  --------------------------- to perform granger causality on the entire time series history------------------------------to reduce computation--------------####\n",
        "daily_df = df #no downsampling needed\n",
        "daily_df.head()\n",
        "#daily_df =df\n",
        "ts_len = daily_df.shape[0]\n",
        "\n",
        "#Now convert index to column\n",
        "daily_df['datetime']=daily_df.index\n",
        "\n",
        "#VISUALISE THE TIMESERIES\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=daily_df['datetime'], y=daily_df['CO(GT)'], name='CO(GT)'))\n",
        "\n",
        "fig.update_layout(showlegend=True, title='Air Quality')\n",
        "fig.show()\n",
        "\n",
        "#remove index column unless required.\n",
        "\n",
        "daily_df.drop(daily_df.columns[13], axis=1, inplace=True)\n",
        "#daily_df.drop(daily_df.columns[2], axis=1, inplace=True) #dropped Voltage\n",
        "#Scaling the values\n",
        "whole_series = daily_df\n",
        "scalers={}\n",
        "for i in daily_df.columns:\n",
        "    scaler = MinMaxScaler(feature_range=(-1,1))\n",
        "    s_s = scaler.fit_transform(whole_series[i].values.reshape(-1,1))\n",
        "    s_s=np.reshape(s_s,len(s_s))\n",
        "    scalers['scaler_'+ i] = scaler\n",
        "    whole_series[i]=s_s\n",
        "\n",
        "\n",
        "\n",
        "#Stationarity check for each time series ---- This module can be run manually for now\n",
        "\n",
        "def augmented_dickey_fuller_statistics(time_series):\n",
        "  result = adfuller(time_series.values)\n",
        "  ADF_Statistic = result[0]\n",
        "  p_value = result[1]\n",
        "  Critical_values_1 = result[4][\"1%\"]\n",
        "  Critical_values_5 = result[4][\"5%\"]\n",
        "  Critical_values_10 = result[4][\"10%\"]\n",
        "\n",
        "  # We take that p-value should be less than 0.05 and ADF_statistic should be less than critical value at 5% confidence Critical_value_5\n",
        "  if p_value <0.05 and ADF_Statistic < Critical_values_5:\n",
        "    return \"stationary\"\n",
        "  else:\n",
        "    return \"non-stationary\"\n",
        "\n",
        "for i in range(0,whole_series.shape[1]):\n",
        "  print('Augmented Dickey-Fuller Test Result:', whole_series.iloc[:,i].name)\n",
        "  x= augmented_dickey_fuller_statistics(whole_series.iloc[:,i])\n",
        "  print(x)\n",
        "  #if any of the x is \"non-stationary\": df_difference = whole_series.diff() -- and then deal with df_difference\n",
        "\n",
        "#Granger Causality\n",
        "\n",
        "max_lag_GC = 50\n",
        "\n",
        "#https://phdinds-aim.github.io/time_series_handbook/04_GrangerCausality/04_GrangerCausality.html\n",
        "\n",
        "def granger_causation_matrix(data, variables, p, test = 'ssr_chi2test', verbose=False):\n",
        "    \"\"\"Check Granger Causality of all possible combinations of the time series.\n",
        "    The rows are the response variables, columns are predictors. The values in the table\n",
        "    are the P-Values. P-Values lesser than the significance level (0.05), implies\n",
        "    the Null Hypothesis that the coefficients of the corresponding past values is\n",
        "    zero, that is, the X does not cause Y can be rejected.\n",
        "\n",
        "    data      : pandas dataframe containing the time series variables\n",
        "    variables : list containing names of the time series variables.\n",
        "    \"\"\"\n",
        "    df = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)\n",
        "    for c in df.columns:\n",
        "        for r in df.index:\n",
        "            test_result = grangercausalitytests(data[[r, c]], p, verbose=False)\n",
        "            p_values = [round(test_result[i+1][0][test][1],4) for i in range(p)]\n",
        "            if verbose: print(f'Y = {r}, X = {c}, P Values = {p_values}')\n",
        "            min_p_value = np.min(p_values)\n",
        "            df.loc[r, c] = min_p_value\n",
        "    df.columns = [var + '_x' for var in variables]\n",
        "    df.index = [var + '_y' for var in variables]\n",
        "    return df\n",
        "\n",
        "granger_causation_matrix(whole_series, whole_series.columns, max_lag_GC)\n",
        "\n",
        "###############Recall: If a given p-value is < significance level (0.05), then, the corresponding X series (column) causes the Y (row).\n",
        "\n",
        "#### GRANGER CAUSALITY PROVES that following features are very weakly related with most (almost no ausal effect) hence will be removed. AH\n",
        "\n",
        "whole_series.drop(whole_series.columns[12], axis=1, inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "def extract_windows_vectorized(array, large_seq_size):\n",
        "    start = 0\n",
        "    last_index = len(array)-1\n",
        "    max_time =  last_index - large_seq_size +1  ##last index upto which sliding windoe begining can go\n",
        "\n",
        "    sub_windows = (\n",
        "        start +\n",
        "        # expand_dims are used to convert a 1D array to 2D array.\n",
        "        np.expand_dims(np.arange(large_seq_size), 0) +\n",
        "        np.expand_dims(np.arange(max_time + 1), 0).T\n",
        "    ).astype(int)\n",
        "\n",
        "    return array[sub_windows]\n",
        "\n",
        "\n",
        "#DEFINE K - User parameter - length of the LONG time series sequence.\n",
        "K = 48  #taking 1 day of hourly data\n",
        "\n",
        "large_seq_size = K\n",
        "n_features = whole_series.shape[1]\n",
        "\n",
        "Long = extract_windows_vectorized(whole_series.values,large_seq_size)\n",
        "\n",
        "Long_train = Long\n",
        "\n",
        "\n",
        "#First, define a function that can generate small subsequences for all the large K sequences\n",
        "\n",
        "def generate_small_seq(series, n_past, n_future):\n",
        "  #\n",
        "  # n_past ==> no of past observations -- OR -- sliding window\n",
        "  #\n",
        "  # n_future ==> no of future observations -- prediction variable y\n",
        "  #\n",
        "  X, y = list(), list()\n",
        "  for window_start in range(len(series)):\n",
        "    past_end = window_start + n_past\n",
        "    future_end = past_end + n_future\n",
        "    if future_end > len(series):\n",
        "      break\n",
        "    # slicing the past and future parts of the window\n",
        "    past, future = series[window_start:past_end, :], series[past_end:future_end, :]\n",
        "    X.append(past)\n",
        "    y.append(future)\n",
        "  return np.array(X), np.array(y)\n",
        "\n",
        "\n",
        "n_future=1\n",
        "predictions = list()\n",
        "\n",
        "rmse_list = list()\n",
        "min_window_list = list()\n",
        "best_window_for_long_seq = list()\n",
        "AIC = list()\n",
        "n_fold = 6 # 5 fold plus 1 for test)\n",
        "# evaluate a logistic regression model using k-fold cross-validation\n",
        "n_future=1\n",
        "predictions = list()\n",
        "\n",
        "rmse_list = list()\n",
        "min_window_list = list()\n",
        "best_window_for_long_seq = list()\n",
        "AIC = list()\n",
        "n_fold = 6 # 5 fold plus 1 for test)\n",
        "# evaluate a logistic regression model using k-fold cross-validation\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "\n",
        "\n",
        "\n",
        "best_window_for_long_seq.clear()\n",
        "\n",
        "#------------------------NEW JUNE 2024 --------------------------------SKIP INDIVIDUAL IOSW--- GO TO COSW DIRECT----------------------------------------------------------------------------------------------------\n",
        "#for i in range(Long_train.shape[0]) :\n",
        "for i in range(3544,3545) :\n",
        "\n",
        "  cur_seq = Long_train[i,:,:]\n",
        "  AIC.clear()\n",
        "  model = VAR(cur_seq)\n",
        "\n",
        "  for m in range(K) :\n",
        "    #print(Long_train)\n",
        "    try:\n",
        "      results = model.fit(m)\n",
        "      print('Order =', m)\n",
        "      print('AIC: ', results.aic)\n",
        "      print('BIC: ', results.bic)\n",
        "      AIC.append(results.aic)\n",
        "    except:\n",
        "      AIC.append(99999)\n",
        "      print('VAR could not solve row number')\n",
        "      print(i, m)\n",
        "\n",
        "\n",
        "  minAIC_index = AIC.index(min(AIC))+1\n",
        "  print(AIC)\n",
        "  print('Minimum lag = ', minAIC_index)\n",
        "  best_window_for_long_seq.append(minAIC_index)\n",
        "\n",
        "#OUT OF ALL LOOPS NOW\n",
        "#best_window_for_long_seq now contains the best multivariate window size for each of the long sequence i\n",
        "print(best_window_for_long_seq)\n",
        "Window = np.array(best_window_for_long_seq)\n",
        "\n",
        "\n",
        "np.save(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_AIRQUALITY/multivariate_long_sequences-TRAIN-Daily-DIRECT-VAR.npy',Long_train)\n",
        "np.save(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_AIRQUALITY/multivariate_long_sequences_WINDOW-Daily-DIRECT-VAR.npy',Window)\n",
        "#np.save(r'/content/drive/MyDrive/PHD/2021/multivariate_long_sequences-TEST.npy',Long_test)\n",
        "print('saving completed')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "W-RMQkgLak9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Xp-Mv3Ksamxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0zEUESMBM_Eo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQ6ZgIvrdRNp"
      },
      "source": [
        "# New Section"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "https://github.com/supriyag123/PHD_Pub/blob/main/PAPER_GDRNet_PREDMAINT_Step1.ipynb",
      "authorship_tag": "ABX9TyMopKhi1fwWPk8RmS7EYsZm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}