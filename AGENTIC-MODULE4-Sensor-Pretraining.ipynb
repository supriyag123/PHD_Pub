{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supriyag123/PHD_Pub/blob/main/AGENTIC-MODULE4-Sensor-Pretraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HoP7OuWNxlsJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7ed54f2f-a3f8-4c26-acd4-a2ebaf0be9a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Original data shape: (3627, 50, 12)\n",
            "Training data shape: (2627, 50, 12)\n",
            "Training 12 sensors...\n",
            "\n",
            "Training sensor 0...\n",
            "Data shape: (2627, 50, 1)\n",
            "Train: 2101, Val: 526\n",
            "Epoch 1/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - loss: 0.3428 - val_loss: 0.0599\n",
            "Epoch 2/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.1577 - val_loss: 0.0472\n",
            "Epoch 3/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.1252 - val_loss: 0.2405\n",
            "Epoch 4/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 60ms/step - loss: 0.2178 - val_loss: 0.0569\n",
            "Epoch 5/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.1385 - val_loss: 0.0522\n",
            "Epoch 6/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.1334 - val_loss: 0.0500\n",
            "Epoch 7/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - loss: 0.1330 - val_loss: 0.0490\n",
            "Epoch 8/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.1201 - val_loss: 0.0485\n",
            "Epoch 9/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.1079 - val_loss: 0.0455\n",
            "Epoch 10/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.1008 - val_loss: 0.0434\n",
            "Epoch 11/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - loss: 0.0915 - val_loss: 0.0417\n",
            "Epoch 12/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0819 - val_loss: 0.0419\n",
            "Epoch 13/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0808 - val_loss: 0.0400\n",
            "Epoch 14/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0753 - val_loss: 0.0378\n",
            "Epoch 15/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - loss: 0.0780 - val_loss: 0.0482\n",
            "Epoch 16/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - loss: 0.1252 - val_loss: 0.0425\n",
            "Epoch 17/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0981 - val_loss: 0.0406\n",
            "Epoch 18/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0830 - val_loss: 0.0377\n",
            "Epoch 19/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - loss: 0.0750 - val_loss: 0.0388\n",
            "Epoch 20/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - loss: 0.0681 - val_loss: 0.0392\n",
            "Epoch 21/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - loss: 0.0656 - val_loss: 0.0381\n",
            "Epoch 22/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0598 - val_loss: 0.0345\n",
            "Epoch 23/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - loss: 0.0601 - val_loss: 0.0361\n",
            "Epoch 24/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - loss: 0.0572 - val_loss: 0.0337\n",
            "Epoch 25/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0534 - val_loss: 0.0327\n",
            "Epoch 26/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0507 - val_loss: 0.0307\n",
            "Epoch 27/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - loss: 0.0486 - val_loss: 0.0311\n",
            "Epoch 28/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.0471 - val_loss: 0.0308\n",
            "Epoch 29/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 0.0461 - val_loss: 0.0300\n",
            "Epoch 30/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 0.0453 - val_loss: 0.0300\n",
            "Epoch 31/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 53ms/step - loss: 0.0469 - val_loss: 0.0337\n",
            "Epoch 32/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - loss: 0.0457 - val_loss: 0.0290\n",
            "Epoch 33/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 0.0447 - val_loss: 0.0299\n",
            "Epoch 34/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - loss: 0.0458 - val_loss: 0.0317\n",
            "Epoch 35/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - loss: 0.0421 - val_loss: 0.0288\n",
            "Epoch 36/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - loss: 0.0438 - val_loss: 0.0295\n",
            "Epoch 37/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - loss: 0.0438 - val_loss: 0.0398\n",
            "Epoch 38/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0673 - val_loss: 0.0318\n",
            "Epoch 39/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 58ms/step - loss: 0.0465 - val_loss: 0.0308\n",
            "Epoch 40/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0439 - val_loss: 0.0288\n",
            "Epoch 41/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.0413 - val_loss: 0.0297\n",
            "Epoch 42/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0435 - val_loss: 0.0287\n",
            "Epoch 43/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - loss: 0.0395 - val_loss: 0.0287\n",
            "Epoch 44/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0419 - val_loss: 0.0295\n",
            "Epoch 45/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.0415 - val_loss: 0.0290\n",
            "Epoch 46/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - loss: 0.0415 - val_loss: 0.0291\n",
            "Epoch 47/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - loss: 0.0378 - val_loss: 0.0283\n",
            "Epoch 48/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 0.0386 - val_loss: 0.0283\n",
            "Epoch 49/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - loss: 0.0384 - val_loss: 0.0282\n",
            "Epoch 50/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 0.0364 - val_loss: 0.0296\n",
            "Epoch 51/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - loss: 0.0389 - val_loss: 0.0286\n",
            "Epoch 52/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0387 - val_loss: 0.0302\n",
            "Epoch 53/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - loss: 0.0381 - val_loss: 0.0280\n",
            "Epoch 54/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0356 - val_loss: 0.0284\n",
            "Epoch 55/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.0436 - val_loss: 0.0274\n",
            "Epoch 56/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - loss: 0.0352 - val_loss: 0.0279\n",
            "Epoch 57/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.0360 - val_loss: 0.0281\n",
            "Epoch 58/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - loss: 0.0345 - val_loss: 0.0254\n",
            "Epoch 59/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.0358 - val_loss: 0.0334\n",
            "Epoch 60/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - loss: 0.0380 - val_loss: 0.0264\n",
            "Epoch 61/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - loss: 0.0337 - val_loss: 0.0297\n",
            "Epoch 62/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0331 - val_loss: 0.0252\n",
            "Epoch 63/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - loss: 0.0335 - val_loss: 0.0288\n",
            "Epoch 64/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 53ms/step - loss: 0.0366 - val_loss: 0.0258\n",
            "Epoch 65/100\n",
            "\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - loss: 0.0329 - val_loss: 0.0269\n",
            "Epoch 66/100\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2923473075.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2923473075.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mbaseline_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_sensor_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msensor_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensor_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msensor_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'success'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'baseline_stats'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbaseline_stats\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2923473075.py\u001b[0m in \u001b[0;36mtrain_sensor_model\u001b[0;34m(sensor_data, sensor_id, base_path, window_length)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mearly_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     history = model.fit(\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/callbacks/callback_list.py\u001b[0m in \u001b[0;36mon_train_batch_begin\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Simple Sensor Pre-Training System\n",
        "=================================\n",
        "\n",
        "Trains LSTM Autoencoders for each sensor and saves models with baseline statistics.\n",
        "\n",
        "Usage:\n",
        "    python sensor_pretraining.py\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import LSTM, Dense, RepeatVector, TimeDistributed, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "\n",
        "def build_lstm_autoencoder(window_length: int, latent_dim: int = 32) -> Model:\n",
        "    \"\"\"Build LSTM Autoencoder.\"\"\"\n",
        "    inputs = Input(shape=(window_length, 1))\n",
        "\n",
        "    # Encoder\n",
        "    encoded = LSTM(latent_dim, activation='relu', return_sequences=False)(inputs)\n",
        "\n",
        "    # Decoder\n",
        "    decoded = RepeatVector(window_length)(encoded)\n",
        "    decoded = LSTM(latent_dim, activation='relu', return_sequences=True)(decoded)\n",
        "    outputs = TimeDistributed(Dense(1, activation='linear'))(decoded)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def train_sensor_model(sensor_data, sensor_id, base_path, window_length):\n",
        "    \"\"\"Train model for one sensor.\"\"\"\n",
        "\n",
        "    print(f\"\\nTraining sensor {sensor_id}...\")\n",
        "    print(f\"Data shape: {sensor_data.shape}\")\n",
        "\n",
        "    # Split data\n",
        "    n_samples = len(sensor_data)\n",
        "    n_train = int(0.8 * n_samples)\n",
        "\n",
        "    X_train = sensor_data[:n_train]\n",
        "    X_val = sensor_data[n_train:]\n",
        "\n",
        "    print(f\"Train: {len(X_train)}, Val: {len(X_val)}\")\n",
        "\n",
        "    # Create directories\n",
        "    sensor_dir = os.path.join(base_path, 'sensor', 'model')\n",
        "    checkpoint_dir = os.path.join(sensor_dir, 'checkpoints')\n",
        "    os.makedirs(sensor_dir, exist_ok=True)\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "    # Build model\n",
        "    model = build_lstm_autoencoder(window_length)\n",
        "\n",
        "    # Setup callbacks\n",
        "    checkpoint_path = os.path.join(checkpoint_dir, f'sensor_{sensor_id}_best.h5')\n",
        "\n",
        "    callbacks = [\n",
        "        # Save best model during training\n",
        "        ModelCheckpoint(\n",
        "            filepath=checkpoint_path,\n",
        "            monitor='val_loss',\n",
        "            save_best_only=True,\n",
        "            save_weights_only=False,\n",
        "            mode='min',\n",
        "            verbose=1\n",
        "        ),\n",
        "        # Early stopping\n",
        "        EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=15,\n",
        "            restore_best_weights=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        # Reduce learning rate on plateau\n",
        "        ReduceLROnPlateau(\n",
        "            monitor='val_loss',\n",
        "            factor=0.5,\n",
        "            patience=7,\n",
        "            min_lr=1e-6,\n",
        "            verbose=1\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    # Train model\n",
        "    print(\"Starting training with checkpointing...\")\n",
        "    history = model.fit(\n",
        "        X_train, X_train,\n",
        "        validation_data=(X_val, X_val),\n",
        "        epochs=100,\n",
        "        batch_size=32,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    print(f\"Training completed. Best model saved to: {checkpoint_path}\")\n",
        "\n",
        "    # Compute baseline reconstruction errors on validation set\n",
        "    print(\"Computing baseline errors...\")\n",
        "    val_predictions = model.predict(X_val, verbose=0)\n",
        "    baseline_errors = []\n",
        "\n",
        "    for i in range(len(X_val)):\n",
        "        error = mean_squared_error(X_val[i].flatten(), val_predictions[i].flatten())\n",
        "        baseline_errors.append(error)\n",
        "\n",
        "    baseline_stats = {\n",
        "        'mean': float(np.mean(baseline_errors)),\n",
        "        'std': float(np.std(baseline_errors)) + 1e-8,\n",
        "        'q95': float(np.percentile(baseline_errors, 95)),\n",
        "        'q99': float(np.percentile(baseline_errors, 99)),\n",
        "        'baseline_errors': baseline_errors  # Store for drift detection\n",
        "    }\n",
        "\n",
        "    # Save final model and metadata\n",
        "    model_path = os.path.join(sensor_dir, f'sensor_{sensor_id}_model.h5')\n",
        "    metadata_path = os.path.join(sensor_dir, f'sensor_{sensor_id}_metadata.pkl')\n",
        "\n",
        "    model.save(model_path)\n",
        "\n",
        "    metadata = {\n",
        "        'sensor_id': sensor_id,\n",
        "        'window_length': window_length,\n",
        "        'baseline_stats': baseline_stats,\n",
        "        'trained_at': datetime.now(),\n",
        "        'epochs_trained': len(history.history['loss']),\n",
        "        'final_val_loss': float(history.history['val_loss'][-1]),\n",
        "        'checkpoint_path': checkpoint_path\n",
        "    }\n",
        "\n",
        "    with open(metadata_path, 'wb') as f:\n",
        "        pickle.dump(metadata, f)\n",
        "\n",
        "    print(f\"âœ… Sensor {sensor_id} completed\")\n",
        "    print(f\"   Final model: {model_path}\")\n",
        "    print(f\"   Best checkpoint: {checkpoint_path}\")\n",
        "    print(f\"   Baseline error: {baseline_stats['mean']:.6f} Â± {baseline_stats['std']:.6f}\")\n",
        "\n",
        "    return baseline_stats\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main training function.\"\"\"\n",
        "\n",
        "    # Your exact paths\n",
        "    data_path = r'/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/multivariate_long_sequences-TRAIN-Daily-DIRECT-VAR.npy'\n",
        "    base_path = r'/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/'\n",
        "\n",
        "    print(\"ğŸš€ Simple Sensor Pre-Training\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    # Load data\n",
        "    print(\"Loading data...\")\n",
        "    data = np.load(data_path)\n",
        "    print(f\"Original data shape: {data.shape}\")\n",
        "\n",
        "    # Remove last 1000 samples (holdout)\n",
        "    training_data = data[:-1000]\n",
        "    print(f\"Training data shape: {training_data.shape}\")\n",
        "\n",
        "    batch_size, window_length, num_sensors = training_data.shape\n",
        "    print(f\"Will train {num_sensors} sensors\")\n",
        "\n",
        "    # Train each sensor\n",
        "    print(f\"\\nğŸ‹ï¸ Training {num_sensors} LSTM Autoencoders...\")\n",
        "\n",
        "    results = {}\n",
        "    successful = 0\n",
        "\n",
        "    for sensor_id in range(num_sensors):\n",
        "        try:\n",
        "            # Extract data for this sensor: [batch, timestep, 1]\n",
        "            sensor_data = training_data[:, :, sensor_id:sensor_id+1]  # Keep feature dimension\n",
        "\n",
        "            baseline_stats = train_sensor_model(sensor_data, sensor_id, base_path, window_length)\n",
        "            results[sensor_id] = {'success': True, 'baseline_stats': baseline_stats}\n",
        "            successful += 1\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Failed training sensor {sensor_id}: {e}\")\n",
        "            results[sensor_id] = {'success': False, 'error': str(e)}\n",
        "\n",
        "    # Final summary\n",
        "    print(f\"\\nğŸ“Š TRAINING SUMMARY\")\n",
        "    print(\"=\" * 40)\n",
        "    print(f\"âœ… Successful: {successful}/{num_sensors}\")\n",
        "    print(f\"ğŸ’¾ Models saved to: {base_path}/sensor/model/\")\n",
        "\n",
        "    if successful > 0:\n",
        "        print(f\"\\nğŸ† Successfully trained sensors:\")\n",
        "        for sensor_id, result in results.items():\n",
        "            if result['success']:\n",
        "                baseline = result['baseline_stats']\n",
        "                print(f\"  Sensor {sensor_id}: baseline error {baseline['mean']:.6f}\")\n",
        "\n",
        "    # Save training summary\n",
        "    summary_path = os.path.join(base_path, 'sensor', 'model', 'training_summary.pkl')\n",
        "    with open(summary_path, 'wb') as f:\n",
        "        pickle.dump({\n",
        "            'results': results,\n",
        "            'training_data_shape': training_data.shape,\n",
        "            'successful_sensors': successful,\n",
        "            'timestamp': datetime.now()\n",
        "        }, f)\n",
        "\n",
        "    print(f\"\\nğŸ’¾ Summary saved: {summary_path}\")\n",
        "    print(\"âœ… Pre-training completed!\")\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "v_5iji919H_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8OtWHK--uG6W"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "https://github.com/supriyag123/PHD_Pub/blob/main/AGENTIC-MODULE4-Sensor-Pretraining.ipynb",
      "authorship_tag": "ABX9TyPx0WEeyLipLEOtb4fuWWFN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}