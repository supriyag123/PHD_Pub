{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supriyag123/PHD_Pub/blob/main/PAPER_GDRNet_Step4-SVR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HoP7OuWNxlsJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "527b5f67-f434-4a62-ec98-c305a4d1d06c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "/content/drive/MyDrive/PHD/2024/MLPOutput/AQ_predicted_window.csv not found.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-fba8c0654ef7>\u001b[0m in \u001b[0;36m<cell line: 54>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m#-----------for test dataset-----------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'/content/drive/MyDrive/PHD/2024/MLPOutput/AQ_predicted_window.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'/content/drive/MyDrive/PHD/2024/MLPOutput/AQ_derived_window_label.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0mx_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'/content/drive/MyDrive/PHD/2024/MLPOutput/AQ_test_data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0mdelimiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m     arr = _read(fname, dtype=dtype, comment=comment, delimiter=delimiter,\n\u001b[0m\u001b[1;32m   1374\u001b[0m                 \u001b[0mconverters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiplines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskiprows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m                 \u001b[0munpack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[1;32m    990\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m                 \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    531\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    532\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{path} not found.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: /content/drive/MyDrive/PHD/2024/MLPOutput/AQ_predicted_window.csv not found."
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import math\n",
        "import plotly.graph_objects as go\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, RepeatVector, TimeDistributed, Input\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import keras.backend as K\n",
        "from keras.callbacks import Callback\n",
        "import plotly\n",
        "import plotly.express as px # for data visualization\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LassoCV, MultiTaskLassoCV, Ridge\n",
        "from sklearn.ensemble import IsolationForest\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "from sklearn.svm import SVR\n",
        "from numpy import array\n",
        "from numpy import hstack\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LassoCV, MultiTaskLassoCV\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from math import sqrt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from keras.models import Model\n",
        "from statsmodels.tsa.api import VAR\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.tools.eval_measures import rmse, aic\n",
        "from statsmodels.tsa.stattools import acf\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from numpy import arange\n",
        "#-----------------------------------------------------GET DATA - X, Predicted Wndow from MLP, and Derived Labels, for the entire dataset that was gennerated through VAE-----------------------------------\n",
        "\n",
        "\n",
        "#-----------for test dataset-----------------------------------------------------------------------\n",
        "y_pred = np.loadtxt(r'/content/drive/MyDrive/PHD/2024/MLPOutput/AQ_predicted_window.csv')\n",
        "y_true = np.loadtxt(r'/content/drive/MyDrive/PHD/2024/MLPOutput/AQ_derived_window_label.csv')\n",
        "x_orig = np.loadtxt(r'/content/drive/MyDrive/PHD/2024/MLPOutput/AQ_test_data.csv')\n",
        "\n",
        "\n",
        "\n",
        "n_features = 12\n",
        "n_future = 1\n",
        "window_size = int(x_orig.shape[1]/n_features)\n",
        "x = x_orig.reshape((x_orig.shape[0],window_size,n_features))\n",
        "\n",
        "sample_size = 10000\n",
        "#-----------------------------------------------CASES - pot window values and pick a few fixed window sizes -------------------------------------------\n",
        "\n",
        "plt.figure(figsize=(15,6))\n",
        "plt.subplot(1,2,1)\n",
        "plt.title(\"Distribution before Transformation\", fontsize=15)\n",
        "sns.histplot(y_true, kde=True, color=\"red\")\n",
        "plt.subplot(1,2,2)\n",
        "\n",
        "# Import libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "fig = plt.figure(figsize =(10, 7))\n",
        "# Creating plot\n",
        "plt.boxplot(y_true)\n",
        "# show plot\n",
        "plt.show()\n",
        "\n",
        "fx_window1 = 10\n",
        "fx_window2 = 20\n",
        "fx_window3 = 30\n",
        "fx_window4 = 40\n",
        "pred_step = n_future=1\n",
        "\n",
        "se_1 = list()\n",
        "se_2 = list()\n",
        "se_3 = list()\n",
        "se_4 = list()\n",
        "se_x = list()\n",
        "\n",
        "ape_1 = list()\n",
        "ape_2 = list()\n",
        "ape_3 = list()\n",
        "ape_4 = list()\n",
        "ape_x = list()\n",
        "\n",
        "ae_1 = list()\n",
        "ae_2 = list()\n",
        "ae_3 = list()\n",
        "ae_4 = list()\n",
        "ae_x = list()\n",
        "\n",
        "\n",
        "\n",
        "################---------------------------METHOD 2- -GO BY RMSE----------------------------------------------------####################\n",
        "\n",
        "def generate_small_seq(series, n_past, n_future):\n",
        "  #\n",
        "  # n_past ==> no of past observations -- OR -- sliding window\n",
        "  #\n",
        "  # n_future ==> no of future observations -- prediction variable y\n",
        "  #\n",
        "  X, y = list(), list()\n",
        "  for window_start in range(len(series)):\n",
        "    past_end = window_start + n_past\n",
        "    future_end = past_end + n_future\n",
        "    if future_end > len(series):\n",
        "      break\n",
        "    # slicing the past and future parts of the window\n",
        "    past, future = series[window_start:past_end, :], series[past_end:future_end, 1] #We just take the active power as the prediction variable\n",
        "    X.append(past)\n",
        "    y.append(future)\n",
        "  return np.array(X), np.array(y)\n",
        "\n",
        "se_1 = list()\n",
        "se_2 = list()\n",
        "se_3 = list()\n",
        "se_4 = list()\n",
        "se_x = list()\n",
        "\n",
        "ape_1 = list()\n",
        "ape_2 = list()\n",
        "ape_3 = list()\n",
        "ape_4 = list()\n",
        "ape_x = list()\n",
        "\n",
        "ae_1 = list()\n",
        "ae_2 = list()\n",
        "ae_3 = list()\n",
        "ae_4 = list()\n",
        "ae_x = list()\n",
        "\n",
        "\n",
        "min_window_list = list()\n",
        "best_window_for_long_seq = list()\n",
        "AIC = list()\n",
        "n_fold = 6 # 5 fold plus 1 for test)\n",
        "# evaluate a logistic regression model using k-fold cross-validation\n",
        "n_future=1\n",
        "predictions = list()\n",
        "\n",
        "\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "\n",
        "best_window_for_long_seq.clear()\n",
        "\n",
        "#window_list = [fx_window1, fx_window2, fx_window3, fx_window4]\n",
        "########------------Window 1-------------------------\n",
        "\n",
        "\n",
        "############## Window 1-----------------------------------\n",
        "se_1.clear()\n",
        "ape_1.clear()\n",
        "ae_1.clear()\n",
        "for i in range(sample_size) :\n",
        "#iterate over the entire  long sequences of multivariate time series\n",
        "  Total_small_seq_X, Total_small_seq_y = generate_small_seq(x[i,:,:], fx_window1 , n_future)\n",
        "  Total_small_seq_X_reshaped = Total_small_seq_X.reshape(Total_small_seq_X.shape[0],Total_small_seq_X.shape[1]*Total_small_seq_X.shape[2])\n",
        "  Total_small_seq_y_reshaped = Total_small_seq_y\n",
        "  maxval2 = Total_small_seq_X_reshaped.shape[0]\n",
        "  count_train2 = int(math.ceil(0.7*maxval2))\n",
        "  Small_train_X = Total_small_seq_X_reshaped[0:count_train2]\n",
        "  Small_train_y = Total_small_seq_y_reshaped[0:count_train2]\n",
        "  Small_test_X =  Total_small_seq_X_reshaped[count_train2:]\n",
        "  Small_test_y = Total_small_seq_y_reshaped[count_train2:]\n",
        "  tscv = TimeSeriesSplit(n_splits=n_fold-1)\n",
        "  #regressor = LassoCV(alphas=0.1)\n",
        "  SVR(C=1.0, epsilon=0.2)\n",
        "  #regressor = LinearRegression()\n",
        "  try:\n",
        "    regressor.fit(Small_train_X, Small_train_y.ravel()) #get jth time series only\n",
        "    if Small_test_X.shape[0] == 0:\n",
        "      break\n",
        "    y_predk = regressor.predict(Small_test_X)\n",
        "    #print('alpha: %f' % regressor.alpha_)\n",
        "    se =  ((Small_test_y-y_predk)**2).mean()/abs(Small_test_y.mean())\n",
        "    ape = abs(Small_test_y-y_predk).mean()/abs(Small_test_y.mean())\n",
        "    ae = abs(Small_test_y-y_predk).mean()\n",
        "    #mse = mean_squared_error(Small_test_y, y_predk)\n",
        "    #print(rmse)\n",
        "    se_1.append(se)\n",
        "    ape_1.append(ape)\n",
        "    ae_1.append(ae)\n",
        "  except:\n",
        "    se_1.append(9999)\n",
        "    ape_1.append(9999)\n",
        "    ae_1.append(9999)\n",
        "    print('error')\n",
        "\n",
        "\n",
        "\n",
        "############## Window 2-----------------------------------\n",
        "se_2.clear()\n",
        "ape_2.clear()\n",
        "ae_2.clear()\n",
        "for i in range(sample_size) :\n",
        "#iterate over the entire  long sequences of multivariate time series\n",
        "  Total_small_seq_X, Total_small_seq_y = generate_small_seq(x[i,:,:], fx_window2 , n_future)\n",
        "  Total_small_seq_X_reshaped = Total_small_seq_X.reshape(Total_small_seq_X.shape[0],Total_small_seq_X.shape[1]*Total_small_seq_X.shape[2])\n",
        "  Total_small_seq_y_reshaped = Total_small_seq_y\n",
        "  maxval2 = Total_small_seq_X_reshaped.shape[0]\n",
        "  count_train2 = int(math.ceil(0.7*maxval2))\n",
        "  Small_train_X = Total_small_seq_X_reshaped[0:count_train2]\n",
        "  Small_train_y = Total_small_seq_y_reshaped[0:count_train2]\n",
        "  Small_test_X =  Total_small_seq_X_reshaped[count_train2:]\n",
        "  Small_test_y = Total_small_seq_y_reshaped[count_train2:]\n",
        "  tscv = TimeSeriesSplit(n_splits=n_fold-1)\n",
        "  #regressor = LassoCV(alphas=0.1)\n",
        "  SVR(C=1.0, epsilon=0.2)\n",
        "  #regressor = LinearRegression()\n",
        "  try:\n",
        "    regressor.fit(Small_train_X, Small_train_y.ravel()) #get jth time series only\n",
        "    if Small_test_X.shape[0] == 0:\n",
        "      break\n",
        "    y_predk = regressor.predict(Small_test_X)\n",
        "    #print('alpha: %f' % regressor.alpha_)\n",
        "    se =  ((Small_test_y-y_predk)**2).mean()/abs(Small_test_y.mean())\n",
        "    ape = abs(Small_test_y-y_predk).mean()/abs(Small_test_y.mean())\n",
        "    ae = abs(Small_test_y-y_predk).mean()\n",
        "    #mse = mean_squared_error(Small_test_y, y_predk)\n",
        "    #print(rmse)\n",
        "    se_2.append(se)\n",
        "    ape_2.append(ape)\n",
        "    ae_2.append(ae)\n",
        "  except:\n",
        "    se_2.append(9999)\n",
        "    ape_2.append(9999)\n",
        "    ae_2.append(9999)\n",
        "    print('error')\n",
        "\n",
        "\n",
        "############## Window 3-----------------------------------\n",
        "se_3.clear()\n",
        "ape_3.clear()\n",
        "ae_3.clear()\n",
        "for i in range(sample_size) :\n",
        "#iterate over the entire  long sequences of multivariate time series\n",
        "  Total_small_seq_X, Total_small_seq_y = generate_small_seq(x[i,:,:], fx_window3 , n_future)\n",
        "  Total_small_seq_X_reshaped = Total_small_seq_X.reshape(Total_small_seq_X.shape[0],Total_small_seq_X.shape[1]*Total_small_seq_X.shape[2])\n",
        "  Total_small_seq_y_reshaped = Total_small_seq_y\n",
        "  maxval2 = Total_small_seq_X_reshaped.shape[0]\n",
        "  count_train2 = int(math.ceil(0.7*maxval2))\n",
        "  Small_train_X = Total_small_seq_X_reshaped[0:count_train2]\n",
        "  Small_train_y = Total_small_seq_y_reshaped[0:count_train2]\n",
        "  Small_test_X =  Total_small_seq_X_reshaped[count_train2:]\n",
        "  Small_test_y = Total_small_seq_y_reshaped[count_train2:]\n",
        "  tscv = TimeSeriesSplit(n_splits=n_fold-1)\n",
        "  #regressor = LassoCV(alphas=0.1)\n",
        "  SVR(C=1.0, epsilon=0.2)\n",
        "  #regressor = LinearRegression()\n",
        "  try:\n",
        "    regressor.fit(Small_train_X, Small_train_y.ravel()) #get jth time series only\n",
        "    if Small_test_X.shape[0] == 0:\n",
        "      break\n",
        "    y_predk = regressor.predict(Small_test_X)\n",
        "    #print('alpha: %f' % regressor.alpha_)\n",
        "    se =  ((Small_test_y-y_predk)**2).mean()/abs(Small_test_y.mean())\n",
        "    ape = abs(Small_test_y-y_predk).mean()/abs(Small_test_y.mean())\n",
        "    ae = abs(Small_test_y-y_predk).mean()\n",
        "    #mse = mean_squared_error(Small_test_y, y_predk)\n",
        "    #print(rmse)\n",
        "    se_3.append(se)\n",
        "    ape_3.append(ape)\n",
        "    ae_3.append(ae)\n",
        "  except:\n",
        "    se_3.append(9999)\n",
        "    ape_3.append(9999)\n",
        "    ae_3.append(9999)\n",
        "    print('error')\n",
        "\n",
        "\n",
        "############## Window 4-----------------------------------\n",
        "se_4.clear()\n",
        "ape_4.clear()\n",
        "ae_4.clear()\n",
        "for i in range(sample_size) :\n",
        "#iterate over the entire  long sequences of multivariate time series\n",
        "  Total_small_seq_X, Total_small_seq_y = generate_small_seq(x[i,:,:], fx_window4 , n_future)\n",
        "  Total_small_seq_X_reshaped = Total_small_seq_X.reshape(Total_small_seq_X.shape[0],Total_small_seq_X.shape[1]*Total_small_seq_X.shape[2])\n",
        "  Total_small_seq_y_reshaped = Total_small_seq_y\n",
        "  maxval2 = Total_small_seq_X_reshaped.shape[0]\n",
        "  count_train2 = int(math.ceil(0.7*maxval2))\n",
        "  Small_train_X = Total_small_seq_X_reshaped[0:count_train2]\n",
        "  Small_train_y = Total_small_seq_y_reshaped[0:count_train2]\n",
        "  Small_test_X =  Total_small_seq_X_reshaped[count_train2:]\n",
        "  Small_test_y = Total_small_seq_y_reshaped[count_train2:]\n",
        "  tscv = TimeSeriesSplit(n_splits=n_fold-1)\n",
        "  #regressor = LassoCV(alphas=0.1)\n",
        "  SVR(C=1.0, epsilon=0.2)\n",
        "  #regressor = LinearRegression()\n",
        "  try:\n",
        "    regressor.fit(Small_train_X, Small_train_y.ravel()) #get jth time series only\n",
        "    if Small_test_X.shape[0] == 0:\n",
        "      break\n",
        "    y_predk = regressor.predict(Small_test_X)\n",
        "    #print('alpha: %f' % regressor.alpha_)\n",
        "    se =  ((Small_test_y-y_predk)**2).mean()/abs(Small_test_y.mean())\n",
        "    ape = abs(Small_test_y-y_predk).mean()/abs(Small_test_y.mean())\n",
        "    ae = abs(Small_test_y-y_predk).mean()\n",
        "    #mse = mean_squared_error(Small_test_y, y_predk)\n",
        "    #print(rmse)\n",
        "    se_4.append(se)\n",
        "    ape_4.append(ape)\n",
        "    ae_4.append(ae)\n",
        "  except:\n",
        "    se_4.append(9999)\n",
        "    ape_4.append(9999)\n",
        "    ae_4.append(9999)\n",
        "    print('error')\n",
        "\n",
        "\n",
        "############## NOW FOR PREDICTED WINDOW -----------------------------------\n",
        "\n",
        "se_x.clear()\n",
        "ape_x.clear()\n",
        "ae_x.clear()\n",
        "for i in range(10000) :\n",
        "#iterate over the entire  long sequences of multivariate time series\n",
        "  Total_small_seq_X, Total_small_seq_y = generate_small_seq(x[i,:,:], int(y_pred[i]) , n_future)\n",
        "  Total_small_seq_X_reshaped = Total_small_seq_X.reshape(Total_small_seq_X.shape[0],Total_small_seq_X.shape[1]*Total_small_seq_X.shape[2])\n",
        "  Total_small_seq_y_reshaped = Total_small_seq_y\n",
        "  maxval2 = Total_small_seq_X_reshaped.shape[0]\n",
        "  count_train2 = int(math.ceil(0.7*maxval2))\n",
        "  Small_train_X = Total_small_seq_X_reshaped[0:count_train2]\n",
        "  Small_train_y = Total_small_seq_y_reshaped[0:count_train2]\n",
        "  Small_test_X =  Total_small_seq_X_reshaped[count_train2:]\n",
        "  Small_test_y = Total_small_seq_y_reshaped[count_train2:]\n",
        "  tscv = TimeSeriesSplit(n_splits=n_fold-1)\n",
        "  #regressor = LassoCV(alphas=0.1)\n",
        "  SVR(C=1.0, epsilon=0.2)\n",
        "  #regressor = LinearRegression()\n",
        "  try:\n",
        "    regressor.fit(Small_train_X, Small_train_y.ravel()) #get jth time series only\n",
        "    if Small_test_X.shape[0] == 0:\n",
        "      break\n",
        "    y_predk = regressor.predict(Small_test_X)\n",
        "    #print('alpha: %f' % regressor.alpha_)\n",
        "    se =  ((Small_test_y-y_predk)**2).mean()/abs(Small_test_y.mean())\n",
        "    ape = abs(Small_test_y-y_predk).mean()/abs(Small_test_y.mean())\n",
        "    ae = abs(Small_test_y-y_predk).mean()\n",
        "    #mse = mean_squared_error(Small_test_y, y_predk)\n",
        "    #print(rmse)\n",
        "    se_x.append(se)\n",
        "    ape_x.append(ape)\n",
        "    ae_x.append(ae)\n",
        "  except:\n",
        "    se_x.append(9999)\n",
        "    ape_x.append(9999)\n",
        "    ae_x.append(9999)\n",
        "    print('error', i)\n",
        "\n",
        "\n",
        "se_1 = [i for i in se_1 if i != 9999]\n",
        "se_2 = [i for i in se_2 if i != 9999]\n",
        "se_3 = [i for i in se_3 if i != 9999]\n",
        "se_4 = [i for i in se_4 if i != 9999]\n",
        "se_x = [i for i in se_x if i != 9999]\n",
        "\n",
        "ape_1 = [i for i in ape_1 if i != 9999]\n",
        "ape_2 = [i for i in ape_2 if i != 9999]\n",
        "ape_3 = [i for i in ape_3 if i != 9999]\n",
        "ape_4 = [i for i in ape_4 if i != 9999]\n",
        "ape_x = [i for i in ape_x if i != 9999]\n",
        "\n",
        "ae_1 = [i for i in ae_1 if i != 9999]\n",
        "ae_2 = [i for i in ae_2 if i != 9999]\n",
        "ae_3 = [i for i in ae_3 if i != 9999]\n",
        "ae_4 = [i for i in ae_4 if i != 9999]\n",
        "ae_x = [i for i in ae_x if i != 9999]\n",
        "\n",
        "rmse_1 = sqrt(np.mean(se_1))\n",
        "rmse_2 = sqrt(np.mean(se_2))\n",
        "rmse_3 = sqrt(np.mean(se_3))\n",
        "rmse_4 = sqrt(np.mean(se_4))\n",
        "rmse_x = sqrt(np.mean(se_x))\n",
        "\n",
        "\n",
        "mape_1 = mean(ape_1)\n",
        "mape_2 = mean(ape_2)\n",
        "mape_3 = mean(ape_3)\n",
        "mape_4 = mean(ape_4)\n",
        "mape_x = mean(ape_x)\n",
        "mae_1 = mean(ae_1)\n",
        "mae_2 = mean(ae_2)\n",
        "mae_3 = mean(ae_3)\n",
        "mae_4 = mean(ae_4)\n",
        "mae_x = mean(ae_x)\n",
        "\n",
        "\n",
        "print(\"RMSE:\", rmse_1, rmse_2, rmse_3, rmse_4, rmse_x)\n",
        "print(\"MAPE:\", mape_1, mape_2, mape_3, mape_4, mape_x)\n",
        "print(\"MAE:\", mae_1, mae_2, mae_3, mae_4, mae_x)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "v_5iji919H_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8OtWHK--uG6W"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "https://github.com/supriyag123/PHD_Pub/blob/main/PAPER_GDRNet_Step4-RIDGE.ipynb",
      "authorship_tag": "ABX9TyPpkUKGciL83R/TQdep57vS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}