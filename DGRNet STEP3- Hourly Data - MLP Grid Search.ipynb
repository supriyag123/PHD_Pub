{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supriyag123/PHD_Pub/blob/main/DGRNet%20STEP3-%20Hourly%20Data%20-%20MLP%20Grid%20Search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HoP7OuWNxlsJ",
        "outputId": "3ce1b06a-a198-4899-b0e1-e39b5f1651a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "849/849 [==============================] - 6s 5ms/step - loss: 0.9114 - mean_squared_error: 0.9114 - val_loss: 0.9022 - val_mean_squared_error: 0.9022\n",
            "Epoch 2/500\n",
            "849/849 [==============================] - 4s 5ms/step - loss: 0.8831 - mean_squared_error: 0.8831 - val_loss: 0.9013 - val_mean_squared_error: 0.9013\n",
            "Epoch 3/500\n",
            "849/849 [==============================] - 4s 4ms/step - loss: 0.8786 - mean_squared_error: 0.8786 - val_loss: 0.8940 - val_mean_squared_error: 0.8940\n",
            "Epoch 4/500\n",
            "849/849 [==============================] - 3s 4ms/step - loss: 0.8733 - mean_squared_error: 0.8733 - val_loss: 0.8969 - val_mean_squared_error: 0.8969\n",
            "Epoch 5/500\n",
            "849/849 [==============================] - 5s 5ms/step - loss: 0.8743 - mean_squared_error: 0.8743 - val_loss: 0.9051 - val_mean_squared_error: 0.9051\n",
            "Epoch 6/500\n",
            "849/849 [==============================] - 4s 4ms/step - loss: 0.8740 - mean_squared_error: 0.8740 - val_loss: 0.9052 - val_mean_squared_error: 0.9052\n",
            "Epoch 7/500\n",
            "849/849 [==============================] - 3s 4ms/step - loss: 0.8726 - mean_squared_error: 0.8726 - val_loss: 0.9056 - val_mean_squared_error: 0.9056\n",
            "Epoch 8/500\n",
            "849/849 [==============================] - 3s 4ms/step - loss: 0.8700 - mean_squared_error: 0.8700 - val_loss: 0.9042 - val_mean_squared_error: 0.9042\n",
            "Epoch 9/500\n",
            "849/849 [==============================] - 4s 5ms/step - loss: 0.8726 - mean_squared_error: 0.8726 - val_loss: 0.8932 - val_mean_squared_error: 0.8932\n",
            "Epoch 10/500\n",
            "849/849 [==============================] - 3s 4ms/step - loss: 0.8695 - mean_squared_error: 0.8695 - val_loss: 0.8997 - val_mean_squared_error: 0.8997\n",
            "Epoch 11/500\n",
            "849/849 [==============================] - 3s 4ms/step - loss: 0.8707 - mean_squared_error: 0.8707 - val_loss: 0.8976 - val_mean_squared_error: 0.8976\n",
            "Epoch 12/500\n",
            "849/849 [==============================] - 4s 5ms/step - loss: 0.8686 - mean_squared_error: 0.8686 - val_loss: 0.9158 - val_mean_squared_error: 0.9158\n",
            "Epoch 13/500\n",
            "849/849 [==============================] - 4s 5ms/step - loss: 0.8677 - mean_squared_error: 0.8677 - val_loss: 0.8946 - val_mean_squared_error: 0.8946\n",
            "Epoch 14/500\n",
            "849/849 [==============================] - 3s 4ms/step - loss: 0.8687 - mean_squared_error: 0.8687 - val_loss: 0.9013 - val_mean_squared_error: 0.9013\n",
            "Epoch 15/500\n",
            "849/849 [==============================] - 3s 4ms/step - loss: 0.8665 - mean_squared_error: 0.8665 - val_loss: 0.9082 - val_mean_squared_error: 0.9082\n",
            "Epoch 16/500\n",
            "849/849 [==============================] - 5s 5ms/step - loss: 0.8642 - mean_squared_error: 0.8642 - val_loss: 0.9003 - val_mean_squared_error: 0.9003\n",
            "Epoch 17/500\n",
            "849/849 [==============================] - 4s 4ms/step - loss: 0.8652 - mean_squared_error: 0.8652 - val_loss: 0.8928 - val_mean_squared_error: 0.8928\n",
            "Epoch 18/500\n",
            "849/849 [==============================] - 4s 4ms/step - loss: 0.8651 - mean_squared_error: 0.8651 - val_loss: 0.8926 - val_mean_squared_error: 0.8926\n",
            "Epoch 19/500\n",
            "849/849 [==============================] - 4s 4ms/step - loss: 0.8644 - mean_squared_error: 0.8644 - val_loss: 0.9113 - val_mean_squared_error: 0.9113\n",
            "Epoch 20/500\n",
            "849/849 [==============================] - 4s 5ms/step - loss: 0.8643 - mean_squared_error: 0.8643 - val_loss: 0.8937 - val_mean_squared_error: 0.8937\n",
            "Epoch 21/500\n",
            "849/849 [==============================] - 3s 4ms/step - loss: 0.8630 - mean_squared_error: 0.8630 - val_loss: 0.8909 - val_mean_squared_error: 0.8909\n",
            "Epoch 22/500\n",
            "849/849 [==============================] - 3s 4ms/step - loss: 0.8641 - mean_squared_error: 0.8641 - val_loss: 0.8900 - val_mean_squared_error: 0.8900\n",
            "Epoch 23/500\n",
            "849/849 [==============================] - 4s 5ms/step - loss: 0.8623 - mean_squared_error: 0.8623 - val_loss: 0.8938 - val_mean_squared_error: 0.8938\n",
            "Epoch 24/500\n",
            "849/849 [==============================] - 4s 5ms/step - loss: 0.8637 - mean_squared_error: 0.8637 - val_loss: 0.8941 - val_mean_squared_error: 0.8941\n",
            "Epoch 25/500\n",
            "849/849 [==============================] - 4s 4ms/step - loss: 0.8630 - mean_squared_error: 0.8630 - val_loss: 0.9023 - val_mean_squared_error: 0.9023\n",
            "Epoch 26/500\n",
            "849/849 [==============================] - 4s 4ms/step - loss: 0.8619 - mean_squared_error: 0.8619 - val_loss: 0.8922 - val_mean_squared_error: 0.8922\n",
            "Epoch 27/500\n",
            "849/849 [==============================] - 5s 5ms/step - loss: 0.8628 - mean_squared_error: 0.8628 - val_loss: 0.8905 - val_mean_squared_error: 0.8905\n",
            "Epoch 28/500\n",
            "849/849 [==============================] - 3s 4ms/step - loss: 0.8629 - mean_squared_error: 0.8629 - val_loss: 0.9010 - val_mean_squared_error: 0.9010\n",
            "Epoch 29/500\n",
            "849/849 [==============================] - 3s 4ms/step - loss: 0.8622 - mean_squared_error: 0.8622 - val_loss: 0.8938 - val_mean_squared_error: 0.8938\n",
            "Epoch 30/500\n",
            "849/849 [==============================] - 4s 4ms/step - loss: 0.8639 - mean_squared_error: 0.8639 - val_loss: 0.8918 - val_mean_squared_error: 0.8918\n",
            "Epoch 31/500\n",
            "849/849 [==============================] - 4s 5ms/step - loss: 0.8621 - mean_squared_error: 0.8621 - val_loss: 0.9054 - val_mean_squared_error: 0.9054\n",
            "Epoch 32/500\n",
            "849/849 [==============================] - 4s 4ms/step - loss: 0.8626 - mean_squared_error: 0.8626 - val_loss: 0.8901 - val_mean_squared_error: 0.8901\n",
            "Epoch 33/500\n",
            "849/849 [==============================] - 3s 4ms/step - loss: 0.8621 - mean_squared_error: 0.8621 - val_loss: 0.8889 - val_mean_squared_error: 0.8889\n",
            "Epoch 34/500\n",
            "849/849 [==============================] - 4s 5ms/step - loss: 0.8613 - mean_squared_error: 0.8613 - val_loss: 0.8927 - val_mean_squared_error: 0.8927\n",
            "Epoch 35/500\n",
            "849/849 [==============================] - 4s 5ms/step - loss: 0.8613 - mean_squared_error: 0.8613 - val_loss: 0.8882 - val_mean_squared_error: 0.8882\n",
            "Epoch 36/500\n",
            "849/849 [==============================] - 4s 4ms/step - loss: 0.8627 - mean_squared_error: 0.8627 - val_loss: 0.8998 - val_mean_squared_error: 0.8998\n",
            "Epoch 37/500\n",
            "849/849 [==============================] - 4s 4ms/step - loss: 0.8612 - mean_squared_error: 0.8612 - val_loss: 0.8893 - val_mean_squared_error: 0.8893\n",
            "Epoch 38/500\n",
            "849/849 [==============================] - 5s 5ms/step - loss: 0.8606 - mean_squared_error: 0.8606 - val_loss: 0.8978 - val_mean_squared_error: 0.8978\n",
            "Epoch 39/500\n",
            "849/849 [==============================] - 4s 4ms/step - loss: 0.8604 - mean_squared_error: 0.8604 - val_loss: 0.8929 - val_mean_squared_error: 0.8929\n",
            "Epoch 40/500\n",
            "849/849 [==============================] - 4s 4ms/step - loss: 0.8602 - mean_squared_error: 0.8602 - val_loss: 0.8927 - val_mean_squared_error: 0.8927\n",
            "Epoch 41/500\n",
            "849/849 [==============================] - 4s 4ms/step - loss: 0.8602 - mean_squared_error: 0.8602 - val_loss: 0.8884 - val_mean_squared_error: 0.8884\n",
            "Epoch 42/500\n",
            "849/849 [==============================] - 4s 5ms/step - loss: 0.8595 - mean_squared_error: 0.8595 - val_loss: 0.8936 - val_mean_squared_error: 0.8936\n",
            "Epoch 43/500\n",
            "849/849 [==============================] - 3s 4ms/step - loss: 0.8614 - mean_squared_error: 0.8614 - val_loss: 0.8871 - val_mean_squared_error: 0.8871\n",
            "Epoch 44/500\n",
            "849/849 [==============================] - 3s 4ms/step - loss: 0.8603 - mean_squared_error: 0.8603 - val_loss: 0.8870 - val_mean_squared_error: 0.8870\n",
            "Epoch 45/500\n",
            "849/849 [==============================] - 4s 5ms/step - loss: 0.8606 - mean_squared_error: 0.8606 - val_loss: 0.8889 - val_mean_squared_error: 0.8889\n",
            "Epoch 46/500\n",
            "849/849 [==============================] - 4s 5ms/step - loss: 0.8609 - mean_squared_error: 0.8609 - val_loss: 0.8949 - val_mean_squared_error: 0.8949\n",
            "Epoch 47/500\n",
            "849/849 [==============================] - 3s 4ms/step - loss: 0.8608 - mean_squared_error: 0.8608 - val_loss: 0.8973 - val_mean_squared_error: 0.8973\n",
            "Epoch 48/500\n",
            "849/849 [==============================] - 4s 4ms/step - loss: 0.8589 - mean_squared_error: 0.8589 - val_loss: 0.8971 - val_mean_squared_error: 0.8971\n",
            "Epoch 49/500\n",
            "849/849 [==============================] - 4s 5ms/step - loss: 0.8607 - mean_squared_error: 0.8607 - val_loss: 0.8919 - val_mean_squared_error: 0.8919\n",
            "Epoch 50/500\n",
            "849/849 [==============================] - 4s 4ms/step - loss: 0.8588 - mean_squared_error: 0.8588 - val_loss: 0.9065 - val_mean_squared_error: 0.9065\n",
            "Epoch 51/500\n",
            "849/849 [==============================] - 3s 4ms/step - loss: 0.8591 - mean_squared_error: 0.8591 - val_loss: 0.8892 - val_mean_squared_error: 0.8892\n",
            "Epoch 52/500\n",
            "849/849 [==============================] - 3s 4ms/step - loss: 0.8599 - mean_squared_error: 0.8599 - val_loss: 0.8954 - val_mean_squared_error: 0.8954\n",
            "Epoch 53/500\n",
            "849/849 [==============================] - 5s 5ms/step - loss: 0.8604 - mean_squared_error: 0.8604 - val_loss: 0.8857 - val_mean_squared_error: 0.8857\n",
            "Epoch 54/500\n",
            "849/849 [==============================] - 4s 4ms/step - loss: 0.8589 - mean_squared_error: 0.8589 - val_loss: 0.8856 - val_mean_squared_error: 0.8856\n",
            "Epoch 55/500\n",
            "823/849 [============================>.] - ETA: 0s - loss: 0.8588 - mean_squared_error: 0.8588"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-e9b3c470bcc8>\u001b[0m in \u001b[0;36m<cell line: 76>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_transformed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m history=model.fit( x_train,y_train,\n\u001b[0m\u001b[1;32m     77\u001b[0m                  \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1796\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1797\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1798\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1799\u001b[0m                         with tf.profiler.experimental.Trace(\n\u001b[1;32m   1800\u001b[0m                             \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/data_adapter.py\u001b[0m in \u001b[0;36msteps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1409\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1411\u001b[0;31m             \u001b[0moriginal_spe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1412\u001b[0m             can_run_full_execution = (\n\u001b[1;32m   1413\u001b[0m                 \u001b[0moriginal_spe\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    687\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m     raise NotImplementedError(\n\u001b[1;32m    691\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \"\"\"\n\u001b[1;32m    393\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    358\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import math\n",
        "import plotly.graph_objects as go\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, RepeatVector, TimeDistributed, Input\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import keras.backend as K\n",
        "from keras.callbacks import Callback\n",
        "import plotly\n",
        "import plotly.express as px # for data visualization\n",
        "import seaborn as sns\n",
        "\n",
        "generator_multiply = 1 #each input record will generate 100 random vectors from the latent space, given the mu and sigma generated by the encoder\n",
        "\n",
        "#from keras.utils import plot_model\n",
        "#import matplotlib.pyplot as plt\n",
        "\n",
        "#window1 = np.load(r'/content/drive/MyDrive/PHD/2021/multivariate_long_sequences_WINDOW-500.npy')\n",
        "#window2 = np.load(r'/content/drive/MyDrive/PHD/2021/multivariate_long_sequences_WINDOW-1000.npy')\n",
        "#window = np.concatenate((window1, window2), axis=0)\n",
        "#train_data = np.load(r'/content/drive/MyDrive/PHD/2021/multivariate_long_sequences-TRAIN.npy')\n",
        "#test_data = np.load(r'/content/drive/MyDrive/PHD/2021/multivariate_long_sequences-TEST.npy')\n",
        "\n",
        "\n",
        "\n",
        "train_data = np.load(r'/content/drive/MyDrive/PHD/2024/multivariate_long_sequences-TRAIN_hourly.npy') #------for Hourly data\n",
        "index = 500\n",
        "#We missed i=500 from processing the iosw. So here we are dropping row with index =500\n",
        "train_data= np.delete(train_data, index, axis=0)\n",
        "\n",
        "\n",
        "#test_data = np.load(r'/content/drive/MyDrive/PHD/2024/multivariate_long_sequences-TEST_hourly.npy')\n",
        "#all_data = np.concatenate((train_data,test_data),axis=0)\n",
        "window_label = np.load(r'/content/drive/MyDrive/PHD/2024/multivariate_long_sequences_WINDOW-TRAIN_hourly.npy')\n",
        "n_seq = train_data.shape[0]\n",
        "window_size = train_data.shape[1]\n",
        "n_features = train_data.shape[2]\n",
        "\n",
        "\n",
        "#---------------------------VAE ------------------------------------------\n",
        "#from sklearn.model_selection import train_test_split\n",
        "#x_train, x_test, y_train, y_test = train_test_split(train_data, window_label, test_size = 0.2, random_state = 42)\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "encoder = keras.models.load_model(r'/content/drive/MyDrive/PHD/2024/VAE_SIMULATION/vae-encoder-saved-hourly-latent10-dim128-latest.model')\n",
        "decoder = keras.models.load_model(r'/content/drive/MyDrive/PHD/2024/VAE_SIMULATION/vae-decoder-saved-hourly-latent10-dim128-latest.model')\n",
        "\n",
        "X_train_encoded = encoder.predict(train_data)\n",
        "mu, logvar, z = X_train_encoded\n",
        "sigma = tf.exp(0.5 * logvar)\n",
        "batch = tf.shape(mu)[0]  #number of recors / batchs\n",
        "dim = tf.shape(mu)[1] #Ndimension of latent variable\n",
        "store = list()\n",
        "storetemp = list()\n",
        "\n",
        "\n",
        "#For each batch, iterate, get the generator_multipy number of latent vectors with same window_size.\n",
        "#For each z, concatenate z_mean, so it will become 100 dimensional vector\n",
        "\n",
        "for i in range(0,batch):\n",
        "  all_Z_i = tf.random.normal(shape=(generator_multiply,dim), mean = mu[i,:], stddev=sigma[i,:]) #all randorm vectors for this record i\n",
        "  X_train_decoded = decoder.predict(all_Z_i)\n",
        "  X_train_decoded = X_train_decoded.reshape((X_train_decoded.shape[0],window_size*n_features))\n",
        "  a = np.arange(generator_multiply)\n",
        "  a.fill(window_label[i])\n",
        "  c=np.concatenate(((X_train_decoded,a[:,None])),axis=1)\n",
        "  store.append(c)\n",
        "\n",
        "results1=np.concatenate(store,axis=0)\n",
        "results1=np.load(r'/content/drive/MyDrive/PHD/2024/labelled_subsquence_data_hourly.npy')\n",
        "np.save(r'/content/drive/MyDrive/PHD/2024/labelled_subsquence_data_hourly',results1)\n",
        "\n",
        "\n",
        "#Regression fitting\n",
        "x=results1[:,:-1]\n",
        "y=results1[:,window_size*n_features]\n",
        "\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "#----- get a test set from this data, to avoid further wrangling----------------\n",
        "#x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.1, random_state = 42)\n",
        "\n",
        "\n",
        "maxval = x.shape[0]\n",
        "count_train = int(math.ceil(0.9*maxval))\n",
        "x_train = x[:count_train]\n",
        "x_test = x[count_train:]\n",
        "\n",
        "y_train = y[:count_train]\n",
        "y_test = y[count_train:]\n",
        "\n",
        "\n",
        "from sklearn.ensemble import IsolationForest\n",
        "iso = IsolationForest(contamination=0.4)\n",
        "yhat = iso.fit_predict(x_train)\n",
        "# select all rows that are not outliers\n",
        "mask = yhat != -1\n",
        "x_train, y_train = x_train[mask, :], y_train[mask]\n",
        "\n",
        "##x_train = x_train.reshape((x_train.shape[0], window_size, n_features))  #DONT RUN IF MLP\n",
        "#x_test = x_test.reshape((x_test.shape[0], window_size, n_features))    #DONT RUN IF MLP\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "transformer = StandardScaler()\n",
        "\n",
        "y_train_transformed = transformer.fit_transform(y_train.reshape(-1,1)).flatten()\n",
        "y_test_transformed = transformer.fit_transform(y_test.reshape(-1,1)).flatten()\n",
        "\n",
        "\n",
        "from keras.layers import LeakyReLU\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "#model.add(Dense(units = 256))\n",
        "#model.add(LeakyReLU(alpha=0.01))\n",
        "#model.add(Dense(units = 128))\n",
        "#model.add(LeakyReLU(alpha=0.01))\n",
        "model.add(Dense(units = 24, activation = 'relu'))\n",
        "model.add(Dense(units = 16, activation = 'relu'))\n",
        "model.add(Dense(units = 12, activation = 'relu'))\n",
        "model.add(Dense(units = 8))\n",
        "\n",
        "model.add(Dense(units = 1))\n",
        "\n",
        "#sgd = tf.keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "optimizr = keras.optimizers.Adam(learning_rate=0.001,clipnorm=1)\n",
        "model.compile(loss='mean_squared_error', optimizer= optimizr, metrics=['mean_squared_error'])\n",
        "#model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
        "\n",
        "\n",
        "#reduce_lr = tf.keras.callbacks.LearningRateScheduler(lambda x: 1e-3 * 0.90 ** x)\n",
        "es = keras.callbacks.EarlyStopping(patience=20, verbose=1, min_delta=0.000001, monitor='loss', mode='auto', restore_best_weights=True)\n",
        "n_epochs = 500\n",
        "#model.fit(x_train, y_train,epochs=5, batch_size=50, verbose=True)\n",
        "\n",
        "#y_pred = model.predict(x_test)\n",
        "\n",
        "#transform\n",
        "\n",
        "#x_val = x_train[10001:13000]\n",
        "#y_val = y_train_transformed[10001:13000]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train_transformed, test_size = 0.1, random_state = 42)\n",
        "\n",
        "history=model.fit( x_train,y_train,\n",
        "                 epochs=n_epochs,\n",
        "                 batch_size=32,\n",
        "                   #validation_data=(x_val,y_val),\n",
        "                   validation_split=0.1)\n",
        "                 #callbacks=[es])\n",
        "\n",
        "y_train_pred = model.predict(x_train)\n",
        "y_train_pred = transformer.inverse_transform(y_train_pred)\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred = transformer.inverse_transform(y_pred)\n",
        "\n",
        "y_train = transformer.inverse_transform(y_train.reshape(-1,1)).flatten()\n",
        "y_test = transformer.inverse_transform(y_test.reshape(-1,1)).flatten()\n",
        "\n",
        "\n",
        "\n",
        "score_train= r2_score(y_train,y_train_pred)\n",
        "print(\"r2 score is ==\",score_train)\n",
        "\n",
        "score= r2_score(y_test,y_pred)\n",
        "print(\"r2 score is ==\",score)\n",
        "\n",
        "\n",
        "#plt.scatter(y_test,y_pred);\n",
        "#plt.xlabel('Actual');\n",
        "#plt.ylabel('Predicted');\n",
        "plt.plot(y_train[0:100], color = 'red', label = 'Real data')\n",
        "plt.plot(y_train_pred[0:100], color = 'blue', label = 'Predicted data')\n",
        "plt.title('Prediction')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#plt.scatter(y_test,y_pred);\n",
        "#plt.xlabel('Actual');\n",
        "#plt.ylabel('Predicted');\n",
        "plt.plot(y_test[100:150], color = 'red', label = 'Real data')\n",
        "plt.plot(y_pred[100:150], color = 'blue', label = 'Predicted data')\n",
        "plt.title('Prediction')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "np.savetxt(r'/content/drive/MyDrive/PHD/2024/MLPOutput/preduber_2.csv',y_pred)\n",
        "np.savetxt(r'/content/drive/MyDrive/PHD/2024/MLPOutput/realuber_2.csv',y_test)\n",
        "print(\"MAE is==\",mean_absolute_error(y_test,y_pred))\n",
        "\n",
        "#--------------------------------------Random Forest-------------------------------------------------------\n",
        "\n",
        "\n",
        "###### Random forrest ergression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        " # create regressor object\n",
        "regressor = RandomForestRegressor(n_estimators = 1000, random_state = 0)\n",
        "# fit the regressor with x and y data\n",
        "regressor.fit(x_train[0:10000],y_train_transformed[0:10000])\n",
        "\n",
        "\n",
        "y_train_pred = regressor.predict(x_train[0:10000])\n",
        "y_train_pred = y_train_pred.reshape(-1,1)\n",
        "y_train_pred = transformer.inverse_transform(y_train_pred)\n",
        "\n",
        "y_pred = regressor.predict(x_test[0:1000])\n",
        "y_pred = y_pred.reshape(-1,1)\n",
        "y_pred = transformer.inverse_transform(y_pred)\n",
        "\n",
        "\n",
        "score_train= r2_score(y_train[0:10000],y_train_pred)\n",
        "print(\"r2 score is ==\",score_train)\n",
        "\n",
        "score= r2_score(y_test[0:1000],y_pred)\n",
        "print(\"r2 score is ==\",score)\n",
        "\n",
        "\n",
        "#plt.scatter(y_test,y_pred);\n",
        "#plt.xlabel('Actual');\n",
        "#plt.ylabel('Predicted');\n",
        "plt.plot(y_train[0:1000], color = 'red', label = 'Real data')\n",
        "plt.plot(y_train_pred[0:1000], color = 'blue', label = 'Predicted data')\n",
        "plt.title('Prediction')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#plt.scatter(y_test,y_pred);\n",
        "#plt.xlabel('Actual');\n",
        "#plt.ylabel('Predicted');\n",
        "plt.plot(y_test[0:1000], color = 'red', label = 'Real data')\n",
        "plt.plot(y_pred[0:1000], color = 'blue', label = 'Predicted data')\n",
        "plt.title('Prediction')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "sns.regplot(x=y_test[0:10],y=y_pred,ci=None,color ='red');"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "v_5iji919H_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8OtWHK--uG6W"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/supriyag123/PHD_Pub/blob/main/DGRNet%20STEP3-%20Hourly%20Data.ipynb",
      "authorship_tag": "ABX9TyOjsq/fP8IOO2ub0ojYN3sO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}