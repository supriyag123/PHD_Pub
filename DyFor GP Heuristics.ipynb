{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supriyag123/PHD_Pub/blob/main/DyFor%20GP%20Heuristics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "bx-5b_puABG1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import math\n",
        "import plotly.graph_objects as go\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout, RepeatVector, TimeDistributed, Input\n",
        "from keras.models import Model\n",
        "from keras import saving\n",
        "\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import Callback\n",
        "import plotly\n",
        "from keras import losses\n",
        "import plotly.express as px # for data visualization\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import IsolationForest\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import pylab as pl\n",
        "\n",
        "\n",
        "\n",
        "##### Take one dataset at a time\n",
        "#train_data = np.load(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_METROPM/multivariate_long_sequences-TRAIN-Daily-DIRECT-VAR.npy')\n",
        "#train_data = np.load(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_AIRQUALITY/multivariate_long_sequences-TRAIN-Daily-DIRECT-VAR.npy')\n",
        "train_data = np.load(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_ELECTRICITY/multivariate_long_sequences-TRAIN-DATA-FullSearch-VAR.npy')\n",
        "\n",
        "\n",
        "n_seq = train_data.shape[0]\n",
        "window_size = train_data.shape[1]\n",
        "n_features = train_data.shape[2]\n",
        "\n",
        "##Get large set of subsequence from previous steps (VAE)... this is not labelled yet.\n",
        "#results1=np.load(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_METROPM/generated_large_subsquence2_data_V2.npy')\n",
        "#results1=np.load(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_AIRQUALITY/generated_large_subsquence2_data.npy')\n",
        "results1=np.load(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_ELECTRICITY/generated_large_subsquence2_data.npy')\n",
        "x=results1\n",
        "\n",
        "\n",
        "\n",
        "##############DyFOR GP Heuristic#######################################################\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "\n",
        "def get_window_size (series, pred_point, small_w, large_w):\n",
        "  # pred_point ==> the point of prediction (starting point)\n",
        "  # small_w ==> smaller window size preceding the pred_point\n",
        "  # large_w ==> larger window size preceding the pred_point\n",
        "  # series is flttened long subsequence --> multivariate converted into univariate by flattening...\n",
        "\n",
        "  n_future = n_features\n",
        "  pred_l_start = pred_point - (large_w + 1)\n",
        "  pred_s_start = pred_point - (small_w + 1)\n",
        "  pred_l_window = series[pred_l_start:pred_point-1]\n",
        "  pred_s_window = series[pred_s_start:pred_point-1]\n",
        "  modell = ARIMA(pred_l_window, order=(2,0,0))\n",
        "  fitl = modell.fit()\n",
        "  forecastl = fitl.forecast(steps=n_future)\n",
        "  models = ARIMA(pred_s_window, order=(2,0,0))\n",
        "  fits = models.fit()\n",
        "  forecasts = fits.forecast(steps=n_future)\n",
        "  mse_l = mean_squared_error(series[pred_point-1:pred_point+n_future-1], forecastl)\n",
        "  mse_s = mean_squared_error(series[pred_point-1:pred_point+n_future-1], forecasts)\n",
        "  if mse_l < mse_s:\n",
        "    return large_w\n",
        "  else:\n",
        "    return small_w\n",
        "\n",
        "\n",
        "best_window_for_long_seq = list()\n",
        "best_window_for_long_seq.clear()\n",
        "\n",
        "\n",
        "\n",
        "for i in range(x.shape[0]):\n",
        "  cur_seq = x[i,:]\n",
        "  start_small_w = 2\n",
        "  start_large_w = 3\n",
        "  start_index = start_large_w\n",
        "  ### we need to increment by number of variables, as we have flattened the ime series\n",
        "  for k in range (start_index*n_features, x.shape[1]-n_features, n_features):\n",
        "    pred_point_k = k\n",
        "    small_w_k = start_small_w*n_features\n",
        "    large_w_k = start_large_w*n_features\n",
        "    best_window_k = get_window_size(cur_seq, pred_point_k, small_w_k, large_w_k)\n",
        "    if best_window_k == large_w_k:\n",
        "      start_large_w = start_large_w + 1\n",
        "      start_small_w = start_small_w + 1\n",
        "    if best_window_k == small_w_k:\n",
        "      start_large_w = start_large_w -1\n",
        "      start_small_w = start_small_w -1\n",
        "\n",
        "    final_best_window =  get_window_size(cur_seq, x.shape[1]-n_features, small_w_k, large_w_k)\n",
        "    best_window_for_long_seq.append(final_best_window)\n",
        "\n",
        "\n",
        "print(best_window_for_long_seq)\n",
        "Window = np.array(best_window_for_long_seq)\n",
        "np.save(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_ELECTRICITY/generated-data-DyFOR_Window',Window)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "nxij89jyeebm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/supriyag123/PHD_Pub/blob/main/DyFor%20GP%20Heuristics.ipynb",
      "authorship_tag": "ABX9TyNOVmsXKf8otM1IZeyOE/hM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}