{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supriyag123/PHD_Pub/blob/main/AGENTIC-MODULE3-MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bx-5b_puABG1",
        "outputId": "13c4cecf-558e-45f4-f2d2-e98d1e281034",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Enhanced Feature Engineering MLP\n",
            "Running enhanced pipeline on: generated-data-OPTIMIZED.npy, generated-data-true-window-OPTIMIZED.npy\n",
            "📁 Enhanced MLP directory: /content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/enhanced_mlp/\n",
            "================================================================================\n",
            "🚀 ENHANCED FEATURE ENGINEERING MLP PIPELINE\n",
            "================================================================================\n",
            "📊 Loading original data for feature engineering...\n",
            "✅ Original data loaded: X=(350000, 650), y=(350000,)\n",
            "\n",
            "🔧 Creating enhanced features based on correlation analysis...\n",
            "   Starting with 650 original features\n",
            "   ✅ Original features: 650\n",
            "   ✅ Best interaction (7×8): 1 feature\n",
            "   Creating systematic feature interactions...\n",
            "   ✅ Feature interactions: 50\n",
            "   Creating polynomial features...\n",
            "   ✅ Polynomial features: 15\n",
            "   Creating statistical features...\n",
            "   ✅ Statistical features: 22\n",
            "\n",
            "📈 Feature Engineering Summary:\n",
            "   Original features: 650\n",
            "   Enhanced features: 738\n",
            "   Enhancement factor: 1.1x\n",
            "\n",
            "🎯 Selecting best 200 features from 738...\n",
            "   Selected 200 features\n",
            "   Score range: [0.030463, 0.043289]\n",
            "\n",
            "📊 Splitting enhanced data...\n",
            "   Train: 210000 samples, 200 features\n",
            "   Validation: 70000 samples\n",
            "   Test: 70000 samples\n",
            "\n",
            "🚀 Training enhanced feature model...\n",
            "\n",
            "🏗️ Building interaction-focused MLP for 200 features...\n",
            "   Model parameters: 12,042,241\n",
            "   Loss function: MAE (better for weak signals)\n",
            "   Learning rate: 0.002 (higher for weak relationships)\n",
            "Epoch 1/1500\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.2709 - mae: 0.8564 - mse: 1.0758\n",
            "Epoch 1: val_loss improved from inf to 1.79065, saving model to /content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/enhanced_mlp/best_enhanced_model.weights.h5\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 12ms/step - loss: 4.2704 - mae: 0.8564 - mse: 1.0758 - val_loss: 1.7906 - val_mae: 0.8463 - val_mse: 1.0492 - learning_rate: 0.0020\n",
            "Epoch 2/1500\n",
            "\u001b[1m3275/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5901 - mae: 0.8456 - mse: 1.0392\n",
            "Epoch 2: val_loss improved from 1.79065 to 1.44689, saving model to /content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/enhanced_mlp/best_enhanced_model.weights.h5\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 1.5899 - mae: 0.8456 - mse: 1.0392 - val_loss: 1.4469 - val_mae: 0.8447 - val_mse: 1.0359 - learning_rate: 0.0020\n",
            "Epoch 3/1500\n",
            "\u001b[1m3276/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2487 - mae: 0.8440 - mse: 1.0288\n",
            "Epoch 3: val_loss improved from 1.44689 to 1.10498, saving model to /content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/enhanced_mlp/best_enhanced_model.weights.h5\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 1.2486 - mae: 0.8440 - mse: 1.0288 - val_loss: 1.1050 - val_mae: 0.8466 - val_mse: 1.0367 - learning_rate: 0.0020\n",
            "Epoch 4/1500\n",
            "\u001b[1m3277/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1180 - mae: 0.8479 - mse: 1.0407\n",
            "Epoch 4: val_loss did not improve from 1.10498\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 1.1180 - mae: 0.8479 - mse: 1.0407 - val_loss: 1.1104 - val_mae: 0.8466 - val_mse: 1.0325 - learning_rate: 0.0020\n",
            "Epoch 5/1500\n",
            "\u001b[1m3275/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1149 - mae: 0.8485 - mse: 1.0347\n",
            "Epoch 5: val_loss did not improve from 1.10498\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 1.1149 - mae: 0.8485 - mse: 1.0347 - val_loss: 1.1169 - val_mae: 0.8466 - val_mse: 1.0424 - learning_rate: 0.0020\n",
            "Epoch 6/1500\n",
            "\u001b[1m3279/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1145 - mae: 0.8448 - mse: 1.0374\n",
            "Epoch 6: val_loss did not improve from 1.10498\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.1145 - mae: 0.8448 - mse: 1.0374 - val_loss: 1.1161 - val_mae: 0.8466 - val_mse: 1.0380 - learning_rate: 0.0020\n",
            "Epoch 7/1500\n",
            "\u001b[1m3276/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1608 - mae: 0.8476 - mse: 1.0514\n",
            "Epoch 7: val_loss did not improve from 1.10498\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.1609 - mae: 0.8476 - mse: 1.0514 - val_loss: 2.0646 - val_mae: 1.5795 - val_mse: 3.8374 - learning_rate: 0.0020\n",
            "Epoch 8/1500\n",
            "\u001b[1m3278/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1508 - mae: 0.8447 - mse: 1.0484\n",
            "Epoch 8: val_loss did not improve from 1.10498\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.1508 - mae: 0.8448 - mse: 1.0484 - val_loss: 1.3664 - val_mae: 0.9264 - val_mse: 1.3933 - learning_rate: 0.0020\n",
            "Epoch 9/1500\n",
            "\u001b[1m3277/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1715 - mae: 0.8438 - mse: 1.0401\n",
            "Epoch 9: val_loss did not improve from 1.10498\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.1714 - mae: 0.8438 - mse: 1.0402 - val_loss: 1.1334 - val_mae: 0.8466 - val_mse: 1.0351 - learning_rate: 0.0020\n",
            "Epoch 10/1500\n",
            "\u001b[1m3277/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1103 - mae: 0.8465 - mse: 1.0334\n",
            "Epoch 10: val_loss did not improve from 1.10498\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.1102 - mae: 0.8465 - mse: 1.0334 - val_loss: 1.1060 - val_mae: 0.8466 - val_mse: 1.0401 - learning_rate: 0.0020\n",
            "Epoch 11/1500\n",
            "\u001b[1m3280/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1431 - mae: 0.8456 - mse: 1.0615\n",
            "Epoch 11: val_loss did not improve from 1.10498\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 1.1431 - mae: 0.8456 - mse: 1.0615 - val_loss: 1.1560 - val_mae: 0.8466 - val_mse: 1.0264 - learning_rate: 0.0020\n",
            "Epoch 12/1500\n",
            "\u001b[1m3278/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1729 - mae: 0.8475 - mse: 1.0381\n",
            "Epoch 12: val_loss did not improve from 1.10498\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.1728 - mae: 0.8475 - mse: 1.0381 - val_loss: 1.1406 - val_mae: 0.8466 - val_mse: 1.0300 - learning_rate: 0.0020\n",
            "Epoch 13/1500\n",
            "\u001b[1m3281/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1283 - mae: 0.8468 - mse: 1.0337\n",
            "Epoch 13: val_loss improved from 1.10498 to 1.08053, saving model to /content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/enhanced_mlp/best_enhanced_model.weights.h5\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - loss: 1.1283 - mae: 0.8468 - mse: 1.0337 - val_loss: 1.0805 - val_mae: 0.8466 - val_mse: 1.0582 - learning_rate: 0.0020\n",
            "Epoch 14/1500\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0858 - mae: 0.8449 - mse: 1.0654\n",
            "Epoch 14: val_loss did not improve from 1.08053\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.0858 - mae: 0.8449 - mse: 1.0653 - val_loss: 1.1090 - val_mae: 0.8466 - val_mse: 1.0245 - learning_rate: 0.0020\n",
            "Epoch 15/1500\n",
            "\u001b[1m3280/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1238 - mae: 0.8482 - mse: 1.0348\n",
            "Epoch 15: val_loss did not improve from 1.08053\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.1238 - mae: 0.8482 - mse: 1.0348 - val_loss: 1.1124 - val_mae: 0.8466 - val_mse: 1.0362 - learning_rate: 0.0020\n",
            "Epoch 16/1500\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0818 - mae: 0.8437 - mse: 1.0321\n",
            "Epoch 16: val_loss improved from 1.08053 to 1.04489, saving model to /content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/enhanced_mlp/best_enhanced_model.weights.h5\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - loss: 1.0818 - mae: 0.8437 - mse: 1.0321 - val_loss: 1.0449 - val_mae: 0.8466 - val_mse: 1.0241 - learning_rate: 0.0020\n",
            "Epoch 17/1500\n",
            "\u001b[1m3279/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0920 - mae: 0.8440 - mse: 1.0365\n",
            "Epoch 17: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.0920 - mae: 0.8440 - mse: 1.0365 - val_loss: 1.0558 - val_mae: 0.8466 - val_mse: 1.0251 - learning_rate: 0.0020\n",
            "Epoch 18/1500\n",
            "\u001b[1m3274/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1109 - mae: 0.8455 - mse: 1.0386\n",
            "Epoch 18: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.1109 - mae: 0.8455 - mse: 1.0386 - val_loss: 1.0752 - val_mae: 0.8466 - val_mse: 1.0222 - learning_rate: 0.0020\n",
            "Epoch 19/1500\n",
            "\u001b[1m3281/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1609 - mae: 0.8455 - mse: 1.0289\n",
            "Epoch 19: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.1609 - mae: 0.8455 - mse: 1.0289 - val_loss: 1.1793 - val_mae: 0.8466 - val_mse: 1.0343 - learning_rate: 0.0020\n",
            "Epoch 20/1500\n",
            "\u001b[1m3279/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1651 - mae: 0.8467 - mse: 1.0360\n",
            "Epoch 20: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.1651 - mae: 0.8467 - mse: 1.0360 - val_loss: 1.1216 - val_mae: 0.8466 - val_mse: 1.0310 - learning_rate: 0.0020\n",
            "Epoch 21/1500\n",
            "\u001b[1m3277/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2266 - mae: 0.8456 - mse: 1.0304\n",
            "Epoch 21: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.2265 - mae: 0.8456 - mse: 1.0304 - val_loss: 1.0995 - val_mae: 0.8466 - val_mse: 1.0642 - learning_rate: 0.0020\n",
            "Epoch 22/1500\n",
            "\u001b[1m3277/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1107 - mae: 0.8456 - mse: 1.0572\n",
            "Epoch 22: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 1.1107 - mae: 0.8456 - mse: 1.0572 - val_loss: 1.1494 - val_mae: 0.8466 - val_mse: 1.0397 - learning_rate: 0.0020\n",
            "Epoch 23/1500\n",
            "\u001b[1m3279/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1229 - mae: 0.8462 - mse: 1.0331\n",
            "Epoch 23: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 1.1229 - mae: 0.8462 - mse: 1.0331 - val_loss: 1.1533 - val_mae: 0.8466 - val_mse: 1.0758 - learning_rate: 0.0020\n",
            "Epoch 24/1500\n",
            "\u001b[1m3278/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0992 - mae: 0.8462 - mse: 1.0535\n",
            "Epoch 24: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 1.0992 - mae: 0.8462 - mse: 1.0535 - val_loss: 1.2111 - val_mae: 0.8466 - val_mse: 1.0540 - learning_rate: 0.0020\n",
            "Epoch 25/1500\n",
            "\u001b[1m3275/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1872 - mae: 0.8468 - mse: 1.0562\n",
            "Epoch 25: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.1871 - mae: 0.8468 - mse: 1.0562 - val_loss: 1.0830 - val_mae: 0.8466 - val_mse: 1.0540 - learning_rate: 0.0020\n",
            "Epoch 26/1500\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0954 - mae: 0.8455 - mse: 1.0436\n",
            "Epoch 26: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.0954 - mae: 0.8455 - mse: 1.0436 - val_loss: 1.0807 - val_mae: 0.8466 - val_mse: 1.0325 - learning_rate: 0.0020\n",
            "Epoch 27/1500\n",
            "\u001b[1m3274/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0984 - mae: 0.8455 - mse: 1.0317\n",
            "Epoch 27: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.0984 - mae: 0.8455 - mse: 1.0318 - val_loss: 1.0836 - val_mae: 0.8466 - val_mse: 1.0305 - learning_rate: 0.0020\n",
            "Epoch 28/1500\n",
            "\u001b[1m3277/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0998 - mae: 0.8467 - mse: 1.0409\n",
            "Epoch 28: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.0998 - mae: 0.8467 - mse: 1.0409 - val_loss: 1.0858 - val_mae: 0.8466 - val_mse: 1.0307 - learning_rate: 0.0020\n",
            "Epoch 29/1500\n",
            "\u001b[1m3276/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0980 - mae: 0.8447 - mse: 1.0376\n",
            "Epoch 29: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 1.0980 - mae: 0.8447 - mse: 1.0377 - val_loss: 1.0836 - val_mae: 0.8466 - val_mse: 1.0230 - learning_rate: 0.0020\n",
            "Epoch 30/1500\n",
            "\u001b[1m3281/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0977 - mae: 0.8446 - mse: 1.0364\n",
            "Epoch 30: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.0977 - mae: 0.8446 - mse: 1.0364 - val_loss: 1.0817 - val_mae: 0.8466 - val_mse: 1.0276 - learning_rate: 0.0020\n",
            "Epoch 31/1500\n",
            "\u001b[1m3279/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1030 - mae: 0.8498 - mse: 1.0349\n",
            "Epoch 31: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.1030 - mae: 0.8498 - mse: 1.0349 - val_loss: 1.0879 - val_mae: 0.8466 - val_mse: 1.0591 - learning_rate: 0.0020\n",
            "Epoch 32/1500\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0980 - mae: 0.8448 - mse: 1.0546\n",
            "Epoch 32: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.0980 - mae: 0.8448 - mse: 1.0546 - val_loss: 1.0817 - val_mae: 0.8466 - val_mse: 1.0277 - learning_rate: 0.0020\n",
            "Epoch 33/1500\n",
            "\u001b[1m3276/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0975 - mae: 0.8443 - mse: 1.0349\n",
            "Epoch 33: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.0975 - mae: 0.8443 - mse: 1.0349 - val_loss: 1.0834 - val_mae: 0.8466 - val_mse: 1.0250 - learning_rate: 0.0020\n",
            "Epoch 34/1500\n",
            "\u001b[1m3278/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0996 - mae: 0.8464 - mse: 1.0373\n",
            "Epoch 34: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.0996 - mae: 0.8464 - mse: 1.0373 - val_loss: 1.0859 - val_mae: 0.8466 - val_mse: 1.0275 - learning_rate: 0.0020\n",
            "Epoch 35/1500\n",
            "\u001b[1m3278/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1018 - mae: 0.8485 - mse: 1.0380\n",
            "Epoch 35: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.1018 - mae: 0.8485 - mse: 1.0380 - val_loss: 1.0838 - val_mae: 0.8466 - val_mse: 1.0702 - learning_rate: 0.0020\n",
            "Epoch 36/1500\n",
            "\u001b[1m3278/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1000 - mae: 0.8468 - mse: 1.0659\n",
            "Epoch 36: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 1.1000 - mae: 0.8468 - mse: 1.0659 - val_loss: 1.0815 - val_mae: 0.8466 - val_mse: 1.0569 - learning_rate: 0.0020\n",
            "Epoch 37/1500\n",
            "\u001b[1m3277/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0990 - mae: 0.8458 - mse: 1.0477\n",
            "Epoch 37: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.0990 - mae: 0.8458 - mse: 1.0477 - val_loss: 1.0882 - val_mae: 0.8466 - val_mse: 1.0506 - learning_rate: 0.0020\n",
            "Epoch 38/1500\n",
            "\u001b[1m3280/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1007 - mae: 0.8476 - mse: 1.0646\n",
            "Epoch 38: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 1.1007 - mae: 0.8476 - mse: 1.0646 - val_loss: 1.0815 - val_mae: 0.8467 - val_mse: 1.0216 - learning_rate: 0.0020\n",
            "Epoch 39/1500\n",
            "\u001b[1m3279/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1000 - mae: 0.8468 - mse: 1.0366\n",
            "Epoch 39: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 1.1000 - mae: 0.8468 - mse: 1.0366 - val_loss: 1.0835 - val_mae: 0.8466 - val_mse: 1.0385 - learning_rate: 0.0020\n",
            "Epoch 40/1500\n",
            "\u001b[1m3280/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0991 - mae: 0.8459 - mse: 1.0315\n",
            "Epoch 40: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 1.0991 - mae: 0.8459 - mse: 1.0315 - val_loss: 1.0862 - val_mae: 0.8466 - val_mse: 1.0650 - learning_rate: 0.0020\n",
            "Epoch 41/1500\n",
            "\u001b[1m3278/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1010 - mae: 0.8477 - mse: 1.0454\n",
            "Epoch 41: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 1.1010 - mae: 0.8477 - mse: 1.0454 - val_loss: 1.0835 - val_mae: 0.8466 - val_mse: 1.0806 - learning_rate: 0.0020\n",
            "Epoch 42/1500\n",
            "\u001b[1m3274/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1004 - mae: 0.8473 - mse: 1.0773\n",
            "Epoch 42: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.1004 - mae: 0.8473 - mse: 1.0772 - val_loss: 1.0816 - val_mae: 0.8466 - val_mse: 1.0226 - learning_rate: 0.0020\n",
            "Epoch 43/1500\n",
            "\u001b[1m3279/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1006 - mae: 0.8474 - mse: 1.0449\n",
            "Epoch 43: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 1.1006 - mae: 0.8474 - mse: 1.0450 - val_loss: 1.0879 - val_mae: 0.8466 - val_mse: 1.0285 - learning_rate: 0.0020\n",
            "Epoch 44/1500\n",
            "\u001b[1m3278/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0998 - mae: 0.8466 - mse: 1.0365\n",
            "Epoch 44: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 1.0998 - mae: 0.8466 - mse: 1.0365 - val_loss: 1.0816 - val_mae: 0.8466 - val_mse: 1.0352 - learning_rate: 0.0020\n",
            "Epoch 45/1500\n",
            "\u001b[1m3281/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0974 - mae: 0.8442 - mse: 1.0326\n",
            "Epoch 45: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 1.0974 - mae: 0.8442 - mse: 1.0326 - val_loss: 1.0836 - val_mae: 0.8466 - val_mse: 1.0448 - learning_rate: 0.0020\n",
            "Epoch 46/1500\n",
            "\u001b[1m3281/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0989 - mae: 0.8457 - mse: 1.0429\n",
            "Epoch 46: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 1.0989 - mae: 0.8457 - mse: 1.0429 - val_loss: 1.0858 - val_mae: 0.8466 - val_mse: 1.0368 - learning_rate: 0.0020\n",
            "Epoch 47/1500\n",
            "\u001b[1m3281/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1014 - mae: 0.8482 - mse: 1.0374\n",
            "Epoch 47: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.1014 - mae: 0.8482 - mse: 1.0374 - val_loss: 1.0838 - val_mae: 0.8466 - val_mse: 1.0435 - learning_rate: 0.0020\n",
            "Epoch 48/1500\n",
            "\u001b[1m3274/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0985 - mae: 0.8454 - mse: 1.0394\n",
            "Epoch 48: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.0985 - mae: 0.8454 - mse: 1.0394 - val_loss: 1.0814 - val_mae: 0.8466 - val_mse: 1.0316 - learning_rate: 0.0020\n",
            "Epoch 49/1500\n",
            "\u001b[1m3275/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0989 - mae: 0.8456 - mse: 1.0294\n",
            "Epoch 49: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 1.0989 - mae: 0.8456 - mse: 1.0295 - val_loss: 1.0881 - val_mae: 0.8467 - val_mse: 1.0853 - learning_rate: 0.0020\n",
            "Epoch 50/1500\n",
            "\u001b[1m3280/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0979 - mae: 0.8447 - mse: 1.0616\n",
            "Epoch 50: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 1.0979 - mae: 0.8447 - mse: 1.0615 - val_loss: 1.0817 - val_mae: 0.8466 - val_mse: 1.0434 - learning_rate: 0.0020\n",
            "Epoch 51/1500\n",
            "\u001b[1m3281/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0984 - mae: 0.8452 - mse: 1.0450\n",
            "Epoch 51: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 1.0984 - mae: 0.8452 - mse: 1.0450 - val_loss: 1.0833 - val_mae: 0.8466 - val_mse: 1.0280 - learning_rate: 0.0020\n",
            "Epoch 52/1500\n",
            "\u001b[1m3278/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0995 - mae: 0.8456 - mse: 1.0306\n",
            "Epoch 52: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 1.0995 - mae: 0.8456 - mse: 1.0306 - val_loss: 1.0878 - val_mae: 0.8466 - val_mse: 1.0378 - learning_rate: 0.0020\n",
            "Epoch 53/1500\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1039 - mae: 0.8471 - mse: 1.0345\n",
            "Epoch 53: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.1039 - mae: 0.8471 - mse: 1.0345 - val_loss: 1.1283 - val_mae: 0.8466 - val_mse: 1.0675 - learning_rate: 0.0020\n",
            "Epoch 54/1500\n",
            "\u001b[1m3273/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0939 - mae: 0.8433 - mse: 1.0548\n",
            "Epoch 54: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.0939 - mae: 0.8433 - mse: 1.0548 - val_loss: 1.0866 - val_mae: 0.8466 - val_mse: 1.0287 - learning_rate: 0.0020\n",
            "Epoch 55/1500\n",
            "\u001b[1m3278/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0972 - mae: 0.8464 - mse: 1.0427\n",
            "Epoch 55: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 1.0972 - mae: 0.8464 - mse: 1.0427 - val_loss: 1.1288 - val_mae: 0.8466 - val_mse: 1.0242 - learning_rate: 0.0020\n",
            "Epoch 56/1500\n",
            "\u001b[1m3280/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0953 - mae: 0.8450 - mse: 1.0371\n",
            "Epoch 56: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 1.0953 - mae: 0.8450 - mse: 1.0371 - val_loss: 1.0819 - val_mae: 0.8466 - val_mse: 1.0545 - learning_rate: 0.0020\n",
            "Epoch 57/1500\n",
            "\u001b[1m3280/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0958 - mae: 0.8451 - mse: 1.0578\n",
            "Epoch 57: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 1.0958 - mae: 0.8451 - mse: 1.0578 - val_loss: 1.1324 - val_mae: 0.8466 - val_mse: 1.0331 - learning_rate: 0.0020\n",
            "Epoch 58/1500\n",
            "\u001b[1m3278/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0978 - mae: 0.8474 - mse: 1.0335\n",
            "Epoch 58: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.0978 - mae: 0.8474 - mse: 1.0335 - val_loss: 1.0802 - val_mae: 0.8466 - val_mse: 1.0554 - learning_rate: 0.0020\n",
            "Epoch 59/1500\n",
            "\u001b[1m3277/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0949 - mae: 0.8444 - mse: 1.0617\n",
            "Epoch 59: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.0949 - mae: 0.8444 - mse: 1.0617 - val_loss: 1.1239 - val_mae: 0.8466 - val_mse: 1.0270 - learning_rate: 0.0020\n",
            "Epoch 60/1500\n",
            "\u001b[1m3281/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0989 - mae: 0.8485 - mse: 1.0357\n",
            "Epoch 60: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 1.0989 - mae: 0.8485 - mse: 1.0357 - val_loss: 1.0884 - val_mae: 0.8466 - val_mse: 1.0369 - learning_rate: 0.0020\n",
            "Epoch 61/1500\n",
            "\u001b[1m3281/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0950 - mae: 0.8443 - mse: 1.0501\n",
            "Epoch 61: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 1.0950 - mae: 0.8443 - mse: 1.0501 - val_loss: 1.1261 - val_mae: 0.8466 - val_mse: 1.0319 - learning_rate: 0.0020\n",
            "Epoch 62/1500\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0981 - mae: 0.8478 - mse: 1.0387\n",
            "Epoch 62: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.0981 - mae: 0.8478 - mse: 1.0387 - val_loss: 1.0820 - val_mae: 0.8466 - val_mse: 1.0641 - learning_rate: 0.0020\n",
            "Epoch 63/1500\n",
            "\u001b[1m3280/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0965 - mae: 0.8459 - mse: 1.0598\n",
            "Epoch 63: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 1.0965 - mae: 0.8459 - mse: 1.0598 - val_loss: 1.1301 - val_mae: 0.8466 - val_mse: 1.0323 - learning_rate: 0.0020\n",
            "Epoch 64/1500\n",
            "\u001b[1m3278/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0969 - mae: 0.8461 - mse: 1.0439\n",
            "Epoch 64: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 1.0969 - mae: 0.8461 - mse: 1.0439 - val_loss: 1.0903 - val_mae: 0.8466 - val_mse: 1.0231 - learning_rate: 0.0020\n",
            "Epoch 65/1500\n",
            "\u001b[1m3280/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1328 - mae: 0.8462 - mse: 1.0291\n",
            "Epoch 65: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.1328 - mae: 0.8462 - mse: 1.0291 - val_loss: 1.1131 - val_mae: 0.8466 - val_mse: 1.0799 - learning_rate: 0.0020\n",
            "Epoch 66/1500\n",
            "\u001b[1m3278/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1458 - mae: 0.8462 - mse: 1.0672\n",
            "Epoch 66: val_loss did not improve from 1.04489\n",
            "\n",
            "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.1458 - mae: 0.8462 - mse: 1.0672 - val_loss: 1.0996 - val_mae: 0.8466 - val_mse: 1.0553 - learning_rate: 0.0020\n",
            "Epoch 67/1500\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0632 - mae: 0.8427 - mse: 1.0514\n",
            "Epoch 67: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.0632 - mae: 0.8427 - mse: 1.0514 - val_loss: 1.1213 - val_mae: 0.8405 - val_mse: 0.9996 - learning_rate: 0.0010\n",
            "Epoch 68/1500\n",
            "\u001b[1m3275/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1411 - mae: 0.8410 - mse: 1.0434\n",
            "Epoch 68: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.1411 - mae: 0.8410 - mse: 1.0434 - val_loss: 1.0715 - val_mae: 0.8392 - val_mse: 1.0467 - learning_rate: 0.0010\n",
            "Epoch 69/1500\n",
            "\u001b[1m3279/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1042 - mae: 0.8408 - mse: 1.0451\n",
            "Epoch 69: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.1042 - mae: 0.8408 - mse: 1.0451 - val_loss: 1.1575 - val_mae: 0.8377 - val_mse: 1.0546 - learning_rate: 0.0010\n",
            "Epoch 70/1500\n",
            "\u001b[1m3276/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1279 - mae: 0.8385 - mse: 1.0381\n",
            "Epoch 70: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.1279 - mae: 0.8385 - mse: 1.0381 - val_loss: 1.0955 - val_mae: 0.8412 - val_mse: 1.0700 - learning_rate: 0.0010\n",
            "Epoch 71/1500\n",
            "\u001b[1m3277/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1039 - mae: 0.8364 - mse: 1.0366\n",
            "Epoch 71: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.1040 - mae: 0.8364 - mse: 1.0366 - val_loss: 1.2528 - val_mae: 0.8464 - val_mse: 0.9915 - learning_rate: 0.0010\n",
            "Epoch 72/1500\n",
            "\u001b[1m3276/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1301 - mae: 0.8404 - mse: 1.0389\n",
            "Epoch 72: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.1300 - mae: 0.8404 - mse: 1.0389 - val_loss: 1.0884 - val_mae: 0.8370 - val_mse: 1.0543 - learning_rate: 0.0010\n",
            "Epoch 73/1500\n",
            "\u001b[1m3276/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0935 - mae: 0.8361 - mse: 1.0323\n",
            "Epoch 73: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.0935 - mae: 0.8361 - mse: 1.0323 - val_loss: 1.0720 - val_mae: 0.8378 - val_mse: 1.0309 - learning_rate: 0.0010\n",
            "Epoch 74/1500\n",
            "\u001b[1m3273/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1143 - mae: 0.8371 - mse: 1.0328\n",
            "Epoch 74: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.1143 - mae: 0.8371 - mse: 1.0328 - val_loss: 1.1085 - val_mae: 0.8342 - val_mse: 1.0387 - learning_rate: 0.0010\n",
            "Epoch 75/1500\n",
            "\u001b[1m3281/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1095 - mae: 0.8371 - mse: 1.0344\n",
            "Epoch 75: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.1095 - mae: 0.8371 - mse: 1.0344 - val_loss: 1.0806 - val_mae: 0.8406 - val_mse: 1.0480 - learning_rate: 0.0010\n",
            "Epoch 76/1500\n",
            "\u001b[1m3274/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1418 - mae: 0.8370 - mse: 1.0365\n",
            "Epoch 76: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.1417 - mae: 0.8369 - mse: 1.0365 - val_loss: 1.0611 - val_mae: 0.8351 - val_mse: 0.9960 - learning_rate: 0.0010\n",
            "Epoch 77/1500\n",
            "\u001b[1m3279/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0895 - mae: 0.8371 - mse: 1.0325\n",
            "Epoch 77: val_loss did not improve from 1.04489\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.0895 - mae: 0.8371 - mse: 1.0325 - val_loss: 1.2162 - val_mae: 0.8408 - val_mse: 0.9878 - learning_rate: 0.0010\n",
            "Epoch 78/1500\n",
            "\u001b[1m3277/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0806 - mae: 0.8381 - mse: 1.0333\n",
            "Epoch 78: val_loss improved from 1.04489 to 1.04375, saving model to /content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/enhanced_mlp/best_enhanced_model.weights.h5\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - loss: 1.0806 - mae: 0.8381 - mse: 1.0333 - val_loss: 1.0438 - val_mae: 0.8367 - val_mse: 1.0446 - learning_rate: 0.0010\n",
            "Epoch 79/1500\n",
            "\u001b[1m3275/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0860 - mae: 0.8350 - mse: 1.0271\n",
            "Epoch 79: val_loss did not improve from 1.04375\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.0860 - mae: 0.8350 - mse: 1.0271 - val_loss: 1.0630 - val_mae: 0.8361 - val_mse: 1.0310 - learning_rate: 0.0010\n",
            "Epoch 80/1500\n",
            "\u001b[1m3277/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0821 - mae: 0.8358 - mse: 1.0288\n",
            "Epoch 80: val_loss did not improve from 1.04375\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.0822 - mae: 0.8358 - mse: 1.0288 - val_loss: 1.0822 - val_mae: 0.8344 - val_mse: 1.0218 - learning_rate: 0.0010\n",
            "Epoch 81/1500\n",
            "\u001b[1m3277/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0911 - mae: 0.8340 - mse: 1.0282\n",
            "Epoch 81: val_loss did not improve from 1.04375\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.0911 - mae: 0.8340 - mse: 1.0282 - val_loss: 1.0757 - val_mae: 0.8362 - val_mse: 1.0229 - learning_rate: 0.0010\n",
            "Epoch 82/1500\n",
            "\u001b[1m3276/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1010 - mae: 0.8365 - mse: 1.0326\n",
            "Epoch 82: val_loss improved from 1.04375 to 1.03215, saving model to /content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/enhanced_mlp/best_enhanced_model.weights.h5\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - loss: 1.1009 - mae: 0.8365 - mse: 1.0326 - val_loss: 1.0322 - val_mae: 0.8435 - val_mse: 0.9843 - learning_rate: 0.0010\n",
            "Epoch 83/1500\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0738 - mae: 0.8375 - mse: 1.0315\n",
            "Epoch 83: val_loss did not improve from 1.03215\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.0738 - mae: 0.8375 - mse: 1.0315 - val_loss: 1.1918 - val_mae: 0.8357 - val_mse: 1.0352 - learning_rate: 0.0010\n",
            "Epoch 84/1500\n",
            "\u001b[1m3274/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0980 - mae: 0.8376 - mse: 1.0328\n",
            "Epoch 84: val_loss did not improve from 1.03215\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.0980 - mae: 0.8376 - mse: 1.0328 - val_loss: 1.0505 - val_mae: 0.8354 - val_mse: 1.0044 - learning_rate: 0.0010\n",
            "Epoch 85/1500\n",
            "\u001b[1m3281/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1021 - mae: 0.8371 - mse: 1.0362\n",
            "Epoch 85: val_loss improved from 1.03215 to 1.02267, saving model to /content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/enhanced_mlp/best_enhanced_model.weights.h5\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 1.1021 - mae: 0.8371 - mse: 1.0362 - val_loss: 1.0227 - val_mae: 0.8389 - val_mse: 1.0212 - learning_rate: 0.0010\n",
            "Epoch 86/1500\n",
            "\u001b[1m3279/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0807 - mae: 0.8374 - mse: 1.0311\n",
            "Epoch 86: val_loss improved from 1.02267 to 1.02032, saving model to /content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/enhanced_mlp/best_enhanced_model.weights.h5\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.0807 - mae: 0.8374 - mse: 1.0311 - val_loss: 1.0203 - val_mae: 0.8389 - val_mse: 1.0583 - learning_rate: 0.0010\n",
            "Epoch 87/1500\n",
            "\u001b[1m3274/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1009 - mae: 0.8394 - mse: 1.0517\n",
            "Epoch 87: val_loss did not improve from 1.02032\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.1010 - mae: 0.8394 - mse: 1.0517 - val_loss: 1.1450 - val_mae: 0.8351 - val_mse: 1.0354 - learning_rate: 0.0010\n",
            "Epoch 88/1500\n",
            "\u001b[1m3275/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1164 - mae: 0.8425 - mse: 1.0605\n",
            "Epoch 88: val_loss did not improve from 1.02032\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.1164 - mae: 0.8425 - mse: 1.0605 - val_loss: 1.1542 - val_mae: 0.8564 - val_mse: 1.0069 - learning_rate: 0.0010\n",
            "Epoch 89/1500\n",
            "\u001b[1m3281/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1152 - mae: 0.8370 - mse: 1.0298\n",
            "Epoch 89: val_loss did not improve from 1.02032\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.1152 - mae: 0.8370 - mse: 1.0298 - val_loss: 1.0212 - val_mae: 0.8349 - val_mse: 1.0275 - learning_rate: 0.0010\n",
            "Epoch 90/1500\n",
            "\u001b[1m3274/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1033 - mae: 0.8363 - mse: 1.0286\n",
            "Epoch 90: val_loss did not improve from 1.02032\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.1033 - mae: 0.8363 - mse: 1.0286 - val_loss: 1.0788 - val_mae: 0.8361 - val_mse: 1.0264 - learning_rate: 0.0010\n",
            "Epoch 91/1500\n",
            "\u001b[1m3281/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1374 - mae: 0.8394 - mse: 1.0335\n",
            "Epoch 91: val_loss did not improve from 1.02032\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.1374 - mae: 0.8394 - mse: 1.0335 - val_loss: 1.1310 - val_mae: 0.8314 - val_mse: 1.0036 - learning_rate: 0.0010\n",
            "Epoch 92/1500\n",
            "\u001b[1m3274/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1615 - mae: 0.8386 - mse: 1.0350\n",
            "Epoch 92: val_loss did not improve from 1.02032\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.1615 - mae: 0.8386 - mse: 1.0351 - val_loss: 1.1209 - val_mae: 0.8391 - val_mse: 1.0593 - learning_rate: 0.0010\n",
            "Epoch 93/1500\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1376 - mae: 0.8383 - mse: 1.0402\n",
            "Epoch 93: val_loss did not improve from 1.02032\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.1376 - mae: 0.8383 - mse: 1.0402 - val_loss: 1.3362 - val_mae: 0.8402 - val_mse: 1.0545 - learning_rate: 0.0010\n",
            "Epoch 94/1500\n",
            "\u001b[1m3281/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2008 - mae: 0.8413 - mse: 1.0434\n",
            "Epoch 94: val_loss did not improve from 1.02032\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.2008 - mae: 0.8413 - mse: 1.0434 - val_loss: 1.1443 - val_mae: 0.8370 - val_mse: 1.0263 - learning_rate: 0.0010\n",
            "Epoch 95/1500\n",
            "\u001b[1m3274/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1578 - mae: 0.8386 - mse: 1.0458\n",
            "Epoch 95: val_loss did not improve from 1.02032\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.1578 - mae: 0.8386 - mse: 1.0458 - val_loss: 1.0884 - val_mae: 0.8370 - val_mse: 1.0147 - learning_rate: 0.0010\n",
            "Epoch 96/1500\n",
            "\u001b[1m3276/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1806 - mae: 0.8417 - mse: 1.0382\n",
            "Epoch 96: val_loss did not improve from 1.02032\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.1805 - mae: 0.8417 - mse: 1.0382 - val_loss: 1.0232 - val_mae: 0.8379 - val_mse: 1.0451 - learning_rate: 0.0010\n",
            "Epoch 97/1500\n",
            "\u001b[1m3273/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1214 - mae: 0.8363 - mse: 1.0352\n",
            "Epoch 97: val_loss did not improve from 1.02032\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.1214 - mae: 0.8363 - mse: 1.0352 - val_loss: 1.2121 - val_mae: 0.8381 - val_mse: 1.0440 - learning_rate: 0.0010\n",
            "Epoch 98/1500\n",
            "\u001b[1m3275/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1422 - mae: 0.8386 - mse: 1.0483\n",
            "Epoch 98: val_loss did not improve from 1.02032\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.1422 - mae: 0.8386 - mse: 1.0483 - val_loss: 1.2429 - val_mae: 0.8395 - val_mse: 1.0255 - learning_rate: 0.0010\n",
            "Epoch 99/1500\n",
            "\u001b[1m3277/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1815 - mae: 0.8398 - mse: 1.0354\n",
            "Epoch 99: val_loss did not improve from 1.02032\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.1815 - mae: 0.8398 - mse: 1.0354 - val_loss: 1.0680 - val_mae: 0.8394 - val_mse: 1.0175 - learning_rate: 0.0010\n",
            "Epoch 100/1500\n",
            "\u001b[1m3275/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1086 - mae: 0.8351 - mse: 1.0297\n",
            "Epoch 100: val_loss did not improve from 1.02032\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.1086 - mae: 0.8351 - mse: 1.0297 - val_loss: 1.1661 - val_mae: 0.8327 - val_mse: 0.9815 - learning_rate: 0.0010\n",
            "Epoch 101/1500\n",
            "\u001b[1m3275/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1134 - mae: 0.8299 - mse: 1.0217\n",
            "Epoch 101: val_loss did not improve from 1.02032\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.1134 - mae: 0.8299 - mse: 1.0217 - val_loss: 1.1267 - val_mae: 0.8319 - val_mse: 0.9851 - learning_rate: 0.0010\n",
            "Epoch 102/1500\n",
            "\u001b[1m3281/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0999 - mae: 0.8287 - mse: 1.0158\n",
            "Epoch 102: val_loss did not improve from 1.02032\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.0999 - mae: 0.8287 - mse: 1.0158 - val_loss: 1.1317 - val_mae: 0.8227 - val_mse: 1.0354 - learning_rate: 0.0010\n",
            "Epoch 103/1500\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1085 - mae: 0.8287 - mse: 1.0168\n",
            "Epoch 103: val_loss did not improve from 1.02032\n",
            "\u001b[1m3282/3282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 1.1085 - mae: 0.8287 - mse: 1.0168 - val_loss: 1.0438 - val_mae: 0.8237 - val_mse: 1.0163 - learning_rate: 0.0010\n",
            "Epoch 104/1500\n",
            "\u001b[1m 187/3282\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 1.0556 - mae: 0.8203 - mse: 1.0001"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-743405381.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Running enhanced pipeline on: {data_file}, {windows_file}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_enhanced_feature_mlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindows_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-743405381.py\u001b[0m in \u001b[0;36mrun_enhanced_feature_mlp\u001b[0;34m(data_filename, windows_filename)\u001b[0m\n\u001b[1;32m    505\u001b[0m     \"\"\"\n\u001b[1;32m    506\u001b[0m     \u001b[0menhanced_mlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEnhancedFeatureEngineeringMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0menhanced_mlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_enhanced_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindows_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;31m# Main execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-743405381.py\u001b[0m in \u001b[0;36mrun_enhanced_pipeline\u001b[0;34m(self, data_filename, windows_filename)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0;31m# 6. Train enhanced model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m             history = self.train_enhanced_model(\n\u001b[0m\u001b[1;32m    460\u001b[0m                 \u001b[0mx_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_scaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m             )\n",
            "\u001b[0;32m/tmp/ipython-input-743405381.py\u001b[0m in \u001b[0;36mtrain_enhanced_model\u001b[0;34m(self, x_train, y_train, x_val, y_val)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         history = self.model.fit(\n\u001b[0m\u001b[1;32m    281\u001b[0m             \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    219\u001b[0m             ):\n\u001b[1;32m    220\u001b[0m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/optional_ops.py\u001b[0m in \u001b[0;36mhas_value\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    174\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m       return gen_optional_ops.optional_has_value(\n\u001b[0m\u001b[1;32m    177\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/gen_optional_ops.py\u001b[0m in \u001b[0;36moptional_has_value\u001b[0;34m(optional, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m    173\u001b[0m         _ctx, \"OptionalHasValue\", name, optional)\n\u001b[1;32m    174\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Enhanced Feature Engineering MLP - RESUMABLE VERSION\n",
        "# Added comprehensive checkpoint/resume functionality\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import pickle\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Dropout, BatchNormalization\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from keras.regularizers import l1_l2\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class ResumableEnhancedFeatureEngineeringMLP:\n",
        "    \"\"\"\n",
        "    MLP with explicit feature engineering and full resume capability\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, output_dir='/content/drive/MyDrive/PHD/2025/TEMP_OUTPUT_METROPM/'):\n",
        "        self.output_dir = output_dir\n",
        "        self.y_scaler = StandardScaler()\n",
        "        self.x_scaler = StandardScaler()\n",
        "        self.model = None\n",
        "\n",
        "        # Create directory for enhanced model\n",
        "        self.enhanced_dir = f\"{output_dir}enhanced_mlp/\"\n",
        "        os.makedirs(self.enhanced_dir, exist_ok=True)\n",
        "\n",
        "        # Checkpoint files\n",
        "        self.checkpoint_dir = f\"{self.enhanced_dir}checkpoints/\"\n",
        "        os.makedirs(self.checkpoint_dir, exist_ok=True)\n",
        "\n",
        "        self.checkpoint_files = {\n",
        "            'enhanced_features': f\"{self.checkpoint_dir}enhanced_features.npy\",\n",
        "            'feature_names': f\"{self.checkpoint_dir}feature_names.pkl\",\n",
        "            'selected_features': f\"{self.checkpoint_dir}selected_features.npy\",\n",
        "            'selected_indices': f\"{self.checkpoint_dir}selected_indices.npy\",\n",
        "            'selector': f\"{self.checkpoint_dir}selector.pkl\",\n",
        "            'split_data': f\"{self.checkpoint_dir}split_data.npz\",\n",
        "            'scalers': f\"{self.checkpoint_dir}scalers.pkl\",\n",
        "            'model_weights': f\"{self.checkpoint_dir}training_checkpoint.weights.h5\",\n",
        "            'training_state': f\"{self.checkpoint_dir}training_state.json\",\n",
        "            'final_model': f\"{self.enhanced_dir}enhanced_feature_model.keras\",\n",
        "            'results': f\"{self.checkpoint_dir}results.pkl\"\n",
        "        }\n",
        "\n",
        "        self.pipeline_state = self.load_pipeline_state()\n",
        "        print(f\"📁 Enhanced MLP directory: {self.enhanced_dir}\")\n",
        "        print(f\"💾 Checkpoint directory: {self.checkpoint_dir}\")\n",
        "\n",
        "    def load_pipeline_state(self):\n",
        "        \"\"\"Load or initialize pipeline state\"\"\"\n",
        "        state_file = f\"{self.checkpoint_dir}pipeline_state.json\"\n",
        "        if os.path.exists(state_file):\n",
        "            with open(state_file, 'r') as f:\n",
        "                state = json.load(f)\n",
        "            print(f\"📋 Loaded pipeline state: {state}\")\n",
        "            return state\n",
        "        else:\n",
        "            state = {\n",
        "                'data_loaded': False,\n",
        "                'features_enhanced': False,\n",
        "                'features_selected': False,\n",
        "                'data_split': False,\n",
        "                'data_scaled': False,\n",
        "                'model_trained': False,\n",
        "                'model_evaluated': False,\n",
        "                'pipeline_complete': False\n",
        "            }\n",
        "            print(f\"🆕 Initialized new pipeline state\")\n",
        "            return state\n",
        "\n",
        "    def save_pipeline_state(self):\n",
        "        \"\"\"Save current pipeline state\"\"\"\n",
        "        state_file = f\"{self.checkpoint_dir}pipeline_state.json\"\n",
        "        with open(state_file, 'w') as f:\n",
        "            json.dump(self.pipeline_state, f, indent=2)\n",
        "        print(f\"💾 Pipeline state saved\")\n",
        "\n",
        "    def load_original_data(self, data_filename, windows_filename):\n",
        "        \"\"\"Load original data for feature engineering\"\"\"\n",
        "        if self.pipeline_state['data_loaded']:\n",
        "            print(\"📊 Data already loaded, skipping...\")\n",
        "            return None, None\n",
        "\n",
        "        print(\"📊 Loading original data for feature engineering...\")\n",
        "\n",
        "        data_path = os.path.join(self.output_dir, data_filename)\n",
        "        windows_path = os.path.join(self.output_dir, windows_filename)\n",
        "\n",
        "        x = np.load(data_path)\n",
        "        y = np.load(windows_path)\n",
        "\n",
        "        # Save loaded data for resume\n",
        "        np.save(f\"{self.checkpoint_dir}original_x.npy\", x)\n",
        "        np.save(f\"{self.checkpoint_dir}original_y.npy\", y)\n",
        "\n",
        "        self.pipeline_state['data_loaded'] = True\n",
        "        self.save_pipeline_state()\n",
        "\n",
        "        print(f\"✅ Original data loaded and saved: X={x.shape}, y={y.shape}\")\n",
        "        return x, y\n",
        "\n",
        "    def create_enhanced_features(self, x=None, force_recreate=False):\n",
        "        \"\"\"Create enhanced features with checkpoint support\"\"\"\n",
        "        if self.pipeline_state['features_enhanced'] and not force_recreate:\n",
        "            print(\"🔧 Enhanced features already created, loading from checkpoint...\")\n",
        "            X_enhanced = np.load(self.checkpoint_files['enhanced_features'])\n",
        "            with open(self.checkpoint_files['feature_names'], 'rb') as f:\n",
        "                feature_names = pickle.load(f)\n",
        "            print(f\"✅ Loaded enhanced features: {X_enhanced.shape}\")\n",
        "            return X_enhanced, feature_names\n",
        "\n",
        "        # Load original data if not provided\n",
        "        if x is None:\n",
        "            x = np.load(f\"{self.checkpoint_dir}original_x.npy\")\n",
        "\n",
        "        print(f\"\\n🔧 Creating enhanced features based on correlation analysis...\")\n",
        "        print(f\"   Starting with {x.shape[1]} original features\")\n",
        "\n",
        "        enhanced_features = []\n",
        "        feature_names = []\n",
        "\n",
        "        # 1. Original features (scaled)\n",
        "        enhanced_features.append(x)\n",
        "        feature_names.extend([f\"orig_{i}\" for i in range(x.shape[1])])\n",
        "        print(f\"   ✅ Original features: {x.shape[1]}\")\n",
        "\n",
        "        # 2. Best interaction found (Feature 7 × Feature 8)\n",
        "        if x.shape[1] > 8:\n",
        "            best_interaction = x[:, 7] * x[:, 8]\n",
        "            enhanced_features.append(best_interaction.reshape(-1, 1))\n",
        "            feature_names.append(\"feat_7_x_feat_8\")\n",
        "            print(f\"   ✅ Best interaction (7×8): 1 feature\")\n",
        "\n",
        "        # 3. Top feature interactions (systematic)\n",
        "        print(\"   Creating systematic feature interactions...\")\n",
        "        interaction_features = []\n",
        "        interaction_names = []\n",
        "\n",
        "        top_features = min(15, x.shape[1])\n",
        "        interaction_count = 0\n",
        "\n",
        "        for i in range(top_features):\n",
        "            for j in range(i+1, top_features):\n",
        "                if interaction_count < 50:\n",
        "                    # Multiplication\n",
        "                    mult_feat = x[:, i] * x[:, j]\n",
        "                    interaction_features.append(mult_feat)\n",
        "                    interaction_names.append(f\"feat_{i}_x_feat_{j}\")\n",
        "\n",
        "                    # Division (safe)\n",
        "                    if np.all(np.abs(x[:, j]) > 1e-8):\n",
        "                        div_feat = x[:, i] / (x[:, j] + 1e-8)\n",
        "                        interaction_features.append(div_feat)\n",
        "                        interaction_names.append(f\"feat_{i}_div_feat_{j}\")\n",
        "\n",
        "                    interaction_count += 2\n",
        "\n",
        "                    if interaction_count >= 50:\n",
        "                        break\n",
        "            if interaction_count >= 50:\n",
        "                break\n",
        "\n",
        "        if interaction_features:\n",
        "            interaction_matrix = np.column_stack(interaction_features)\n",
        "            enhanced_features.append(interaction_matrix)\n",
        "            feature_names.extend(interaction_names)\n",
        "            print(f\"   ✅ Feature interactions: {len(interaction_features)}\")\n",
        "\n",
        "        # 4. Polynomial features (degree 2) for top features\n",
        "        print(\"   Creating polynomial features...\")\n",
        "        poly_features = []\n",
        "        poly_names = []\n",
        "\n",
        "        top_poly_features = min(10, x.shape[1])\n",
        "        for i in range(top_poly_features):\n",
        "            # Quadratic terms\n",
        "            quad_feat = x[:, i] ** 2\n",
        "            poly_features.append(quad_feat)\n",
        "            poly_names.append(f\"feat_{i}_squared\")\n",
        "\n",
        "            # Cubic terms (selective)\n",
        "            if i < 5:  # Only for top 5\n",
        "                cube_feat = x[:, i] ** 3\n",
        "                poly_features.append(cube_feat)\n",
        "                poly_names.append(f\"feat_{i}_cubed\")\n",
        "\n",
        "        if poly_features:\n",
        "            poly_matrix = np.column_stack(poly_features)\n",
        "            enhanced_features.append(poly_matrix)\n",
        "            feature_names.extend(poly_names)\n",
        "            print(f\"   ✅ Polynomial features: {len(poly_features)}\")\n",
        "\n",
        "        # 5. Statistical features\n",
        "        print(\"   Creating statistical features...\")\n",
        "        stat_features = []\n",
        "        stat_names = []\n",
        "\n",
        "        if x.shape[1] >= 5:\n",
        "            for window in [3, 5]:\n",
        "                if x.shape[1] >= window:\n",
        "                    for start in range(0, min(20, x.shape[1] - window + 1), window):\n",
        "                        end = start + window\n",
        "                        mean_feat = np.mean(x[:, start:end], axis=1)\n",
        "                        std_feat = np.std(x[:, start:end], axis=1)\n",
        "\n",
        "                        stat_features.extend([mean_feat, std_feat])\n",
        "                        stat_names.extend([f\"mean_{start}_{end}\", f\"std_{start}_{end}\"])\n",
        "\n",
        "        if stat_features:\n",
        "            stat_matrix = np.column_stack(stat_features)\n",
        "            enhanced_features.append(stat_matrix)\n",
        "            feature_names.extend(stat_names)\n",
        "            print(f\"   ✅ Statistical features: {len(stat_features)}\")\n",
        "\n",
        "        # 6. Combine all features\n",
        "        X_enhanced = np.hstack(enhanced_features)\n",
        "\n",
        "        # Save enhanced features\n",
        "        np.save(self.checkpoint_files['enhanced_features'], X_enhanced)\n",
        "        with open(self.checkpoint_files['feature_names'], 'wb') as f:\n",
        "            pickle.dump(feature_names, f)\n",
        "\n",
        "        self.pipeline_state['features_enhanced'] = True\n",
        "        self.save_pipeline_state()\n",
        "\n",
        "        print(f\"\\n📈 Feature Engineering Summary:\")\n",
        "        print(f\"   Original features: {x.shape[1]}\")\n",
        "        print(f\"   Enhanced features: {X_enhanced.shape[1]}\")\n",
        "        print(f\"   Enhancement factor: {X_enhanced.shape[1] / x.shape[1]:.1f}x\")\n",
        "        print(f\"💾 Enhanced features saved to checkpoint\")\n",
        "\n",
        "        return X_enhanced, feature_names\n",
        "\n",
        "    def select_best_features(self, X_enhanced=None, y=None, max_features=200, force_reselect=False):\n",
        "        \"\"\"Select best features with checkpoint support\"\"\"\n",
        "        if self.pipeline_state['features_selected'] and not force_reselect:\n",
        "            print(\"🎯 Feature selection already done, loading from checkpoint...\")\n",
        "            X_selected = np.load(self.checkpoint_files['selected_features'])\n",
        "            selected_indices = np.load(self.checkpoint_files['selected_indices'])\n",
        "            with open(self.checkpoint_files['selector'], 'rb') as f:\n",
        "                selector = pickle.load(f)\n",
        "            print(f\"✅ Loaded selected features: {X_selected.shape}\")\n",
        "            return X_selected, selected_indices, selector\n",
        "\n",
        "        # Load data if not provided\n",
        "        if X_enhanced is None:\n",
        "            X_enhanced = np.load(self.checkpoint_files['enhanced_features'])\n",
        "        if y is None:\n",
        "            y = np.load(f\"{self.checkpoint_dir}original_y.npy\")\n",
        "\n",
        "        print(f\"🎯 Selecting best {max_features} features from {X_enhanced.shape[1]}...\")\n",
        "\n",
        "        # Use mutual information for non-linear feature selection\n",
        "        selector = SelectKBest(mutual_info_regression, k=min(max_features, X_enhanced.shape[1]))\n",
        "        X_selected = selector.fit_transform(X_enhanced, y)\n",
        "\n",
        "        # Get selected feature indices\n",
        "        selected_indices = selector.get_support(indices=True)\n",
        "        selected_scores = selector.scores_[selected_indices]\n",
        "\n",
        "        # Save feature selection\n",
        "        np.save(self.checkpoint_files['selected_features'], X_selected)\n",
        "        np.save(self.checkpoint_files['selected_indices'], selected_indices)\n",
        "        with open(self.checkpoint_files['selector'], 'wb') as f:\n",
        "            pickle.dump(selector, f)\n",
        "\n",
        "        self.pipeline_state['features_selected'] = True\n",
        "        self.save_pipeline_state()\n",
        "\n",
        "        print(f\"   Selected {X_selected.shape[1]} features\")\n",
        "        print(f\"   Score range: [{np.min(selected_scores):.6f}, {np.max(selected_scores):.6f}]\")\n",
        "        print(f\"💾 Feature selection saved to checkpoint\")\n",
        "\n",
        "        return X_selected, selected_indices, selector\n",
        "\n",
        "    def split_and_scale_data(self, X_selected=None, y=None, force_resplit=False):\n",
        "        \"\"\"Split and scale data with checkpoint support\"\"\"\n",
        "        if self.pipeline_state['data_scaled'] and not force_resplit:\n",
        "            print(\"📊 Data already split and scaled, loading from checkpoint...\")\n",
        "            data = np.load(self.checkpoint_files['split_data'])\n",
        "            with open(self.checkpoint_files['scalers'], 'rb') as f:\n",
        "                scalers = pickle.load(f)\n",
        "\n",
        "            self.x_scaler = scalers['x_scaler']\n",
        "            self.y_scaler = scalers['y_scaler']\n",
        "\n",
        "            return (data['x_train_scaled'], data['x_val_scaled'], data['x_test_scaled'],\n",
        "                   data['y_train_scaled'], data['y_val_scaled'], data['y_test_scaled'])\n",
        "\n",
        "        # Load data if not provided\n",
        "        if X_selected is None:\n",
        "            X_selected = np.load(self.checkpoint_files['selected_features'])\n",
        "        if y is None:\n",
        "            y = np.load(f\"{self.checkpoint_dir}original_y.npy\")\n",
        "\n",
        "        print(f\"📊 Splitting and scaling data...\")\n",
        "\n",
        "        # Split data\n",
        "        x_temp, x_test, y_temp, y_test = train_test_split(\n",
        "            X_selected, y, test_size=0.2, random_state=42\n",
        "        )\n",
        "        x_train, x_val, y_train, y_val = train_test_split(\n",
        "            x_temp, y_temp, test_size=0.25, random_state=42\n",
        "        )\n",
        "\n",
        "        # Scale features and targets\n",
        "        x_train_scaled = self.x_scaler.fit_transform(x_train)\n",
        "        x_val_scaled = self.x_scaler.transform(x_val)\n",
        "        x_test_scaled = self.x_scaler.transform(x_test)\n",
        "\n",
        "        y_train_scaled = self.y_scaler.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
        "        y_val_scaled = self.y_scaler.transform(y_val.reshape(-1, 1)).flatten()\n",
        "        y_test_scaled = self.y_scaler.transform(y_test.reshape(-1, 1)).flatten()\n",
        "\n",
        "        # Save split and scaled data\n",
        "        np.savez(self.checkpoint_files['split_data'],\n",
        "                x_train_scaled=x_train_scaled, x_val_scaled=x_val_scaled, x_test_scaled=x_test_scaled,\n",
        "                y_train_scaled=y_train_scaled, y_val_scaled=y_val_scaled, y_test_scaled=y_test_scaled)\n",
        "\n",
        "        with open(self.checkpoint_files['scalers'], 'wb') as f:\n",
        "            pickle.dump({'x_scaler': self.x_scaler, 'y_scaler': self.y_scaler}, f)\n",
        "\n",
        "        self.pipeline_state['data_split'] = True\n",
        "        self.pipeline_state['data_scaled'] = True\n",
        "        self.save_pipeline_state()\n",
        "\n",
        "        print(f\"   Train: {x_train_scaled.shape[0]} samples, {x_train_scaled.shape[1]} features\")\n",
        "        print(f\"   Validation: {x_val_scaled.shape[0]} samples\")\n",
        "        print(f\"   Test: {x_test_scaled.shape[0]} samples\")\n",
        "        print(f\"💾 Split and scaled data saved to checkpoint\")\n",
        "\n",
        "        return (x_train_scaled, x_val_scaled, x_test_scaled,\n",
        "               y_train_scaled, y_val_scaled, y_test_scaled)\n",
        "\n",
        "    def build_interaction_focused_mlp(self, input_dim):\n",
        "        \"\"\"Build MLP optimized for learning feature interactions\"\"\"\n",
        "        print(f\"🏗️ Building interaction-focused MLP for {input_dim} features...\")\n",
        "\n",
        "        model = Sequential([\n",
        "            Dense(4096, input_dim=input_dim, activation='relu',\n",
        "                  kernel_regularizer=l1_l2(0.0001, 0.001)),\n",
        "            BatchNormalization(),\n",
        "            Dropout(0.4),\n",
        "\n",
        "            Dense(2048, activation='relu',\n",
        "                  kernel_regularizer=l1_l2(0.0001, 0.001)),\n",
        "            BatchNormalization(),\n",
        "            Dropout(0.4),\n",
        "\n",
        "            Dense(1024, activation='relu',\n",
        "                  kernel_regularizer=l1_l2(0.0001, 0.001)),\n",
        "            BatchNormalization(),\n",
        "            Dropout(0.3),\n",
        "\n",
        "            Dense(512, activation='relu',\n",
        "                  kernel_regularizer=l1_l2(0.0001, 0.001)),\n",
        "            BatchNormalization(),\n",
        "            Dropout(0.3),\n",
        "\n",
        "            Dense(256, activation='relu'),\n",
        "            Dropout(0.2),\n",
        "\n",
        "            Dense(128, activation='relu'),\n",
        "            Dropout(0.2),\n",
        "\n",
        "            Dense(64, activation='relu'),\n",
        "            Dropout(0.1),\n",
        "\n",
        "            Dense(32, activation='relu'),\n",
        "\n",
        "            Dense(1, activation='linear')\n",
        "        ])\n",
        "\n",
        "        optimizer = keras.optimizers.Adam(\n",
        "            learning_rate=0.002,\n",
        "            clipnorm=1.0,\n",
        "            beta_1=0.9,\n",
        "            beta_2=0.999\n",
        "        )\n",
        "\n",
        "        model.compile(\n",
        "            loss='mae',\n",
        "            optimizer=optimizer,\n",
        "            metrics=['mse', 'mae']\n",
        "        )\n",
        "\n",
        "        print(f\"   Model parameters: {model.count_params():,}\")\n",
        "        return model\n",
        "\n",
        "    def train_enhanced_model(self, force_retrain=False):\n",
        "        \"\"\"Train model with resume capability\"\"\"\n",
        "        if self.pipeline_state['model_trained'] and not force_retrain:\n",
        "            print(\"🚀 Model already trained, loading from checkpoint...\")\n",
        "            if os.path.exists(self.checkpoint_files['final_model']):\n",
        "                self.model = load_model(self.checkpoint_files['final_model'])\n",
        "                print(\"✅ Loaded trained model\")\n",
        "                return None\n",
        "            else:\n",
        "                print(\"⚠️  Final model not found, will retrain...\")\n",
        "\n",
        "        # Load scaled data\n",
        "        data = np.load(self.checkpoint_files['split_data'])\n",
        "        x_train_scaled = data['x_train_scaled']\n",
        "        x_val_scaled = data['x_val_scaled']\n",
        "        y_train_scaled = data['y_train_scaled']\n",
        "        y_val_scaled = data['y_val_scaled']\n",
        "\n",
        "        print(f\"🚀 Training enhanced feature model...\")\n",
        "\n",
        "        # Build model\n",
        "        self.model = self.build_interaction_focused_mlp(x_train_scaled.shape[1])\n",
        "\n",
        "        # Check for existing training checkpoint\n",
        "        initial_epoch = 0\n",
        "        if os.path.exists(self.checkpoint_files['training_state']) and not force_retrain:\n",
        "            try:\n",
        "                with open(self.checkpoint_files['training_state'], 'r') as f:\n",
        "                    training_state = json.load(f)\n",
        "                initial_epoch = training_state.get('last_epoch', 0)\n",
        "                if initial_epoch > 0:\n",
        "                    self.model.load_weights(self.checkpoint_files['model_weights'])\n",
        "                    print(f\"📋 Resuming training from epoch {initial_epoch}\")\n",
        "            except:\n",
        "                print(\"⚠️  Could not load training checkpoint, starting fresh\")\n",
        "                initial_epoch = 0\n",
        "\n",
        "        # Custom callback to save training state\n",
        "        class TrainingStateCallback(keras.callbacks.Callback):\n",
        "            def __init__(self, state_file, weights_file):\n",
        "                self.state_file = state_file\n",
        "                self.weights_file = weights_file\n",
        "\n",
        "            def on_epoch_end(self, epoch, logs=None):\n",
        "                # Save every 50 epochs\n",
        "                if epoch % 50 == 0:\n",
        "                    state = {\n",
        "                        'last_epoch': epoch + 1,\n",
        "                        'val_loss': float(logs.get('val_loss', 0)),\n",
        "                        'loss': float(logs.get('loss', 0))\n",
        "                    }\n",
        "                    with open(self.state_file, 'w') as f:\n",
        "                        json.dump(state, f)\n",
        "                    self.model.save_weights(self.weights_file)\n",
        "\n",
        "        # Enhanced callbacks\n",
        "        callbacks = [\n",
        "            ModelCheckpoint(\n",
        "                f\"{self.enhanced_dir}best_enhanced_model.weights.h5\",\n",
        "                monitor='val_loss',\n",
        "                save_best_only=True,\n",
        "                save_weights_only=True,\n",
        "                verbose=1\n",
        "            ),\n",
        "            EarlyStopping(\n",
        "                monitor='val_loss',\n",
        "                patience=150,\n",
        "                restore_best_weights=True,\n",
        "                verbose=1,\n",
        "                min_delta=0.0001\n",
        "            ),\n",
        "            ReduceLROnPlateau(\n",
        "                monitor='val_loss',\n",
        "                factor=0.5,\n",
        "                patience=50,\n",
        "                min_lr=1e-7,\n",
        "                verbose=1\n",
        "            ),\n",
        "            TrainingStateCallback(\n",
        "                self.checkpoint_files['training_state'],\n",
        "                self.checkpoint_files['model_weights']\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        # Train model\n",
        "        history = self.model.fit(\n",
        "            x_train_scaled, y_train_scaled,\n",
        "            validation_data=(x_val_scaled, y_val_scaled),\n",
        "            epochs=1500,\n",
        "            batch_size=64,\n",
        "            callbacks=callbacks,\n",
        "            verbose=1,\n",
        "            initial_epoch=initial_epoch\n",
        "        )\n",
        "\n",
        "        # Save final model\n",
        "        self.model.save(self.checkpoint_files['final_model'])\n",
        "\n",
        "        self.pipeline_state['model_trained'] = True\n",
        "        self.save_pipeline_state()\n",
        "\n",
        "        print(\"✅ Enhanced model training complete and saved!\")\n",
        "        return history\n",
        "\n",
        "    def evaluate_enhanced_model(self, history=None, force_reevaluate=False):\n",
        "        \"\"\"Evaluate model with checkpoint support\"\"\"\n",
        "        if self.pipeline_state['model_evaluated'] and not force_reevaluate:\n",
        "            print(\"📊 Model already evaluated, loading results...\")\n",
        "            with open(self.checkpoint_files['results'], 'rb') as f:\n",
        "                results = pickle.load(f)\n",
        "            print(f\"✅ Loaded evaluation results: R²={results['r2']:.6f}\")\n",
        "            return results\n",
        "\n",
        "        print(\"📊 Evaluating enhanced model...\")\n",
        "\n",
        "        # Load model if not in memory\n",
        "        if self.model is None:\n",
        "            self.model = load_model(self.checkpoint_files['final_model'])\n",
        "\n",
        "        # Load scalers and test data\n",
        "        data = np.load(self.checkpoint_files['split_data'])\n",
        "        with open(self.checkpoint_files['scalers'], 'rb') as f:\n",
        "            scalers = pickle.load(f)\n",
        "\n",
        "        self.x_scaler = scalers['x_scaler']\n",
        "        self.y_scaler = scalers['y_scaler']\n",
        "\n",
        "        x_test_scaled = data['x_test_scaled']\n",
        "        y_test_scaled = data['y_test_scaled']\n",
        "\n",
        "        # Predictions\n",
        "        y_pred_scaled = self.model.predict(x_test_scaled, verbose=0)\n",
        "        y_pred = self.y_scaler.inverse_transform(y_pred_scaled).flatten()\n",
        "        y_true = self.y_scaler.inverse_transform(y_test_scaled.reshape(-1, 1)).flatten()\n",
        "\n",
        "        # Metrics\n",
        "        r2 = r2_score(y_true, y_pred)\n",
        "        mse = mean_squared_error(y_true, y_pred)\n",
        "        mae = mean_absolute_error(y_true, y_pred)\n",
        "        rmse = np.sqrt(mse)\n",
        "\n",
        "        # Accuracy metrics\n",
        "        acc_05 = np.mean(np.abs(y_true - y_pred) <= 0.5) * 100\n",
        "        acc_1 = np.mean(np.abs(y_true - y_pred) <= 1) * 100\n",
        "        acc_15 = np.mean(np.abs(y_true - y_pred) <= 1.5) * 100\n",
        "        acc_2 = np.mean(np.abs(y_true - y_pred) <= 2) * 100\n",
        "\n",
        "        results = {\n",
        "            'r2': r2, 'mse': mse, 'mae': mae, 'rmse': rmse,\n",
        "            'acc_05': acc_05, 'acc_1': acc_1, 'acc_15': acc_15, 'acc_2': acc_2,\n",
        "            'y_true': y_true, 'y_pred': y_pred\n",
        "        }\n",
        "\n",
        "        # Save results\n",
        "        with open(self.checkpoint_files['results'], 'wb') as f:\n",
        "            pickle.dump(results, f)\n",
        "\n",
        "        self.pipeline_state['model_evaluated'] = True\n",
        "        self.save_pipeline_state()\n",
        "\n",
        "        print(f\"📈 Enhanced Model Results:\")\n",
        "        print(f\"   R²: {r2:.6f}\")\n",
        "        print(f\"   MAE: {mae:.4f}\")\n",
        "        print(f\"   RMSE: {rmse:.4f}\")\n",
        "        print(f\"   Accuracy ±0.5: {acc_05:.1f}%\")\n",
        "        print(f\"   Accuracy ±1.0: {acc_1:.1f}%\")\n",
        "        print(f\"   Accuracy ±1.5: {acc_15:.1f}%\")\n",
        "        print(f\"   Accuracy ±2.0: {acc_2:.1f}%\")\n",
        "        print(f\"💾 Results saved to checkpoint\")\n",
        "\n",
        "        # Plot results if history available\n",
        "        if history:\n",
        "            self.plot_enhanced_results(y_true, y_pred, history, r2, mae)\n",
        "\n",
        "        return results\n",
        "\n",
        "    def plot_enhanced_results(self, y_true, y_pred, history, r2, mae):\n",
        "        \"\"\"Plot comprehensive results\"\"\"\n",
        "        fig, axes = plt.subplots(2, 4, figsize=(24, 12))\n",
        "\n",
        "        # Training history plots and other visualizations\n",
        "        # (same as original but with checkpoint awareness)\n",
        "\n",
        "        # Training history - Loss\n",
        "        axes[0,0].plot(history.history['loss'], label='Training', linewidth=2)\n",
        "        axes[0,0].plot(history.history['val_loss'], label='Validation', linewidth=2)\n",
        "        axes[0,0].set_title('Enhanced Model Loss')\n",
        "        axes[0,0].set_yscale('log')\n",
        "        axes[0,0].legend()\n",
        "        axes[0,0].grid(True, alpha=0.3)\n",
        "\n",
        "        # Training history - MAE\n",
        "        axes[0,1].plot(history.history['mae'], label='Training', linewidth=2)\n",
        "        axes[0,1].plot(history.history['val_mae'], label='Validation', linewidth=2)\n",
        "        axes[0,1].set_title('Enhanced Model MAE')\n",
        "        axes[0,1].legend()\n",
        "        axes[0,1].grid(True, alpha=0.3)\n",
        "\n",
        "        # Predictions scatter\n",
        "        axes[0,2].scatter(y_true, y_pred, alpha=0.6, s=3, color='darkblue')\n",
        "        axes[0,2].plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--', lw=2)\n",
        "        axes[0,2].set_xlabel('True Values')\n",
        "        axes[0,2].set_ylabel('Predictions')\n",
        "        axes[0,2].set_title(f'Enhanced Predictions\\n(R²={r2:.6f})')\n",
        "        axes[0,2].grid(True, alpha=0.3)\n",
        "\n",
        "        # Residuals and other plots\n",
        "        residuals = y_true - y_pred\n",
        "        axes[1,0].scatter(y_pred, residuals, alpha=0.6, s=3, color='green')\n",
        "        axes[1,0].axhline(y=0, color='r', linestyle='--')\n",
        "        axes[1,0].set_xlabel('Predictions')\n",
        "        axes[1,0].set_ylabel('Residuals')\n",
        "        axes[1,0].set_title('Enhanced Model Residuals')\n",
        "        axes[1,0].grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{self.enhanced_dir}enhanced_results.png\", dpi=150, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "    def run_enhanced_pipeline(self, data_filename, windows_filename, force_restart=False):\n",
        "        \"\"\"Run complete enhanced pipeline with resume capability\"\"\"\n",
        "        print(\"=\"*80)\n",
        "        print(\"🚀 RESUMABLE ENHANCED FEATURE ENGINEERING MLP PIPELINE\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        if force_restart:\n",
        "            print(\"🔄 Force restart requested, clearing all checkpoints...\")\n",
        "            self.clear_checkpoints()\n",
        "            self.pipeline_state = self.load_pipeline_state()\n",
        "\n",
        "        try:\n",
        "            # 1. Load original data\n",
        "            print(f\"\\n📋 Step 1/7: Loading Data\")\n",
        "            print(f\"   Status: {'✅ Complete' if self.pipeline_state['data_loaded'] else '⏳ Pending'}\")\n",
        "            x, y = self.load_original_data(data_filename, windows_filename)\n",
        "\n",
        "            # 2. Create enhanced features\n",
        "            print(f\"\\n📋 Step 2/7: Feature Engineering\")\n",
        "            print(f\"   Status: {'✅ Complete' if self.pipeline_state['features_enhanced'] else '⏳ Pending'}\")\n",
        "            X_enhanced, feature_names = self.create_enhanced_features(x)\n",
        "\n",
        "            # 3. Select best features\n",
        "            print(f\"\\n📋 Step 3/7: Feature Selection\")\n",
        "            print(f\"   Status: {'✅ Complete' if self.pipeline_state['features_selected'] else '⏳ Pending'}\")\n",
        "            X_selected, selected_indices, selector = self.select_best_features(X_enhanced, y)\n",
        "\n",
        "            # 4. Split and scale data\n",
        "            print(f\"\\n📋 Step 4/7: Data Preparation\")\n",
        "            print(f\"   Status: {'✅ Complete' if self.pipeline_state['data_scaled'] else '⏳"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "nxij89jyeebm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "L4",
      "mount_file_id": "https://github.com/supriyag123/PHD_Pub/blob/main/AGENTIC-MODULE3-MLP.ipynb",
      "authorship_tag": "ABX9TyOKg2tW0Zh+23kAESQMdyGg",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}