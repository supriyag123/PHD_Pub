{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supriyag123/PHD_Pub/blob/main/DyFor%20GP%20Heuristics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bx-5b_puABG1",
        "outputId": "8dc6a807-0d3b-42c6-cbf6-63561e6d10e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "time: 129 ms (started: 2025-03-18 16:01:00 +00:00)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import math\n",
        "import plotly.graph_objects as go\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout, RepeatVector, TimeDistributed, Input\n",
        "from keras.models import Model\n",
        "from keras import saving\n",
        "\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import Callback\n",
        "import plotly\n",
        "from keras import losses\n",
        "import plotly.express as px # for data visualization\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import IsolationForest\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import pylab as pl\n",
        "\n",
        "\n",
        "\n",
        "##### Take one dataset at a time\n",
        "#train_data = np.load(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_METROPM/multivariate_long_sequences-TRAIN-Daily-DIRECT-VAR.npy')\n",
        "#train_data = np.load(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_AIRQUALITY/multivariate_long_sequences-TRAIN-Daily-DIRECT-VAR.npy')\n",
        "train_data = np.load(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_ELECTRICITY/multivariate_long_sequences-TRAIN-DATA-FullSearch-VAR.npy')\n",
        "\n",
        "\n",
        "n_seq = train_data.shape[0]\n",
        "window_size = train_data.shape[1]\n",
        "n_features = train_data.shape[2]\n",
        "TestSample = 1\n",
        "\n",
        "\n",
        "##Get large set of subsequence from previous steps (VAE)... this is not labelled yet.\n",
        "#results1=np.load(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_METROPM/generated_large_subsquence2_data_V2.npy')\n",
        "#results1=np.load(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_AIRQUALITY/generated_large_subsquence2_data.npy')\n",
        "results1=np.load(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_ELECTRICITY/generated_large_subsquence2_data.npy')\n",
        "\n",
        "x=results1\n",
        "\n",
        "import random\n",
        "rd = list()\n",
        "rd = random.sample(range(1, results1.shape[0]), TestSample)\n",
        "\n",
        "\n",
        "############### VAR PREDICTION TIMING ####################################################################################################################\n",
        "\n",
        "!pip install ipython-autotime\n",
        "##Start measuring time-----THIS ONE IS FOR VAR --------------------------------\n",
        "%load_ext autotime\n",
        "\n",
        "rmse_list = list()\n",
        "min_window_list = list()\n",
        "best_window_for_long_seq = list()\n",
        "best_window_for_long_seq.clear()\n",
        "#for i in range(2) :\n",
        "x_3d = x.reshape((x.shape[0],window_size,n_features))\n",
        "n_future = 1\n",
        "K= window_size\n",
        "\n",
        "\n",
        "\n",
        "best_window_for_long_seq.clear()\n",
        "\n",
        "from statsmodels.tsa.api import VAR\n",
        "\n",
        "## Note for some reason first run takes longer. So run it twice to get a better time\n",
        "for i in rd :\n",
        "\n",
        "  rmse_list.clear()\n",
        "  for k in range(2,(round(K))):\n",
        "    cur_seq = x_3d[i,:,:]\n",
        "    #df = pd.DataFrame(cur_seq, columns=['V1','V2','V3','V4','V5','V6','V7','V8','V9','V10','V11','V12'])\n",
        "    df = pd.DataFrame(cur_seq, columns=['V1','V2','V3','V4','V5','V6'])\n",
        "    df_train, df_test = df[0:-n_future], df[-n_future:]\n",
        "    model= VAR(df_train)\n",
        "    try:\n",
        "      model_fitted1 = model.fit(k)\n",
        "      forecast_input1 = df_train.values[-k:]\n",
        "      fc1 = model_fitted1.forecast(y=forecast_input1, steps=n_future)\n",
        "      df_forecast1 = pd.DataFrame(fc1, index=df.index[-n_future:], columns=df.columns)\n",
        "      mse =  mean_squared_error(df_test['V1'], df_forecast1['V1'].values)\n",
        "      rmse_list.append(mse)\n",
        "    except:\n",
        "      rmse_list.append(99999)\n",
        "      print('VAR could not solve row number')\n",
        "      print(i, k)\n",
        "\n",
        "  #For this i, find minimum rmse for all sliding window, and corresponding sw size\n",
        "  min_index = rmse_list.index(min(rmse_list))\n",
        "  min_sw = min_index + 2\n",
        "  print('i=', i,'SW =', min_sw, rmse_list)\n",
        "  best_window_for_long_seq.append(min_sw)\n",
        "\n",
        "\n",
        "#OUT OF ALL LOOPS NOW\n",
        "#best_window_for_long_seq now contains the best multivariate window size for each of the long sequence i\n",
        "print(best_window_for_long_seq)\n",
        "Window = np.array(best_window_for_long_seq)\n",
        "y= Window\n",
        "\n",
        "##Commenting this for now but they may be needed\n",
        "#np.save(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_METROPM/generated-data-true-window2-COHORT1.npy',y)\n",
        "#np.save(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_METROPM/generated-data2-COHORT1.npy',x)\n",
        "\n",
        "\n",
        "########################## MLP PREDICTION TIMING ###################################################################################\n",
        "#---------------------------------------------------------Get parts of the results and combine them --------------------------------\n",
        "\n",
        "\n",
        "#y = np.load(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_METROPM/generated-data-true-window2.npy')\n",
        "#x = np.load(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_METROPM/generated-data2.npy')\n",
        "\n",
        "#y = np.load(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_AIRQUALITY/generated-data-true-window2.npy')\n",
        "#x = np.load(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_AIRQUALITY/generated-data2.npy')\n",
        "\n",
        "x=np.load(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_ELECTRICITY/generated-data2.npy')\n",
        "y=np.load(r'/content/drive/MyDrive/PHD/2024/TEMP_OUTPUT_ELECTRICITY/generated-data-true-window2.npy')\n",
        "\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "transformer = StandardScaler()\n",
        "y_transformed = transformer.fit_transform(y.reshape(-1,1)).flatten()\n",
        "\n",
        "##Simply take first 100 records - no need to sample... we just need to check prediction time\n",
        "\n",
        "x_test = x[TestSample:TestSample+1,:]\n",
        "y_test = y_transformed[TestSample:TestSample + 1]\n",
        "#------------------------------------------------------Retrieve Trained MLP Model----------\n",
        "\n",
        "#base_model = keras.models.load_model(r'/content/drive/MyDrive/PHD/2024/DGRNet-MLP-Versions/METROPM_MLP_model_Daily.keras')\n",
        "#base_model = keras.models.load_model(r'/content/drive/MyDrive/PHD/2024/DGRNet-MLP-Versions/AQ_MLP_model_Daily.keras')\n",
        "base_model = keras.models.load_model(r'/content/drive/MyDrive/PHD/2024/DGRNet-MLP-Versions/ELEC_MLP_model_Daily.keras')\n",
        "\n",
        "#-----------------------------------------------------Run Prediction on MLP------------------------\n",
        "## Note for some reason first run takes longer. So run it twice to get a better time\n",
        "\n",
        "y_pred_raw = base_model.predict(x_test)\n",
        "y_test_pred = transformer.inverse_transform(y_pred_raw)\n",
        "print(y_test_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "nxij89jyeebm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/supriyag123/PHD_Pub/blob/main/2025-%20Additional%20Results.ipynb",
      "authorship_tag": "ABX9TyPSIkxzsSGU1wVAo/KranuY",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}